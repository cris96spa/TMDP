{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from TMDP import TMDP\n",
    "from algorithms import *\n",
    "from model_functions import *\n",
    "from policy_utils import *\n",
    "from experiment_result_utils import *\n",
    "from constants import *\n",
    "\n",
    "from FrozenLake import *\n",
    "from CurriculumQ import CurriculumQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_slippery = False\n",
    "reward_shape = True\n",
    "dense_reward = True\n",
    "num_bins = 15\n",
    "nrows = 30\n",
    "\n",
    "num_runs = 10\n",
    "episodes = 4900000\n",
    "checkpoint_step=500\n",
    "test_episodes = 1000\n",
    "\n",
    "shape_range=(-1,0)\n",
    "goal_reward = 1.\n",
    "debug = False\n",
    "param_decay=True\n",
    "\n",
    "lam = 1\n",
    "experiment_results = []\n",
    "tests_returns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frozen Lake Environment\n",
    "tau = 0.\n",
    "nS = nrows**2\n",
    "nA = 4\n",
    "gamma = 0.999\n",
    "xi = np.ones(nS) * 1/nS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"Q_{num_bins}\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "experiment_name = f\"FrozenLake_{nrows}x{nrows}_{num_bins}\"\n",
    "experiment_id = get_or_create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "save_path = f\"results/{experiment_name}/run_{run_name}\"\n",
    "label = run_name.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = 0.15869281717397965\n",
    "\n",
    "batch_size = 20\n",
    "exp_rate = 0.4\n",
    "eps_model = compute_eps_model(gamma, tau, episodes/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(index, seed, run_name, change_map=False):\n",
    "    sub_run_name = f\"{run_name}_{index}\"\n",
    "    \n",
    "    with mlflow.start_run(nested=True, run_name=sub_run_name):\n",
    "        # Environment specific configuration   \n",
    "        map_seed = seed if change_map else constants.SEEDS[0]\n",
    "        set_policy_seed(seed)\n",
    "        env = FrozenLakeEnv(is_slippery=is_slippery, seed=seed, \n",
    "                        desc=generate_random_map(nrows, seed=map_seed), \n",
    "                        reward_shape=reward_shape,\n",
    "                        num_bins=num_bins,\n",
    "                        dense_reward=dense_reward,\n",
    "                        shape_range=shape_range,\n",
    "                        goal_reward=goal_reward,\n",
    "                        )\n",
    "        \n",
    "        # Environment independent configuration\n",
    "        tmdp = TMDP(env, xi, tau=tau, gamma=gamma, seed=seed)\n",
    "        tmdp.update_tau(tau)\n",
    "        curr_Q = CurriculumQ(tmdp, checkpoint_step=checkpoint_step)\n",
    "\n",
    "        curr_Q.train(model_lr, batch_size=batch_size, \n",
    "                lam=lam, exp_rate=exp_rate,\n",
    "                episodes=episodes,\n",
    "                eps_model=eps_model,\n",
    "                param_decay=param_decay,\n",
    "                debug=debug,)\n",
    "    \n",
    "        avg_return = np.average(curr_Q.reward_records[-10:])/batch_size\n",
    "        \n",
    "        mlflow.log_metric(\"Avg Return\", avg_return)\n",
    "        \n",
    "        run_dict = {\n",
    "            \"episodes\": curr_Q.episodes,\n",
    "            \"model_lr\": model_lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lam\": lam,\n",
    "            \"eps_model\": eps_model,\n",
    "            \"exp_rate\": exp_rate,\n",
    "        }\n",
    "        mlflow.log_params(run_dict)\n",
    "        mlflow.set_tags(tags={\n",
    "            \"run_name\": run_name,\n",
    "            \"change_map\": change_map,\n",
    "            \"seed\": seed,\n",
    "            \"tau\": tau,\n",
    "            \"gamma\": gamma,\n",
    "            \"checkpoint_step\": checkpoint_step,\n",
    "            \"test_episodes\": test_episodes,\n",
    "            \"index\": index,\n",
    "            \"dense_reward\": dense_reward,\n",
    "            \"shape_range\": shape_range,\n",
    "            \"goal_reward\": goal_reward,\n",
    "            \"reward_shape\": reward_shape,\n",
    "        })\n",
    "\n",
    "        \n",
    "        test_policies_return = test_Q_policies(tmdp, curr_Q.Qs, test_episodes)\n",
    "        \n",
    "        result_dict = {\n",
    "            \"Qs\" : curr_Q.Qs,\n",
    "            \"taus\" : curr_Q.taus,\n",
    "            \"reward_records\" : curr_Q.reward_records,\n",
    "            \"test_policies_return\" : test_policies_return,\n",
    "            \"index\" : index,\n",
    "        }\n",
    "\n",
    "        tests_returns.append(test_policies_return)\n",
    "        experiment_results.append(result_dict)\n",
    "        # Save artifact to MLFlow\n",
    "        try:\n",
    "            save_to_mlflow(result_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to MLFlow: {e}\")\n",
    "            print(\"Saving locally instead.\")\n",
    "            time.sleep(5)\n",
    "            path = save_path+f\"/{sub_run_name}\"\n",
    "            save(path, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(change_map=False, num_runs=10):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            seed = constants.SEEDS[i]\n",
    "            run_experiment(i, seed, run_name, change_map)\n",
    "        \n",
    "        experiment_dict = {\n",
    "            \"tests_returns\": tests_returns,\n",
    "            \"num_runs\": num_runs,\n",
    "            \"change_map\": change_map,\n",
    "            \"num_bins\": num_bins,\n",
    "            \"label\": label,\n",
    "        }\n",
    "        try:\n",
    "            save_to_mlflow(experiment_dict)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Something went wrong saving the experiment results to MLFlow.\")\n",
    "            print(\"Saving locally instead.\")\n",
    "            time.sleep(5)\n",
    "            save(save_path, experiment_dict)\n",
    "\n",
    "        rewards_fig = plot_avg_test_return(tests_returns, f\"{run_name[:-3]} Avg Rewards on {num_runs} runs\")\n",
    "        try:\n",
    "            mlflow.log_figure(figure=rewards_fig, artifact_file=\"reward_image.png\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Something went wrong saving the figure to MLFlow.\")\n",
    "            print(\"Saving locally instead.\")\n",
    "            time.sleep(5)\n",
    "            rewards_fig.savefig(save_path+\"/reward_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed for result reproducibility: 2999\n",
      "Episode: 5000 reward: -17057.933333333258 length: 652\n",
      "Episode: 10000 reward: -15624.199999999968 length: 23\n",
      "Episode: 15000 reward: -15855.13333333327 length: 176\n",
      "Episode: 20000 reward: -16128.39999999992 length: 300\n",
      "Episode: 25000 reward: -15362.599999999971 length: 159\n",
      "Episode: 30000 reward: -14657.799999999947 length: 34\n",
      "Episode: 35000 reward: -15292.933333333256 length: 354\n",
      "Episode: 40000 reward: -15043.333333333296 length: 231\n",
      "Episode: 45000 reward: -14624.533333333295 length: 298\n",
      "Episode: 50000 reward: -14743.133333333295 length: 441\n",
      "Episode: 55000 reward: -15213.999999999936 length: 215\n",
      "Episode: 60000 reward: -14817.866666666652 length: 514\n",
      "Episode: 65000 reward: -15040.466666666616 length: 198\n",
      "Episode: 70000 reward: -15576.533333333296 length: 30\n",
      "Episode: 75000 reward: -15676.066666666617 length: 87\n",
      "Episode: 80000 reward: -13883.39999999996 length: 341\n",
      "Episode: 85000 reward: -14295.799999999927 length: 125\n",
      "Episode: 90000 reward: -14174.99999999996 length: 6\n",
      "Episode: 95000 reward: -14394.733333333306 length: 461\n",
      "Episode: 100000 reward: -14176.066666666604 length: 290\n",
      "Episode: 105000 reward: -13733.066666666642 length: 356\n",
      "Episode: 110000 reward: -14339.399999999972 length: 191\n",
      "Episode: 115000 reward: -14182.333333333287 length: 510\n",
      "Episode: 120000 reward: -14663.066666666633 length: 294\n",
      "Episode: 125000 reward: -14358.533333333258 length: 534\n",
      "Episode: 130000 reward: -14919.866666666632 length: 64\n",
      "Episode: 135000 reward: -14056.333333333298 length: 294\n",
      "Episode: 140000 reward: -14103.466666666623 length: 435\n",
      "Episode: 145000 reward: -14471.66666666663 length: 111\n",
      "Episode: 150000 reward: -15394.99999999996 length: 165\n",
      "Episode: 155000 reward: -13151.199999999943 length: 46\n",
      "Episode: 160000 reward: -14092.666666666652 length: 205\n",
      "Episode: 165000 reward: -14105.599999999979 length: 363\n",
      "Episode: 170000 reward: -14089.799999999927 length: 19\n",
      "Episode: 175000 reward: -13784.933333333332 length: 513\n",
      "Episode: 180000 reward: -15025.266666666643 length: 283\n",
      "Episode: 185000 reward: -15379.599999999966 length: 220\n",
      "Episode: 190000 reward: -14705.06666666663 length: 217\n",
      "Episode: 195000 reward: -14073.333333333312 length: 281\n",
      "Episode: 200000 reward: -14951.26666666663 length: 272\n",
      "Episode: 205000 reward: -14218.333333333263 length: 264\n",
      "Episode: 210000 reward: -14837.46666666665 length: 200\n",
      "Episode: 215000 reward: -14278.066666666627 length: 416\n",
      "Episode: 220000 reward: -13408.866666666607 length: 439\n",
      "Episode: 225000 reward: -14806.999999999969 length: 360\n",
      "Episode: 230000 reward: -14245.399999999952 length: 343\n",
      "Episode: 235000 reward: -15089.733333333295 length: 21\n",
      "Episode: 240000 reward: -13559.333333333287 length: 56\n",
      "Episode: 245000 reward: -14127.133333333286 length: 417\n",
      "Episode: 250000 reward: -13978.599999999946 length: 380\n",
      "Episode: 255000 reward: -14218.86666666664 length: 302\n",
      "Episode: 260000 reward: -14361.066666666637 length: 148\n",
      "Episode: 265000 reward: -13908.999999999985 length: 340\n",
      "Episode: 270000 reward: -15172.999999999982 length: 427\n",
      "Episode: 275000 reward: -13684.799999999968 length: 353\n",
      "Episode: 280000 reward: -14367.79999999996 length: 440\n",
      "Episode: 285000 reward: -13599.399999999952 length: 418\n",
      "Episode: 290000 reward: -14380.199999999963 length: 1\n",
      "Episode: 295000 reward: -14110.46666666664 length: 531\n",
      "Episode: 300000 reward: -14907.333333333296 length: 54\n",
      "Episode: 305000 reward: -14098.799999999954 length: 218\n",
      "Episode: 310000 reward: -15260.066666666626 length: 94\n",
      "Episode: 315000 reward: -14683.333333333278 length: 76\n",
      "Episode: 320000 reward: -13886.533333333307 length: 122\n",
      "Episode: 325000 reward: -15371.39999999996 length: 413\n",
      "Episode: 330000 reward: -15552.066666666635 length: 38\n",
      "Episode: 335000 reward: -14423.733333333297 length: 197\n",
      "Episode: 340000 reward: -14024.266666666643 length: 174\n",
      "Episode: 345000 reward: -14937.533333333295 length: 132\n",
      "Episode: 350000 reward: -13436.33333333331 length: 202\n",
      "Episode: 355000 reward: -13880.866666666623 length: 264\n",
      "Episode: 360000 reward: -13667.46666666662 length: 545\n",
      "Episode: 365000 reward: -14434.266666666632 length: 459\n",
      "Episode: 370000 reward: -14664.066666666642 length: 207\n",
      "Episode: 375000 reward: -14113.733333333299 length: 334\n",
      "Episode: 380000 reward: -13223.399999999958 length: 72\n",
      "Episode: 385000 reward: -12951.066666666664 length: 279\n",
      "Episode: 390000 reward: -14425.066666666607 length: 357\n",
      "Episode: 395000 reward: -14268.399999999972 length: 208\n",
      "Episode: 400000 reward: -14711.46666666662 length: 95\n",
      "Episode: 405000 reward: -13984.066666666615 length: 275\n",
      "Episode: 410000 reward: -13511.066666666651 length: 153\n",
      "Episode: 415000 reward: -13712.599999999968 length: 70\n",
      "Episode: 420000 reward: -14839.866666666625 length: 454\n",
      "Episode: 425000 reward: -13853.333333333305 length: 126\n",
      "Episode: 430000 reward: -14541.666666666635 length: 9\n",
      "Episode: 435000 reward: -13987.533333333293 length: 238\n",
      "Episode: 440000 reward: -13773.799999999976 length: 383\n",
      "Episode: 445000 reward: -14032.666666666631 length: 277\n",
      "Episode: 450000 reward: -15837.266666666625 length: 125\n",
      "Episode: 455000 reward: -14074.599999999955 length: 477\n",
      "Episode: 460000 reward: -14348.399999999938 length: 166\n",
      "Episode: 465000 reward: -15088.599999999966 length: 238\n",
      "Episode: 470000 reward: -13945.933333333305 length: 371\n",
      "Episode: 475000 reward: -15198.333333333301 length: 34\n",
      "Episode: 480000 reward: -14282.400000000005 length: 124\n",
      "Episode: 485000 reward: -14082.333333333274 length: 8\n",
      "Episode: 490000 reward: -14320.333333333301 length: 298\n",
      "Episode: 495000 reward: -13944.999999999965 length: 320\n",
      "Episode: 500000 reward: -14958.999999999964 length: 206\n",
      "Episode: 505000 reward: -15472.199999999959 length: 195\n",
      "Episode: 510000 reward: -13477.333333333274 length: 494\n",
      "Episode: 515000 reward: -14407.066666666633 length: 209\n",
      "Episode: 520000 reward: -14190.266666666637 length: 57\n",
      "Episode: 525000 reward: -13355.33333333331 length: 5\n",
      "Episode: 530000 reward: -14874.599999999982 length: 271\n",
      "Episode: 535000 reward: -14060.999999999969 length: 79\n",
      "Episode: 540000 reward: -14420.199999999966 length: 379\n",
      "Episode: 545000 reward: -13762.79999999997 length: 482\n",
      "Episode: 550000 reward: -14900.066666666624 length: 601\n",
      "Episode: 555000 reward: -14345.333333333288 length: 462\n",
      "Episode: 560000 reward: -13802.599999999964 length: 319\n",
      "Episode: 565000 reward: -13784.399999999987 length: 300\n",
      "Episode: 570000 reward: -14120.39999999997 length: 83\n",
      "Episode: 575000 reward: -13706.399999999972 length: 68\n",
      "Episode: 580000 reward: -13637.333333333318 length: 125\n",
      "Episode: 585000 reward: -13309.266666666614 length: 189\n",
      "Episode: 590000 reward: -13764.933333333312 length: 94\n",
      "Episode: 595000 reward: -14096.199999999933 length: 458\n",
      "Episode: 600000 reward: -13221.0 length: 161\n",
      "Episode: 605000 reward: -13371.933333333305 length: 299\n",
      "Episode: 610000 reward: -13714.733333333294 length: 28\n",
      "Episode: 615000 reward: -15497.666666666628 length: 255\n",
      "Episode: 620000 reward: -15870.199999999964 length: 160\n",
      "Episode: 625000 reward: -14602.86666666665 length: 238\n",
      "Episode: 630000 reward: -13812.999999999953 length: 37\n",
      "Episode: 635000 reward: -13812.066666666617 length: 57\n",
      "Episode: 640000 reward: -14595.66666666662 length: 530\n",
      "Episode: 645000 reward: -14490.733333333294 length: 368\n",
      "Episode: 650000 reward: -14294.866666666649 length: 322\n",
      "Episode: 655000 reward: -13821.866666666632 length: 142\n",
      "Episode: 660000 reward: -14003.466666666653 length: 269\n",
      "Episode: 665000 reward: -14183.199999999939 length: 365\n",
      "Episode: 670000 reward: -14439.533333333333 length: 342\n",
      "Episode: 675000 reward: -13753.266666666636 length: 382\n",
      "Episode: 680000 reward: -12883.99999999997 length: 348\n",
      "Episode: 685000 reward: -13988.599999999951 length: 44\n",
      "Episode: 690000 reward: -13822.999999999969 length: 241\n",
      "Episode: 695000 reward: -14557.266666666632 length: 316\n",
      "Episode: 700000 reward: -13277.666666666644 length: 334\n",
      "Episode: 705000 reward: -14283.066666666657 length: 424\n",
      "Episode: 710000 reward: -14754.866666666641 length: 388\n",
      "Episode: 715000 reward: -13812.39999999998 length: 2\n",
      "Episode: 720000 reward: -12918.666666666664 length: 249\n",
      "Episode: 725000 reward: -14033.933333333276 length: 314\n",
      "Episode: 730000 reward: -13457.399999999965 length: 129\n",
      "Episode: 735000 reward: -14755.666666666628 length: 117\n",
      "Episode: 740000 reward: -14874.799999999965 length: 343\n",
      "Episode: 745000 reward: -14618.93333333329 length: 274\n",
      "Episode: 750000 reward: -13562.266666666646 length: 120\n",
      "Episode: 755000 reward: -13460.13333333327 length: 89\n",
      "Episode: 760000 reward: -14597.599999999957 length: 110\n",
      "Episode: 765000 reward: -13464.19999999995 length: 183\n",
      "Episode: 770000 reward: -14465.466666666625 length: 212\n",
      "Episode: 775000 reward: -13077.266666666645 length: 417\n",
      "Episode: 780000 reward: -13378.133333333288 length: 440\n",
      "Episode: 785000 reward: -14181.733333333323 length: 158\n",
      "Episode: 790000 reward: -13565.66666666663 length: 58\n",
      "Episode: 795000 reward: -14041.93333333332 length: 270\n",
      "Episode: 800000 reward: -13662.66666666664 length: 29\n",
      "Episode: 805000 reward: -13994.53333333333 length: 168\n",
      "Episode: 810000 reward: -15027.799999999948 length: 254\n",
      "Episode: 815000 reward: -14274.333333333303 length: 31\n",
      "Episode: 820000 reward: -13094.33333333331 length: 136\n",
      "Episode: 825000 reward: -13428.933333333278 length: 69\n",
      "Episode: 830000 reward: -12806.799999999941 length: 351\n",
      "Episode: 835000 reward: -13941.999999999947 length: 551\n",
      "Episode: 840000 reward: -14257.133333333308 length: 337\n",
      "Episode: 845000 reward: -14300.133333333322 length: 197\n",
      "Episode: 850000 reward: -14105.466666666649 length: 82\n",
      "Episode: 855000 reward: -14159.599999999971 length: 224\n",
      "Episode: 860000 reward: -13794.533333333276 length: 387\n",
      "Episode: 865000 reward: -14941.466666666642 length: 238\n",
      "Episode: 870000 reward: -14168.999999999978 length: 300\n",
      "Episode: 875000 reward: -14131.66666666662 length: 53\n",
      "Episode: 880000 reward: -13878.266666666632 length: 318\n",
      "Episode: 885000 reward: -15368.26666666663 length: 108\n",
      "Episode: 890000 reward: -14611.199999999943 length: 327\n",
      "Episode: 895000 reward: -13776.333333333323 length: 134\n",
      "Episode: 900000 reward: -14192.733333333295 length: 375\n",
      "Episode: 905000 reward: -14320.199999999983 length: 310\n",
      "Episode: 910000 reward: -13789.333333333334 length: 296\n",
      "Episode: 915000 reward: -15245.39999999995 length: 21\n",
      "Episode: 920000 reward: -13620.533333333311 length: 359\n",
      "Episode: 925000 reward: -14480.066666666631 length: 398\n",
      "Episode: 930000 reward: -15236.666666666633 length: 473\n",
      "Episode: 935000 reward: -14150.199999999973 length: 219\n",
      "Episode: 940000 reward: -14894.33333333333 length: 28\n",
      "Episode: 945000 reward: -15322.999999999955 length: 428\n",
      "Episode: 950000 reward: -13540.866666666661 length: 359\n",
      "Episode: 955000 reward: -13206.93333333332 length: 38\n",
      "Episode: 960000 reward: -14264.266666666606 length: 317\n",
      "Episode: 965000 reward: -14003.666666666619 length: 424\n",
      "Episode: 970000 reward: -14621.133333333284 length: 50\n",
      "Episode: 975000 reward: -14168.99999999996 length: 411\n",
      "Episode: 980000 reward: -14279.3333333333 length: 285\n",
      "Episode: 985000 reward: -14078.799999999967 length: 100\n",
      "Episode: 990000 reward: -12845.199999999984 length: 31\n",
      "Episode: 995000 reward: -15068.066666666618 length: 383\n",
      "Episode: 1000000 reward: -14596.46666666664 length: 250\n",
      "Episode: 1005000 reward: -13150.06666666663 length: 149\n",
      "Episode: 1010000 reward: -13920.599999999968 length: 281\n",
      "Episode: 1015000 reward: -13636.066666666635 length: 394\n",
      "Episode: 1020000 reward: -14172.5333333333 length: 448\n",
      "Episode: 1025000 reward: -14001.599999999951 length: 102\n",
      "Episode: 1030000 reward: -14225.333333333283 length: 81\n",
      "Episode: 1035000 reward: -14365.799999999968 length: 24\n",
      "Episode: 1040000 reward: -13917.53333333331 length: 437\n",
      "Episode: 1045000 reward: -13600.533333333313 length: 17\n",
      "Episode: 1050000 reward: -13108.066666666617 length: 289\n",
      "Episode: 1055000 reward: -13226.666666666666 length: 10\n",
      "Episode: 1060000 reward: -13387.733333333324 length: 325\n",
      "Episode: 1065000 reward: -14743.733333333292 length: 316\n",
      "Episode: 1070000 reward: -14122.133333333297 length: 235\n",
      "Episode: 1075000 reward: -14053.333333333294 length: 66\n",
      "Episode: 1080000 reward: -15135.333333333296 length: 204\n",
      "Episode: 1085000 reward: -13846.933333333309 length: 247\n",
      "Episode: 1090000 reward: -14202.599999999951 length: 255\n",
      "Episode: 1095000 reward: -13993.466666666622 length: 302\n",
      "Episode: 1100000 reward: -13537.99999999995 length: 240\n",
      "Episode: 1105000 reward: -13898.133333333295 length: 112\n",
      "Episode: 1110000 reward: -13951.866666666649 length: 174\n",
      "Episode: 1115000 reward: -14705.133333333286 length: 42\n",
      "Episode: 1120000 reward: -15121.333333333287 length: 506\n",
      "Episode: 1125000 reward: -13238.466666666685 length: 230\n",
      "Episode: 1130000 reward: -14449.866666666641 length: 364\n",
      "Episode: 1135000 reward: -13089.333333333303 length: 326\n",
      "Episode: 1140000 reward: -13859.799999999974 length: 107\n",
      "Episode: 1145000 reward: -14392.39999999996 length: 325\n",
      "Episode: 1150000 reward: -14385.533333333278 length: 324\n",
      "Episode: 1155000 reward: -14086.999999999978 length: 479\n",
      "Episode: 1160000 reward: -13969.133333333293 length: 108\n",
      "Episode: 1165000 reward: -14510.533333333304 length: 335\n",
      "Episode: 1170000 reward: -13814.999999999969 length: 263\n",
      "Episode: 1175000 reward: -14556.733333333308 length: 406\n",
      "Episode: 1180000 reward: -15384.199999999966 length: 525\n",
      "Episode: 1185000 reward: -14433.599999999966 length: 399\n",
      "Episode: 1190000 reward: -14453.733333333274 length: 202\n",
      "Episode: 1195000 reward: -13265.799999999983 length: 288\n",
      "Episode: 1200000 reward: -12561.466666666654 length: 102\n",
      "Episode: 1205000 reward: -13716.999999999947 length: 208\n",
      "Episode: 1210000 reward: -13762.39999999995 length: 341\n",
      "Episode: 1215000 reward: -13989.799999999972 length: 92\n",
      "Episode: 1220000 reward: -14350.133333333275 length: 177\n",
      "Episode: 1225000 reward: -14240.999999999973 length: 391\n",
      "Episode: 1230000 reward: -13551.13333333331 length: 83\n",
      "Episode: 1235000 reward: -14925.266666666628 length: 488\n",
      "Episode: 1240000 reward: -14510.066666666644 length: 453\n",
      "Episode: 1245000 reward: -13689.066666666648 length: 133\n",
      "Episode: 1250000 reward: -13978.066666666671 length: 286\n",
      "Episode: 1255000 reward: -14246.399999999989 length: 104\n",
      "Episode: 1260000 reward: -14044.799999999952 length: 168\n",
      "Episode: 1265000 reward: -13944.133333333308 length: 101\n",
      "Episode: 1270000 reward: -14778.466666666625 length: 401\n",
      "Episode: 1275000 reward: -13885.799999999977 length: 164\n",
      "Episode: 1280000 reward: -13914.79999999997 length: 463\n",
      "Episode: 1285000 reward: -13996.533333333307 length: 206\n",
      "Episode: 1290000 reward: -13666.53333333328 length: 189\n",
      "Episode: 1295000 reward: -14179.399999999965 length: 279\n",
      "Episode: 1300000 reward: -12845.999999999969 length: 126\n",
      "Episode: 1305000 reward: -12016.866666666645 length: 278\n",
      "Episode: 1310000 reward: -14222.933333333305 length: 101\n",
      "Episode: 1315000 reward: -14882.266666666625 length: 285\n",
      "Episode: 1320000 reward: -13560.266666666657 length: 374\n",
      "Episode: 1325000 reward: -14354.733333333303 length: 287\n",
      "Episode: 1330000 reward: -14270.533333333316 length: 181\n",
      "Episode: 1335000 reward: -13792.866666666652 length: 25\n",
      "Episode: 1340000 reward: -13982.26666666663 length: 308\n",
      "Episode: 1345000 reward: -14558.733333333292 length: 306\n",
      "Episode: 1350000 reward: -13799.933333333296 length: 417\n",
      "Episode: 1355000 reward: -13289.066666666648 length: 209\n",
      "Episode: 1360000 reward: -14347.933333333289 length: 186\n",
      "Episode: 1365000 reward: -14119.599999999975 length: 388\n",
      "Episode: 1370000 reward: -13500.93333333328 length: 183\n",
      "Episode: 1375000 reward: -14243.933333333294 length: 29\n",
      "Episode: 1380000 reward: -13620.933333333302 length: 109\n",
      "Episode: 1385000 reward: -13493.133333333317 length: 255\n",
      "Episode: 1390000 reward: -13015.533333333313 length: 120\n",
      "Episode: 1395000 reward: -14008.933333333305 length: 86\n",
      "Episode: 1400000 reward: -12798.133333333333 length: 328\n",
      "Episode: 1405000 reward: -13930.46666666664 length: 106\n",
      "Episode: 1410000 reward: -12733.666666666626 length: 183\n",
      "Episode: 1415000 reward: -14454.73333333328 length: 417\n",
      "Episode: 1420000 reward: -14307.133333333315 length: 453\n",
      "Episode: 1425000 reward: -13473.59999999996 length: 228\n",
      "Episode: 1430000 reward: -12582.1333333333 length: 337\n",
      "Episode: 1435000 reward: -14455.733333333315 length: 352\n",
      "Episode: 1440000 reward: -13562.999999999982 length: 182\n",
      "Episode: 1445000 reward: -13760.399999999989 length: 268\n",
      "Episode: 1450000 reward: -13693.46666666665 length: 365\n",
      "Episode: 1455000 reward: -13463.333333333283 length: 112\n",
      "Episode: 1460000 reward: -13698.799999999965 length: 124\n",
      "Episode: 1465000 reward: -13249.266666666663 length: 51\n",
      "Episode: 1470000 reward: -13151.99999999998 length: 339\n",
      "Episode: 1475000 reward: -12231.599999999977 length: 175\n",
      "Episode: 1480000 reward: -13739.399999999972 length: 322\n",
      "Episode: 1485000 reward: -15159.999999999978 length: 183\n",
      "Episode: 1490000 reward: -12835.533333333307 length: 124\n",
      "Episode: 1495000 reward: -14417.46666666664 length: 224\n",
      "Episode: 1500000 reward: -13869.666666666648 length: 433\n",
      "Episode: 1505000 reward: -15314.799999999968 length: 39\n",
      "Episode: 1510000 reward: -13994.466666666644 length: 297\n",
      "Episode: 1515000 reward: -13165.599999999966 length: 457\n",
      "Episode: 1520000 reward: -14330.199999999977 length: 304\n",
      "Episode: 1525000 reward: -13909.599999999964 length: 453\n",
      "Episode: 1530000 reward: -15533.866666666627 length: 451\n",
      "Episode: 1535000 reward: -14183.666666666617 length: 182\n",
      "Episode: 1540000 reward: -13134.533333333324 length: 382\n",
      "Episode: 1545000 reward: -15194.866666666632 length: 260\n",
      "Episode: 1550000 reward: -14006.266666666625 length: 439\n",
      "Episode: 1555000 reward: -14548.19999999999 length: 188\n",
      "Episode: 1560000 reward: -13199.999999999969 length: 568\n",
      "Episode: 1565000 reward: -13490.999999999962 length: 382\n",
      "Episode: 1570000 reward: -14498.599999999982 length: 387\n",
      "Episode: 1575000 reward: -13391.733333333324 length: 102\n",
      "Episode: 1580000 reward: -14053.333333333301 length: 197\n",
      "Episode: 1585000 reward: -14648.733333333303 length: 267\n",
      "Episode: 1590000 reward: -13962.333333333288 length: 325\n",
      "Episode: 1595000 reward: -14098.199999999948 length: 113\n",
      "Episode: 1600000 reward: -13930.86666666663 length: 107\n",
      "Episode: 1605000 reward: -14348.999999999965 length: 291\n",
      "Episode: 1610000 reward: -14011.199999999977 length: 437\n",
      "Episode: 1615000 reward: -13434.933333333307 length: 417\n",
      "Episode: 1620000 reward: -14017.866666666592 length: 114\n",
      "Episode: 1625000 reward: -14832.999999999947 length: 202\n",
      "Episode: 1630000 reward: -12561.399999999981 length: 67\n",
      "Episode: 1635000 reward: -12404.133333333299 length: 122\n",
      "Episode: 1640000 reward: -13645.066666666664 length: 180\n",
      "Episode: 1645000 reward: -14329.066666666655 length: 301\n",
      "Episode: 1650000 reward: -13330.533333333336 length: 314\n",
      "Episode: 1655000 reward: -14150.266666666632 length: 446\n",
      "Episode: 1660000 reward: -13725.533333333295 length: 177\n",
      "Episode: 1665000 reward: -13354.733333333306 length: 408\n",
      "Episode: 1670000 reward: -13452.399999999989 length: 30\n",
      "Episode: 1675000 reward: -12794.066666666624 length: 327\n",
      "Episode: 1680000 reward: -13603.066666666644 length: 209\n",
      "Episode: 1685000 reward: -13195.33333333332 length: 456\n",
      "Episode: 1690000 reward: -14541.999999999962 length: 530\n",
      "Episode: 1695000 reward: -13995.266666666605 length: 86\n",
      "Episode: 1700000 reward: -13213.266666666615 length: 47\n",
      "Episode: 1705000 reward: -12607.199999999964 length: 228\n",
      "Episode: 1710000 reward: -14422.933333333305 length: 373\n"
     ]
    }
   ],
   "source": [
    "run_experiments(change_map=False, num_runs=num_runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
