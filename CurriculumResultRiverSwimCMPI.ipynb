{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from TMDP import TMDP\n",
    "from algorithms import *\n",
    "from model_functions import *\n",
    "from policy_utils import *\n",
    "from experiment_result_utils import *\n",
    "from constants import *\n",
    "\n",
    "from RiverSwim import *\n",
    "from CurriculumMPI import CurriculumMPI\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#River Swim Environment\n",
    "nS = 50\n",
    "uniform_restart = True\n",
    "num_runs = 1\n",
    "\n",
    "small = 5e-3\n",
    "large = 1.\n",
    "nA = 2\n",
    "gamma = 0.99\n",
    "\n",
    "original_mu = np.zeros(nS)\n",
    "original_mu[1] = 1.\n",
    "xi = np.ones(nS)/(nS-2)\n",
    "xi[0] = 0\n",
    "xi[-1] = 0\n",
    "\n",
    "if uniform_restart:\n",
    "    mu = xi\n",
    "else:\n",
    "    mu = original_mu\n",
    "\n",
    "\n",
    "episodes = 10000000\n",
    "checkpoint_step=10000\n",
    "test_episodes = 10000\n",
    "discount_tau = True\n",
    "param_decay=True\n",
    "debug = False\n",
    "\n",
    "lam = 1\n",
    "experiment_results = []\n",
    "tests_returns = []\n",
    "tests_lens = []\n",
    "exp_taus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"CurrMPI_{uniform_restart}\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "experiment_name = f\"RiverSwim_{nS}_{uniform_restart}\"\n",
    "experiment_id = get_or_create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "save_path = f\"results/{experiment_name}/run_{run_name}\"\n",
    "label = run_name.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.3\n",
    "model_lr = 0.09\n",
    "pol_lr = 0.05\n",
    "temp = 3.0\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "final_temp=1\n",
    "\n",
    "check_convergence=False\n",
    "biased=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(index, seed, run_name):\n",
    "    sub_run_name = f\"{run_name}_{index}\"\n",
    "    \n",
    "    with mlflow.start_run(nested=True, run_name=sub_run_name):\n",
    "        \n",
    "        # Environment specific configuration   \n",
    "        set_policy_seed(seed)\n",
    "        env = RiverSwim(nS, mu, small=small, large=large, seed=seed)\n",
    "        \n",
    "        # Environment independent configuration\n",
    "        tmdp = TMDP(env, \n",
    "                    xi, \n",
    "                    tau=tau, \n",
    "                    gamma=gamma, \n",
    "                    discount_tau=discount_tau, \n",
    "                    seed=seed, \n",
    "                    xi_schedule=river_swim_uniform_curr_xi)\n",
    "        tmdp.update_tau(tau)\n",
    "\n",
    "        curr_MPI = CurriculumMPI(tmdp, checkpoint_step=checkpoint_step)\n",
    "        curr_MPI.train(model_lr, pol_lr, batch_size=batch_size, \n",
    "                        lam=lam, temp=temp, final_temp=final_temp,\n",
    "                        episodes=episodes, check_convergence=check_convergence,\n",
    "                        param_decay=param_decay, biased=biased,\n",
    "                        debug=debug, epochs=epochs, original_mu=original_mu)   \n",
    "        \n",
    "        avg_return = np.average(curr_MPI.reward_records[-10:])/batch_size\n",
    "        \n",
    "        mlflow.log_metric(\"Avg Return\", avg_return)\n",
    "\n",
    "        test_policies = test_policies_len(tmdp, curr_MPI.thetas, test_episodes, 1e-100, mu=original_mu)\n",
    "        test_policies_return = test_policies[0]\n",
    "        test_pol_len = test_policies[1]\n",
    "\n",
    "        result_dict = {\n",
    "            \"thetas\" : curr_MPI.thetas,\n",
    "            \"taus\" : curr_MPI.taus,\n",
    "            \"reward_records\" : curr_MPI.reward_records,\n",
    "            \"test_policies_return\" : test_policies_return,\n",
    "            \"index\" : index,\n",
    "            \"test_pol_len\" : test_pol_len,\n",
    "            \"Qs\": curr_MPI.Qs,\n",
    "        }\n",
    "\n",
    "        tests_returns.append(test_policies_return)\n",
    "        experiment_results.append(result_dict)\n",
    "        tests_lens.append(test_pol_len)\n",
    "        exp_taus.append(curr_MPI.taus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(num_runs=10):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            seed = constants.SEEDS[i]\n",
    "            run_experiment(i, seed, run_name)\n",
    "        \n",
    "        pad_results = pad_to_same_length(tests_returns)\n",
    "        pad_lens = pad_to_same_length(tests_lens)\n",
    "        pad_taus = pad_to_same_length(exp_taus)\n",
    "        experiment_dict = {\n",
    "            \"tests_returns\": pad_results,\n",
    "            \"taus\": pad_taus,\n",
    "            \"tests_lens\": pad_lens,\n",
    "            \"num_runs\": num_runs,\n",
    "            \"label\": label,\n",
    "            \"checkpoint_step\": checkpoint_step,\n",
    "            \"uniform_restart\": uniform_restart,\n",
    "        }\n",
    "\n",
    "        mlflow.set_tags(tags={\n",
    "            \"seed\": seed,\n",
    "            \"tau\": tau,\n",
    "            \"gamma\": gamma,\n",
    "            \"checkpoint_step\": checkpoint_step,\n",
    "            \"test_episodes\": test_episodes,\n",
    "            \"episodes\": episodes,\n",
    "            \"model_lr\": model_lr,\n",
    "            \"pol_lr\": pol_lr,\n",
    "            \"temp\": temp,\n",
    "            \"final_temp\": final_temp,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"lam\": lam,\n",
    "            \"discount_tau\": discount_tau,\n",
    "            \"param_decay\": param_decay,\n",
    "            \"small\": small,\n",
    "            \"large\": large,\n",
    "        })\n",
    "        try:\n",
    "            save_to_mlflow(experiment_dict)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Something went wrong saving the experiment results to MLFlow.\")\n",
    "            print(\"Saving locally instead.\")\n",
    "            time.sleep(5)\n",
    "            save(save_path, experiment_dict)\n",
    "\n",
    "        rewards_fig = plot_avg_test_return(tests_returns, f\"{run_name[:-3]} Avg Return on {num_runs} runs\")\n",
    "        try:\n",
    "            mlflow.log_figure(figure=rewards_fig, artifact_file=\"reward_image.png\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Something went wrong saving the figure to MLFlow.\")\n",
    "            print(\"Saving locally instead.\")\n",
    "            time.sleep(5)\n",
    "            rewards_fig.savefig(save_path+\"/reward_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed for result reproducibility: 2999\n",
      "Episode: 100000 reward: 3.5 tau 0.3 batch_len 5 teleports 1307\n",
      "Episode: 200000 reward: 3.5 tau 0.3 batch_len 5 teleports 379\n",
      "Episode: 300000 reward: 0.0 tau 0.3 batch_len 0 teleports 27\n",
      "Episode: 400000 reward: 0.7000500000000001 tau 0.29995 batch_len 1 teleports 224\n",
      "Episode: 500000 reward: 6.3126 tau 0.2986 batch_len 9 teleports 557\n",
      "Episode: 600000 reward: 6.339510000000001 tau 0.29561 batch_len 9 teleports 446\n",
      "Episode: 700000 reward: 4.9710013 tau 0.29087 batch_len 9 teleports 455\n",
      "Episode: 800000 reward: 0.71409 tau 0.28591 batch_len 1 teleports 158\n",
      "Episode: 900000 reward: 1.4411939999999999 tau 0.2812 batch_len 3 teleports 106\n",
      "Episode: 1000000 reward: 3.6224500000000006 tau 0.27551 batch_len 5 teleports 335\n",
      "Episode: 1100000 reward: 0.0 tau 0.26971 batch_len 0 teleports 18\n",
      "Episode: 1200000 reward: 4.41618 tau 0.26397 batch_len 6 teleports 330\n",
      "Episode: 1300000 reward: 4.45212 tau 0.25798 batch_len 6 teleports 491\n",
      "Episode: 1400000 reward: 4.49196 tau 0.25134 batch_len 6 teleports 397\n",
      "Episode: 1500000 reward: 0.75501 tau 0.24499 batch_len 1 teleports 87\n",
      "Episode: 1600000 reward: 3.04608 tau 0.23848 batch_len 4 teleports 306\n",
      "Episode: 1700000 reward: 6.913259999999999 tau 0.23186 batch_len 9 teleports 435\n",
      "Episode: 1800000 reward: 5.425769999999999 tau 0.22489 batch_len 7 teleports 522\n",
      "Episode: 1900000 reward: 0.78213 tau 0.21787 batch_len 1 teleports 145\n",
      "Episode: 2000000 reward: 4.73358 tau 0.21107 batch_len 6 teleports 354\n",
      "Episode: 2100000 reward: 2.38728 tau 0.20424 batch_len 3 teleports 228\n",
      "Episode: 2200000 reward: 5.614979999999999 tau 0.19786 batch_len 7 teleports 329\n"
     ]
    }
   ],
   "source": [
    "run_experiments(num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.99999595e-01 5.00000405e-01]\n",
      " [5.00224535e-01 4.99775465e-01]\n",
      " [5.00074242e-01 4.99925758e-01]\n",
      " [5.00156586e-01 4.99843414e-01]\n",
      " [5.00066930e-01 4.99933070e-01]\n",
      " [5.00069192e-01 4.99930808e-01]\n",
      " [5.00071809e-01 4.99928191e-01]\n",
      " [5.00084453e-01 4.99915547e-01]\n",
      " [5.00064295e-01 4.99935705e-01]\n",
      " [5.00044531e-01 4.99955469e-01]\n",
      " [5.00065432e-01 4.99934568e-01]\n",
      " [5.00046898e-01 4.99953102e-01]\n",
      " [5.00051028e-01 4.99948972e-01]\n",
      " [5.00054619e-01 4.99945381e-01]\n",
      " [5.00060811e-01 4.99939189e-01]\n",
      " [5.00058650e-01 4.99941350e-01]\n",
      " [5.00056644e-01 4.99943356e-01]\n",
      " [5.00061310e-01 4.99938690e-01]\n",
      " [5.00061301e-01 4.99938699e-01]\n",
      " [5.00062129e-01 4.99937871e-01]\n",
      " [5.00063220e-01 4.99936780e-01]\n",
      " [5.00063904e-01 4.99936096e-01]\n",
      " [5.00057626e-01 4.99942374e-01]\n",
      " [5.00059929e-01 4.99940071e-01]\n",
      " [5.00061504e-01 4.99938496e-01]\n",
      " [5.00059689e-01 4.99940311e-01]\n",
      " [5.00061757e-01 4.99938243e-01]\n",
      " [5.00062610e-01 4.99937390e-01]\n",
      " [5.00059413e-01 4.99940587e-01]\n",
      " [5.00056565e-01 4.99943435e-01]\n",
      " [5.00052770e-01 4.99947230e-01]\n",
      " [5.00056768e-01 4.99943232e-01]\n",
      " [5.00056976e-01 4.99943024e-01]\n",
      " [5.00057250e-01 4.99942750e-01]\n",
      " [5.00056433e-01 4.99943567e-01]\n",
      " [5.00053492e-01 4.99946508e-01]\n",
      " [5.00038558e-01 4.99961442e-01]\n",
      " [4.99998124e-01 5.00001876e-01]\n",
      " [4.99855837e-01 5.00144163e-01]\n",
      " [4.99293960e-01 5.00706040e-01]\n",
      " [4.97366105e-01 5.02633895e-01]\n",
      " [4.88659430e-01 5.11340570e-01]\n",
      " [4.51042000e-01 5.48958000e-01]\n",
      " [3.21792173e-01 6.78207827e-01]\n",
      " [5.71961700e-02 9.42803830e-01]\n",
      " [4.51709992e-04 9.99548290e-01]\n",
      " [2.12655964e-07 9.99999787e-01]\n",
      " [4.25938874e-12 1.00000000e+00]\n",
      " [8.94380242e-18 1.00000000e+00]\n",
      " [5.00000000e-01 5.00000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(get_softmax_policy(experiment_results[-1][\"thetas\"][-1], 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.005     ]\n",
      " [0.005      0.00500001]\n",
      " [0.005      0.00500003]\n",
      " [0.00500002 0.00500011]\n",
      " [0.00500006 0.00500035]\n",
      " [0.00500021 0.00500138]\n",
      " [0.00500078 0.00500468]\n",
      " [0.00500268 0.00501728]\n",
      " [0.00501025 0.00506059]\n",
      " [0.00503569 0.00520426]\n",
      " [0.00512995 0.00570765]\n",
      " [0.00542874 0.00788389]\n",
      " [0.00656685 0.01566498]\n",
      " [0.01127354 0.04376932]\n",
      " [0.02587886 0.12647569]\n",
      " [0.08646757 0.30527604]\n",
      " [0.24148603 0.56767363]\n",
      " [0.52004842 0.80948608]\n",
      " [0.76572815 0.94153985]\n",
      " [0.         0.        ]] 0.1\n"
     ]
    }
   ],
   "source": [
    "print(experiment_results[-1][\"Qs\"][-1], 1e-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
