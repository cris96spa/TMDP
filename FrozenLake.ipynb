{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Current seed for result reproducibility: 329109417943062232536003320066158495377\n"
=======
      "Current seed for result reproducibility: 167925375570414789350573803683571645367\n"
>>>>>>> refs/remotes/origin/main
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from TMDP import TMDP\n",
    "from River_swim import River\n",
    "\n",
    "from algorithms import *\n",
    "from model_functions import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from FrozenLake import *\n",
    "\n",
    "#np.set_printoptions(precision=4)\n",
    "import math\n",
    "from utils import *\n",
    "\n",
<<<<<<< HEAD
    "nrows = 8\n",
    "nS = nrows**2\n",
    "nA = 4\n",
    "seed = get_current_seed()\n",
    "gamma = .9\n",
    "tau = 1.\n",
    "#tmdp = TMDP(river, xi, tau=tau, gamma=gamma, seed=seed)\n",
    "#mdp = TMDP(river, xi, tau=0., gamma=gamma, seed=seed)\n",
    "\n",
    "env = FrozenLakeEnv(is_slippery=False, seed=seed, desc=generate_random_map(nrows))#, render_mode=\"human\")\n",
=======
    "nS = 8\n",
    "nA = 2\n",
    "seed = get_current_seed()\n",
    "gamma = .9\n",
    "mu = np.ones(nS) * 1/nS\n",
    "tau = 1.\n",
    "xi_river = np.ones(nS) * 1/nS\n",
    "#tmdp = TMDP(river, xi, tau=tau, gamma=gamma, seed=seed)\n",
    "#mdp = TMDP(river, xi, tau=0., gamma=gamma, seed=seed)\n",
    "\n",
    "env = FrozenLakeEnv(seed=seed, desc=generate_random_map(40))#, render_mode=\"human\")\n",
>>>>>>> refs/remotes/origin/main
    "xi_frozen = np.ones(env.nS) * 1/env.nS\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdp = TMDP(env, xi_frozen, tau=tau, gamma=gamma, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "status_step = 500000\n",
    "episodes = 500000\n",
=======
    "status_step = 50000\n",
    "episodes = 1000000\n",
>>>>>>> refs/remotes/origin/main
    "batch_nS = 1\n",
    "temperature = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Updating tau to 0.95\n",
      "Updating tau to 0.8999999999999999\n",
      "Updating tau to 0.8499999999999999\n",
      "Updating tau to 0.7999999999999998\n",
      "Updating tau to 0.7499999999999998\n",
      "Updating tau to 0.6999999999999997\n",
      "Updating tau to 0.6499999999999997\n",
      "Updating tau to 0.5999999999999996\n",
      "Updating tau to 0.5499999999999996\n",
      "Updating tau to 0.4999999999999996\n",
      "Updating tau to 0.4499999999999996\n",
      "Updating tau to 0.39999999999999963\n",
      "Updating tau to 0.34999999999999964\n",
      "Updating tau to 0.29999999999999966\n",
      "Updating tau to 0.24999999999999967\n",
      "Updating tau to 0.19999999999999968\n",
      "Updating tau to 0.1499999999999997\n",
      "Updating tau to 0.09999999999999969\n",
      "Updating tau to 0.049999999999999684\n",
      "Updating tau to 0.0\n",
      "Updating tau to 0.0\n"
=======
      "Updating tau from 1.0 to 0.95\n",
      "Updating tau from 0.95 to 0.8999999999999999\n",
      "Updating tau from 0.8999999999999999 to 0.8499999999999999\n",
      "Updating tau from 0.8499999999999999 to 0.7999999999999998\n",
      "Updating tau from 0.7999999999999998 to 0.7499999999999998\n",
      "Updating tau from 0.7499999999999998 to 0.6999999999999997\n",
      "Updating tau from 0.6999999999999997 to 0.6499999999999997\n",
      "Updating tau from 0.6499999999999997 to 0.5999999999999996\n",
      "Updating tau from 0.5999999999999996 to 0.5499999999999996\n",
      "Updating tau from 0.5499999999999996 to 0.4999999999999996\n",
      "Updating tau from 0.4999999999999996 to 0.4499999999999996\n",
      "Updating tau from 0.4499999999999996 to 0.39999999999999963\n",
      "Updating tau from 0.39999999999999963 to 0.34999999999999964\n",
      "Updating tau from 0.34999999999999964 to 0.29999999999999966\n",
      "Updating tau from 0.29999999999999966 to 0.24999999999999967\n",
      "Updating tau from 0.24999999999999967 to 0.19999999999999968\n",
      "Updating tau from 0.19999999999999968 to 0.1499999999999997\n",
      "Updating tau from 0.1499999999999997 to 0.09999999999999969\n",
      "Updating tau from 0.09999999999999969 to 0.049999999999999684\n",
      "Updating tau from 0.05 to 0.0\n",
      "Updating tau from 0.05 to 0.0\n"
>>>>>>> refs/remotes/origin/main
     ]
    }
   ],
   "source": [
    "done = False\n",
    "Q = np.zeros((tmdp.nS, tmdp.nA))\n",
    "tau = 1.\n",
    "while not done:\n",
    "    if tau == 0:\n",
    "        done = True\n",
    "    batch_res = batch_q_learning(tmdp, Q, alpha=.25, episodes=episodes, status_step=status_step, batch_nS=batch_nS)    \n",
    "    Q = batch_res[\"Qs\"][-1]\n",
    "    tau = max(0.,tau-0.05)\n",
    "    tmdp.update_tau(tau)\n",
<<<<<<< HEAD
    "    print(\"Updating tau to {}\".format(tau))"
=======
    "    print(\"Updating tau from {} to {}\".format(tau+0.05, tau))"
>>>>>>> refs/remotes/origin/main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "res = {\"Q\":Q}\n",
    "json_res = to_json(res, indent=True)\n",
    "write_results(nrows, nA, \"FrozenLake\", json_res, \"w\")\n",
    "json_res = read_results(nrows, nA, \"FrozenLake\")\n",
    "res = from_json(json_res)"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n",
      "Step 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tmdp = TMDP(env, xi_frozen, tau=0., gamma=gamma, seed=seed)\n",
    "env.render_mode = \"human\"\n",
    "tmdp.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while True:\n",
    "    a = greedy(tmdp.env.s, Q, tmdp.env.allowed_actions[int(tmdp.env.s)])\n",
    "    s_prime, reward, flags, prob = tmdp.step(a)\n",
    "    if flags[\"done\"]:\n",
    "        tmdp.reset()"
>>>>>>> refs/remotes/origin/main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "Q = np.array(res[\"Q\"])\n",
    "tmdp = TMDP(env, xi_frozen, tau=0., gamma=gamma, seed=seed)\n",
    "env.render_mode = \"human\"\n",
    "env.is_slippery = False\n",
    "tmdp.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while True:\n",
    "    a = greedy(tmdp.env.s, Q, tmdp.env.allowed_actions[int(tmdp.env.s)])\n",
    "    s_prime, reward, flags, prob = tmdp.step(a)\n",
    "    if flags[\"done\"]:\n",
    "        tmdp.reset()\n",
    "    step +=1\n",
    "    if step > max(1000,nrows*2):\n",
    "        break"
=======
    "tmdp = TMDP(env, xi_frozen, tau=0., gamma=gamma, seed=seed)\n",
    "env.render_mode = None\n",
    "env.reset()\n",
    "Q_0 = np.zeros((tmdp.nS, tmdp.nA))\n",
    "batch_res = batch_q_learning(tmdp, Q_0, alpha=.25, episodes=20000000, status_step=500000, batch_nS=batch_nS)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "Step 10\n",
      "Step 11\n",
      "Step 12\n",
      "Step 13\n",
      "Step 14\n",
      "Step 15\n",
      "Step 16\n",
      "Step 17\n",
      "Step 18\n",
      "Step 19\n",
      "Step 20\n",
      "Step 21\n",
      "Step 22\n",
      "Step 23\n",
      "Step 24\n",
      "Step 25\n",
      "Step 26\n",
      "Step 27\n",
      "Step 28\n",
      "Step 29\n",
      "Step 30\n",
      "Step 31\n",
      "Step 32\n",
      "Step 33\n",
      "Step 34\n",
      "Step 35\n",
      "Step 36\n",
      "Step 37\n",
      "Step 38\n",
      "Step 39\n",
      "Step 40\n",
      "Step 41\n",
      "Step 42\n",
      "Step 43\n",
      "Step 44\n"
     ]
    }
   ],
   "source": [
    "tmdp = TMDP(env, xi_frozen, tau=0., gamma=gamma, seed=seed)\n",
    "env.render_mode = \"human\"\n",
    "tmdp.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while not done:\n",
    "    a = greedy(tmdp.env.s, Q_0, tmdp.env.allowed_actions[int(tmdp.env.s)])\n",
    "    s_prime, reward, flags, prob = tmdp.step(a)\n",
    "    print(\"Step\", step)\n",
    "    step += 1\n",
    "    done = flags[\"done\"] or step > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(batch_res[\"Qs\"][-1])"
>>>>>>> refs/remotes/origin/main
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
