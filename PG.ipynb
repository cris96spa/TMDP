{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed for result reproducibility: 279448955339602318355000264086417676581\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from TMDP import TMDP\n",
    "from River_swim import River\n",
    "\n",
    "#from algorithms import *\n",
    "from PG_algorithms import *\n",
    "from model_functions import *\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#np.set_printoptions(precision=4)\n",
    "import math\n",
    "from utils import *\n",
    "from ActorCritic import *\n",
    "from ReplayBuffer import ReplayBuffer\n",
    "\n",
    "nS = 10\n",
    "nA = 2\n",
    "seed = get_current_seed()\n",
    "seed = 44697628841978080856580175700798794719\n",
    "gamma = .9\n",
    "mu = np.ones(nS) * 1/nS\n",
    "river = River(nS, mu, small=5, large=1000, seed=seed)\n",
    "tau = 1.\n",
    "xi = np.ones(nS) * 1/nS\n",
    "tmdp = TMDP(river, xi, tau=tau, gamma=gamma, seed=seed)\n",
    "mdp = TMDP(river, xi, tau=0., gamma=gamma, seed=seed)\n",
    "tmdp_1 = TMDP(river, xi, tau=.5, gamma=gamma, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_buffer = ReplayBuffer(max_size=int(10e5), input_shape=(1,), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ref_policy = ActorNet(nS, nA, hidden_dim=64).to(device)\n",
    "policy_pi = ActorNet(nS, nA, hidden_dim=64).to(device)\n",
    "\n",
    "v_net = ValueNet(nS, hidden_dim=64).to(device)\n",
    "q_net = QNet(nS, nA, hidden_dim=64).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_opt = torch.optim.AdamW(ref_policy.parameters(), lr=1e-3)\n",
    "v_opt = torch.optim.AdamW(v_net.parameters(), lr=1e-3)\n",
    "q_opt = torch.optim.AdamW(q_net.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Loss:  2.026451587677002\n",
      "Q Loss:  2.7697932720184326\n",
      "Policy Loss:  -0.09093543887138367\n",
      "[(0.08067, 0.6), (0.0, 0.59717), (1.0, 0.6)]\n",
      "Alpha*: 0.08067 tau*: 0.6 Episode: 86 length: 41 #teleports:46\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03000617027282715\n",
      "Value Loss:  0.11149057745933533\n",
      "Q Loss:  0.3787388205528259\n",
      "Policy Loss:  -0.2655957043170929\n",
      "[(0.07902, 0.6), (0.0, 0.59722), (1.0, 0.6)]\n",
      "Alpha*: 0.07902 tau*: 0.6 Episode: 103 length: 4 #teleports:13\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  0.0674281194806099\n",
      "Q Loss:  0.07191913574934006\n",
      "Policy Loss:  -0.008050583302974701\n",
      "[(0.07776, 0.6), (0.0, 0.59731), (1.0, 0.6)]\n",
      "Alpha*: 0.07776 tau*: 0.6 Episode: 108 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.051964499056339264\n",
      "Q Loss:  0.02505240961909294\n",
      "Policy Loss:  -0.09569841623306274\n",
      "[(0.07457, 0.6), (0.0, 0.59737), (1.0, 0.6)]\n",
      "Alpha*: 0.07457 tau*: 0.6 Episode: 117 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.05585922673344612\n",
      "Q Loss:  0.017468828707933426\n",
      "Policy Loss:  -0.1472485065460205\n",
      "[(0.07105, 0.6), (0.0, 0.59742), (1.0, 0.6)]\n",
      "Alpha*: 0.07105 tau*: 0.6 Episode: 129 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  1.4550846815109253\n",
      "Q Loss:  1.9739662408828735\n",
      "Policy Loss:  -0.1298413723707199\n",
      "[(0.03509, 0.6), (0.0, 0.59731), (1.0, 0.6)]\n",
      "Alpha*: 0.03509 tau*: 0.6 Episode: 278 length: 56 #teleports:93\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.017095934599637985\n",
      "Q Loss:  0.017980318516492844\n",
      "Policy Loss:  0.05577443540096283\n",
      "[(0.0327, 0.6), (0.0, 0.59733), (1.0, 0.6)]\n",
      "Alpha*: 0.0327 tau*: 0.6 Episode: 287 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  38438.18359375\n",
      "Q Loss:  38454.76953125\n",
      "Policy Loss:  -0.09609784930944443\n",
      "[(0.00061, 0.6), (0.0, 0.59961), (1.0, 0.6)]\n",
      "Alpha*: 0.0 tau*: 0.59961 Episode: 416 length: 52 #teleports:77\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.03124759905040264\n",
      "Q Loss:  0.05510873720049858\n",
      "Policy Loss:  0.04862207546830177\n",
      "[(0.00058, 0.59961), (0.0, 0.59922), (1.0, 0.59961)]\n",
      "Alpha*: 0.0 tau*: 0.59922 Episode: 425 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  12040.669921875\n",
      "Q Loss:  12046.0400390625\n",
      "Policy Loss:  -0.06325073540210724\n",
      "[(0.00037, 0.59922), (0.0, 0.59884), (1.0, 0.59922)]\n",
      "Alpha*: 0.0 tau*: 0.59884 Episode: 622 length: 83 #teleports:114\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.1420695781707764\n",
      "Q Loss:  1.545201063156128\n",
      "Policy Loss:  -0.09826085716485977\n",
      "[(0.00035, 0.59884), (0.0, 0.59844), (1.0, 0.59884)]\n",
      "Alpha*: 0.0 tau*: 0.59844 Episode: 807 length: 71 #teleports:114\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.04644393548369408\n",
      "Q Loss:  0.04044383391737938\n",
      "Policy Loss:  0.0347854420542717\n",
      "[(0.00032, 0.59844), (0.0, 0.59804), (1.0, 0.59844)]\n",
      "Alpha*: 0.0 tau*: 0.59804 Episode: 817 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.02248600497841835\n",
      "Q Loss:  0.07240372151136398\n",
      "Policy Loss:  0.05405915528535843\n",
      "[(0.0003, 0.59804), (0.0, 0.59764), (1.0, 0.59804)]\n",
      "Alpha*: 0.0 tau*: 0.59764 Episode: 826 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  1.7421998977661133\n",
      "Q Loss:  2.348820686340332\n",
      "Policy Loss:  -0.13182282447814941\n",
      "[(0.00028, 0.59764), (0.0, 0.59723), (1.0, 0.59764)]\n",
      "Alpha*: 0.0 tau*: 0.59723 Episode: 920 length: 45 #teleports:49\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.13269548118114471\n",
      "Q Loss:  0.0757145881652832\n",
      "Policy Loss:  -0.016371410340070724\n",
      "[(0.00026, 0.59723), (0.0, 0.59682), (1.0, 0.59723)]\n",
      "Alpha*: 0.0 tau*: 0.59682 Episode: 931 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.6715373396873474\n",
      "Q Loss:  0.9050154685974121\n",
      "Policy Loss:  -0.06274402141571045\n",
      "[(0.00024, 0.59682), (0.0, 0.59639), (1.0, 0.59682)]\n",
      "Alpha*: 0.0 tau*: 0.59639 Episode: 1259 length: 124 #teleports:204\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.06642544269561768\n",
      "Q Loss:  0.24567019939422607\n",
      "Policy Loss:  -0.2367878556251526\n",
      "[(0.00022, 0.59639), (0.0, 0.59596), (1.0, 0.59639)]\n",
      "Alpha*: 0.0 tau*: 0.59596 Episode: 1271 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  52588.6796875\n",
      "Q Loss:  52612.125\n",
      "Policy Loss:  -0.13534194231033325\n",
      "[(0.00016, 0.59596), (0.0, 0.59555), (1.0, 0.59596)]\n",
      "Alpha*: 0.0 tau*: 0.59555 Episode: 1328 length: 19 #teleports:38\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001016616821289\n",
      "Value Loss:  0.06328605115413666\n",
      "Q Loss:  0.03671539947390556\n",
      "Policy Loss:  -0.07064834237098694\n",
      "[(0.00015, 0.59555), (0.0, 0.59514), (1.0, 0.59555)]\n",
      "Alpha*: 0.0 tau*: 0.59514 Episode: 1339 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.14181217551231384\n",
      "Q Loss:  0.07064175605773926\n",
      "Policy Loss:  -0.04569486528635025\n",
      "[(0.00014, 0.59514), (0.0, 0.59473), (1.0, 0.59514)]\n",
      "Alpha*: 0.0 tau*: 0.59473 Episode: 1351 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  2.861354112625122\n",
      "Q Loss:  3.969738483428955\n",
      "Policy Loss:  -0.09573154151439667\n",
      "[(0.00013, 0.59473), (0.0, 0.59431), (1.0, 0.59473)]\n",
      "Alpha*: 0.0 tau*: 0.59431 Episode: 1403 length: 26 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.1325217485427856\n",
      "Q Loss:  1.5031909942626953\n",
      "Policy Loss:  -0.09560544043779373\n",
      "[(0.00012, 0.59431), (0.0, 0.59388), (1.0, 0.59431)]\n",
      "Alpha*: 0.0 tau*: 0.59388 Episode: 1598 length: 70 #teleports:125\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  7511.67333984375\n",
      "Q Loss:  7515.07568359375\n",
      "Policy Loss:  -0.08404756337404251\n",
      "[(9e-05, 0.59388), (0.0, 0.59347), (1.0, 0.59388)]\n",
      "Alpha*: 0.0 tau*: 0.59347 Episode: 1924 length: 133 #teleports:193\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.10394768416881561\n",
      "Q Loss:  0.024509621784090996\n",
      "Policy Loss:  -0.23862899839878082\n",
      "[(8e-05, 0.59347), (0.0, 0.59306), (1.0, 0.59347)]\n",
      "Alpha*: 0.0 tau*: 0.59306 Episode: 1944 length: 4 #teleports:16\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.05498844385147095\n",
      "Q Loss:  0.005006716120988131\n",
      "Policy Loss:  0.023051224648952484\n",
      "[(8e-05, 0.59306), (0.0, 0.59265), (1.0, 0.59306)]\n",
      "Alpha*: 0.0 tau*: 0.59265 Episode: 1952 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.03318587690591812\n",
      "Q Loss:  0.20164631307125092\n",
      "Policy Loss:  -0.003285590559244156\n",
      "[(7e-05, 0.59265), (0.0, 0.59224)]\n",
      "Alpha*: 0.0 tau*: 0.59224 Episode: 1963 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  41623.18359375\n",
      "Q Loss:  41642.1484375\n",
      "Policy Loss:  -0.17801184952259064\n",
      "[(6e-05, 0.59224), (0.0, 0.59184)]\n",
      "Alpha*: 0.0 tau*: 0.59184 Episode: 2019 length: 24 #teleports:32\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.047711584717035294\n",
      "Q Loss:  0.004176036454737186\n",
      "Policy Loss:  -0.031306229531764984\n",
      "[(5e-05, 0.59184), (0.0, 0.59144)]\n",
      "Alpha*: 0.0 tau*: 0.59144 Episode: 2027 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.025005578994750977\n",
      "Value Loss:  0.09307698905467987\n",
      "Q Loss:  0.024572286754846573\n",
      "Policy Loss:  -0.14562027156352997\n",
      "[(5e-05, 0.59144), (0.0, 0.59104)]\n",
      "Alpha*: 0.0 tau*: 0.59104 Episode: 2037 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.09328878670930862\n",
      "Q Loss:  0.03802940994501114\n",
      "Policy Loss:  -0.07890395075082779\n",
      "[(5e-05, 0.59104), (0.0, 0.59064)]\n",
      "Alpha*: 0.0 tau*: 0.59064 Episode: 2053 length: 4 #teleports:12\n",
      "Time for bound evaluation:  0.03500771522521973\n",
      "Value Loss:  0.045114848762750626\n",
      "Q Loss:  0.00886533036828041\n",
      "Policy Loss:  0.01007271371781826\n",
      "[(5e-05, 0.59064), (0.0, 0.59024)]\n",
      "Alpha*: 0.0 tau*: 0.59024 Episode: 2065 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0481325164437294\n",
      "Q Loss:  0.005895865149796009\n",
      "Policy Loss:  0.01888120174407959\n",
      "[(5e-05, 0.59024), (0.0, 0.58984)]\n",
      "Alpha*: 0.0 tau*: 0.58984 Episode: 2071 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.12492102384567261\n",
      "Q Loss:  0.19335274398326874\n",
      "Policy Loss:  -0.22506284713745117\n",
      "[(4e-05, 0.58984), (0.0, 0.58944)]\n",
      "Alpha*: 0.0 tau*: 0.58944 Episode: 2082 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.11600515991449356\n",
      "Q Loss:  0.013290122151374817\n",
      "Policy Loss:  -0.1750178039073944\n",
      "[(4e-05, 0.58944), (0.0, 0.58904)]\n",
      "Alpha*: 0.0 tau*: 0.58904 Episode: 2091 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  17522.1171875\n",
      "Q Loss:  17530.21875\n",
      "Policy Loss:  -0.044489432126283646\n",
      "[(4e-05, 0.58904), (0.0, 0.58865)]\n",
      "Alpha*: 0.0 tau*: 0.58865 Episode: 2224 length: 57 #teleports:76\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.12260453402996063\n",
      "Q Loss:  0.08821248263120651\n",
      "Policy Loss:  0.002224177122116089\n",
      "[(4e-05, 0.58865), (0.0, 0.58826)]\n",
      "Alpha*: 0.0 tau*: 0.58826 Episode: 2235 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.14273762702941895\n",
      "Q Loss:  0.01466735266149044\n",
      "Policy Loss:  -0.26118242740631104\n",
      "[(3e-05, 0.58826), (0.0, 0.58787)]\n",
      "Alpha*: 0.0 tau*: 0.58787 Episode: 2250 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  115228.1953125\n",
      "Q Loss:  115279.65625\n",
      "Policy Loss:  -0.12415117770433426\n",
      "[(3e-05, 0.58787), (0.0, 0.5875)]\n",
      "Alpha*: 0.0 tau*: 0.5875 Episode: 2324 length: 26 #teleports:48\n",
      "Got not null reward 3005.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.14242571592330933\n",
      "Q Loss:  0.08196573704481125\n",
      "Policy Loss:  -0.17146843671798706\n",
      "[(3e-05, 0.5875), (0.0, 0.58713)]\n",
      "Alpha*: 0.0 tau*: 0.58713 Episode: 2336 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.14542987942695618\n",
      "Q Loss:  0.10226796567440033\n",
      "Policy Loss:  -0.10062680393457413\n",
      "[(3e-05, 0.58713), (0.0, 0.58676)]\n",
      "Alpha*: 0.0 tau*: 0.58676 Episode: 2341 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009505987167358398\n",
      "Value Loss:  0.4157734513282776\n",
      "Q Loss:  0.026628881692886353\n",
      "Policy Loss:  -0.9629049897193909\n",
      "[(3e-05, 0.58676), (0.0, 0.58639)]\n",
      "Alpha*: 0.0 tau*: 0.58639 Episode: 2348 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0425572544336319\n",
      "Q Loss:  0.03724713623523712\n",
      "Policy Loss:  0.11276896297931671\n",
      "[(3e-05, 0.58639), (0.0, 0.58602)]\n",
      "Alpha*: 0.0 tau*: 0.58602 Episode: 2357 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01001596450805664\n",
      "Value Loss:  0.21929800510406494\n",
      "Q Loss:  0.15232862532138824\n",
      "Policy Loss:  -0.044648006558418274\n",
      "[(3e-05, 0.58602), (0.0, 0.58565)]\n",
      "Alpha*: 0.0 tau*: 0.58565 Episode: 2363 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010003328323364258\n",
      "Value Loss:  17517.296875\n",
      "Q Loss:  17525.529296875\n",
      "Policy Loss:  -0.13920468091964722\n",
      "[(3e-05, 0.58565), (0.0, 0.58528)]\n",
      "Alpha*: 0.0 tau*: 0.58528 Episode: 2486 length: 57 #teleports:66\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011003732681274414\n",
      "Value Loss:  4.902892112731934\n",
      "Q Loss:  6.837888717651367\n",
      "Policy Loss:  -0.385638028383255\n",
      "[(3e-05, 0.58528), (0.0, 0.58491)]\n",
      "Alpha*: 0.0 tau*: 0.58491 Episode: 2535 length: 14 #teleports:35\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.031006813049316406\n",
      "Value Loss:  0.19637417793273926\n",
      "Q Loss:  0.09663594514131546\n",
      "Policy Loss:  -0.028899848461151123\n",
      "[(3e-05, 0.58491), (0.0, 0.58454)]\n",
      "Alpha*: 0.0 tau*: 0.58454 Episode: 2544 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.18420933187007904\n",
      "Q Loss:  0.09487307816743851\n",
      "Policy Loss:  -0.03798694908618927\n",
      "[(3e-05, 0.58454), (0.0, 0.58417)]\n",
      "Alpha*: 0.0 tau*: 0.58417 Episode: 2551 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  10971.1943359375\n",
      "Q Loss:  10976.4140625\n",
      "Policy Loss:  -0.02714530937373638\n",
      "[(3e-05, 0.58417), (0.0, 0.5838)]\n",
      "Alpha*: 0.0 tau*: 0.5838 Episode: 2763 length: 91 #teleports:121\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.24743729829788208\n",
      "Q Loss:  0.09132951498031616\n",
      "Policy Loss:  -0.13331066071987152\n",
      "[(3e-05, 0.5838), (0.0, 0.58343)]\n",
      "Alpha*: 0.0 tau*: 0.58343 Episode: 2772 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.48088958859443665\n",
      "Q Loss:  0.2528303861618042\n",
      "Policy Loss:  -0.2516651153564453\n",
      "[(3e-05, 0.58343), (0.0, 0.58306)]\n",
      "Alpha*: 0.0 tau*: 0.58306 Episode: 2779 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  15125.8759765625\n",
      "Q Loss:  15133.146484375\n",
      "Policy Loss:  0.02922580949962139\n",
      "[(3e-05, 0.58306), (0.0, 0.58269)]\n",
      "Alpha*: 0.0 tau*: 0.58269 Episode: 2932 length: 66 #teleports:87\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.027477849274873734\n",
      "Q Loss:  0.12674935162067413\n",
      "Policy Loss:  0.2571580410003662\n",
      "[(3e-05, 0.58269), (0.0, 0.58232)]\n",
      "Alpha*: 0.0 tau*: 0.58232 Episode: 2945 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.045604996383190155\n",
      "Q Loss:  0.020521853119134903\n",
      "Policy Loss:  0.0752837061882019\n",
      "[(3e-05, 0.58232), (0.0, 0.58195)]\n",
      "Alpha*: 0.0 tau*: 0.58195 Episode: 2953 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  76787.4375\n",
      "Q Loss:  76824.625\n",
      "Policy Loss:  -0.36639392375946045\n",
      "[(3e-05, 0.58195), (0.0, 0.58158)]\n",
      "Alpha*: 0.0 tau*: 0.58158 Episode: 2975 length: 13 #teleports:9\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.22991129755973816\n",
      "Q Loss:  0.1574546992778778\n",
      "Policy Loss:  -0.05010975897312164\n",
      "[(3e-05, 0.58158), (0.0, 0.58121)]\n",
      "Alpha*: 0.0 tau*: 0.58121 Episode: 2990 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.9227097630500793\n",
      "Q Loss:  1.3184328079223633\n",
      "Policy Loss:  0.02993452362716198\n",
      "[(3e-05, 0.58121), (0.0, 0.58084)]\n",
      "Alpha*: 0.0 tau*: 0.58084 Episode: 3175 length: 75 #teleports:110\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.24281151592731476\n",
      "Q Loss:  0.16298314929008484\n",
      "Policy Loss:  4.6640634536743164e-05\n",
      "[(3e-05, 0.58084), (0.0, 0.58047)]\n",
      "Alpha*: 0.0 tau*: 0.58047 Episode: 3191 length: 4 #teleports:12\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  7677.74169921875\n",
      "Q Loss:  7681.50439453125\n",
      "Policy Loss:  0.002319963416084647\n",
      "[(3e-05, 0.58047), (0.0, 0.5801)]\n",
      "Alpha*: 0.0 tau*: 0.5801 Episode: 3516 length: 130 #teleports:195\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0344996303319931\n",
      "Q Loss:  0.18123231828212738\n",
      "Policy Loss:  0.1730770766735077\n",
      "[(3e-05, 0.5801), (0.0, 0.57973)]\n",
      "Alpha*: 0.0 tau*: 0.57973 Episode: 3522 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.045941345393657684\n",
      "Q Loss:  0.02277812547981739\n",
      "Policy Loss:  0.10875594615936279\n",
      "[(3e-05, 0.57973), (0.0, 0.57936)]\n",
      "Alpha*: 0.0 tau*: 0.57936 Episode: 3530 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.009157279506325722\n",
      "Q Loss:  0.20603103935718536\n",
      "Policy Loss:  0.23820635676383972\n",
      "[(3e-05, 0.57936), (0.0, 0.57899)]\n",
      "Alpha*: 0.0 tau*: 0.57899 Episode: 3541 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.28620386123657227\n",
      "Q Loss:  0.30761420726776123\n",
      "Policy Loss:  -0.09805399924516678\n",
      "[(3e-05, 0.57899), (0.0, 0.57862)]\n",
      "Alpha*: 0.0 tau*: 0.57862 Episode: 3553 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.3300374448299408\n",
      "Q Loss:  0.17831136286258698\n",
      "Policy Loss:  -0.09366881102323532\n",
      "[(3e-05, 0.57862), (0.0, 0.57825)]\n",
      "Alpha*: 0.0 tau*: 0.57825 Episode: 3564 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  1.1671327352523804\n",
      "Q Loss:  1.5841814279556274\n",
      "Policy Loss:  -0.1255100965499878\n",
      "[(3e-05, 0.57825), (0.0, 0.57788)]\n",
      "Alpha*: 0.0 tau*: 0.57788 Episode: 3709 length: 62 #teleports:83\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.563765287399292\n",
      "Q Loss:  0.037801921367645264\n",
      "Policy Loss:  -1.0129830837249756\n",
      "[(3e-05, 0.57788), (0.0, 0.57751)]\n",
      "Alpha*: 0.0 tau*: 0.57751 Episode: 3715 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.0619262158870697\n",
      "Q Loss:  0.025676950812339783\n",
      "Policy Loss:  -0.003729298710823059\n",
      "[(3e-05, 0.57751), (0.0, 0.57714)]\n",
      "Alpha*: 0.0 tau*: 0.57714 Episode: 3725 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.5803525447845459\n",
      "Q Loss:  0.17133332788944244\n",
      "Policy Loss:  -1.0787543058395386\n",
      "[(3e-05, 0.57714), (0.0, 0.57677)]\n",
      "Alpha*: 0.0 tau*: 0.57677 Episode: 3745 length: 4 #teleports:16\n",
      "Time for bound evaluation:  0.009795665740966797\n",
      "Value Loss:  0.5863879919052124\n",
      "Q Loss:  0.3124881684780121\n",
      "Policy Loss:  -0.8818920850753784\n",
      "[(3e-05, 0.57677), (0.0, 0.5764)]\n",
      "Alpha*: 0.0 tau*: 0.5764 Episode: 3756 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.010001182556152344\n",
      "Value Loss:  0.023653678596019745\n",
      "Q Loss:  0.07517027854919434\n",
      "Policy Loss:  0.2720049321651459\n",
      "[(3e-05, 0.5764), (0.0, 0.57603)]\n",
      "Alpha*: 0.0 tau*: 0.57603 Episode: 3762 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0031054303981363773\n",
      "Q Loss:  0.049738381057977676\n",
      "Policy Loss:  0.28029197454452515\n",
      "[(3e-05, 0.57603), (0.0, 0.57566)]\n",
      "Alpha*: 0.0 tau*: 0.57566 Episode: 3772 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0200620386749506\n",
      "Q Loss:  0.036388132721185684\n",
      "Policy Loss:  0.18915557861328125\n",
      "[(3e-05, 0.57566), (0.0, 0.57529)]\n",
      "Alpha*: 0.0 tau*: 0.57529 Episode: 3779 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.047842733561992645\n",
      "Q Loss:  0.02727368101477623\n",
      "Policy Loss:  0.07848353683948517\n",
      "[(4e-05, 0.57529), (0.0, 0.57492)]\n",
      "Alpha*: 0.0 tau*: 0.57492 Episode: 3787 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  0.01879405416548252\n",
      "Q Loss:  0.10773837566375732\n",
      "Policy Loss:  0.2981744408607483\n",
      "[(4e-05, 0.57492), (0.0, 0.57455)]\n",
      "Alpha*: 0.0 tau*: 0.57455 Episode: 3797 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.6019683480262756\n",
      "Q Loss:  0.2672869563102722\n",
      "Policy Loss:  -0.47817549109458923\n",
      "[(4e-05, 0.57455), (0.0, 0.57418)]\n",
      "Alpha*: 0.0 tau*: 0.57418 Episode: 3806 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.018188782036304474\n",
      "Q Loss:  0.18655776977539062\n",
      "Policy Loss:  0.28696951270103455\n",
      "[(4e-05, 0.57418), (0.0, 0.57381)]\n",
      "Alpha*: 0.0 tau*: 0.57381 Episode: 3811 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.292011559009552\n",
      "Q Loss:  0.126059889793396\n",
      "Policy Loss:  -0.1482265144586563\n",
      "[(4e-05, 0.57381), (0.0, 0.57344)]\n",
      "Alpha*: 0.0 tau*: 0.57344 Episode: 3820 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.03059602528810501\n",
      "Q Loss:  0.1539352536201477\n",
      "Policy Loss:  0.17065700888633728\n",
      "[(4e-05, 0.57344), (0.0, 0.57307)]\n",
      "Alpha*: 0.0 tau*: 0.57307 Episode: 3833 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.30255457758903503\n",
      "Q Loss:  0.18524087965488434\n",
      "Policy Loss:  -0.2731730341911316\n",
      "[(4e-05, 0.57307), (0.0, 0.5727)]\n",
      "Alpha*: 0.0 tau*: 0.5727 Episode: 3843 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.009003400802612305\n",
      "Value Loss:  0.3190687596797943\n",
      "Q Loss:  0.2222994565963745\n",
      "Policy Loss:  -0.41321682929992676\n",
      "[(4e-05, 0.5727), (0.0, 0.57233)]\n",
      "Alpha*: 0.0 tau*: 0.57233 Episode: 3852 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.3299177587032318\n",
      "Q Loss:  0.020226432010531425\n",
      "Policy Loss:  -0.8111652135848999\n",
      "[(4e-05, 0.57233), (0.0, 0.57196)]\n",
      "Alpha*: 0.0 tau*: 0.57196 Episode: 3863 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002641865867190063\n",
      "Q Loss:  0.23847094178199768\n",
      "Policy Loss:  0.3010835349559784\n",
      "[(4e-05, 0.57196), (0.0, 0.57159)]\n",
      "Alpha*: 0.0 tau*: 0.57159 Episode: 3868 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  28920.818359375\n",
      "Q Loss:  28935.19921875\n",
      "Policy Loss:  -0.07552162557840347\n",
      "[(4e-05, 0.57159), (0.0, 0.57123)]\n",
      "Alpha*: 0.0 tau*: 0.57123 Episode: 4018 length: 69 #teleports:81\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.2813025712966919\n",
      "Q Loss:  0.036028191447257996\n",
      "Policy Loss:  -0.3277837634086609\n",
      "[(4e-05, 0.57123), (0.0, 0.57087)]\n",
      "Alpha*: 0.0 tau*: 0.57087 Episode: 4026 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.28294920921325684\n",
      "Q Loss:  0.17324218153953552\n",
      "Policy Loss:  -0.20959949493408203\n",
      "[(4e-05, 0.57087), (0.0, 0.57051)]\n",
      "Alpha*: 0.0 tau*: 0.57051 Episode: 4042 length: 4 #teleports:12\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00019853273988701403\n",
      "Q Loss:  0.12117268890142441\n",
      "Policy Loss:  0.28721898794174194\n",
      "[(4e-05, 0.57051), (0.0, 0.57015)]\n",
      "Alpha*: 0.0 tau*: 0.57015 Episode: 4054 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.26574718952178955\n",
      "Q Loss:  0.22228208184242249\n",
      "Policy Loss:  -0.10673344135284424\n",
      "[(4e-05, 0.57015), (0.0, 0.56979)]\n",
      "Alpha*: 0.0 tau*: 0.56979 Episode: 4063 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.014997122809290886\n",
      "Q Loss:  0.060782693326473236\n",
      "Policy Loss:  0.08450178802013397\n",
      "[(4e-05, 0.56979), (0.0, 0.56943)]\n",
      "Alpha*: 0.0 tau*: 0.56943 Episode: 4069 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  12629.5419921875\n",
      "Q Loss:  12635.896484375\n",
      "Policy Loss:  -0.22038742899894714\n",
      "[(4e-05, 0.56943), (0.0, 0.56907)]\n",
      "Alpha*: 0.0 tau*: 0.56907 Episode: 4264 length: 79 #teleports:116\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.5768873691558838\n",
      "Q Loss:  0.7019270062446594\n",
      "Policy Loss:  -0.1773369312286377\n",
      "[(4e-05, 0.56907), (0.0, 0.56871)]\n",
      "Alpha*: 0.0 tau*: 0.56871 Episode: 4570 length: 145 #teleports:161\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  0.99444580078125\n",
      "Q Loss:  1.3660811185836792\n",
      "Policy Loss:  0.04900621622800827\n",
      "[(4e-05, 0.56871), (0.0, 0.56835)]\n",
      "Alpha*: 0.0 tau*: 0.56835 Episode: 4720 length: 68 #teleports:82\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.782385753467679e-05\n",
      "Q Loss:  0.18738199770450592\n",
      "Policy Loss:  0.3877437114715576\n",
      "[(4e-05, 0.56835), (0.0, 0.56799)]\n",
      "Alpha*: 0.0 tau*: 0.56799 Episode: 4725 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.25356626510620117\n",
      "Q Loss:  0.0898348018527031\n",
      "Policy Loss:  -0.2609277665615082\n",
      "[(4e-05, 0.56799), (0.0, 0.56763)]\n",
      "Alpha*: 0.0 tau*: 0.56763 Episode: 4735 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  36277.62109375\n",
      "Q Loss:  36295.66796875\n",
      "Policy Loss:  -0.3457242250442505\n",
      "[(4e-05, 0.56763), (0.0, 0.56727)]\n",
      "Alpha*: 0.0 tau*: 0.56727 Episode: 4859 length: 55 #teleports:69\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.3649802803993225\n",
      "Q Loss:  0.10794279724359512\n",
      "Policy Loss:  -0.7380841374397278\n",
      "[(4e-05, 0.56727), (0.0, 0.56691)]\n",
      "Alpha*: 0.0 tau*: 0.56691 Episode: 4864 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.012290626764297485\n",
      "Q Loss:  0.047502301633358\n",
      "Policy Loss:  0.2628069818019867\n",
      "[(4e-05, 0.56691), (0.0, 0.56655)]\n",
      "Alpha*: 0.0 tau*: 0.56655 Episode: 4875 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.0001219984915223904\n",
      "Q Loss:  0.062416672706604004\n",
      "Policy Loss:  0.2563146948814392\n",
      "[(4e-05, 0.56655), (0.0, 0.56619)]\n",
      "Alpha*: 0.0 tau*: 0.56619 Episode: 4885 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.005931589752435684\n",
      "Q Loss:  0.12124784290790558\n",
      "Policy Loss:  0.2993508577346802\n",
      "[(4e-05, 0.56619), (0.0, 0.56583)]\n",
      "Alpha*: 0.0 tau*: 0.56583 Episode: 4897 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.39044639468193054\n",
      "Q Loss:  0.5052537322044373\n",
      "Policy Loss:  -0.46335840225219727\n",
      "[(4e-05, 0.56583), (0.0, 0.56547)]\n",
      "Alpha*: 0.0 tau*: 0.56547 Episode: 4905 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  2.0401885509490967\n",
      "Q Loss:  2.674161434173584\n",
      "Policy Loss:  -0.1078590378165245\n",
      "[(4e-05, 0.56547), (0.0, 0.56511)]\n",
      "Alpha*: 0.0 tau*: 0.56511 Episode: 4990 length: 33 #teleports:52\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  5.215700366534293e-05\n",
      "Q Loss:  0.08784777671098709\n",
      "Policy Loss:  0.2858785390853882\n",
      "[(4e-05, 0.56511), (0.0, 0.56475)]\n",
      "Alpha*: 0.0 tau*: 0.56475 Episode: 4998 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.6859756112098694\n",
      "Q Loss:  0.8422521352767944\n",
      "Policy Loss:  -0.11405713111162186\n",
      "[(4e-05, 0.56475), (0.0, 0.56439)]\n",
      "Alpha*: 0.0 tau*: 0.56439 Episode: 5303 length: 119 #teleports:186\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.030253726989030838\n",
      "Q Loss:  0.10205657035112381\n",
      "Policy Loss:  0.27662771940231323\n",
      "[(4e-05, 0.56439), (0.0, 0.56403)]\n",
      "Alpha*: 0.0 tau*: 0.56403 Episode: 5312 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.02734583243727684\n",
      "Q Loss:  0.06232115998864174\n",
      "Policy Loss:  0.08066238462924957\n",
      "[(4e-05, 0.56403), (0.0, 0.56367)]\n",
      "Alpha*: 0.0 tau*: 0.56367 Episode: 5317 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  0.003811753122135997\n",
      "Q Loss:  0.12505991756916046\n",
      "Policy Loss:  0.32095634937286377\n",
      "[(4e-05, 0.56367), (0.0, 0.56331)]\n",
      "Alpha*: 0.0 tau*: 0.56331 Episode: 5330 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00688552763313055\n",
      "Q Loss:  0.009568218141794205\n",
      "Policy Loss:  0.12885966897010803\n",
      "[(4e-05, 0.56331), (0.0, 0.56295)]\n",
      "Alpha*: 0.0 tau*: 0.56295 Episode: 5341 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.003101239213719964\n",
      "Q Loss:  0.039350222796201706\n",
      "Policy Loss:  0.3106039762496948\n",
      "[(4e-05, 0.56295), (0.0, 0.56259)]\n",
      "Alpha*: 0.0 tau*: 0.56259 Episode: 5352 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0041945381090044975\n",
      "Q Loss:  0.021408796310424805\n",
      "Policy Loss:  0.14867645502090454\n",
      "[(4e-05, 0.56259), (0.0, 0.56223)]\n",
      "Alpha*: 0.0 tau*: 0.56223 Episode: 5361 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.0348994731903076\n",
      "Q Loss:  1.2768826484680176\n",
      "Policy Loss:  -0.2474423348903656\n",
      "[(4e-05, 0.56223), (0.0, 0.56187)]\n",
      "Alpha*: 0.0 tau*: 0.56187 Episode: 5532 length: 72 #teleports:99\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.01292125228792429\n",
      "Q Loss:  0.22326435148715973\n",
      "Policy Loss:  0.5166429281234741\n",
      "[(4e-05, 0.56187), (0.0, 0.56151)]\n",
      "Alpha*: 0.0 tau*: 0.56151 Episode: 5542 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0022581506054848433\n",
      "Q Loss:  0.02438712865114212\n",
      "Policy Loss:  0.13942763209342957\n",
      "[(4e-05, 0.56151), (0.0, 0.56115)]\n",
      "Alpha*: 0.0 tau*: 0.56115 Episode: 5563 length: 4 #teleports:17\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  2.6730127334594727\n",
      "Q Loss:  3.49373722076416\n",
      "Policy Loss:  -0.5443001985549927\n",
      "[(4e-05, 0.56115), (0.0, 0.56079)]\n",
      "Alpha*: 0.0 tau*: 0.56079 Episode: 5617 length: 25 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.012887177988886833\n",
      "Q Loss:  0.054369572550058365\n",
      "Policy Loss:  0.12699387967586517\n",
      "[(4e-05, 0.56079), (0.0, 0.56043)]\n",
      "Alpha*: 0.0 tau*: 0.56043 Episode: 5623 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.00900125503540039\n",
      "Value Loss:  0.000388964603189379\n",
      "Q Loss:  0.09010089933872223\n",
      "Policy Loss:  0.18826547265052795\n",
      "[(4e-05, 0.56043), (0.0, 0.56007)]\n",
      "Alpha*: 0.0 tau*: 0.56007 Episode: 5629 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.4352608025074005\n",
      "Q Loss:  0.014899758622050285\n",
      "Policy Loss:  -0.9772000908851624\n",
      "[(4e-05, 0.56007), (0.0, 0.55971)]\n",
      "Alpha*: 0.0 tau*: 0.55971 Episode: 5639 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.7365580797195435\n",
      "Q Loss:  2.1083357334136963\n",
      "Policy Loss:  -0.5831083059310913\n",
      "[(4e-05, 0.55971), (0.0, 0.55935)]\n",
      "Alpha*: 0.0 tau*: 0.55935 Episode: 5748 length: 42 #teleports:67\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.010100085288286209\n",
      "Q Loss:  0.051874466240406036\n",
      "Policy Loss:  0.1760827600955963\n",
      "[(4e-05, 0.55935), (0.0, 0.55899)]\n",
      "Alpha*: 0.0 tau*: 0.55899 Episode: 5759 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.000943192804697901\n",
      "Q Loss:  0.026765888556838036\n",
      "Policy Loss:  0.3328661024570465\n",
      "[(3e-05, 0.55899), (0.0, 0.55863)]\n",
      "Alpha*: 0.0 tau*: 0.55863 Episode: 5768 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  9321.6640625\n",
      "Q Loss:  9326.619140625\n",
      "Policy Loss:  -0.27199873328208923\n",
      "[(3e-05, 0.55863), (0.0, 0.55827)]\n",
      "Alpha*: 0.0 tau*: 0.55827 Episode: 6005 length: 107 #teleports:130\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.4407913088798523\n",
      "Q Loss:  0.02948186732828617\n",
      "Policy Loss:  -1.1818245649337769\n",
      "[(3e-05, 0.55827), (0.0, 0.55791)]\n",
      "Alpha*: 0.0 tau*: 0.55791 Episode: 6012 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.3053988814353943\n",
      "Q Loss:  0.14230486750602722\n",
      "Policy Loss:  -0.36749690771102905\n",
      "[(3e-05, 0.55791), (0.0, 0.55755)]\n",
      "Alpha*: 0.0 tau*: 0.55755 Episode: 6017 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010712623596191406\n",
      "Value Loss:  0.3063786029815674\n",
      "Q Loss:  0.15980926156044006\n",
      "Policy Loss:  -0.4572789669036865\n",
      "[(3e-05, 0.55755), (0.0, 0.5572)]\n",
      "Alpha*: 0.0 tau*: 0.5572 Episode: 6025 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.007817278616130352\n",
      "Q Loss:  0.03826327249407768\n",
      "Policy Loss:  0.1532011330127716\n",
      "[(3e-05, 0.5572), (0.0, 0.55685)]\n",
      "Alpha*: 0.0 tau*: 0.55685 Episode: 6035 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.9334585070610046\n",
      "Q Loss:  1.1599748134613037\n",
      "Policy Loss:  -0.2063005566596985\n",
      "[(3e-05, 0.55685), (0.0, 0.5565)]\n",
      "Alpha*: 0.0 tau*: 0.5565 Episode: 6211 length: 73 #teleports:103\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.006608304567635059\n",
      "Q Loss:  0.3269135653972626\n",
      "Policy Loss:  0.41298848390579224\n",
      "[(3e-05, 0.5565), (0.0, 0.55615)]\n",
      "Alpha*: 0.0 tau*: 0.55615 Episode: 6221 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  9409.2158203125\n",
      "Q Loss:  9414.259765625\n",
      "Policy Loss:  -0.16391105949878693\n",
      "[(3e-05, 0.55615), (0.0, 0.5558)]\n",
      "Alpha*: 0.0 tau*: 0.5558 Episode: 6454 length: 106 #teleports:127\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.7834447622299194\n",
      "Q Loss:  2.3170063495635986\n",
      "Policy Loss:  -0.38014253973960876\n",
      "[(3e-05, 0.5558), (0.0, 0.55545)]\n",
      "Alpha*: 0.0 tau*: 0.55545 Episode: 6554 length: 36 #teleports:64\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0064414371736347675\n",
      "Q Loss:  0.04011610150337219\n",
      "Policy Loss:  0.14537331461906433\n",
      "[(3e-05, 0.55545), (0.0, 0.5551)]\n",
      "Alpha*: 0.0 tau*: 0.5551 Episode: 6562 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013995885848999023\n",
      "Value Loss:  0.00011617837299127132\n",
      "Q Loss:  0.05901695787906647\n",
      "Policy Loss:  0.22735190391540527\n",
      "[(3e-05, 0.5551), (0.0, 0.55475)]\n",
      "Alpha*: 0.0 tau*: 0.55475 Episode: 6570 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.46772322058677673\n",
      "Q Loss:  0.3742865025997162\n",
      "Policy Loss:  -0.5153347253799438\n",
      "[(3e-05, 0.55475), (0.0, 0.5544)]\n",
      "Alpha*: 0.0 tau*: 0.5544 Episode: 6578 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0007839608006179333\n",
      "Q Loss:  0.07534611970186234\n",
      "Policy Loss:  0.1793026477098465\n",
      "[(3e-05, 0.5544), (0.0, 0.55405)]\n",
      "Alpha*: 0.0 tau*: 0.55405 Episode: 6593 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.011758442036807537\n",
      "Q Loss:  0.03867895528674126\n",
      "Policy Loss:  0.049297891557216644\n",
      "[(3e-05, 0.55405), (0.0, 0.5537)]\n",
      "Alpha*: 0.0 tau*: 0.5537 Episode: 6599 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  36937.734375\n",
      "Q Loss:  36957.61328125\n",
      "Policy Loss:  -0.7541216015815735\n",
      "[(3e-05, 0.5537), (0.0, 0.55335)]\n",
      "Alpha*: 0.0 tau*: 0.55335 Episode: 6651 length: 27 #teleports:25\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.4827282130718231\n",
      "Q Loss:  0.33059749007225037\n",
      "Policy Loss:  -1.060862421989441\n",
      "[(3e-05, 0.55335), (0.0, 0.553)]\n",
      "Alpha*: 0.0 tau*: 0.553 Episode: 6666 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0008817721391096711\n",
      "Q Loss:  0.04084063693881035\n",
      "Policy Loss:  0.2196231633424759\n",
      "[(3e-05, 0.553), (0.0, 0.55265)]\n",
      "Alpha*: 0.0 tau*: 0.55265 Episode: 6673 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.01972735859453678\n",
      "Q Loss:  0.04685034602880478\n",
      "Policy Loss:  0.012534014880657196\n",
      "[(3e-05, 0.55265), (0.0, 0.5523)]\n",
      "Alpha*: 0.0 tau*: 0.5523 Episode: 6678 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.34850093722343445\n",
      "Q Loss:  0.052611906081438065\n",
      "Policy Loss:  -0.717960774898529\n",
      "[(3e-05, 0.5523), (0.0, 0.55195)]\n",
      "Alpha*: 0.0 tau*: 0.55195 Episode: 6688 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.005539397709071636\n",
      "Q Loss:  0.04888254404067993\n",
      "Policy Loss:  0.0834236592054367\n",
      "[(3e-05, 0.55195), (0.0, 0.5516)]\n",
      "Alpha*: 0.0 tau*: 0.5516 Episode: 6692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.004486519377678633\n",
      "Q Loss:  0.032405007630586624\n",
      "Policy Loss:  0.2198525369167328\n",
      "[(3e-05, 0.5516), (0.0, 0.55125)]\n",
      "Alpha*: 0.0 tau*: 0.55125 Episode: 6699 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  0.006150282919406891\n",
      "Q Loss:  0.030615532770752907\n",
      "Policy Loss:  0.23855198919773102\n",
      "[(2e-05, 0.55125), (0.0, 0.5509)]\n",
      "Alpha*: 0.0 tau*: 0.5509 Episode: 6704 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0011231382377445698\n",
      "Q Loss:  0.1258258819580078\n",
      "Policy Loss:  0.2854554057121277\n",
      "[(2e-05, 0.5509), (0.0, 0.55055)]\n",
      "Alpha*: 0.0 tau*: 0.55055 Episode: 6720 length: 4 #teleports:12\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.7606512904167175\n",
      "Q Loss:  0.947701096534729\n",
      "Policy Loss:  -0.39221078157424927\n",
      "[(2e-05, 0.55055), (0.0, 0.5502)]\n",
      "Alpha*: 0.0 tau*: 0.5502 Episode: 6904 length: 97 #teleports:87\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0009624859085306525\n",
      "Q Loss:  0.03783666342496872\n",
      "Policy Loss:  0.21079802513122559\n",
      "[(2e-05, 0.5502), (0.0, 0.54985)]\n",
      "Alpha*: 0.0 tau*: 0.54985 Episode: 6911 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  40697.30078125\n",
      "Q Loss:  40719.81640625\n",
      "Policy Loss:  -0.40829238295555115\n",
      "[(2e-05, 0.54985), (0.0, 0.5495)]\n",
      "Alpha*: 0.0 tau*: 0.5495 Episode: 7031 length: 49 #teleports:71\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.004961150232702494\n",
      "Q Loss:  0.13267259299755096\n",
      "Policy Loss:  0.20266419649124146\n",
      "[(2e-05, 0.5495), (0.0, 0.54915)]\n",
      "Alpha*: 0.0 tau*: 0.54915 Episode: 7042 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00685223238542676\n",
      "Q Loss:  0.06756828725337982\n",
      "Policy Loss:  0.10142841190099716\n",
      "[(2e-05, 0.54915), (0.0, 0.5488)]\n",
      "Alpha*: 0.0 tau*: 0.5488 Episode: 7050 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.5830967426300049\n",
      "Q Loss:  0.05591568350791931\n",
      "Policy Loss:  -1.2525447607040405\n",
      "[(2e-05, 0.5488), (0.0, 0.54845)]\n",
      "Alpha*: 0.0 tau*: 0.54845 Episode: 7058 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.37937843799591064\n",
      "Q Loss:  0.06571399420499802\n",
      "Policy Loss:  -0.5537819862365723\n",
      "[(2e-05, 0.54845), (0.0, 0.5481)]\n",
      "Alpha*: 0.0 tau*: 0.5481 Episode: 7063 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.026005268096923828\n",
      "Value Loss:  8308.0771484375\n",
      "Q Loss:  8312.873046875\n",
      "Policy Loss:  -0.2605774998664856\n",
      "[(2e-05, 0.5481), (0.0, 0.54775)]\n",
      "Alpha*: 0.0 tau*: 0.54775 Episode: 7321 length: 120 #teleports:138\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04600930213928223\n",
      "Value Loss:  1.9815105199813843\n",
      "Q Loss:  2.5666561126708984\n",
      "Policy Loss:  -0.6998869180679321\n",
      "[(2e-05, 0.54775), (0.0, 0.5474)]\n",
      "Alpha*: 0.0 tau*: 0.5474 Episode: 7394 length: 31 #teleports:42\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6212214827537537\n",
      "Q Loss:  0.49991923570632935\n",
      "Policy Loss:  -1.1735972166061401\n",
      "[(2e-05, 0.5474), (0.0, 0.54705)]\n",
      "Alpha*: 0.0 tau*: 0.54705 Episode: 7402 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.002913242671638727\n",
      "Q Loss:  0.009660021401941776\n",
      "Policy Loss:  0.09621688723564148\n",
      "[(2e-05, 0.54705), (0.0, 0.5467)]\n",
      "Alpha*: 0.0 tau*: 0.5467 Episode: 7409 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0011027713771909475\n",
      "Q Loss:  0.06696368753910065\n",
      "Policy Loss:  0.1344894915819168\n",
      "[(2e-05, 0.5467), (0.0, 0.54635)]\n",
      "Alpha*: 0.0 tau*: 0.54635 Episode: 7415 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0009901877492666245\n",
      "Q Loss:  0.052536871284246445\n",
      "Policy Loss:  0.2147921919822693\n",
      "[(2e-05, 0.54635), (0.0, 0.546)]\n",
      "Alpha*: 0.0 tau*: 0.546 Episode: 7421 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0030677986796945333\n",
      "Q Loss:  0.045719511806964874\n",
      "Policy Loss:  0.2519185543060303\n",
      "[(2e-05, 0.546), (0.0, 0.54565)]\n",
      "Alpha*: 0.0 tau*: 0.54565 Episode: 7429 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.004333227872848511\n",
      "Q Loss:  0.025310833007097244\n",
      "Policy Loss:  0.07408390939235687\n",
      "[(2e-05, 0.54565), (0.0, 0.5453)]\n",
      "Alpha*: 0.0 tau*: 0.5453 Episode: 7436 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0006853839149698615\n",
      "Q Loss:  0.013795150443911552\n",
      "Policy Loss:  0.06847615540027618\n",
      "[(2e-05, 0.5453), (0.0, 0.54495)]\n",
      "Alpha*: 0.0 tau*: 0.54495 Episode: 7441 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.6684070825576782\n",
      "Q Loss:  0.45753785967826843\n",
      "Policy Loss:  -1.5172151327133179\n",
      "[(2e-05, 0.54495), (0.0, 0.5446)]\n",
      "Alpha*: 0.0 tau*: 0.5446 Episode: 7462 length: 4 #teleports:17\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.0006203437806107104\n",
      "Q Loss:  0.01825142279267311\n",
      "Policy Loss:  0.07902082055807114\n",
      "[(2e-05, 0.5446), (0.0, 0.54425)]\n",
      "Alpha*: 0.0 tau*: 0.54425 Episode: 7471 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005018071969971061\n",
      "Q Loss:  0.05599702522158623\n",
      "Policy Loss:  0.2089034914970398\n",
      "[(2e-05, 0.54425), (0.0, 0.5439)]\n",
      "Alpha*: 0.0 tau*: 0.5439 Episode: 7478 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.40534454584121704\n",
      "Q Loss:  0.15149913728237152\n",
      "Policy Loss:  -1.0027673244476318\n",
      "[(2e-05, 0.5439), (0.0, 0.54355), (1.0, 0.5439)]\n",
      "Alpha*: 0.0 tau*: 0.54355 Episode: 7487 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0018690288998186588\n",
      "Q Loss:  0.1791554093360901\n",
      "Policy Loss:  0.20136010646820068\n",
      "[(2e-05, 0.54355), (0.0, 0.5432), (1.0, 0.54355)]\n",
      "Alpha*: 0.0 tau*: 0.5432 Episode: 7492 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0015779651002958417\n",
      "Q Loss:  0.15307161211967468\n",
      "Policy Loss:  0.16629299521446228\n",
      "[(2e-05, 0.5432), (0.0, 0.54285), (1.0, 0.5432)]\n",
      "Alpha*: 0.0 tau*: 0.54285 Episode: 7498 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0007475719321519136\n",
      "Q Loss:  0.2866637110710144\n",
      "Policy Loss:  0.2861989438533783\n",
      "[(2e-05, 0.54285), (0.0, 0.54251), (1.0, 0.54285)]\n",
      "Alpha*: 0.0 tau*: 0.54251 Episode: 7508 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.04400897026062012\n",
      "Value Loss:  0.00041958666406571865\n",
      "Q Loss:  0.004721777979284525\n",
      "Policy Loss:  0.01613844744861126\n",
      "[(2e-05, 0.54251), (0.0, 0.54217), (1.0, 0.54251)]\n",
      "Alpha*: 0.0 tau*: 0.54217 Episode: 7515 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  0.003149956464767456\n",
      "Q Loss:  0.04439951479434967\n",
      "Policy Loss:  0.11060479283332825\n",
      "[(2e-05, 0.54217), (0.0, 0.54183), (1.0, 0.54217)]\n",
      "Alpha*: 0.0 tau*: 0.54183 Episode: 7522 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.6984079480171204\n",
      "Q Loss:  0.4782046675682068\n",
      "Policy Loss:  -1.7874164581298828\n",
      "[(2e-05, 0.54183), (0.0, 0.54149), (1.0, 0.54183)]\n",
      "Alpha*: 0.0 tau*: 0.54149 Episode: 7528 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.7747523188591003\n",
      "Q Loss:  0.8959277272224426\n",
      "Policy Loss:  -0.6554639339447021\n",
      "[(2e-05, 0.54149), (0.0, 0.54115), (1.0, 0.54149)]\n",
      "Alpha*: 0.0 tau*: 0.54115 Episode: 7736 length: 101 #teleports:107\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00040597509359940886\n",
      "Q Loss:  0.050222717225551605\n",
      "Policy Loss:  0.15942414104938507\n",
      "[(2e-05, 0.54115), (0.0, 0.54081), (1.0, 0.54115)]\n",
      "Alpha*: 0.0 tau*: 0.54081 Episode: 7742 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  0.7022369503974915\n",
      "Q Loss:  0.4825352728366852\n",
      "Policy Loss:  -1.691256046295166\n",
      "[(2e-05, 0.54081), (0.0, 0.54047), (1.0, 0.54081)]\n",
      "Alpha*: 0.0 tau*: 0.54047 Episode: 7748 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  181211.4375\n",
      "Q Loss:  181320.265625\n",
      "Policy Loss:  -2.166468858718872\n",
      "[(2e-05, 0.54047), (0.0, 0.54013), (1.0, 0.54047)]\n",
      "Alpha*: 0.0 tau*: 0.54013 Episode: 7770 length: 11 #teleports:11\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.5023232814855874e-05\n",
      "Q Loss:  0.5474289059638977\n",
      "Policy Loss:  0.08383341133594513\n",
      "[(2e-05, 0.54013), (0.0, 0.53979), (1.0, 0.54013)]\n",
      "Alpha*: 0.0 tau*: 0.53979 Episode: 7780 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  14035.7978515625\n",
      "Q Loss:  14044.443359375\n",
      "Policy Loss:  -0.9674593806266785\n",
      "[(2e-05, 0.53979), (0.0, 0.53945), (1.0, 0.53979)]\n",
      "Alpha*: 0.0 tau*: 0.53945 Episode: 7924 length: 71 #teleports:73\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00029054353944957256\n",
      "Q Loss:  0.004284385591745377\n",
      "Policy Loss:  0.07697085291147232\n",
      "[(2e-05, 0.53945), (0.0, 0.53911), (1.0, 0.53945)]\n",
      "Alpha*: 0.0 tau*: 0.53911 Episode: 7935 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  26219.810546875\n",
      "Q Loss:  26236.306640625\n",
      "Policy Loss:  -0.9829851984977722\n",
      "[(2e-05, 0.53911), (0.0, 0.53877), (1.0, 0.53911)]\n",
      "Alpha*: 0.0 tau*: 0.53877 Episode: 8099 length: 76 #teleports:88\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  29302.998046875\n",
      "Q Loss:  29322.00390625\n",
      "Policy Loss:  -1.5701218843460083\n",
      "[(2e-05, 0.53877), (0.0, 0.53843), (1.0, 0.53877)]\n",
      "Alpha*: 0.0 tau*: 0.53843 Episode: 8179 length: 34 #teleports:46\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.4614447057247162\n",
      "Q Loss:  0.16893018782138824\n",
      "Policy Loss:  -1.6328738927841187\n",
      "[(2e-05, 0.53843), (0.0, 0.53809), (1.0, 0.53843)]\n",
      "Alpha*: 0.0 tau*: 0.53809 Episode: 8187 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014056921005249023\n",
      "Value Loss:  0.9625552296638489\n",
      "Q Loss:  0.0029534625355154276\n",
      "Policy Loss:  -3.54757022857666\n",
      "[(2e-05, 0.53809), (0.0, 0.53775), (1.0, 0.53809)]\n",
      "Alpha*: 0.0 tau*: 0.53775 Episode: 8200 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.998367965221405\n",
      "Q Loss:  1.080741286277771\n",
      "Policy Loss:  -0.9989187121391296\n",
      "[(2e-05, 0.53775), (0.0, 0.53741)]\n",
      "Alpha*: 0.0 tau*: 0.53741 Episode: 8332 length: 72 #teleports:60\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.004564167000353336\n",
      "Q Loss:  0.07038193941116333\n",
      "Policy Loss:  0.1058768779039383\n",
      "[(2e-05, 0.53741), (0.0, 0.53707)]\n",
      "Alpha*: 0.0 tau*: 0.53707 Episode: 8343 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8585.8056640625\n",
      "Q Loss:  8591.6806640625\n",
      "Policy Loss:  -0.6696484088897705\n",
      "[(2e-05, 0.53707), (0.0, 0.53673)]\n",
      "Alpha*: 0.0 tau*: 0.53673 Episode: 8578 length: 116 #teleports:119\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4862329959869385\n",
      "Q Loss:  0.49941954016685486\n",
      "Policy Loss:  -4.613900661468506\n",
      "[(2e-05, 0.53673), (0.0, 0.53639)]\n",
      "Alpha*: 0.0 tau*: 0.53639 Episode: 8585 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00652339868247509\n",
      "Q Loss:  0.007250751834362745\n",
      "Policy Loss:  0.07900173217058182\n",
      "[(2e-05, 0.53639), (0.0, 0.53605)]\n",
      "Alpha*: 0.0 tau*: 0.53605 Episode: 8592 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00913299061357975\n",
      "Q Loss:  0.001454932615160942\n",
      "Policy Loss:  -0.015401802957057953\n",
      "[(2e-05, 0.53605), (0.0, 0.53571)]\n",
      "Alpha*: 0.0 tau*: 0.53571 Episode: 8596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.004704931750893593\n",
      "Q Loss:  0.04791931062936783\n",
      "Policy Loss:  0.16523917019367218\n",
      "[(2e-05, 0.53571), (0.0, 0.53537)]\n",
      "Alpha*: 0.0 tau*: 0.53537 Episode: 8603 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0028466577641665936\n",
      "Q Loss:  0.09800645709037781\n",
      "Policy Loss:  0.20278584957122803\n",
      "[(2e-05, 0.53537), (0.0, 0.53503)]\n",
      "Alpha*: 0.0 tau*: 0.53503 Episode: 8612 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.4436767101287842\n",
      "Q Loss:  1.8399032354354858\n",
      "Policy Loss:  -0.9815952181816101\n",
      "[(2e-05, 0.53503), (0.0, 0.53469)]\n",
      "Alpha*: 0.0 tau*: 0.53469 Episode: 8691 length: 42 #teleports:37\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.006931097246706486\n",
      "Q Loss:  0.26788488030433655\n",
      "Policy Loss:  0.21579715609550476\n",
      "[(2e-05, 0.53469), (0.0, 0.53435)]\n",
      "Alpha*: 0.0 tau*: 0.53435 Episode: 8697 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.2436007261276245\n",
      "Q Loss:  0.9066294431686401\n",
      "Policy Loss:  -3.0187675952911377\n",
      "[(2e-05, 0.53435), (0.0, 0.53401)]\n",
      "Alpha*: 0.0 tau*: 0.53401 Episode: 8704 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.872508750646375e-05\n",
      "Q Loss:  0.056676995009183884\n",
      "Policy Loss:  0.2632587254047394\n",
      "[(2e-05, 0.53401), (0.0, 0.53367)]\n",
      "Alpha*: 0.0 tau*: 0.53367 Episode: 8711 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.004597209393978119\n",
      "Q Loss:  0.04954684525728226\n",
      "Policy Loss:  0.5475596785545349\n",
      "[(2e-05, 0.53367), (0.0, 0.53333)]\n",
      "Alpha*: 0.0 tau*: 0.53333 Episode: 8720 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.49724724888801575\n",
      "Q Loss:  0.380961537361145\n",
      "Policy Loss:  -0.8928462862968445\n",
      "[(2e-05, 0.53333), (0.0, 0.53299)]\n",
      "Alpha*: 0.0 tau*: 0.53299 Episode: 8725 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.2947838306427002\n",
      "Q Loss:  0.06138481944799423\n",
      "Policy Loss:  -4.488183498382568\n",
      "[(2e-05, 0.53299), (0.0, 0.53265)]\n",
      "Alpha*: 0.0 tau*: 0.53265 Episode: 8736 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.013006448745727539\n",
      "Value Loss:  1.3046964406967163\n",
      "Q Loss:  0.8497979044914246\n",
      "Policy Loss:  -4.800148010253906\n",
      "[(2e-05, 0.53265), (0.0, 0.53231)]\n",
      "Alpha*: 0.0 tau*: 0.53231 Episode: 8747 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00018698995700106025\n",
      "Q Loss:  0.021101687103509903\n",
      "Policy Loss:  0.1694951206445694\n",
      "[(2e-05, 0.53231), (0.0, 0.53197)]\n",
      "Alpha*: 0.0 tau*: 0.53197 Episode: 8753 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.06058502197265625\n",
      "Value Loss:  0.00019417848670855165\n",
      "Q Loss:  0.0077736517414450645\n",
      "Policy Loss:  0.11456406116485596\n",
      "[(2e-05, 0.53197), (0.0, 0.53163)]\n",
      "Alpha*: 0.0 tau*: 0.53163 Episode: 8759 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.4907185137271881\n",
      "Q Loss:  0.40426650643348694\n",
      "Policy Loss:  -1.6859533786773682\n",
      "[(2e-05, 0.53163), (0.0, 0.53129)]\n",
      "Alpha*: 0.0 tau*: 0.53129 Episode: 8764 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0006930610979907215\n",
      "Q Loss:  0.009620271623134613\n",
      "Policy Loss:  0.11520293354988098\n",
      "[(2e-05, 0.53129), (0.0, 0.53095)]\n",
      "Alpha*: 0.0 tau*: 0.53095 Episode: 8772 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.007624398916959763\n",
      "Q Loss:  0.03517356142401695\n",
      "Policy Loss:  0.06921353191137314\n",
      "[(2e-05, 0.53095), (0.0, 0.53061)]\n",
      "Alpha*: 0.0 tau*: 0.53061 Episode: 8780 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.007384053431451321\n",
      "Q Loss:  0.28291720151901245\n",
      "Policy Loss:  0.31961172819137573\n",
      "[(2e-05, 0.53061), (0.0, 0.53027)]\n",
      "Alpha*: 0.0 tau*: 0.53027 Episode: 8786 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0068557290360331535\n",
      "Q Loss:  0.09447263181209564\n",
      "Policy Loss:  0.1522998958826065\n",
      "[(2e-05, 0.53027), (0.0, 0.52993)]\n",
      "Alpha*: 0.0 tau*: 0.52993 Episode: 8791 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0005137841799296439\n",
      "Q Loss:  0.10946351289749146\n",
      "Policy Loss:  0.2503424286842346\n",
      "[(2e-05, 0.52993), (0.0, 0.52959)]\n",
      "Alpha*: 0.0 tau*: 0.52959 Episode: 8801 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006877388805150986\n",
      "Q Loss:  0.04693782702088356\n",
      "Policy Loss:  0.5395046472549438\n",
      "[(2e-05, 0.52959), (0.0, 0.52925)]\n",
      "Alpha*: 0.0 tau*: 0.52925 Episode: 8807 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.005272543989121914\n",
      "Q Loss:  0.23473109304904938\n",
      "Policy Loss:  0.21356770396232605\n",
      "[(2e-05, 0.52925), (0.0, 0.52891), (1.0, 0.52925)]\n",
      "Alpha*: 0.0 tau*: 0.52891 Episode: 8812 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.001266902545467019\n",
      "Q Loss:  0.043182842433452606\n",
      "Policy Loss:  0.3347689211368561\n",
      "[(2e-05, 0.52891), (0.0, 0.52857), (1.0, 0.52891)]\n",
      "Alpha*: 0.0 tau*: 0.52857 Episode: 8818 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.025005817413330078\n",
      "Value Loss:  2.312819004058838\n",
      "Q Loss:  1.2422053813934326\n",
      "Policy Loss:  -6.360424995422363\n",
      "[(2e-05, 0.52857), (0.0, 0.52823), (1.0, 0.52857)]\n",
      "Alpha*: 0.0 tau*: 0.52823 Episode: 8830 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.01800251007080078\n",
      "Value Loss:  41473.8046875\n",
      "Q Loss:  41504.046875\n",
      "Policy Loss:  -2.7988221645355225\n",
      "[(2e-05, 0.52823), (0.0, 0.52789), (1.0, 0.52823)]\n",
      "Alpha*: 0.0 tau*: 0.52789 Episode: 8869 length: 24 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04400992393493652\n",
      "Value Loss:  3.109009027481079\n",
      "Q Loss:  4.027052402496338\n",
      "Policy Loss:  -1.46734619140625\n",
      "[(2e-05, 0.52789), (0.0, 0.52755), (1.0, 0.52789)]\n",
      "Alpha*: 0.0 tau*: 0.52755 Episode: 8912 length: 17 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.001966803567484021\n",
      "Q Loss:  0.055290453135967255\n",
      "Policy Loss:  0.15837456285953522\n",
      "[(2e-05, 0.52755), (0.0, 0.52721), (1.0, 0.52755)]\n",
      "Alpha*: 0.0 tau*: 0.52721 Episode: 8922 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.47538354992866516\n",
      "Q Loss:  0.145996555685997\n",
      "Policy Loss:  -2.4165093898773193\n",
      "[(2e-05, 0.52721), (0.0, 0.52687), (1.0, 0.52721)]\n",
      "Alpha*: 0.0 tau*: 0.52687 Episode: 8935 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0005911029875278473\n",
      "Q Loss:  0.01178451906889677\n",
      "Policy Loss:  0.16542531549930573\n",
      "[(2e-05, 0.52687), (0.0, 0.52653), (1.0, 0.52687)]\n",
      "Alpha*: 0.0 tau*: 0.52653 Episode: 8941 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.003267554333433509\n",
      "Q Loss:  0.02875005267560482\n",
      "Policy Loss:  0.277945339679718\n",
      "[(2e-05, 0.52653), (0.0, 0.52619), (1.0, 0.52653)]\n",
      "Alpha*: 0.0 tau*: 0.52619 Episode: 8951 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.62227217212785e-06\n",
      "Q Loss:  0.12336083501577377\n",
      "Policy Loss:  0.44237545132637024\n",
      "[(2e-05, 0.52619), (0.0, 0.52586), (1.0, 0.52619)]\n",
      "Alpha*: 0.0 tau*: 0.52586 Episode: 8958 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  23695.2109375\n",
      "Q Loss:  23713.029296875\n",
      "Policy Loss:  -1.6466420888900757\n",
      "[(2e-05, 0.52586), (0.0, 0.52553), (1.0, 0.52586)]\n",
      "Alpha*: 0.0 tau*: 0.52553 Episode: 9047 length: 42 #teleports:47\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0030598363373428583\n",
      "Q Loss:  0.025728385895490646\n",
      "Policy Loss:  0.030299168080091476\n",
      "[(2e-05, 0.52553), (0.0, 0.5252), (1.0, 0.52553)]\n",
      "Alpha*: 0.0 tau*: 0.5252 Episode: 9056 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0014341098722070456\n",
      "Q Loss:  0.06409285217523575\n",
      "Policy Loss:  0.3671863079071045\n",
      "[(2e-05, 0.5252), (0.0, 0.52487), (1.0, 0.5252)]\n",
      "Alpha*: 0.0 tau*: 0.52487 Episode: 9062 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  43265.31640625\n",
      "Q Loss:  43297.828125\n",
      "Policy Loss:  -2.967879295349121\n",
      "[(2e-05, 0.52487), (0.0, 0.52454), (1.0, 0.52487)]\n",
      "Alpha*: 0.0 tau*: 0.52454 Episode: 9113 length: 23 #teleports:28\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0001934390893438831\n",
      "Q Loss:  0.010431366972625256\n",
      "Policy Loss:  0.19473813474178314\n",
      "[(2e-05, 0.52454), (0.0, 0.52421), (1.0, 0.52454)]\n",
      "Alpha*: 0.0 tau*: 0.52421 Episode: 9117 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.601863980293274\n",
      "Q Loss:  1.149485468864441\n",
      "Policy Loss:  -5.124560832977295\n",
      "[(2e-05, 0.52421), (0.0, 0.52388), (1.0, 0.52421)]\n",
      "Alpha*: 0.0 tau*: 0.52388 Episode: 9124 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.003342144191265106\n",
      "Q Loss:  0.28428155183792114\n",
      "Policy Loss:  0.2770301103591919\n",
      "[(2e-05, 0.52388), (0.0, 0.52355), (1.0, 0.52388)]\n",
      "Alpha*: 0.0 tau*: 0.52355 Episode: 9129 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  19508.18359375\n",
      "Q Loss:  19523.080078125\n",
      "Policy Loss:  -2.544964551925659\n",
      "[(2e-05, 0.52355), (0.0, 0.52322), (1.0, 0.52355)]\n",
      "Alpha*: 0.0 tau*: 0.52322 Episode: 9233 length: 51 #teleports:53\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.5239074230194092\n",
      "Q Loss:  0.08406183868646622\n",
      "Policy Loss:  -2.955418109893799\n",
      "[(2e-05, 0.52322), (0.0, 0.52289), (1.0, 0.52322)]\n",
      "Alpha*: 0.0 tau*: 0.52289 Episode: 9242 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.04901123046875\n",
      "Value Loss:  0.002794155851006508\n",
      "Q Loss:  0.04452434927225113\n",
      "Policy Loss:  0.09878785163164139\n",
      "[(2e-05, 0.52289), (0.0, 0.52256), (1.0, 0.52289)]\n",
      "Alpha*: 0.0 tau*: 0.52256 Episode: 9249 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  23134.33203125\n",
      "Q Loss:  23152.36328125\n",
      "Policy Loss:  -3.3661599159240723\n",
      "[(2e-05, 0.52256), (0.0, 0.52223), (1.0, 0.52256)]\n",
      "Alpha*: 0.0 tau*: 0.52223 Episode: 9320 length: 43 #teleports:28\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00352376326918602\n",
      "Q Loss:  0.017102591693401337\n",
      "Policy Loss:  0.04649137705564499\n",
      "[(2e-05, 0.52223), (0.0, 0.5219), (1.0, 0.52223)]\n",
      "Alpha*: 0.0 tau*: 0.5219 Episode: 9325 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.8274685144424438\n",
      "Q Loss:  1.592328429222107\n",
      "Policy Loss:  -4.639419078826904\n",
      "[(2e-05, 0.5219), (0.0, 0.52157), (1.0, 0.5219)]\n",
      "Alpha*: 0.0 tau*: 0.52157 Episode: 9332 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0029115257784724236\n",
      "Q Loss:  0.27370309829711914\n",
      "Policy Loss:  0.2944730818271637\n",
      "[(2e-05, 0.52157), (0.0, 0.52124), (1.0, 0.52157)]\n",
      "Alpha*: 0.0 tau*: 0.52124 Episode: 9341 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.000972065725363791\n",
      "Q Loss:  0.03853490948677063\n",
      "Policy Loss:  0.10379737615585327\n",
      "[(2e-05, 0.52124), (0.0, 0.52091), (1.0, 0.52124)]\n",
      "Alpha*: 0.0 tau*: 0.52091 Episode: 9350 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0002712554414756596\n",
      "Q Loss:  0.06045825034379959\n",
      "Policy Loss:  0.2761732339859009\n",
      "[(2e-05, 0.52091), (0.0, 0.52058), (1.0, 0.52091)]\n",
      "Alpha*: 0.0 tau*: 0.52058 Episode: 9362 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.055497169494629\n",
      "Q Loss:  1.0629394054412842\n",
      "Policy Loss:  -2.154212474822998\n",
      "[(2e-05, 0.52058), (0.0, 0.52025), (1.0, 0.52058)]\n",
      "Alpha*: 0.0 tau*: 0.52025 Episode: 9545 length: 90 #teleports:93\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.005921999458223581\n",
      "Q Loss:  0.14932486414909363\n",
      "Policy Loss:  0.2605360448360443\n",
      "[(2e-05, 0.52025), (0.0, 0.51992), (1.0, 0.52025)]\n",
      "Alpha*: 0.0 tau*: 0.51992 Episode: 9554 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.003331560641527176\n",
      "Q Loss:  0.03733401000499725\n",
      "Policy Loss:  0.06857429444789886\n",
      "[(2e-05, 0.51992), (0.0, 0.51959), (1.0, 0.51992)]\n",
      "Alpha*: 0.0 tau*: 0.51959 Episode: 9559 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00019845268980134279\n",
      "Q Loss:  0.0506046898663044\n",
      "Policy Loss:  0.2433445006608963\n",
      "[(2e-05, 0.51959), (0.0, 0.51926), (1.0, 0.51959)]\n",
      "Alpha*: 0.0 tau*: 0.51926 Episode: 9570 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.018190860748291\n",
      "Q Loss:  1.5773048400878906\n",
      "Policy Loss:  -5.308352947235107\n",
      "[(2e-05, 0.51926), (0.0, 0.51893), (1.0, 0.51926)]\n",
      "Alpha*: 0.0 tau*: 0.51893 Episode: 9577 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.0137786865234375\n",
      "Value Loss:  2.0329792499542236\n",
      "Q Loss:  0.052066221833229065\n",
      "Policy Loss:  -7.642422199249268\n",
      "[(2e-05, 0.51893), (0.0, 0.5186), (1.0, 0.51893)]\n",
      "Alpha*: 0.0 tau*: 0.5186 Episode: 9585 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00018933042883872986\n",
      "Q Loss:  1.3860228061676025\n",
      "Policy Loss:  0.18928921222686768\n",
      "[(2e-05, 0.5186), (0.0, 0.51827), (1.0, 0.5186)]\n",
      "Alpha*: 0.0 tau*: 0.51827 Episode: 9589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  2.057497501373291\n",
      "Q Loss:  1.6017521619796753\n",
      "Policy Loss:  -5.438177108764648\n",
      "[(2e-05, 0.51827), (0.0, 0.51794), (1.0, 0.51827)]\n",
      "Alpha*: 0.0 tau*: 0.51794 Episode: 9593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  2.0674819946289062\n",
      "Q Loss:  2.9238784313201904\n",
      "Policy Loss:  -5.382165431976318\n",
      "[(2e-05, 0.51794), (0.0, 0.51761), (1.0, 0.51794)]\n",
      "Alpha*: 0.0 tau*: 0.51761 Episode: 9604 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.569868803024292\n",
      "Q Loss:  0.486473947763443\n",
      "Policy Loss:  -2.424607753753662\n",
      "[(2e-05, 0.51761), (0.0, 0.51728), (1.0, 0.51761)]\n",
      "Alpha*: 0.0 tau*: 0.51728 Episode: 9623 length: 4 #teleports:15\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006866846815682948\n",
      "Q Loss:  0.03827584162354469\n",
      "Policy Loss:  0.0912526547908783\n",
      "[(2e-05, 0.51728), (0.0, 0.51695), (1.0, 0.51728)]\n",
      "Alpha*: 0.0 tau*: 0.51695 Episode: 9628 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.5665156841278076\n",
      "Q Loss:  0.08856604993343353\n",
      "Policy Loss:  -3.608098030090332\n",
      "[(2e-05, 0.51695), (0.0, 0.51662), (1.0, 0.51695)]\n",
      "Alpha*: 0.0 tau*: 0.51662 Episode: 9643 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.1251524686813354\n",
      "Q Loss:  0.279995858669281\n",
      "Policy Loss:  -6.353272438049316\n",
      "[(2e-05, 0.51662), (0.0, 0.51629), (1.0, 0.51662)]\n",
      "Alpha*: 0.0 tau*: 0.51629 Episode: 9651 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.02300405502319336\n",
      "Value Loss:  2.1025733947753906\n",
      "Q Loss:  1.597308874130249\n",
      "Policy Loss:  -5.9209394454956055\n",
      "[(2e-05, 0.51629), (0.0, 0.51596), (1.0, 0.51629)]\n",
      "Alpha*: 0.0 tau*: 0.51596 Episode: 9657 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.5471964478492737\n",
      "Q Loss:  0.15060089528560638\n",
      "Policy Loss:  -3.3074917793273926\n",
      "[(2e-05, 0.51596), (0.0, 0.51563), (1.0, 0.51596)]\n",
      "Alpha*: 0.0 tau*: 0.51563 Episode: 9669 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  22094.115234375\n",
      "Q Loss:  22112.302734375\n",
      "Policy Loss:  -2.0383031368255615\n",
      "[(2e-05, 0.51563), (0.0, 0.5153), (1.0, 0.51563)]\n",
      "Alpha*: 0.0 tau*: 0.5153 Episode: 9865 length: 90 #teleports:106\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.9612847566604614\n",
      "Q Loss:  2.230726957321167\n",
      "Policy Loss:  -2.1795737743377686\n",
      "[(2e-05, 0.5153), (0.0, 0.51497), (1.0, 0.5153)]\n",
      "Alpha*: 0.0 tau*: 0.51497 Episode: 9923 length: 31 #teleports:27\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.5292162299156189\n",
      "Q Loss:  0.1831703931093216\n",
      "Policy Loss:  -2.815082550048828\n",
      "[(2e-05, 0.51497), (0.0, 0.51464), (1.0, 0.51497)]\n",
      "Alpha*: 0.0 tau*: 0.51464 Episode: 9929 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7647.7138671875\n",
      "Q Loss:  7653.8486328125\n",
      "Policy Loss:  -1.6182212829589844\n",
      "[(2e-05, 0.51464), (0.0, 0.51431), (1.0, 0.51464)]\n",
      "Alpha*: 0.0 tau*: 0.51431 Episode: 10218 length: 130 #teleports:159\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.118194818496704\n",
      "Q Loss:  1.4062573909759521\n",
      "Policy Loss:  -1.2674264907836914\n",
      "[(2e-05, 0.51431), (0.0, 0.51398), (1.0, 0.51431)]\n",
      "Alpha*: 0.0 tau*: 0.51398 Episode: 10330 length: 49 #teleports:63\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.5186402201652527\n",
      "Q Loss:  0.11432551592588425\n",
      "Policy Loss:  -3.4606847763061523\n",
      "[(2e-05, 0.51398), (0.0, 0.51365), (1.0, 0.51398)]\n",
      "Alpha*: 0.0 tau*: 0.51365 Episode: 10337 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.05167222023010254\n",
      "Value Loss:  2.216369152069092\n",
      "Q Loss:  0.021513892337679863\n",
      "Policy Loss:  -7.206696033477783\n",
      "[(2e-05, 0.51365), (0.0, 0.51332), (1.0, 0.51365)]\n",
      "Alpha*: 0.0 tau*: 0.51332 Episode: 10350 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.5109543204307556\n",
      "Q Loss:  0.09912512451410294\n",
      "Policy Loss:  -3.4711034297943115\n",
      "[(2e-05, 0.51332), (0.0, 0.51299), (1.0, 0.51332)]\n",
      "Alpha*: 0.0 tau*: 0.51299 Episode: 10361 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.242886781692505\n",
      "Q Loss:  1.6850180625915527\n",
      "Policy Loss:  -6.1313090324401855\n",
      "[(2e-05, 0.51299), (0.0, 0.51266), (1.0, 0.51299)]\n",
      "Alpha*: 0.0 tau*: 0.51266 Episode: 10376 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  4.466946847969666e-05\n",
      "Q Loss:  0.08582799136638641\n",
      "Policy Loss:  0.16816964745521545\n",
      "[(2e-05, 0.51266), (0.0, 0.51233), (1.0, 0.51266)]\n",
      "Alpha*: 0.0 tau*: 0.51233 Episode: 10382 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.5583200454711914\n",
      "Q Loss:  1.3637566566467285\n",
      "Policy Loss:  -3.4416236877441406\n",
      "[(2e-05, 0.51233), (0.0, 0.512), (1.0, 0.51233)]\n",
      "Alpha*: 0.0 tau*: 0.512 Episode: 10513 length: 64 #teleports:67\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0001129868469433859\n",
      "Q Loss:  0.0420135036110878\n",
      "Policy Loss:  0.15817978978157043\n",
      "[(2e-05, 0.512), (0.0, 0.51167), (1.0, 0.512)]\n",
      "Alpha*: 0.0 tau*: 0.51167 Episode: 10528 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00013122982636559755\n",
      "Q Loss:  1.4137471914291382\n",
      "Policy Loss:  0.15020515024662018\n",
      "[(2e-05, 0.51167), (0.0, 0.51134), (1.0, 0.51167)]\n",
      "Alpha*: 0.0 tau*: 0.51134 Episode: 10534 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  2.2882864475250244\n",
      "Q Loss:  1.9945122003555298\n",
      "Policy Loss:  -5.589750289916992\n",
      "[(2e-05, 0.51134), (0.0, 0.51101), (1.0, 0.51134)]\n",
      "Alpha*: 0.0 tau*: 0.51101 Episode: 10545 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0002611932868603617\n",
      "Q Loss:  0.009599835611879826\n",
      "Policy Loss:  0.08249641209840775\n",
      "[(2e-05, 0.51101), (0.0, 0.51068), (1.0, 0.51101)]\n",
      "Alpha*: 0.0 tau*: 0.51068 Episode: 10551 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  2.298522472381592\n",
      "Q Loss:  1.7261232137680054\n",
      "Policy Loss:  -6.150718688964844\n",
      "[(2e-05, 0.51068), (0.0, 0.51035), (1.0, 0.51068)]\n",
      "Alpha*: 0.0 tau*: 0.51035 Episode: 10561 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.302682399749756\n",
      "Q Loss:  1.7301756143569946\n",
      "Policy Loss:  -6.183771133422852\n",
      "[(2e-05, 0.51035), (0.0, 0.51002), (1.0, 0.51035)]\n",
      "Alpha*: 0.0 tau*: 0.51002 Episode: 10571 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.3059580326080322\n",
      "Q Loss:  1.742902159690857\n",
      "Policy Loss:  -6.366050720214844\n",
      "[(2e-05, 0.51002), (0.0, 0.50969), (1.0, 0.51002)]\n",
      "Alpha*: 0.0 tau*: 0.50969 Episode: 10585 length: 4 #teleports:10\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.5202951292158104e-05\n",
      "Q Loss:  0.08058357983827591\n",
      "Policy Loss:  0.1646716296672821\n",
      "[(2e-05, 0.50969), (0.0, 0.50936), (1.0, 0.50969)]\n",
      "Alpha*: 0.0 tau*: 0.50936 Episode: 10591 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.1215531826019287\n",
      "Q Loss:  0.9351038336753845\n",
      "Policy Loss:  -2.3037304878234863\n",
      "[(2e-05, 0.50936), (0.0, 0.50903), (1.0, 0.50936)]\n",
      "Alpha*: 0.0 tau*: 0.50903 Episode: 10759 length: 80 #teleports:88\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0009315332281403244\n",
      "Q Loss:  0.007822640240192413\n",
      "Policy Loss:  0.03453052043914795\n",
      "[(2e-05, 0.50903), (0.0, 0.5087), (1.0, 0.50903)]\n",
      "Alpha*: 0.0 tau*: 0.5087 Episode: 10764 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.050009965896606445\n",
      "Value Loss:  7530.7822265625\n",
      "Q Loss:  7536.70166015625\n",
      "Policy Loss:  -2.8274879455566406\n",
      "[(2e-05, 0.5087), (0.0, 0.50837), (1.0, 0.5087)]\n",
      "Alpha*: 0.0 tau*: 0.50837 Episode: 11022 length: 132 #teleports:126\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.001402490772306919\n",
      "Q Loss:  0.3466932773590088\n",
      "Policy Loss:  0.48058485984802246\n",
      "[(2e-05, 0.50837), (0.0, 0.50804), (1.0, 0.50837)]\n",
      "Alpha*: 0.0 tau*: 0.50804 Episode: 11027 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.051011085510253906\n",
      "Value Loss:  0.946675717830658\n",
      "Q Loss:  0.13982953131198883\n",
      "Policy Loss:  -5.636755466461182\n",
      "[(2e-05, 0.50804), (0.0, 0.50771), (1.0, 0.50804)]\n",
      "Alpha*: 0.0 tau*: 0.50771 Episode: 11032 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  1.8313120603561401\n",
      "Q Loss:  1.6165398359298706\n",
      "Policy Loss:  -2.316420555114746\n",
      "[(2e-05, 0.50771), (0.0, 0.50738), (1.0, 0.50771)]\n",
      "Alpha*: 0.0 tau*: 0.50738 Episode: 11113 length: 40 #teleports:41\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.3375589847564697\n",
      "Q Loss:  0.004358211066573858\n",
      "Policy Loss:  -8.685125350952148\n",
      "[(2e-05, 0.50738), (0.0, 0.50705), (1.0, 0.50738)]\n",
      "Alpha*: 0.0 tau*: 0.50705 Episode: 11121 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005788602866232395\n",
      "Q Loss:  0.3053295314311981\n",
      "Policy Loss:  0.20982274413108826\n",
      "[(2e-05, 0.50705), (0.0, 0.50672), (1.0, 0.50705)]\n",
      "Alpha*: 0.0 tau*: 0.50672 Episode: 11128 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0005986736505292356\n",
      "Q Loss:  0.5445883274078369\n",
      "Policy Loss:  0.5270469188690186\n",
      "[(2e-05, 0.50672), (0.0, 0.50639), (1.0, 0.50672)]\n",
      "Alpha*: 0.0 tau*: 0.50639 Episode: 11134 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.4365017705131322e-05\n",
      "Q Loss:  1.3815714120864868\n",
      "Policy Loss:  0.06645478308200836\n",
      "[(2e-05, 0.50639), (0.0, 0.50606), (1.0, 0.50639)]\n",
      "Alpha*: 0.0 tau*: 0.50606 Episode: 11143 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.3482401371002197\n",
      "Q Loss:  1.4260995388031006\n",
      "Policy Loss:  -7.903181076049805\n",
      "[(2e-05, 0.50606), (0.0, 0.50574), (1.0, 0.50606)]\n",
      "Alpha*: 0.0 tau*: 0.50574 Episode: 11153 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.3492202758789062\n",
      "Q Loss:  0.36945247650146484\n",
      "Policy Loss:  -6.195139408111572\n",
      "[(2e-05, 0.50574), (0.0, 0.50542), (1.0, 0.50574)]\n",
      "Alpha*: 0.0 tau*: 0.50542 Episode: 11159 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00019358719873707741\n",
      "Q Loss:  0.03408493846654892\n",
      "Policy Loss:  0.2977747917175293\n",
      "[(2e-05, 0.50542), (0.0, 0.5051), (1.0, 0.50542)]\n",
      "Alpha*: 0.0 tau*: 0.5051 Episode: 11168 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.4598657488822937\n",
      "Q Loss:  0.4195093512535095\n",
      "Policy Loss:  -2.3234305381774902\n",
      "[(2e-05, 0.5051), (0.0, 0.50478), (1.0, 0.5051)]\n",
      "Alpha*: 0.0 tau*: 0.50478 Episode: 11176 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.4569709002971649\n",
      "Q Loss:  0.05650061368942261\n",
      "Policy Loss:  -2.997235059738159\n",
      "[(2e-05, 0.50478), (0.0, 0.50446), (1.0, 0.50478)]\n",
      "Alpha*: 0.0 tau*: 0.50446 Episode: 11183 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.7671304941177368\n",
      "Q Loss:  1.511459231376648\n",
      "Policy Loss:  -3.58837890625\n",
      "[(2e-05, 0.50446), (0.0, 0.50414), (1.0, 0.50446)]\n",
      "Alpha*: 0.0 tau*: 0.50414 Episode: 11316 length: 65 #teleports:68\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  2.346745014190674\n",
      "Q Loss:  0.03428752347826958\n",
      "Policy Loss:  -7.3516998291015625\n",
      "[(2e-05, 0.50414), (0.0, 0.50382), (1.0, 0.50414)]\n",
      "Alpha*: 0.0 tau*: 0.50382 Episode: 11326 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  5.451010656543076e-05\n",
      "Q Loss:  0.0037197789642959833\n",
      "Policy Loss:  0.023024937137961388\n",
      "[(2e-05, 0.50382), (0.0, 0.5035), (1.0, 0.50382)]\n",
      "Alpha*: 0.0 tau*: 0.5035 Episode: 11334 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.036008358001708984\n",
      "Value Loss:  1.4489380191662349e-05\n",
      "Q Loss:  0.002493529813364148\n",
      "Policy Loss:  0.031658757477998734\n",
      "[(2e-05, 0.5035), (0.0, 0.50318), (1.0, 0.5035)]\n",
      "Alpha*: 0.0 tau*: 0.50318 Episode: 11340 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0380094051361084\n",
      "Value Loss:  2.341641664505005\n",
      "Q Loss:  1.8037683963775635\n",
      "Policy Loss:  -6.506710052490234\n",
      "[(2e-05, 0.50318), (0.0, 0.50286), (1.0, 0.50318)]\n",
      "Alpha*: 0.0 tau*: 0.50286 Episode: 11347 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.00017938140081241727\n",
      "Q Loss:  0.2896696925163269\n",
      "Policy Loss:  0.29566651582717896\n",
      "[(2e-05, 0.50286), (0.0, 0.50254), (1.0, 0.50286)]\n",
      "Alpha*: 0.0 tau*: 0.50254 Episode: 11356 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  8.182867168216035e-05\n",
      "Q Loss:  0.017860600724816322\n",
      "Policy Loss:  0.07795972377061844\n",
      "[(2e-05, 0.50254), (0.0, 0.50222), (1.0, 0.50254)]\n",
      "Alpha*: 0.0 tau*: 0.50222 Episode: 11368 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.8784961866913363e-05\n",
      "Q Loss:  0.03822995349764824\n",
      "Policy Loss:  0.08919432014226913\n",
      "[(2e-05, 0.50222), (0.0, 0.5019), (1.0, 0.50222)]\n",
      "Alpha*: 0.0 tau*: 0.5019 Episode: 11373 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.716386320069432e-05\n",
      "Q Loss:  0.0379566065967083\n",
      "Policy Loss:  0.09008297324180603\n",
      "[(2e-05, 0.5019), (0.0, 0.50158), (1.0, 0.5019)]\n",
      "Alpha*: 0.0 tau*: 0.50158 Episode: 11380 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.04200863838195801\n",
      "Value Loss:  2.758244752883911\n",
      "Q Loss:  2.5638506412506104\n",
      "Policy Loss:  -2.724900007247925\n",
      "[(2e-05, 0.50158), (0.0, 0.50126), (1.0, 0.50158)]\n",
      "Alpha*: 0.0 tau*: 0.50126 Episode: 11433 length: 29 #teleports:24\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  37506.86328125\n",
      "Q Loss:  37534.890625\n",
      "Policy Loss:  -3.054887533187866\n",
      "[(2e-05, 0.50126), (0.0, 0.50094), (1.0, 0.50126)]\n",
      "Alpha*: 0.0 tau*: 0.50094 Episode: 11548 length: 53 #teleports:62\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.361363410949707\n",
      "Q Loss:  0.005024307873100042\n",
      "Policy Loss:  -8.71567153930664\n",
      "[(2e-05, 0.50094), (0.0, 0.50062), (1.0, 0.50094)]\n",
      "Alpha*: 0.0 tau*: 0.50062 Episode: 11563 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.390535593032837\n",
      "Q Loss:  0.0015811651246622205\n",
      "Policy Loss:  -9.03071117401123\n",
      "[(2e-05, 0.50062), (0.0, 0.5003), (1.0, 0.50062)]\n",
      "Alpha*: 0.0 tau*: 0.5003 Episode: 11573 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.41627836227417\n",
      "Q Loss:  0.25782743096351624\n",
      "Policy Loss:  -8.049427032470703\n",
      "[(2e-05, 0.5003), (0.0, 0.49998), (1.0, 0.5003)]\n",
      "Alpha*: 0.0 tau*: 0.49998 Episode: 11582 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.8786089420318604\n",
      "Q Loss:  0.044351883232593536\n",
      "Policy Loss:  -11.493879318237305\n",
      "[(2e-05, 0.49998), (0.0, 0.49966), (1.0, 0.49998)]\n",
      "Alpha*: 0.0 tau*: 0.49966 Episode: 11595 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  40561.7109375\n",
      "Q Loss:  40592.2578125\n",
      "Policy Loss:  -3.022864580154419\n",
      "[(2e-05, 0.49966), (0.0, 0.49934), (1.0, 0.49966)]\n",
      "Alpha*: 0.0 tau*: 0.49934 Episode: 11709 length: 49 #teleports:65\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008373060263693333\n",
      "Q Loss:  0.03414478152990341\n",
      "Policy Loss:  0.05298706889152527\n",
      "[(2e-05, 0.49934), (0.0, 0.49902), (1.0, 0.49934)]\n",
      "Alpha*: 0.0 tau*: 0.49902 Episode: 11715 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  19483.580078125\n",
      "Q Loss:  19498.5390625\n",
      "Policy Loss:  -2.0519461631774902\n",
      "[(2e-05, 0.49902), (0.0, 0.4987), (1.0, 0.49902)]\n",
      "Alpha*: 0.0 tau*: 0.4987 Episode: 11824 length: 51 #teleports:58\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.7857738733291626\n",
      "Q Loss:  1.647770643234253\n",
      "Policy Loss:  -1.8461483716964722\n",
      "[(2e-05, 0.4987), (0.0, 0.49838), (1.0, 0.4987)]\n",
      "Alpha*: 0.0 tau*: 0.49838 Episode: 11885 length: 32 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  15285.5849609375\n",
      "Q Loss:  15296.8779296875\n",
      "Policy Loss:  -3.7127742767333984\n",
      "[(2e-05, 0.49838), (0.0, 0.49806), (1.0, 0.49838)]\n",
      "Alpha*: 0.0 tau*: 0.49806 Episode: 12013 length: 65 #teleports:63\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  15402.6083984375\n",
      "Q Loss:  15414.0390625\n",
      "Policy Loss:  -4.113272666931152\n",
      "[(2e-05, 0.49806), (0.0, 0.49774), (1.0, 0.49806)]\n",
      "Alpha*: 0.0 tau*: 0.49774 Episode: 12297 length: 129 #teleports:155\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.737050175666809\n",
      "Q Loss:  1.674850344657898\n",
      "Policy Loss:  -1.8781439065933228\n",
      "[(2e-05, 0.49774), (0.0, 0.49742), (1.0, 0.49774)]\n",
      "Alpha*: 0.0 tau*: 0.49742 Episode: 12374 length: 39 #teleports:38\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0013520604697987437\n",
      "Q Loss:  0.0042447117157280445\n",
      "Policy Loss:  0.049787357449531555\n",
      "[(2e-05, 0.49742), (0.0, 0.4971), (1.0, 0.49742)]\n",
      "Alpha*: 0.0 tau*: 0.4971 Episode: 12379 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.8619283437728882\n",
      "Q Loss:  1.7252888679504395\n",
      "Policy Loss:  -1.6238189935684204\n",
      "[(2e-05, 0.4971), (0.0, 0.49678), (1.0, 0.4971)]\n",
      "Alpha*: 0.0 tau*: 0.49678 Episode: 12433 length: 30 #teleports:24\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  3.017050266265869\n",
      "Q Loss:  0.3297456204891205\n",
      "Policy Loss:  -8.540167808532715\n",
      "[(2e-05, 0.49678), (0.0, 0.49646), (1.0, 0.49678)]\n",
      "Alpha*: 0.0 tau*: 0.49646 Episode: 12441 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0038329288363456726\n",
      "Q Loss:  1.777565598487854\n",
      "Policy Loss:  0.11366729438304901\n",
      "[(2e-05, 0.49646), (0.0, 0.49614), (1.0, 0.49646)]\n",
      "Alpha*: 0.0 tau*: 0.49614 Episode: 12451 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00446600466966629\n",
      "Q Loss:  0.2146572768688202\n",
      "Policy Loss:  0.05270896106958389\n",
      "[(2e-05, 0.49614), (0.0, 0.49582), (1.0, 0.49614)]\n",
      "Alpha*: 0.0 tau*: 0.49582 Episode: 12458 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.004495850298553705\n",
      "Q Loss:  0.8782625198364258\n",
      "Policy Loss:  0.6374853849411011\n",
      "[(2e-05, 0.49582), (0.0, 0.4955), (1.0, 0.49582)]\n",
      "Alpha*: 0.0 tau*: 0.4955 Episode: 12464 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.7102959156036377\n",
      "Q Loss:  1.2713751792907715\n",
      "Policy Loss:  -3.6627867221832275\n",
      "[(2e-05, 0.4955), (0.0, 0.49518), (1.0, 0.4955)]\n",
      "Alpha*: 0.0 tau*: 0.49518 Episode: 12670 length: 114 #teleports:92\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.060014963150024414\n",
      "Value Loss:  0.004403147380799055\n",
      "Q Loss:  0.26625943183898926\n",
      "Policy Loss:  0.18778109550476074\n",
      "[(2e-05, 0.49518), (0.0, 0.49486), (1.0, 0.49518)]\n",
      "Alpha*: 0.0 tau*: 0.49486 Episode: 12677 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00040229284786619246\n",
      "Q Loss:  0.001754502416588366\n",
      "Policy Loss:  0.014485085383057594\n",
      "[(2e-05, 0.49486), (0.0, 0.49454), (1.0, 0.49486)]\n",
      "Alpha*: 0.0 tau*: 0.49454 Episode: 12684 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0009854185627773404\n",
      "Q Loss:  0.0061466326005756855\n",
      "Policy Loss:  0.06079637259244919\n",
      "[(2e-05, 0.49454), (0.0, 0.49422), (1.0, 0.49454)]\n",
      "Alpha*: 0.0 tau*: 0.49422 Episode: 12692 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0021710186265408993\n",
      "Q Loss:  0.3825802206993103\n",
      "Policy Loss:  0.5685915946960449\n",
      "[(2e-05, 0.49422), (0.0, 0.4939), (1.0, 0.49422)]\n",
      "Alpha*: 0.0 tau*: 0.4939 Episode: 12701 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013113737106323242\n",
      "Value Loss:  3.3215157985687256\n",
      "Q Loss:  2.678140163421631\n",
      "Policy Loss:  -7.45944356918335\n",
      "[(2e-05, 0.4939), (0.0, 0.49358), (1.0, 0.4939)]\n",
      "Alpha*: 0.0 tau*: 0.49358 Episode: 12707 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  6.85130653437227e-05\n",
      "Q Loss:  0.0023941684048622847\n",
      "Policy Loss:  0.007022762205451727\n",
      "[(2e-05, 0.49358), (0.0, 0.49326), (1.0, 0.49358)]\n",
      "Alpha*: 0.0 tau*: 0.49326 Episode: 12713 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.00025606341660022736\n",
      "Q Loss:  0.009473159909248352\n",
      "Policy Loss:  0.05306454002857208\n",
      "[(2e-05, 0.49326), (0.0, 0.49294), (1.0, 0.49326)]\n",
      "Alpha*: 0.0 tau*: 0.49294 Episode: 12718 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.6504313945770264\n",
      "Q Loss:  2.126829147338867\n",
      "Policy Loss:  -4.502153396606445\n",
      "[(3e-05, 0.49294), (0.0, 0.49262), (1.0, 0.49294)]\n",
      "Alpha*: 0.0 tau*: 0.49262 Episode: 12809 length: 49 #teleports:42\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  15757.68359375\n",
      "Q Loss:  15769.1708984375\n",
      "Policy Loss:  -2.3915154933929443\n",
      "[(3e-05, 0.49262), (0.0, 0.4923), (1.0, 0.49262)]\n",
      "Alpha*: 0.0 tau*: 0.4923 Episode: 12929 length: 63 #teleports:57\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.375124454498291\n",
      "Q Loss:  1.0694454908370972\n",
      "Policy Loss:  -1.7998850345611572\n",
      "[(3e-05, 0.4923), (0.0, 0.49198), (1.0, 0.4923)]\n",
      "Alpha*: 0.0 tau*: 0.49198 Episode: 13018 length: 47 #teleports:42\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.001458583166822791\n",
      "Q Loss:  0.09126562625169754\n",
      "Policy Loss:  0.17598295211791992\n",
      "[(3e-05, 0.49198), (0.0, 0.49166), (1.0, 0.49198)]\n",
      "Alpha*: 0.0 tau*: 0.49166 Episode: 13024 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.756641149520874\n",
      "Q Loss:  0.3391108512878418\n",
      "Policy Loss:  -3.6346635818481445\n",
      "[(3e-05, 0.49166), (0.0, 0.49134), (1.0, 0.49166)]\n",
      "Alpha*: 0.0 tau*: 0.49134 Episode: 13031 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.5847502946853638\n",
      "Q Loss:  0.1986793726682663\n",
      "Policy Loss:  -3.519169807434082\n",
      "[(3e-05, 0.49134), (0.0, 0.49102), (1.0, 0.49134)]\n",
      "Alpha*: 0.0 tau*: 0.49102 Episode: 13037 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012597799301147461\n",
      "Value Loss:  0.0010320795699954033\n",
      "Q Loss:  0.0025026188232004642\n",
      "Policy Loss:  0.025256061926484108\n",
      "[(3e-05, 0.49102), (0.0, 0.4907), (1.0, 0.49102)]\n",
      "Alpha*: 0.0 tau*: 0.4907 Episode: 13042 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  0.0002535291132517159\n",
      "Q Loss:  0.007216201163828373\n",
      "Policy Loss:  0.058492261916399\n",
      "[(3e-05, 0.4907), (0.0, 0.49038), (1.0, 0.4907)]\n",
      "Alpha*: 0.0 tau*: 0.49038 Episode: 13047 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  32016.90625\n",
      "Q Loss:  32041.130859375\n",
      "Policy Loss:  -4.186915874481201\n",
      "[(3e-05, 0.49038), (0.0, 0.49006), (1.0, 0.49038)]\n",
      "Alpha*: 0.0 tau*: 0.49006 Episode: 13108 length: 31 #teleports:30\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  11028.1318359375\n",
      "Q Loss:  11036.1748046875\n",
      "Policy Loss:  -3.3979990482330322\n",
      "[(3e-05, 0.49006), (0.0, 0.48974), (1.0, 0.49006)]\n",
      "Alpha*: 0.0 tau*: 0.48974 Episode: 13261 length: 90 #teleports:63\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3.704362154006958\n",
      "Q Loss:  3.0059823989868164\n",
      "Policy Loss:  -7.897066116333008\n",
      "[(3e-05, 0.48974), (0.0, 0.48942), (1.0, 0.48974)]\n",
      "Alpha*: 0.0 tau*: 0.48942 Episode: 13271 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0002455229696352035\n",
      "Q Loss:  0.00275665195658803\n",
      "Policy Loss:  0.013910235837101936\n",
      "[(3e-05, 0.48942), (0.0, 0.4891), (1.0, 0.48942)]\n",
      "Alpha*: 0.0 tau*: 0.4891 Episode: 13280 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.8281185626983643\n",
      "Q Loss:  5.318392753601074\n",
      "Policy Loss:  -7.851414203643799\n",
      "[(3e-05, 0.4891), (0.0, 0.48878), (1.0, 0.4891)]\n",
      "Alpha*: 0.0 tau*: 0.48878 Episode: 13291 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.5831790566444397\n",
      "Q Loss:  0.24197733402252197\n",
      "Policy Loss:  -3.3046793937683105\n",
      "[(3e-05, 0.48878), (0.0, 0.48846), (1.0, 0.48878)]\n",
      "Alpha*: 0.0 tau*: 0.48846 Episode: 13302 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01436161994934082\n",
      "Value Loss:  0.001175351906567812\n",
      "Q Loss:  0.5106098651885986\n",
      "Policy Loss:  0.27876728773117065\n",
      "[(3e-05, 0.48846), (0.0, 0.48814), (1.0, 0.48846)]\n",
      "Alpha*: 0.0 tau*: 0.48814 Episode: 13309 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0018634104635566473\n",
      "Q Loss:  0.04164539650082588\n",
      "Policy Loss:  0.06098126992583275\n",
      "[(3e-05, 0.48814), (0.0, 0.48782), (1.0, 0.48814)]\n",
      "Alpha*: 0.0 tau*: 0.48782 Episode: 13319 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0008075074292719364\n",
      "Q Loss:  0.001664342824369669\n",
      "Policy Loss:  -0.013259051367640495\n",
      "[(3e-05, 0.48782), (0.0, 0.4875), (1.0, 0.48782)]\n",
      "Alpha*: 0.0 tau*: 0.4875 Episode: 13326 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0003840909048449248\n",
      "Q Loss:  0.3699755370616913\n",
      "Policy Loss:  0.29034411907196045\n",
      "[(3e-05, 0.4875), (0.0, 0.48718), (1.0, 0.4875)]\n",
      "Alpha*: 0.0 tau*: 0.48718 Episode: 13337 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.049011945724487305\n",
      "Value Loss:  0.0003929586964659393\n",
      "Q Loss:  0.1748526245355606\n",
      "Policy Loss:  0.22524350881576538\n",
      "[(3e-05, 0.48718), (0.0, 0.48686), (1.0, 0.48718)]\n",
      "Alpha*: 0.0 tau*: 0.48686 Episode: 13342 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.731909990310669\n",
      "Q Loss:  3.0732531547546387\n",
      "Policy Loss:  -3.0668914318084717\n",
      "[(3e-05, 0.48686), (0.0, 0.48654), (1.0, 0.48686)]\n",
      "Alpha*: 0.0 tau*: 0.48654 Episode: 13381 length: 18 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0016128795687109232\n",
      "Q Loss:  2.6527905464172363\n",
      "Policy Loss:  0.28536808490753174\n",
      "[(3e-05, 0.48654), (0.0, 0.48622), (1.0, 0.48654)]\n",
      "Alpha*: 0.0 tau*: 0.48622 Episode: 13393 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.011597871780395508\n",
      "Value Loss:  0.5863872170448303\n",
      "Q Loss:  0.2475927174091339\n",
      "Policy Loss:  -3.3187477588653564\n",
      "[(3e-05, 0.48622), (0.0, 0.4859), (1.0, 0.48622)]\n",
      "Alpha*: 0.0 tau*: 0.4859 Episode: 13400 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.8466747999191284\n",
      "Q Loss:  1.17092764377594\n",
      "Policy Loss:  -3.358292579650879\n",
      "[(3e-05, 0.4859), (0.0, 0.48558), (1.0, 0.4859)]\n",
      "Alpha*: 0.0 tau*: 0.48558 Episode: 13505 length: 57 #teleports:48\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0003755953221116215\n",
      "Q Loss:  0.06814871728420258\n",
      "Policy Loss:  0.13488489389419556\n",
      "[(3e-05, 0.48558), (0.0, 0.48526), (1.0, 0.48558)]\n",
      "Alpha*: 0.0 tau*: 0.48526 Episode: 13512 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.207029819488525\n",
      "Q Loss:  3.4623777866363525\n",
      "Policy Loss:  -8.26076889038086\n",
      "[(3e-05, 0.48526), (0.0, 0.48494), (1.0, 0.48526)]\n",
      "Alpha*: 0.0 tau*: 0.48494 Episode: 13520 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.219437599182129\n",
      "Q Loss:  3.5341029167175293\n",
      "Policy Loss:  -8.045123100280762\n",
      "[(3e-05, 0.48494), (0.0, 0.48462), (1.0, 0.48494)]\n",
      "Alpha*: 0.0 tau*: 0.48462 Episode: 13532 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.03400778770446777\n",
      "Value Loss:  2.017925977706909\n",
      "Q Loss:  1.4773398637771606\n",
      "Policy Loss:  -3.057476758956909\n",
      "[(2e-05, 0.48462), (0.0, 0.4843), (1.0, 0.48462)]\n",
      "Alpha*: 0.0 tau*: 0.4843 Episode: 13600 length: 38 #teleports:30\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010599136352539062\n",
      "Value Loss:  0.00018331212049815804\n",
      "Q Loss:  0.11619949340820312\n",
      "Policy Loss:  0.4524548053741455\n",
      "[(2e-05, 0.4843), (0.0, 0.48398), (1.0, 0.4843)]\n",
      "Alpha*: 0.0 tau*: 0.48398 Episode: 13606 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0004086618428118527\n",
      "Q Loss:  0.03918517008423805\n",
      "Policy Loss:  0.0893445834517479\n",
      "[(2e-05, 0.48398), (0.0, 0.48366), (1.0, 0.48398)]\n",
      "Alpha*: 0.0 tau*: 0.48366 Episode: 13611 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.253249168395996\n",
      "Q Loss:  0.1535029113292694\n",
      "Policy Loss:  -10.841272354125977\n",
      "[(2e-05, 0.48366), (0.0, 0.48335), (1.0, 0.48366)]\n",
      "Alpha*: 0.0 tau*: 0.48335 Episode: 13625 length: 4 #teleports:10\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0005784548120573163\n",
      "Q Loss:  0.1185745894908905\n",
      "Policy Loss:  0.19550108909606934\n",
      "[(2e-05, 0.48335), (0.0, 0.48304), (1.0, 0.48335)]\n",
      "Alpha*: 0.0 tau*: 0.48304 Episode: 13629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00023983644496183842\n",
      "Q Loss:  2.3804471492767334\n",
      "Policy Loss:  0.1085091158747673\n",
      "[(2e-05, 0.48304), (0.0, 0.48273), (1.0, 0.48304)]\n",
      "Alpha*: 0.0 tau*: 0.48273 Episode: 13639 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00021777003712486476\n",
      "Q Loss:  0.29495131969451904\n",
      "Policy Loss:  0.22461748123168945\n",
      "[(2e-05, 0.48273), (0.0, 0.48242), (1.0, 0.48273)]\n",
      "Alpha*: 0.0 tau*: 0.48242 Episode: 13650 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00016690044139977545\n",
      "Q Loss:  0.04483489692211151\n",
      "Policy Loss:  0.06573031842708588\n",
      "[(2e-05, 0.48242), (0.0, 0.48211), (1.0, 0.48242)]\n",
      "Alpha*: 0.0 tau*: 0.48211 Episode: 13658 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.381203532218933\n",
      "Q Loss:  0.965685248374939\n",
      "Policy Loss:  -2.722440242767334\n",
      "[(2e-05, 0.48211), (0.0, 0.4818), (1.0, 0.48211)]\n",
      "Alpha*: 0.0 tau*: 0.4818 Episode: 13905 length: 128 #teleports:119\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  12.823583602905273\n",
      "Q Loss:  3.5029430389404297\n",
      "Policy Loss:  -27.081571578979492\n",
      "[(2e-05, 0.4818), (0.0, 0.48149), (1.0, 0.4818)]\n",
      "Alpha*: 0.0 tau*: 0.48149 Episode: 13917 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00016364808834623545\n",
      "Q Loss:  0.0041380515322089195\n",
      "Policy Loss:  -0.009447921998798847\n",
      "[(2e-05, 0.48149), (0.0, 0.48118), (1.0, 0.48149)]\n",
      "Alpha*: 0.0 tau*: 0.48118 Episode: 13922 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.268584251403809\n",
      "Q Loss:  3.503645181655884\n",
      "Policy Loss:  -8.717758178710938\n",
      "[(2e-05, 0.48118), (0.0, 0.48087), (1.0, 0.48118)]\n",
      "Alpha*: 0.0 tau*: 0.48087 Episode: 13932 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00022912363056093454\n",
      "Q Loss:  0.024532977491617203\n",
      "Policy Loss:  0.06762994825839996\n",
      "[(2e-05, 0.48087), (0.0, 0.48056), (1.0, 0.48087)]\n",
      "Alpha*: 0.0 tau*: 0.48056 Episode: 13941 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  8.520617485046387\n",
      "Q Loss:  3.649268388748169\n",
      "Policy Loss:  -14.240055084228516\n",
      "[(2e-05, 0.48056), (0.0, 0.48025), (1.0, 0.48056)]\n",
      "Alpha*: 0.0 tau*: 0.48025 Episode: 13950 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.10602402687072754\n",
      "Value Loss:  0.6083219051361084\n",
      "Q Loss:  0.4833957552909851\n",
      "Policy Loss:  -2.3668739795684814\n",
      "[(2e-05, 0.48025), (0.0, 0.47994), (1.0, 0.48025)]\n",
      "Alpha*: 0.0 tau*: 0.47994 Episode: 13957 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.2468132972717285\n",
      "Q Loss:  2.289368152618408\n",
      "Policy Loss:  -11.284924507141113\n",
      "[(2e-05, 0.47994), (0.0, 0.47963), (1.0, 0.47994)]\n",
      "Alpha*: 0.0 tau*: 0.47963 Episode: 13964 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  4.239243507385254\n",
      "Q Loss:  3.4986023902893066\n",
      "Policy Loss:  -8.588330268859863\n",
      "[(3e-05, 0.47963), (0.0, 0.47932), (1.0, 0.47963)]\n",
      "Alpha*: 0.0 tau*: 0.47932 Episode: 13973 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0002083539729937911\n",
      "Q Loss:  0.002261401852592826\n",
      "Policy Loss:  0.02061738446354866\n",
      "[(3e-05, 0.47932), (0.0, 0.47901), (1.0, 0.47932)]\n",
      "Alpha*: 0.0 tau*: 0.47901 Episode: 13979 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.222914218902588\n",
      "Q Loss:  0.1529257744550705\n",
      "Policy Loss:  -11.067463874816895\n",
      "[(3e-05, 0.47901), (0.0, 0.4787), (1.0, 0.47901)]\n",
      "Alpha*: 0.0 tau*: 0.4787 Episode: 13985 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.9008860767353326e-05\n",
      "Q Loss:  0.41752317547798157\n",
      "Policy Loss:  0.2831358015537262\n",
      "[(3e-05, 0.4787), (0.0, 0.47839), (1.0, 0.4787)]\n",
      "Alpha*: 0.0 tau*: 0.47839 Episode: 13992 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.914600761665497e-05\n",
      "Q Loss:  0.3133814036846161\n",
      "Policy Loss:  0.19641904532909393\n",
      "[(3e-05, 0.47839), (0.0, 0.47808), (1.0, 0.47839)]\n",
      "Alpha*: 0.0 tau*: 0.47808 Episode: 13999 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.7936320304870605\n",
      "Q Loss:  0.3606458604335785\n",
      "Policy Loss:  -12.902979850769043\n",
      "[(3e-05, 0.47808), (0.0, 0.47777), (1.0, 0.47808)]\n",
      "Alpha*: 0.0 tau*: 0.47777 Episode: 14008 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  29608.951171875\n",
      "Q Loss:  29630.474609375\n",
      "Policy Loss:  -5.273686408996582\n",
      "[(3e-05, 0.47777), (0.0, 0.47746), (1.0, 0.47777)]\n",
      "Alpha*: 0.0 tau*: 0.47746 Episode: 14151 length: 67 #teleports:76\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  7.574816663691308e-06\n",
      "Q Loss:  0.14464323222637177\n",
      "Policy Loss:  0.15226539969444275\n",
      "[(3e-05, 0.47746), (0.0, 0.47715), (1.0, 0.47746)]\n",
      "Alpha*: 0.0 tau*: 0.47715 Episode: 14158 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  1.3019851446151733\n",
      "Q Loss:  0.9757293462753296\n",
      "Policy Loss:  -1.5532257556915283\n",
      "[(3e-05, 0.47715), (0.0, 0.47684), (1.0, 0.47715)]\n",
      "Alpha*: 0.0 tau*: 0.47684 Episode: 14244 length: 50 #teleports:36\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  4.303225040435791\n",
      "Q Loss:  0.0031140001956373453\n",
      "Policy Loss:  -11.889965057373047\n",
      "[(3e-05, 0.47684), (0.0, 0.47653), (1.0, 0.47684)]\n",
      "Alpha*: 0.0 tau*: 0.47653 Episode: 14253 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.0722403860418126e-05\n",
      "Q Loss:  0.40846291184425354\n",
      "Policy Loss:  0.6646285057067871\n",
      "[(3e-05, 0.47653), (0.0, 0.47622), (1.0, 0.47653)]\n",
      "Alpha*: 0.0 tau*: 0.47622 Episode: 14259 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  43117.84765625\n",
      "Q Loss:  43147.92578125\n",
      "Policy Loss:  -3.5855488777160645\n",
      "[(3e-05, 0.47622), (0.0, 0.47591), (1.0, 0.47622)]\n",
      "Alpha*: 0.0 tau*: 0.47591 Episode: 14315 length: 23 #teleports:33\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003303266712464392\n",
      "Q Loss:  0.03136599808931351\n",
      "Policy Loss:  0.25845539569854736\n",
      "[(3e-05, 0.47591), (0.0, 0.4756), (1.0, 0.47591)]\n",
      "Alpha*: 0.0 tau*: 0.4756 Episode: 14325 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.000452106527518481\n",
      "Q Loss:  0.027577055618166924\n",
      "Policy Loss:  0.0345848873257637\n",
      "[(3e-05, 0.4756), (0.0, 0.47529), (1.0, 0.4756)]\n",
      "Alpha*: 0.0 tau*: 0.47529 Episode: 14332 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0003888849460054189\n",
      "Q Loss:  0.0038379966281354427\n",
      "Policy Loss:  -0.03038819693028927\n",
      "[(3e-05, 0.47529), (0.0, 0.47498), (1.0, 0.47529)]\n",
      "Alpha*: 0.0 tau*: 0.47498 Episode: 14343 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  38130.29296875\n",
      "Q Loss:  38156.55859375\n",
      "Policy Loss:  -4.355843544006348\n",
      "[(3e-05, 0.47498), (0.0, 0.47467), (1.0, 0.47498)]\n",
      "Alpha*: 0.0 tau*: 0.47467 Episode: 14431 length: 52 #teleports:36\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0012536172289401293\n",
      "Q Loss:  0.0011995987733826041\n",
      "Policy Loss:  -0.017931915819644928\n",
      "[(3e-05, 0.47467), (0.0, 0.47436), (1.0, 0.47467)]\n",
      "Alpha*: 0.0 tau*: 0.47436 Episode: 14437 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0012776014627888799\n",
      "Q Loss:  0.0013625288847833872\n",
      "Policy Loss:  -0.003237611846998334\n",
      "[(3e-05, 0.47436), (0.0, 0.47405), (1.0, 0.47436)]\n",
      "Alpha*: 0.0 tau*: 0.47405 Episode: 14444 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  12873.248046875\n",
      "Q Loss:  12880.939453125\n",
      "Policy Loss:  -6.051283836364746\n",
      "[(3e-05, 0.47405), (0.0, 0.47374), (1.0, 0.47405)]\n",
      "Alpha*: 0.0 tau*: 0.47374 Episode: 14595 length: 77 #teleports:74\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0022906444501131773\n",
      "Q Loss:  0.017221610993146896\n",
      "Policy Loss:  0.030934996902942657\n",
      "[(3e-05, 0.47374), (0.0, 0.47343), (1.0, 0.47374)]\n",
      "Alpha*: 0.0 tau*: 0.47343 Episode: 14602 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.1743733882904053\n",
      "Q Loss:  1.5045218467712402\n",
      "Policy Loss:  -4.490797519683838\n",
      "[(3e-05, 0.47343), (0.0, 0.47312), (1.0, 0.47343)]\n",
      "Alpha*: 0.0 tau*: 0.47312 Episode: 14648 length: 22 #teleports:24\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0005637775757350028\n",
      "Q Loss:  0.10792506486177444\n",
      "Policy Loss:  0.19481855630874634\n",
      "[(3e-05, 0.47312), (0.0, 0.47281), (1.0, 0.47312)]\n",
      "Alpha*: 0.0 tau*: 0.47281 Episode: 14654 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0013523497618734837\n",
      "Q Loss:  0.10996577888727188\n",
      "Policy Loss:  0.1851087510585785\n",
      "[(3e-05, 0.47281), (0.0, 0.4725), (1.0, 0.47281)]\n",
      "Alpha*: 0.0 tau*: 0.4725 Episode: 14663 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0037732201162725687\n",
      "Q Loss:  0.00017018496873788536\n",
      "Policy Loss:  0.0015419619157910347\n",
      "[(3e-05, 0.4725), (0.0, 0.47219), (1.0, 0.4725)]\n",
      "Alpha*: 0.0 tau*: 0.47219 Episode: 14669 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0310056209564209\n",
      "Value Loss:  0.003650062019005418\n",
      "Q Loss:  3.342672348022461\n",
      "Policy Loss:  0.15956619381904602\n",
      "[(3e-05, 0.47219), (0.0, 0.47188), (1.0, 0.47219)]\n",
      "Alpha*: 0.0 tau*: 0.47188 Episode: 14676 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.6862888932228088\n",
      "Q Loss:  0.25375545024871826\n",
      "Policy Loss:  -3.548037052154541\n",
      "[(3e-05, 0.47188), (0.0, 0.47157), (1.0, 0.47188)]\n",
      "Alpha*: 0.0 tau*: 0.47157 Episode: 14684 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  29565.423828125\n",
      "Q Loss:  29585.69140625\n",
      "Policy Loss:  -3.670670509338379\n",
      "[(3e-05, 0.47157), (0.0, 0.47126), (1.0, 0.47157)]\n",
      "Alpha*: 0.0 tau*: 0.47126 Episode: 14817 length: 67 #teleports:66\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0014283242635428905\n",
      "Q Loss:  0.001127299852669239\n",
      "Policy Loss:  0.009545361623167992\n",
      "[(3e-05, 0.47126), (0.0, 0.47095), (1.0, 0.47126)]\n",
      "Alpha*: 0.0 tau*: 0.47095 Episode: 14822 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.003027609083801508\n",
      "Q Loss:  0.029743485152721405\n",
      "Policy Loss:  0.06546539068222046\n",
      "[(3e-05, 0.47095), (0.0, 0.47064), (1.0, 0.47095)]\n",
      "Alpha*: 0.0 tau*: 0.47064 Episode: 14834 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00015570154937449843\n",
      "Q Loss:  0.713434636592865\n",
      "Policy Loss:  0.4591313898563385\n",
      "[(3e-05, 0.47064), (0.0, 0.47033), (1.0, 0.47064)]\n",
      "Alpha*: 0.0 tau*: 0.47033 Episode: 14838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.7037930488586426\n",
      "Q Loss:  0.9299716949462891\n",
      "Policy Loss:  -2.0013957023620605\n",
      "[(3e-05, 0.47033), (0.0, 0.47002), (1.0, 0.47033)]\n",
      "Alpha*: 0.0 tau*: 0.47002 Episode: 14848 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.067641905043274e-05\n",
      "Q Loss:  0.02035750262439251\n",
      "Policy Loss:  0.3375285863876343\n",
      "[(4e-05, 0.47002), (0.0, 0.46971), (1.0, 0.47002)]\n",
      "Alpha*: 0.0 tau*: 0.46971 Episode: 14855 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.1981577194528654e-05\n",
      "Q Loss:  0.002291119657456875\n",
      "Policy Loss:  0.05350547283887863\n",
      "[(4e-05, 0.46971), (0.0, 0.4694), (1.0, 0.46971)]\n",
      "Alpha*: 0.0 tau*: 0.4694 Episode: 14862 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0012730954913422465\n",
      "Q Loss:  0.10537105053663254\n",
      "Policy Loss:  0.18069744110107422\n",
      "[(4e-05, 0.4694), (0.0, 0.46909), (1.0, 0.4694)]\n",
      "Alpha*: 0.0 tau*: 0.46909 Episode: 14876 length: 4 #teleports:10\n",
      "Time for bound evaluation:  0.014086484909057617\n",
      "Value Loss:  6.528620719909668\n",
      "Q Loss:  5.719793796539307\n",
      "Policy Loss:  -10.654417991638184\n",
      "[(4e-05, 0.46909), (0.0, 0.46878), (1.0, 0.46909)]\n",
      "Alpha*: 0.0 tau*: 0.46878 Episode: 14889 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0003827983164228499\n",
      "Q Loss:  0.01549341157078743\n",
      "Policy Loss:  0.08433838188648224\n",
      "[(4e-05, 0.46878), (0.0, 0.46847), (1.0, 0.46878)]\n",
      "Alpha*: 0.0 tau*: 0.46847 Episode: 14901 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0005488157039508224\n",
      "Q Loss:  0.00689389742910862\n",
      "Policy Loss:  0.045828066766262054\n",
      "[(4e-05, 0.46847), (0.0, 0.46816), (1.0, 0.46847)]\n",
      "Alpha*: 0.0 tau*: 0.46816 Episode: 14910 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0011286054505035281\n",
      "Q Loss:  0.3590714633464813\n",
      "Policy Loss:  0.22865793108940125\n",
      "[(4e-05, 0.46816), (0.0, 0.46785), (1.0, 0.46816)]\n",
      "Alpha*: 0.0 tau*: 0.46785 Episode: 14917 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0008065658039413393\n",
      "Q Loss:  0.005018699914216995\n",
      "Policy Loss:  0.023488856852054596\n",
      "[(4e-05, 0.46785), (0.0, 0.46754), (1.0, 0.46785)]\n",
      "Alpha*: 0.0 tau*: 0.46754 Episode: 14922 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0002196660643676296\n",
      "Q Loss:  0.08847279101610184\n",
      "Policy Loss:  0.13871096074581146\n",
      "[(4e-05, 0.46754), (0.0, 0.46723), (1.0, 0.46754)]\n",
      "Alpha*: 0.0 tau*: 0.46723 Episode: 14930 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.00035021608346141875\n",
      "Q Loss:  0.011528367176651955\n",
      "Policy Loss:  0.03993799537420273\n",
      "[(4e-05, 0.46723), (0.0, 0.46692), (1.0, 0.46723)]\n",
      "Alpha*: 0.0 tau*: 0.46692 Episode: 14939 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012592077255249023\n",
      "Value Loss:  6.821102619171143\n",
      "Q Loss:  7.962994575500488\n",
      "Policy Loss:  -13.765117645263672\n",
      "[(4e-05, 0.46692), (0.0, 0.46661), (1.0, 0.46692)]\n",
      "Alpha*: 0.0 tau*: 0.46661 Episode: 14946 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.098177931969985e-05\n",
      "Q Loss:  0.0384167805314064\n",
      "Policy Loss:  0.3594124913215637\n",
      "[(4e-05, 0.46661), (0.0, 0.4663), (1.0, 0.46661)]\n",
      "Alpha*: 0.0 tau*: 0.4663 Episode: 14955 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007798133883625269\n",
      "Q Loss:  0.4038500487804413\n",
      "Policy Loss:  0.30694255232810974\n",
      "[(4e-05, 0.4663), (0.0, 0.46599), (1.0, 0.4663)]\n",
      "Alpha*: 0.0 tau*: 0.46599 Episode: 14961 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  24138.46875\n",
      "Q Loss:  24154.498046875\n",
      "Policy Loss:  -6.253048419952393\n",
      "[(4e-05, 0.46599), (0.0, 0.46568), (1.0, 0.46599)]\n",
      "Alpha*: 0.0 tau*: 0.46568 Episode: 15041 length: 41 #teleports:39\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  15708.30078125\n",
      "Q Loss:  15718.8681640625\n",
      "Policy Loss:  -4.77263879776001\n",
      "[(4e-05, 0.46568), (0.0, 0.46537), (1.0, 0.46568)]\n",
      "Alpha*: 0.0 tau*: 0.46537 Episode: 15167 length: 63 #teleports:63\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.082364559173584\n",
      "Q Loss:  4.087827682495117\n",
      "Policy Loss:  -14.339616775512695\n",
      "[(4e-05, 0.46537), (0.0, 0.46506), (1.0, 0.46537)]\n",
      "Alpha*: 0.0 tau*: 0.46506 Episode: 15173 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003471876261755824\n",
      "Q Loss:  0.0031860547605901957\n",
      "Policy Loss:  -0.013038144446909428\n",
      "[(4e-05, 0.46506), (0.0, 0.46475), (1.0, 0.46506)]\n",
      "Alpha*: 0.0 tau*: 0.46475 Episode: 15180 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0003574055153876543\n",
      "Q Loss:  4.29424524307251\n",
      "Policy Loss:  0.3464339077472687\n",
      "[(4e-05, 0.46475), (0.0, 0.46444), (1.0, 0.46475)]\n",
      "Alpha*: 0.0 tau*: 0.46444 Episode: 15186 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  36638.84375\n",
      "Q Loss:  36663.14453125\n",
      "Policy Loss:  -4.109676361083984\n",
      "[(4e-05, 0.46444), (0.0, 0.46413), (1.0, 0.46444)]\n",
      "Alpha*: 0.0 tau*: 0.46413 Episode: 15226 length: 27 #teleports:13\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0004694335802923888\n",
      "Q Loss:  0.011854887939989567\n",
      "Policy Loss:  0.0224082563072443\n",
      "[(4e-05, 0.46413), (0.0, 0.46382), (1.0, 0.46413)]\n",
      "Alpha*: 0.0 tau*: 0.46382 Episode: 15232 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  7.696648120880127\n",
      "Q Loss:  4.62021541595459\n",
      "Policy Loss:  -14.31814956665039\n",
      "[(5e-05, 0.46382), (0.0, 0.46351), (1.0, 0.46382)]\n",
      "Alpha*: 0.0 tau*: 0.46351 Episode: 15245 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.6683311462402344\n",
      "Q Loss:  1.606330156326294\n",
      "Policy Loss:  -4.157882213592529\n",
      "[(5e-05, 0.46351), (0.0, 0.4632), (1.0, 0.46351)]\n",
      "Alpha*: 0.0 tau*: 0.4632 Episode: 15295 length: 30 #teleports:20\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0014888811856508255\n",
      "Q Loss:  0.029962075874209404\n",
      "Policy Loss:  0.05689162015914917\n",
      "[(5e-05, 0.4632), (0.0, 0.46289), (1.0, 0.4632)]\n",
      "Alpha*: 0.0 tau*: 0.46289 Episode: 15304 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.5402790307998657\n",
      "Q Loss:  0.5229476094245911\n",
      "Policy Loss:  -6.608586311340332\n",
      "[(5e-05, 0.46289), (0.0, 0.46258), (1.0, 0.46289)]\n",
      "Alpha*: 0.0 tau*: 0.46258 Episode: 15313 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.0467852664296515e-05\n",
      "Q Loss:  4.413646221160889\n",
      "Policy Loss:  0.2420257180929184\n",
      "[(5e-05, 0.46258), (0.0, 0.46227), (1.0, 0.46258)]\n",
      "Alpha*: 0.0 tau*: 0.46227 Episode: 15318 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0013346972409635782\n",
      "Q Loss:  0.7775716185569763\n",
      "Policy Loss:  0.5331646203994751\n",
      "[(5e-05, 0.46227), (0.0, 0.46196), (1.0, 0.46227)]\n",
      "Alpha*: 0.0 tau*: 0.46196 Episode: 15324 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.7697713375091553\n",
      "Q Loss:  0.5423362255096436\n",
      "Policy Loss:  -4.045790672302246\n",
      "[(5e-05, 0.46196), (0.0, 0.46165), (1.0, 0.46196)]\n",
      "Alpha*: 0.0 tau*: 0.46165 Episode: 15328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0290069580078125\n",
      "Value Loss:  2.1827564239501953\n",
      "Q Loss:  1.1250909566879272\n",
      "Policy Loss:  -3.68453311920166\n",
      "[(5e-05, 0.46165), (0.0, 0.46134), (1.0, 0.46165)]\n",
      "Alpha*: 0.0 tau*: 0.46134 Episode: 15510 length: 104 #teleports:78\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005052819033153355\n",
      "Q Loss:  0.3804498612880707\n",
      "Policy Loss:  0.254059374332428\n",
      "[(5e-05, 0.46134), (0.0, 0.46103), (1.0, 0.46134)]\n",
      "Alpha*: 0.0 tau*: 0.46103 Episode: 15523 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.04801011085510254\n",
      "Value Loss:  0.0017758669564500451\n",
      "Q Loss:  0.027763426303863525\n",
      "Policy Loss:  0.03346256539225578\n",
      "[(5e-05, 0.46103), (0.0, 0.46072), (1.0, 0.46103)]\n",
      "Alpha*: 0.0 tau*: 0.46072 Episode: 15531 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.000790858524851501\n",
      "Q Loss:  0.026847241446375847\n",
      "Policy Loss:  0.03199600428342819\n",
      "[(5e-05, 0.46072), (0.0, 0.46041), (1.0, 0.46072)]\n",
      "Alpha*: 0.0 tau*: 0.46041 Episode: 15538 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00025192805333063006\n",
      "Q Loss:  0.024458199739456177\n",
      "Policy Loss:  0.35842543840408325\n",
      "[(5e-05, 0.46041), (0.0, 0.4601), (1.0, 0.46041)]\n",
      "Alpha*: 0.0 tau*: 0.4601 Episode: 15548 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  14322.7734375\n",
      "Q Loss:  14330.9169921875\n",
      "Policy Loss:  -3.0045647621154785\n",
      "[(5e-05, 0.4601), (0.0, 0.45979), (1.0, 0.4601)]\n",
      "Alpha*: 0.0 tau*: 0.45979 Episode: 15682 length: 69 #teleports:65\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.00040845165494829416\n",
      "Q Loss:  5.0031812861561775e-05\n",
      "Policy Loss:  -0.002492704661563039\n",
      "[(5e-05, 0.45979), (0.0, 0.45948), (1.0, 0.45979)]\n",
      "Alpha*: 0.0 tau*: 0.45948 Episode: 15689 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00024819187819957733\n",
      "Q Loss:  0.029095221310853958\n",
      "Policy Loss:  0.06639529764652252\n",
      "[(5e-05, 0.45948), (0.0, 0.45917), (1.0, 0.45948)]\n",
      "Alpha*: 0.0 tau*: 0.45917 Episode: 15695 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.7487427592277527\n",
      "Q Loss:  0.08130434900522232\n",
      "Policy Loss:  -2.267177104949951\n",
      "[(5e-05, 0.45917), (0.0, 0.45886), (1.0, 0.45917)]\n",
      "Alpha*: 0.0 tau*: 0.45886 Episode: 15701 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  9.094383239746094\n",
      "Q Loss:  0.03228620067238808\n",
      "Policy Loss:  -17.053730010986328\n",
      "[(5e-05, 0.45886), (0.0, 0.45855), (1.0, 0.45886)]\n",
      "Alpha*: 0.0 tau*: 0.45855 Episode: 15713 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.779945862130262e-05\n",
      "Q Loss:  0.04385445639491081\n",
      "Policy Loss:  0.37174808979034424\n",
      "[(5e-05, 0.45855), (0.0, 0.45824), (1.0, 0.45855)]\n",
      "Alpha*: 0.0 tau*: 0.45824 Episode: 15720 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.7367252707481384\n",
      "Q Loss:  0.08942420780658722\n",
      "Policy Loss:  -2.1891963481903076\n",
      "[(5e-05, 0.45824), (0.0, 0.45793), (1.0, 0.45824)]\n",
      "Alpha*: 0.0 tau*: 0.45793 Episode: 15725 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.1897783279418945\n",
      "Q Loss:  1.3301877975463867\n",
      "Policy Loss:  -5.435410499572754\n",
      "[(5e-05, 0.45793), (0.0, 0.45762), (1.0, 0.45793)]\n",
      "Alpha*: 0.0 tau*: 0.45762 Episode: 15878 length: 78 #teleports:75\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.29183292388916\n",
      "Q Loss:  8.957284927368164\n",
      "Policy Loss:  -9.761669158935547\n",
      "[(6e-05, 0.45762), (0.0, 0.45731), (1.0, 0.45762)]\n",
      "Alpha*: 0.0 tau*: 0.45731 Episode: 15885 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0006754773203283548\n",
      "Q Loss:  0.02256762981414795\n",
      "Policy Loss:  0.06590767949819565\n",
      "[(6e-05, 0.45731), (0.0, 0.457), (1.0, 0.45731)]\n",
      "Alpha*: 0.0 tau*: 0.457 Episode: 15897 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00035872196895070374\n",
      "Q Loss:  0.006801279727369547\n",
      "Policy Loss:  0.04515957087278366\n",
      "[(6e-05, 0.457), (0.0, 0.4567), (1.0, 0.457)]\n",
      "Alpha*: 0.0 tau*: 0.4567 Episode: 15905 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  10081.4345703125\n",
      "Q Loss:  10086.15625\n",
      "Policy Loss:  -3.8180880546569824\n",
      "[(6e-05, 0.4567), (0.0, 0.4564), (1.0, 0.4567)]\n",
      "Alpha*: 0.0 tau*: 0.4564 Episode: 16086 length: 98 #teleports:83\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00029566476587206125\n",
      "Q Loss:  0.07077199965715408\n",
      "Policy Loss:  0.14087867736816406\n",
      "[(6e-05, 0.4564), (0.0, 0.4561), (1.0, 0.4564)]\n",
      "Alpha*: 0.0 tau*: 0.4561 Episode: 16090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4048311710357666\n",
      "Q Loss:  1.159294843673706\n",
      "Policy Loss:  -2.34993052482605\n",
      "[(6e-05, 0.4561), (0.0, 0.4558), (1.0, 0.4561)]\n",
      "Alpha*: 0.0 tau*: 0.4558 Episode: 16097 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.7038085460662842\n",
      "Q Loss:  1.00100839138031\n",
      "Policy Loss:  -2.439650297164917\n",
      "[(6e-05, 0.4558), (0.0, 0.4555), (1.0, 0.4558)]\n",
      "Alpha*: 0.0 tau*: 0.4555 Episode: 16144 length: 31 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  35276.74609375\n",
      "Q Loss:  35293.609375\n",
      "Policy Loss:  -7.709219455718994\n",
      "[(6e-05, 0.4555), (0.0, 0.4552), (1.0, 0.4555)]\n",
      "Alpha*: 0.0 tau*: 0.4552 Episode: 16241 length: 56 #teleports:41\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.6849170923233032\n",
      "Q Loss:  0.6802916526794434\n",
      "Policy Loss:  -1.3035777807235718\n",
      "[(6e-05, 0.4552), (0.0, 0.4549), (1.0, 0.4552)]\n",
      "Alpha*: 0.0 tau*: 0.4549 Episode: 16249 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.00011940738477278501\n",
      "Q Loss:  5.034046173095703\n",
      "Policy Loss:  0.5090699195861816\n",
      "[(6e-05, 0.4549), (0.0, 0.4546), (1.0, 0.4549)]\n",
      "Alpha*: 0.0 tau*: 0.4546 Episode: 16259 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  10.045369148254395\n",
      "Q Loss:  0.007306234911084175\n",
      "Policy Loss:  -18.559993743896484\n",
      "[(6e-05, 0.4546), (0.0, 0.4543), (1.0, 0.4546)]\n",
      "Alpha*: 0.0 tau*: 0.4543 Episode: 16267 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011594057083129883\n",
      "Value Loss:  10.166699409484863\n",
      "Q Loss:  14.819036483764648\n",
      "Policy Loss:  -11.068568229675293\n",
      "[(6e-05, 0.4543), (0.0, 0.454), (1.0, 0.4543)]\n",
      "Alpha*: 0.0 tau*: 0.454 Episode: 16272 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0009153079590760171\n",
      "Q Loss:  0.0788004919886589\n",
      "Policy Loss:  0.1466899812221527\n",
      "[(6e-05, 0.454), (0.0, 0.4537), (1.0, 0.454)]\n",
      "Alpha*: 0.0 tau*: 0.4537 Episode: 16278 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011291840928606689\n",
      "Q Loss:  0.023774364963173866\n",
      "Policy Loss:  0.32569772005081177\n",
      "[(6e-05, 0.4537), (0.0, 0.4534), (1.0, 0.4537)]\n",
      "Alpha*: 0.0 tau*: 0.4534 Episode: 16283 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.047009944915771484\n",
      "Value Loss:  28206.689453125\n",
      "Q Loss:  28218.755859375\n",
      "Policy Loss:  -6.94464111328125\n",
      "[(6e-05, 0.4534), (0.0, 0.4531), (1.0, 0.4534)]\n",
      "Alpha*: 0.0 tau*: 0.4531 Episode: 16349 length: 35 #teleports:31\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0003260419180151075\n",
      "Q Loss:  1.207834005355835\n",
      "Policy Loss:  0.6638966202735901\n",
      "[(6e-05, 0.4531), (0.0, 0.4528), (1.0, 0.4531)]\n",
      "Alpha*: 0.0 tau*: 0.4528 Episode: 16353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00015054878895170987\n",
      "Q Loss:  0.0845826268196106\n",
      "Policy Loss:  0.12486787140369415\n",
      "[(6e-05, 0.4528), (0.0, 0.4525), (1.0, 0.4528)]\n",
      "Alpha*: 0.0 tau*: 0.4525 Episode: 16363 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  11.62951946258545\n",
      "Q Loss:  0.7277594208717346\n",
      "Policy Loss:  -17.689502716064453\n",
      "[(6e-05, 0.4525), (0.0, 0.4522), (1.0, 0.4525)]\n",
      "Alpha*: 0.0 tau*: 0.4522 Episode: 16371 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.5580196380615234\n",
      "Q Loss:  1.704359769821167\n",
      "Policy Loss:  -5.473978519439697\n",
      "[(6e-05, 0.4522), (0.0, 0.4519), (1.0, 0.4522)]\n",
      "Alpha*: 0.0 tau*: 0.4519 Episode: 16494 length: 65 #teleports:58\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002193058462580666\n",
      "Q Loss:  0.0024958811700344086\n",
      "Policy Loss:  -0.0009932860266417265\n",
      "[(6e-05, 0.4519), (0.0, 0.4516), (1.0, 0.4519)]\n",
      "Alpha*: 0.0 tau*: 0.4516 Episode: 16503 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01199960708618164\n",
      "Value Loss:  0.0014545619487762451\n",
      "Q Loss:  0.7408815622329712\n",
      "Policy Loss:  0.42763257026672363\n",
      "[(6e-05, 0.4516), (0.0, 0.4513), (1.0, 0.4516)]\n",
      "Alpha*: 0.0 tau*: 0.4513 Episode: 16507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.2277371883392334\n",
      "Q Loss:  1.1770113706588745\n",
      "Policy Loss:  -2.786311149597168\n",
      "[(6e-05, 0.4513), (0.0, 0.451), (1.0, 0.4513)]\n",
      "Alpha*: 0.0 tau*: 0.451 Episode: 16610 length: 64 #teleports:39\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.001703178626485169\n",
      "Q Loss:  0.0018983891932293773\n",
      "Policy Loss:  0.005974660627543926\n",
      "[(6e-05, 0.451), (0.0, 0.4507), (1.0, 0.451)]\n",
      "Alpha*: 0.0 tau*: 0.4507 Episode: 16615 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0013355666305869818\n",
      "Q Loss:  0.3747369050979614\n",
      "Policy Loss:  0.1584983617067337\n",
      "[(6e-05, 0.4507), (0.0, 0.4504), (1.0, 0.4507)]\n",
      "Alpha*: 0.0 tau*: 0.4504 Episode: 16620 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005523369763977826\n",
      "Q Loss:  0.8065135478973389\n",
      "Policy Loss:  0.5464345216751099\n",
      "[(6e-05, 0.4504), (0.0, 0.4501), (1.0, 0.4504)]\n",
      "Alpha*: 0.0 tau*: 0.4501 Episode: 16625 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006413889932446182\n",
      "Q Loss:  0.005687518045306206\n",
      "Policy Loss:  0.026653166860342026\n",
      "[(6e-05, 0.4501), (0.0, 0.4498), (1.0, 0.4501)]\n",
      "Alpha*: 0.0 tau*: 0.4498 Episode: 16636 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  35227.1796875\n",
      "Q Loss:  35241.05859375\n",
      "Policy Loss:  -5.282111644744873\n",
      "[(6e-05, 0.4498), (0.0, 0.4495), (1.0, 0.4498)]\n",
      "Alpha*: 0.0 tau*: 0.4495 Episode: 16732 length: 56 #teleports:40\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0004097001801710576\n",
      "Q Loss:  0.028753608465194702\n",
      "Policy Loss:  0.354159951210022\n",
      "[(6e-05, 0.4495), (0.0, 0.4492), (1.0, 0.4495)]\n",
      "Alpha*: 0.0 tau*: 0.4492 Episode: 16737 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.3251572847366333\n",
      "Q Loss:  0.5502997040748596\n",
      "Policy Loss:  -6.205902576446533\n",
      "[(6e-05, 0.4492), (0.0, 0.4489), (1.0, 0.4492)]\n",
      "Alpha*: 0.0 tau*: 0.4489 Episode: 16745 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.6587264537811279\n",
      "Q Loss:  0.4092721939086914\n",
      "Policy Loss:  -2.526961088180542\n",
      "[(6e-05, 0.4489), (0.0, 0.4486), (1.0, 0.4489)]\n",
      "Alpha*: 0.0 tau*: 0.4486 Episode: 16755 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00023795198649168015\n",
      "Q Loss:  0.05913170799612999\n",
      "Policy Loss:  0.11338070780038834\n",
      "[(6e-05, 0.4486), (0.0, 0.4483), (1.0, 0.4486)]\n",
      "Alpha*: 0.0 tau*: 0.4483 Episode: 16763 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.038008689880371094\n",
      "Value Loss:  0.00023411278380081058\n",
      "Q Loss:  0.030059535056352615\n",
      "Policy Loss:  0.08593207597732544\n",
      "[(6e-05, 0.4483), (0.0, 0.448), (1.0, 0.4483)]\n",
      "Alpha*: 0.0 tau*: 0.448 Episode: 16772 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  25.653276443481445\n",
      "Q Loss:  19.10137367248535\n",
      "Policy Loss:  -28.533082962036133\n",
      "[(6e-05, 0.448), (0.0, 0.4477), (1.0, 0.448)]\n",
      "Alpha*: 0.0 tau*: 0.4477 Episode: 16779 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  25.857202529907227\n",
      "Q Loss:  6.947493553161621\n",
      "Policy Loss:  -39.220462799072266\n",
      "[(6e-05, 0.4477), (0.0, 0.4474), (1.0, 0.4477)]\n",
      "Alpha*: 0.0 tau*: 0.4474 Episode: 16784 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0016131226439028978\n",
      "Q Loss:  0.001713234931230545\n",
      "Policy Loss:  -0.01485554687678814\n",
      "[(6e-05, 0.4474), (0.0, 0.4471), (1.0, 0.4474)]\n",
      "Alpha*: 0.0 tau*: 0.4471 Episode: 16792 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003688692522700876\n",
      "Q Loss:  0.3640036880970001\n",
      "Policy Loss:  0.305270254611969\n",
      "[(6e-05, 0.4471), (0.0, 0.4468), (1.0, 0.4471)]\n",
      "Alpha*: 0.0 tau*: 0.4468 Episode: 16798 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.397802306106314e-05\n",
      "Q Loss:  0.030806977301836014\n",
      "Policy Loss:  0.08909718692302704\n",
      "[(6e-05, 0.4468), (0.0, 0.4465), (1.0, 0.4468)]\n",
      "Alpha*: 0.0 tau*: 0.4465 Episode: 16807 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.0005478159873746336\n",
      "Q Loss:  0.002473388332873583\n",
      "Policy Loss:  0.008346378803253174\n",
      "[(6e-05, 0.4465), (0.0, 0.4462), (1.0, 0.4465)]\n",
      "Alpha*: 0.0 tau*: 0.4462 Episode: 16815 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.000606123881880194\n",
      "Q Loss:  0.3310009837150574\n",
      "Policy Loss:  0.21476072072982788\n",
      "[(6e-05, 0.4462), (0.0, 0.4459), (1.0, 0.4462)]\n",
      "Alpha*: 0.0 tau*: 0.4459 Episode: 16820 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00015377362433355302\n",
      "Q Loss:  0.012018234468996525\n",
      "Policy Loss:  0.05394215136766434\n",
      "[(6e-05, 0.4459), (0.0, 0.4456), (1.0, 0.4459)]\n",
      "Alpha*: 0.0 tau*: 0.4456 Episode: 16832 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00010605251009110361\n",
      "Q Loss:  0.0396571010351181\n",
      "Policy Loss:  0.36283671855926514\n",
      "[(6e-05, 0.4456), (0.0, 0.4453), (1.0, 0.4456)]\n",
      "Alpha*: 0.0 tau*: 0.4453 Episode: 16845 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0004976312629878521\n",
      "Q Loss:  0.3224472403526306\n",
      "Policy Loss:  0.21418318152427673\n",
      "[(6e-05, 0.4453), (0.0, 0.445), (1.0, 0.4453)]\n",
      "Alpha*: 0.0 tau*: 0.445 Episode: 16859 length: 4 #teleports:10\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00011513676872709766\n",
      "Q Loss:  0.01168727409094572\n",
      "Policy Loss:  0.035277098417282104\n",
      "[(7e-05, 0.445), (0.0, 0.4447), (1.0, 0.445)]\n",
      "Alpha*: 0.0 tau*: 0.4447 Episode: 16864 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  20112.15234375\n",
      "Q Loss:  20116.0703125\n",
      "Policy Loss:  -4.038086414337158\n",
      "[(7e-05, 0.4447), (0.0, 0.4444), (1.0, 0.4447)]\n",
      "Alpha*: 0.0 tau*: 0.4444 Episode: 16936 length: 49 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.596885085105896\n",
      "Q Loss:  0.04815654084086418\n",
      "Policy Loss:  -3.4666593074798584\n",
      "[(7e-05, 0.4444), (0.0, 0.4441), (1.0, 0.4444)]\n",
      "Alpha*: 0.0 tau*: 0.4441 Episode: 16945 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00020530520123429596\n",
      "Q Loss:  0.00710487412288785\n",
      "Policy Loss:  -0.019590169191360474\n",
      "[(7e-05, 0.4441), (0.0, 0.4438), (1.0, 0.4441)]\n",
      "Alpha*: 0.0 tau*: 0.4438 Episode: 16950 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  0.0001894679298857227\n",
      "Q Loss:  0.01603550836443901\n",
      "Policy Loss:  0.004164817743003368\n",
      "[(7e-05, 0.4438), (0.0, 0.4435), (1.0, 0.4438)]\n",
      "Alpha*: 0.0 tau*: 0.4435 Episode: 16954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.823305130004883\n",
      "Q Loss:  0.6412321329116821\n",
      "Policy Loss:  -3.9897587299346924\n",
      "[(7e-05, 0.4435), (0.0, 0.4432), (1.0, 0.4435)]\n",
      "Alpha*: 0.0 tau*: 0.4432 Episode: 17015 length: 40 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.5898575782775879\n",
      "Q Loss:  1.3001799583435059\n",
      "Policy Loss:  -1.6047852039337158\n",
      "[(7e-05, 0.4432), (0.0, 0.4429), (1.0, 0.4432)]\n",
      "Alpha*: 0.0 tau*: 0.4429 Episode: 17025 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  14.040654182434082\n",
      "Q Loss:  7.688405513763428\n",
      "Policy Loss:  -19.337230682373047\n",
      "[(7e-05, 0.4429), (0.0, 0.4426), (1.0, 0.4429)]\n",
      "Alpha*: 0.0 tau*: 0.4426 Episode: 17034 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.0028230210300535e-05\n",
      "Q Loss:  0.021969269961118698\n",
      "Policy Loss:  0.3244931697845459\n",
      "[(7e-05, 0.4426), (0.0, 0.4423), (1.0, 0.4426)]\n",
      "Alpha*: 0.0 tau*: 0.4423 Episode: 17044 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00012304428673814982\n",
      "Q Loss:  0.0022211766336113214\n",
      "Policy Loss:  0.004299236461520195\n",
      "[(7e-05, 0.4423), (0.0, 0.442), (1.0, 0.4423)]\n",
      "Alpha*: 0.0 tau*: 0.442 Episode: 17050 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.4465883547673e-05\n",
      "Q Loss:  0.2920987904071808\n",
      "Policy Loss:  0.17395594716072083\n",
      "[(7e-05, 0.442), (0.0, 0.4417), (1.0, 0.442)]\n",
      "Alpha*: 0.0 tau*: 0.4417 Episode: 17055 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  14.251090049743652\n",
      "Q Loss:  13.901957511901855\n",
      "Policy Loss:  -15.407478332519531\n",
      "[(7e-05, 0.4417), (0.0, 0.4414), (1.0, 0.4417)]\n",
      "Alpha*: 0.0 tau*: 0.4414 Episode: 17065 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.7406792640686035\n",
      "Q Loss:  2.5571584701538086\n",
      "Policy Loss:  -4.453264236450195\n",
      "[(7e-05, 0.4414), (0.0, 0.4411), (1.0, 0.4414)]\n",
      "Alpha*: 0.0 tau*: 0.4411 Episode: 17141 length: 46 #teleports:30\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00011968060425715521\n",
      "Q Loss:  0.018428893759846687\n",
      "Policy Loss:  0.2671605944633484\n",
      "[(7e-05, 0.4411), (0.0, 0.4408), (1.0, 0.4411)]\n",
      "Alpha*: 0.0 tau*: 0.4408 Episode: 17152 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.570145845413208\n",
      "Q Loss:  0.2830098569393158\n",
      "Policy Loss:  -3.429849624633789\n",
      "[(7e-05, 0.4408), (0.0, 0.4405), (1.0, 0.4408)]\n",
      "Alpha*: 0.0 tau*: 0.4405 Episode: 17157 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.2739382984582335e-05\n",
      "Q Loss:  0.01505901850759983\n",
      "Policy Loss:  0.06978590786457062\n",
      "[(7e-05, 0.4405), (0.0, 0.4402), (1.0, 0.4405)]\n",
      "Alpha*: 0.0 tau*: 0.4402 Episode: 17165 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.063831900362857e-05\n",
      "Q Loss:  0.01945921778678894\n",
      "Policy Loss:  0.284534215927124\n",
      "[(7e-05, 0.4402), (0.0, 0.4399), (1.0, 0.4402)]\n",
      "Alpha*: 0.0 tau*: 0.4399 Episode: 17172 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.5587984323501587\n",
      "Q Loss:  0.2825445532798767\n",
      "Policy Loss:  -2.0025269985198975\n",
      "[(7e-05, 0.4399), (0.0, 0.4396), (1.0, 0.4399)]\n",
      "Alpha*: 0.0 tau*: 0.4396 Episode: 17178 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  6.194906745804474e-05\n",
      "Q Loss:  0.0009688154677860439\n",
      "Policy Loss:  0.020895157009363174\n",
      "[(7e-05, 0.4396), (0.0, 0.4393), (1.0, 0.4396)]\n",
      "Alpha*: 0.0 tau*: 0.4393 Episode: 17187 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  29851.22265625\n",
      "Q Loss:  29849.43359375\n",
      "Policy Loss:  -10.514755249023438\n",
      "[(7e-05, 0.4393), (0.0, 0.439), (1.0, 0.4393)]\n",
      "Alpha*: 0.0 tau*: 0.439 Episode: 17243 length: 33 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.147481013205834e-05\n",
      "Q Loss:  0.00042538114939816296\n",
      "Policy Loss:  0.009959775023162365\n",
      "[(7e-05, 0.439), (0.0, 0.4387), (1.0, 0.439)]\n",
      "Alpha*: 0.0 tau*: 0.4387 Episode: 17251 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.0877286195755005\n",
      "Q Loss:  0.07126852124929428\n",
      "Policy Loss:  -3.0047178268432617\n",
      "[(7e-05, 0.4387), (0.0, 0.4384), (1.0, 0.4387)]\n",
      "Alpha*: 0.0 tau*: 0.4384 Episode: 17259 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  1.0719709396362305\n",
      "Q Loss:  0.054590970277786255\n",
      "Policy Loss:  -4.969078063964844\n",
      "[(7e-05, 0.4384), (0.0, 0.4381), (1.0, 0.4384)]\n",
      "Alpha*: 0.0 tau*: 0.4381 Episode: 17264 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.052011966705322266\n",
      "Value Loss:  0.00013281939027365297\n",
      "Q Loss:  0.2784186601638794\n",
      "Policy Loss:  0.2063329666852951\n",
      "[(7e-05, 0.4381), (0.0, 0.4378), (1.0, 0.4381)]\n",
      "Alpha*: 0.0 tau*: 0.4378 Episode: 17269 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  4.0055832862854\n",
      "Q Loss:  1.261443853378296\n",
      "Policy Loss:  -4.8183159828186035\n",
      "[(7e-05, 0.4378), (0.0, 0.4375), (1.0, 0.4378)]\n",
      "Alpha*: 0.0 tau*: 0.4375 Episode: 17344 length: 44 #teleports:31\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012009859085083008\n",
      "Value Loss:  0.00035199549165554345\n",
      "Q Loss:  0.008121898397803307\n",
      "Policy Loss:  -0.049863118678331375\n",
      "[(7e-05, 0.4375), (0.0, 0.4372), (1.0, 0.4375)]\n",
      "Alpha*: 0.0 tau*: 0.4372 Episode: 17352 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.0326739912852645e-05\n",
      "Q Loss:  0.0012549065286293626\n",
      "Policy Loss:  0.027252303436398506\n",
      "[(7e-05, 0.4372), (0.0, 0.4369), (1.0, 0.4372)]\n",
      "Alpha*: 0.0 tau*: 0.4369 Episode: 17356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00023984811559785157\n",
      "Q Loss:  0.011244799010455608\n",
      "Policy Loss:  0.042060770094394684\n",
      "[(7e-05, 0.4369), (0.0, 0.4366), (1.0, 0.4369)]\n",
      "Alpha*: 0.0 tau*: 0.4366 Episode: 17360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003189893322996795\n",
      "Q Loss:  0.29666170477867126\n",
      "Policy Loss:  0.4351295232772827\n",
      "[(7e-05, 0.4366), (0.0, 0.4363), (1.0, 0.4366)]\n",
      "Alpha*: 0.0 tau*: 0.4363 Episode: 17365 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.04601001739501953\n",
      "Value Loss:  0.0001324423064943403\n",
      "Q Loss:  0.005703221075236797\n",
      "Policy Loss:  0.04126306623220444\n",
      "[(7e-05, 0.4363), (0.0, 0.436), (1.0, 0.4363)]\n",
      "Alpha*: 0.0 tau*: 0.436 Episode: 17374 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.03000617027282715\n",
      "Value Loss:  2.6494128704071045\n",
      "Q Loss:  1.3281508684158325\n",
      "Policy Loss:  -3.4092326164245605\n",
      "[(7e-05, 0.436), (0.0, 0.4357), (1.0, 0.436)]\n",
      "Alpha*: 0.0 tau*: 0.4357 Episode: 17543 length: 95 #teleports:74\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00024186984228435904\n",
      "Q Loss:  0.2682679295539856\n",
      "Policy Loss:  0.21510133147239685\n",
      "[(7e-05, 0.4357), (0.0, 0.4354), (1.0, 0.4357)]\n",
      "Alpha*: 0.0 tau*: 0.4354 Episode: 17549 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014707565307617188\n",
      "Value Loss:  15144.0771484375\n",
      "Q Loss:  15142.5185546875\n",
      "Policy Loss:  -4.883224010467529\n",
      "[(7e-05, 0.4354), (0.0, 0.4351), (1.0, 0.4354)]\n",
      "Alpha*: 0.0 tau*: 0.4351 Episode: 17657 length: 65 #teleports:43\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  25563.54296875\n",
      "Q Loss:  25563.056640625\n",
      "Policy Loss:  -4.426806926727295\n",
      "[(7e-05, 0.4351), (0.0, 0.4348), (1.0, 0.4351)]\n",
      "Alpha*: 0.0 tau*: 0.4348 Episode: 17787 length: 77 #teleports:53\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  17896.017578125\n",
      "Q Loss:  17895.595703125\n",
      "Policy Loss:  -7.422374725341797\n",
      "[(7e-05, 0.4348), (0.0, 0.4345), (1.0, 0.4348)]\n",
      "Alpha*: 0.0 tau*: 0.4345 Episode: 17882 length: 55 #teleports:40\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  22363.078125\n",
      "Q Loss:  22360.7734375\n",
      "Policy Loss:  -6.655430316925049\n",
      "[(7e-05, 0.4345), (0.0, 0.4342), (1.0, 0.4345)]\n",
      "Alpha*: 0.0 tau*: 0.4342 Episode: 17950 length: 44 #teleports:24\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0008780844509601593\n",
      "Q Loss:  0.009405151940882206\n",
      "Policy Loss:  0.030697017908096313\n",
      "[(7e-05, 0.4342), (0.0, 0.4339), (1.0, 0.4342)]\n",
      "Alpha*: 0.0 tau*: 0.4339 Episode: 17958 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  26821.22265625\n",
      "Q Loss:  26820.103515625\n",
      "Policy Loss:  -5.059647083282471\n",
      "[(8e-05, 0.4339), (0.0, 0.43361), (1.0, 0.4339)]\n",
      "Alpha*: 0.0 tau*: 0.43361 Episode: 18161 length: 110 #teleports:93\n",
      "Got not null reward 3005.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.48757266998291016\n",
      "Q Loss:  0.00928155705332756\n",
      "Policy Loss:  -3.183844566345215\n",
      "[(8e-05, 0.43361), (0.0, 0.43332), (1.0, 0.43361)]\n",
      "Alpha*: 0.0 tau*: 0.43332 Episode: 18167 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.253979682922363\n",
      "Q Loss:  0.6342555284500122\n",
      "Policy Loss:  -4.70015287399292\n",
      "[(8e-05, 0.43332), (0.0, 0.43303), (1.0, 0.43332)]\n",
      "Alpha*: 0.0 tau*: 0.43303 Episode: 18254 length: 48 #teleports:39\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.947431564331055\n",
      "Q Loss:  5.173215389251709\n",
      "Policy Loss:  -6.259271144866943\n",
      "[(8e-05, 0.43303), (0.0, 0.43274), (1.0, 0.43303)]\n",
      "Alpha*: 0.0 tau*: 0.43274 Episode: 18341 length: 42 #teleports:45\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.005263133440166712\n",
      "Q Loss:  0.0009155974257737398\n",
      "Policy Loss:  -0.03135812655091286\n",
      "[(8e-05, 0.43274), (0.0, 0.43245), (1.0, 0.43274)]\n",
      "Alpha*: 0.0 tau*: 0.43245 Episode: 18345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002827172284014523\n",
      "Q Loss:  0.054568056017160416\n",
      "Policy Loss:  0.1359805166721344\n",
      "[(8e-05, 0.43245), (0.0, 0.43216), (1.0, 0.43245)]\n",
      "Alpha*: 0.0 tau*: 0.43216 Episode: 18351 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.695943832397461\n",
      "Q Loss:  0.6188071370124817\n",
      "Policy Loss:  -4.79890775680542\n",
      "[(8e-05, 0.43216), (0.0, 0.43187), (1.0, 0.43216)]\n",
      "Alpha*: 0.0 tau*: 0.43187 Episode: 18403 length: 29 #teleports:23\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  41.092010498046875\n",
      "Q Loss:  21.23028564453125\n",
      "Policy Loss:  -35.9525032043457\n",
      "[(8e-05, 0.43187), (0.0, 0.43158), (1.0, 0.43187)]\n",
      "Alpha*: 0.0 tau*: 0.43158 Episode: 18411 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00227977242320776\n",
      "Q Loss:  0.003284389153122902\n",
      "Policy Loss:  0.03933039307594299\n",
      "[(8e-05, 0.43158), (0.0, 0.43129), (1.0, 0.43158)]\n",
      "Alpha*: 0.0 tau*: 0.43129 Episode: 18415 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  42.10849380493164\n",
      "Q Loss:  54.369544982910156\n",
      "Policy Loss:  -22.028282165527344\n",
      "[(8e-05, 0.43129), (0.0, 0.431), (1.0, 0.43129)]\n",
      "Alpha*: 0.0 tau*: 0.431 Episode: 18421 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.03300666809082031\n",
      "Value Loss:  0.0008141472935676575\n",
      "Q Loss:  0.5971948504447937\n",
      "Policy Loss:  0.3618919253349304\n",
      "[(8e-05, 0.431), (0.0, 0.43071), (1.0, 0.431)]\n",
      "Alpha*: 0.0 tau*: 0.43071 Episode: 18429 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.534081220626831\n",
      "Q Loss:  0.02387077361345291\n",
      "Policy Loss:  -1.894650936126709\n",
      "[(8e-05, 0.43071), (0.0, 0.43042), (1.0, 0.43071)]\n",
      "Alpha*: 0.0 tau*: 0.43042 Episode: 18433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.3978168964385986\n",
      "Q Loss:  2.7711055278778076\n",
      "Policy Loss:  -3.5222012996673584\n",
      "[(8e-05, 0.43042), (0.0, 0.43013), (1.0, 0.43042)]\n",
      "Alpha*: 0.0 tau*: 0.43013 Episode: 18584 length: 94 #teleports:57\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00042448187014088035\n",
      "Q Loss:  0.04765592887997627\n",
      "Policy Loss:  0.09637493640184402\n",
      "[(8e-05, 0.43013), (0.0, 0.42984), (1.0, 0.43013)]\n",
      "Alpha*: 0.0 tau*: 0.42984 Episode: 18591 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  21.803855895996094\n",
      "Q Loss:  0.01533466950058937\n",
      "Policy Loss:  -26.633214950561523\n",
      "[(9e-05, 0.42984), (0.0, 0.42955), (1.0, 0.42984)]\n",
      "Alpha*: 0.0 tau*: 0.42955 Episode: 18598 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005089246551506221\n",
      "Q Loss:  0.0037108471151441336\n",
      "Policy Loss:  0.03259583190083504\n",
      "[(9e-05, 0.42955), (0.0, 0.42926), (1.0, 0.42955)]\n",
      "Alpha*: 0.0 tau*: 0.42926 Episode: 18604 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.777007027063519e-05\n",
      "Q Loss:  0.008982866071164608\n",
      "Policy Loss:  0.03945411741733551\n",
      "[(9e-05, 0.42926), (0.0, 0.42897), (1.0, 0.42926)]\n",
      "Alpha*: 0.0 tau*: 0.42897 Episode: 18609 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0005926103331148624\n",
      "Q Loss:  0.008379507809877396\n",
      "Policy Loss:  0.03955499455332756\n",
      "[(9e-05, 0.42897), (0.0, 0.42868), (1.0, 0.42897)]\n",
      "Alpha*: 0.0 tau*: 0.42868 Episode: 18613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  22.110435485839844\n",
      "Q Loss:  0.6292476058006287\n",
      "Policy Loss:  -25.68273162841797\n",
      "[(9e-05, 0.42868), (0.0, 0.42839), (1.0, 0.42868)]\n",
      "Alpha*: 0.0 tau*: 0.42839 Episode: 18620 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0009247899288311601\n",
      "Q Loss:  0.006355137564241886\n",
      "Policy Loss:  0.028119605034589767\n",
      "[(9e-05, 0.42839), (0.0, 0.4281), (1.0, 0.42839)]\n",
      "Alpha*: 0.0 tau*: 0.4281 Episode: 18626 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  13631.513671875\n",
      "Q Loss:  13625.76953125\n",
      "Policy Loss:  -4.5105462074279785\n",
      "[(9e-05, 0.4281), (0.0, 0.42781), (1.0, 0.4281)]\n",
      "Alpha*: 0.0 tau*: 0.42781 Episode: 18734 length: 72 #teleports:36\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.0005843866383656859\n",
      "Q Loss:  0.004221019335091114\n",
      "Policy Loss:  0.029020626097917557\n",
      "[(9e-05, 0.42781), (0.0, 0.42752), (1.0, 0.42781)]\n",
      "Alpha*: 0.0 tau*: 0.42752 Episode: 18738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006658117636106908\n",
      "Q Loss:  0.03192896768450737\n",
      "Policy Loss:  0.08102608472108841\n",
      "[(9e-05, 0.42752), (0.0, 0.42723), (1.0, 0.42752)]\n",
      "Alpha*: 0.0 tau*: 0.42723 Episode: 18745 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1514568541315384e-05\n",
      "Q Loss:  0.02265424281358719\n",
      "Policy Loss:  0.3122813105583191\n",
      "[(9e-05, 0.42723), (0.0, 0.42694), (1.0, 0.42723)]\n",
      "Alpha*: 0.0 tau*: 0.42694 Episode: 18751 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0010676594683900476\n",
      "Q Loss:  1.215492844581604\n",
      "Policy Loss:  0.564651608467102\n",
      "[(9e-05, 0.42694), (0.0, 0.42665), (1.0, 0.42694)]\n",
      "Alpha*: 0.0 tau*: 0.42665 Episode: 18758 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  45.588706970214844\n",
      "Q Loss:  24.908031463623047\n",
      "Policy Loss:  -35.585269927978516\n",
      "[(9e-05, 0.42665), (0.0, 0.42636), (1.0, 0.42665)]\n",
      "Alpha*: 0.0 tau*: 0.42636 Episode: 18767 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.143068847246468e-05\n",
      "Q Loss:  0.2946324944496155\n",
      "Policy Loss:  0.19446206092834473\n",
      "[(9e-05, 0.42636), (0.0, 0.42607), (1.0, 0.42636)]\n",
      "Alpha*: 0.0 tau*: 0.42607 Episode: 18772 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  31644.982421875\n",
      "Q Loss:  31629.939453125\n",
      "Policy Loss:  -3.568654775619507\n",
      "[(9e-05, 0.42607), (0.0, 0.42578), (1.0, 0.42607)]\n",
      "Alpha*: 0.0 tau*: 0.42578 Episode: 18826 length: 31 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  23.198429107666016\n",
      "Q Loss:  0.005304604768753052\n",
      "Policy Loss:  -27.92222785949707\n",
      "[(9e-05, 0.42578), (0.0, 0.42549), (1.0, 0.42578)]\n",
      "Alpha*: 0.0 tau*: 0.42549 Episode: 18831 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.687952995300293\n",
      "Q Loss:  5.000766754150391\n",
      "Policy Loss:  -7.0407819747924805\n",
      "[(9e-05, 0.42549), (0.0, 0.4252), (1.0, 0.42549)]\n",
      "Alpha*: 0.0 tau*: 0.4252 Episode: 19094 length: 137 #teleports:126\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0490107536315918\n",
      "Value Loss:  0.00017431058222427964\n",
      "Q Loss:  0.27015507221221924\n",
      "Policy Loss:  0.19203364849090576\n",
      "[(9e-05, 0.4252), (0.0, 0.42491), (1.0, 0.4252)]\n",
      "Alpha*: 0.0 tau*: 0.42491 Episode: 19100 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.5746805667877197\n",
      "Q Loss:  0.012998878955841064\n",
      "Policy Loss:  -3.3937387466430664\n",
      "[(9e-05, 0.42491), (0.0, 0.42462), (1.0, 0.42491)]\n",
      "Alpha*: 0.0 tau*: 0.42462 Episode: 19108 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00167637481354177\n",
      "Q Loss:  0.009351098909974098\n",
      "Policy Loss:  -0.06236712262034416\n",
      "[(9e-05, 0.42462), (0.0, 0.42433), (1.0, 0.42462)]\n",
      "Alpha*: 0.0 tau*: 0.42433 Episode: 19115 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00048736471217125654\n",
      "Q Loss:  0.5422312617301941\n",
      "Policy Loss:  0.3147437274456024\n",
      "[(9e-05, 0.42433), (0.0, 0.42404), (1.0, 0.42433)]\n",
      "Alpha*: 0.0 tau*: 0.42404 Episode: 19121 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0008019154192879796\n",
      "Q Loss:  0.006220273673534393\n",
      "Policy Loss:  -0.030422374606132507\n",
      "[(9e-05, 0.42404), (0.0, 0.42375), (1.0, 0.42404)]\n",
      "Alpha*: 0.0 tau*: 0.42375 Episode: 19129 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  6.6602630615234375\n",
      "Q Loss:  2.9900400638580322\n",
      "Policy Loss:  -7.3198957443237305\n",
      "[(9e-05, 0.42375), (0.0, 0.42346), (1.0, 0.42375)]\n",
      "Alpha*: 0.0 tau*: 0.42346 Episode: 19305 length: 99 #teleports:77\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0002635590499266982\n",
      "Q Loss:  0.263896107673645\n",
      "Policy Loss:  0.16975471377372742\n",
      "[(9e-05, 0.42346), (0.0, 0.42317), (1.0, 0.42346)]\n",
      "Alpha*: 0.0 tau*: 0.42317 Episode: 19313 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.5754924416542053\n",
      "Q Loss:  0.012254162691533566\n",
      "Policy Loss:  -3.3762972354888916\n",
      "[(9e-05, 0.42317), (0.0, 0.42288), (1.0, 0.42317)]\n",
      "Alpha*: 0.0 tau*: 0.42288 Episode: 19324 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.03500795364379883\n",
      "Value Loss:  0.5712879300117493\n",
      "Q Loss:  0.5361806154251099\n",
      "Policy Loss:  -1.5164766311645508\n",
      "[(9e-05, 0.42288), (0.0, 0.42259), (1.0, 0.42288)]\n",
      "Alpha*: 0.0 tau*: 0.42259 Episode: 19333 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  25.016202926635742\n",
      "Q Loss:  27.1470947265625\n",
      "Policy Loss:  -19.199565887451172\n",
      "[(9e-05, 0.42259), (0.0, 0.4223), (1.0, 0.42259)]\n",
      "Alpha*: 0.0 tau*: 0.4223 Episode: 19341 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.5562817454338074\n",
      "Q Loss:  0.583999752998352\n",
      "Policy Loss:  -2.4225680828094482\n",
      "[(9e-05, 0.4223), (0.0, 0.42201), (1.0, 0.4223)]\n",
      "Alpha*: 0.0 tau*: 0.42201 Episode: 19348 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  75.37693786621094\n",
      "Q Loss:  54.252227783203125\n",
      "Policy Loss:  -37.03721618652344\n",
      "[(9e-05, 0.42201), (0.0, 0.42172), (1.0, 0.42201)]\n",
      "Alpha*: 0.0 tau*: 0.42172 Episode: 19357 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.485718250274658\n",
      "Q Loss:  0.3518977761268616\n",
      "Policy Loss:  -3.8495752811431885\n",
      "[(9e-05, 0.42172), (0.0, 0.42143), (1.0, 0.42172)]\n",
      "Alpha*: 0.0 tau*: 0.42143 Episode: 19431 length: 45 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005054030334576964\n",
      "Q Loss:  0.00316836079582572\n",
      "Policy Loss:  0.03288453444838524\n",
      "[(9e-05, 0.42143), (0.0, 0.42114), (1.0, 0.42143)]\n",
      "Alpha*: 0.0 tau*: 0.42114 Episode: 19441 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  25.04842185974121\n",
      "Q Loss:  27.678817749023438\n",
      "Policy Loss:  -18.529006958007812\n",
      "[(9e-05, 0.42114), (0.0, 0.42085), (1.0, 0.42114)]\n",
      "Alpha*: 0.0 tau*: 0.42085 Episode: 19448 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0014766734093427658\n",
      "Q Loss:  0.0030318116769194603\n",
      "Policy Loss:  0.01483062282204628\n",
      "[(9e-05, 0.42085), (0.0, 0.42056), (1.0, 0.42085)]\n",
      "Alpha*: 0.0 tau*: 0.42056 Episode: 19454 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015594005584716797\n",
      "Value Loss:  0.000850403739605099\n",
      "Q Loss:  0.01328293513506651\n",
      "Policy Loss:  0.02105697989463806\n",
      "[(9e-05, 0.42056), (0.0, 0.42027), (1.0, 0.42056)]\n",
      "Alpha*: 0.0 tau*: 0.42027 Episode: 19459 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002800235233735293\n",
      "Q Loss:  0.003264210419729352\n",
      "Policy Loss:  0.02863645926117897\n",
      "[(9e-05, 0.42027), (0.0, 0.41998), (1.0, 0.42027)]\n",
      "Alpha*: 0.0 tau*: 0.41998 Episode: 19463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0004466964746825397\n",
      "Q Loss:  0.006515474058687687\n",
      "Policy Loss:  0.03215024247765541\n",
      "[(9e-05, 0.41998), (0.0, 0.41969), (1.0, 0.41998)]\n",
      "Alpha*: 0.0 tau*: 0.41969 Episode: 19470 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0005161855951882899\n",
      "Q Loss:  0.007026835810393095\n",
      "Policy Loss:  0.022419694811105728\n",
      "[(9e-05, 0.41969), (0.0, 0.4194), (1.0, 0.41969)]\n",
      "Alpha*: 0.0 tau*: 0.4194 Episode: 19476 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00022007669031154364\n",
      "Q Loss:  0.019148821011185646\n",
      "Policy Loss:  0.24979791045188904\n",
      "[(9e-05, 0.4194), (0.0, 0.41911), (1.0, 0.4194)]\n",
      "Alpha*: 0.0 tau*: 0.41911 Episode: 19483 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  17827.6171875\n",
      "Q Loss:  17814.859375\n",
      "Policy Loss:  -6.872054576873779\n",
      "[(9e-05, 0.41911), (0.0, 0.41882), (1.0, 0.41911)]\n",
      "Alpha*: 0.0 tau*: 0.41882 Episode: 19585 length: 55 #teleports:47\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0015281718224287033\n",
      "Q Loss:  0.006444771774113178\n",
      "Policy Loss:  -0.016615260392427444\n",
      "[(9e-05, 0.41882), (0.0, 0.41853), (1.0, 0.41882)]\n",
      "Alpha*: 0.0 tau*: 0.41853 Episode: 19589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.001250671106390655\n",
      "Q Loss:  0.005094672553241253\n",
      "Policy Loss:  -0.004385250620543957\n",
      "[(9e-05, 0.41853), (0.0, 0.41824), (1.0, 0.41853)]\n",
      "Alpha*: 0.0 tau*: 0.41824 Episode: 19595 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00010274177475366741\n",
      "Q Loss:  0.01625889539718628\n",
      "Policy Loss:  0.23646584153175354\n",
      "[(9e-05, 0.41824), (0.0, 0.41795), (1.0, 0.41824)]\n",
      "Alpha*: 0.0 tau*: 0.41795 Episode: 19604 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.219363811193034e-05\n",
      "Q Loss:  0.00717916339635849\n",
      "Policy Loss:  -0.048672083765268326\n",
      "[(9e-05, 0.41795), (0.0, 0.41766), (1.0, 0.41795)]\n",
      "Alpha*: 0.0 tau*: 0.41766 Episode: 19611 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00024137336004059762\n",
      "Q Loss:  0.0023292985279113054\n",
      "Policy Loss:  -0.029672851786017418\n",
      "[(9e-05, 0.41766), (0.0, 0.41737), (1.0, 0.41766)]\n",
      "Alpha*: 0.0 tau*: 0.41737 Episode: 19615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801201820373535\n",
      "Value Loss:  0.00015232463192660362\n",
      "Q Loss:  0.001758882193826139\n",
      "Policy Loss:  -0.02166512794792652\n",
      "[(9e-05, 0.41737), (0.0, 0.41708), (1.0, 0.41737)]\n",
      "Alpha*: 0.0 tau*: 0.41708 Episode: 19621 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0001684046146692708\n",
      "Q Loss:  0.008912413381040096\n",
      "Policy Loss:  -0.048237066715955734\n",
      "[(9e-05, 0.41708), (0.0, 0.41679), (1.0, 0.41708)]\n",
      "Alpha*: 0.0 tau*: 0.41679 Episode: 19627 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00016465150110889226\n",
      "Q Loss:  0.0010620314860716462\n",
      "Policy Loss:  -0.014107814989984035\n",
      "[(9e-05, 0.41679), (0.0, 0.4165), (1.0, 0.41679)]\n",
      "Alpha*: 0.0 tau*: 0.4165 Episode: 19631 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00025273620849475265\n",
      "Q Loss:  0.0023667234927415848\n",
      "Policy Loss:  -0.027902571484446526\n",
      "[(9e-05, 0.4165), (0.0, 0.41621), (1.0, 0.4165)]\n",
      "Alpha*: 0.0 tau*: 0.41621 Episode: 19636 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011328214168315753\n",
      "Q Loss:  0.01071386132389307\n",
      "Policy Loss:  0.24521803855895996\n",
      "[(9e-05, 0.41621), (0.0, 0.41592), (1.0, 0.41621)]\n",
      "Alpha*: 0.0 tau*: 0.41592 Episode: 19646 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  8.389484405517578\n",
      "Q Loss:  6.092438697814941\n",
      "Policy Loss:  -6.862098693847656\n",
      "[(9e-05, 0.41592), (0.0, 0.41563), (1.0, 0.41592)]\n",
      "Alpha*: 0.0 tau*: 0.41563 Episode: 19699 length: 31 #teleports:22\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010997772216796875\n",
      "Value Loss:  32663.736328125\n",
      "Q Loss:  32628.98046875\n",
      "Policy Loss:  -7.808579921722412\n",
      "[(9e-05, 0.41563), (0.0, 0.41534), (1.0, 0.41563)]\n",
      "Alpha*: 0.0 tau*: 0.41534 Episode: 19759 length: 30 #teleports:30\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.6721943363081664e-05\n",
      "Q Loss:  0.0003947580698877573\n",
      "Policy Loss:  0.008854161016643047\n",
      "[(9e-05, 0.41534), (0.0, 0.41505), (1.0, 0.41534)]\n",
      "Alpha*: 0.0 tau*: 0.41505 Episode: 19772 length: 4 #teleports:9\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005053877830505371\n",
      "Q Loss:  0.007667425088584423\n",
      "Policy Loss:  0.2540680468082428\n",
      "[(9e-05, 0.41505), (0.0, 0.41476), (1.0, 0.41505)]\n",
      "Alpha*: 0.0 tau*: 0.41476 Episode: 19778 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0012172108981758356\n",
      "Q Loss:  0.0025977662298828363\n",
      "Policy Loss:  -0.0036630837712436914\n",
      "[(9e-05, 0.41476), (0.0, 0.41447), (1.0, 0.41476)]\n",
      "Alpha*: 0.0 tau*: 0.41447 Episode: 19786 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  0.00046510601532645524\n",
      "Q Loss:  0.001380512723699212\n",
      "Policy Loss:  0.012851810082793236\n",
      "[(9e-05, 0.41447), (0.0, 0.41418), (1.0, 0.41447)]\n",
      "Alpha*: 0.0 tau*: 0.41418 Episode: 19792 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0003042471071239561\n",
      "Q Loss:  0.0007551105227321386\n",
      "Policy Loss:  0.012662135995924473\n",
      "[(9e-05, 0.41418), (0.0, 0.41389), (1.0, 0.41418)]\n",
      "Alpha*: 0.0 tau*: 0.41389 Episode: 19800 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0005283595528453588\n",
      "Q Loss:  0.17208799719810486\n",
      "Policy Loss:  0.14490950107574463\n",
      "[(9e-05, 0.41389), (0.0, 0.4136), (1.0, 0.41389)]\n",
      "Alpha*: 0.0 tau*: 0.4136 Episode: 19807 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0004181660187896341\n",
      "Q Loss:  0.0024496326223015785\n",
      "Policy Loss:  -0.009140126407146454\n",
      "[(9e-05, 0.4136), (0.0, 0.41331), (1.0, 0.4136)]\n",
      "Alpha*: 0.0 tau*: 0.41331 Episode: 19814 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005669236415997148\n",
      "Q Loss:  0.0056354813277721405\n",
      "Policy Loss:  0.04411064833402634\n",
      "[(9e-05, 0.41331), (0.0, 0.41302), (1.0, 0.41331)]\n",
      "Alpha*: 0.0 tau*: 0.41302 Episode: 19822 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001468192640459165\n",
      "Q Loss:  0.0006413423689082265\n",
      "Policy Loss:  0.014548392966389656\n",
      "[(9e-05, 0.41302), (0.0, 0.41273), (1.0, 0.41302)]\n",
      "Alpha*: 0.0 tau*: 0.41273 Episode: 19827 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00027704142848961055\n",
      "Q Loss:  0.17361262440681458\n",
      "Policy Loss:  0.15587736666202545\n",
      "[(9e-05, 0.41273), (0.0, 0.41244), (1.0, 0.41273)]\n",
      "Alpha*: 0.0 tau*: 0.41244 Episode: 19831 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014063596725463867\n",
      "Value Loss:  0.5610660314559937\n",
      "Q Loss:  0.31312331557273865\n",
      "Policy Loss:  -0.906461775302887\n",
      "[(9e-05, 0.41244), (0.0, 0.41215), (1.0, 0.41244)]\n",
      "Alpha*: 0.0 tau*: 0.41215 Episode: 19835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.5594515800476074\n",
      "Q Loss:  0.6311132907867432\n",
      "Policy Loss:  -1.4958131313323975\n",
      "[(9e-05, 0.41215), (0.0, 0.41186), (1.0, 0.41215)]\n",
      "Alpha*: 0.0 tau*: 0.41186 Episode: 19847 length: 4 #teleports:8\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.376821253681555e-06\n",
      "Q Loss:  0.17697584629058838\n",
      "Policy Loss:  0.16614916920661926\n",
      "[(9e-05, 0.41186), (0.0, 0.41157), (1.0, 0.41186)]\n",
      "Alpha*: 0.0 tau*: 0.41157 Episode: 19851 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.0821433534147218e-05\n",
      "Q Loss:  0.1718812733888626\n",
      "Policy Loss:  0.15587779879570007\n",
      "[(9e-05, 0.41157), (0.0, 0.41128), (1.0, 0.41157)]\n",
      "Alpha*: 0.0 tau*: 0.41128 Episode: 19859 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001118009167839773\n",
      "Q Loss:  0.3395150303840637\n",
      "Policy Loss:  0.2958434820175171\n",
      "[(9e-05, 0.41128), (0.0, 0.41099), (1.0, 0.41128)]\n",
      "Alpha*: 0.0 tau*: 0.41099 Episode: 19863 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0006072871037758887\n",
      "Q Loss:  0.8916283845901489\n",
      "Policy Loss:  0.464576780796051\n",
      "[(9e-05, 0.41099), (0.0, 0.4107), (1.0, 0.41099)]\n",
      "Alpha*: 0.0 tau*: 0.4107 Episode: 19870 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0004441274213604629\n",
      "Q Loss:  0.0024268669076263905\n",
      "Policy Loss:  0.030855238437652588\n",
      "[(9e-05, 0.4107), (0.0, 0.41041), (1.0, 0.4107)]\n",
      "Alpha*: 0.0 tau*: 0.41041 Episode: 19874 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005270217079669237\n",
      "Q Loss:  0.15554232895374298\n",
      "Policy Loss:  0.14583536982536316\n",
      "[(9e-05, 0.41041), (0.0, 0.41012), (1.0, 0.41041)]\n",
      "Alpha*: 0.0 tau*: 0.41012 Episode: 19882 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0002952345530502498\n",
      "Q Loss:  0.15126481652259827\n",
      "Policy Loss:  0.3904372751712799\n",
      "[(9e-05, 0.41012), (0.0, 0.40983), (1.0, 0.41012)]\n",
      "Alpha*: 0.0 tau*: 0.40983 Episode: 19890 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.440352201461792\n",
      "Q Loss:  0.20747219026088715\n",
      "Policy Loss:  -3.74180006980896\n",
      "[(9e-05, 0.40983), (0.0, 0.40954), (1.0, 0.40983)]\n",
      "Alpha*: 0.0 tau*: 0.40954 Episode: 19976 length: 51 #teleports:35\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00040906359208747745\n",
      "Q Loss:  0.0011070810724049807\n",
      "Policy Loss:  0.011566895060241222\n",
      "[(9e-05, 0.40954), (0.0, 0.40925), (1.0, 0.40954)]\n",
      "Alpha*: 0.0 tau*: 0.40925 Episode: 19982 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0004830916877835989\n",
      "Q Loss:  0.0026746527291834354\n",
      "Policy Loss:  -0.012547267600893974\n",
      "[(9e-05, 0.40925), (0.0, 0.40896), (1.0, 0.40925)]\n",
      "Alpha*: 0.0 tau*: 0.40896 Episode: 19988 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00037679210072383285\n",
      "Q Loss:  0.0051032183691859245\n",
      "Policy Loss:  0.02267218381166458\n",
      "[(9e-05, 0.40896), (0.0, 0.40867), (1.0, 0.40896)]\n",
      "Alpha*: 0.0 tau*: 0.40867 Episode: 19995 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00018618980539031327\n",
      "Q Loss:  0.012691957876086235\n",
      "Policy Loss:  -0.015153732150793076\n",
      "[(9e-05, 0.40867), (0.0, 0.40838), (1.0, 0.40867)]\n",
      "Alpha*: 0.0 tau*: 0.40838 Episode: 20001 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001763396430760622\n",
      "Q Loss:  0.3990100920200348\n",
      "Policy Loss:  0.22898170351982117\n",
      "[(9e-05, 0.40838), (0.0, 0.40809), (1.0, 0.40838)]\n",
      "Alpha*: 0.0 tau*: 0.40809 Episode: 20010 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  6.7837495407729875e-06\n",
      "Q Loss:  0.002535127568989992\n",
      "Policy Loss:  0.23425164818763733\n",
      "[(9e-05, 0.40809), (0.0, 0.4078), (1.0, 0.40809)]\n",
      "Alpha*: 0.0 tau*: 0.4078 Episode: 20016 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.5240675806999207\n",
      "Q Loss:  0.46564850211143494\n",
      "Policy Loss:  -3.265835762023926\n",
      "[(9e-05, 0.4078), (0.0, 0.40751), (1.0, 0.4078)]\n",
      "Alpha*: 0.0 tau*: 0.40751 Episode: 20023 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00011156985419802368\n",
      "Q Loss:  0.0037442033644765615\n",
      "Policy Loss:  -0.030830679461359978\n",
      "[(9e-05, 0.40751), (0.0, 0.40722), (1.0, 0.40751)]\n",
      "Alpha*: 0.0 tau*: 0.40722 Episode: 20027 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00019394600531086326\n",
      "Q Loss:  0.0007452171994373202\n",
      "Policy Loss:  -0.0023400234058499336\n",
      "[(9e-05, 0.40722), (0.0, 0.40693), (1.0, 0.40722)]\n",
      "Alpha*: 0.0 tau*: 0.40693 Episode: 20034 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.5122224688529968\n",
      "Q Loss:  0.018360383808612823\n",
      "Policy Loss:  -2.1092865467071533\n",
      "[(9e-05, 0.40693), (0.0, 0.40664), (1.0, 0.40693)]\n",
      "Alpha*: 0.0 tau*: 0.40664 Episode: 20042 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0002443324774503708\n",
      "Q Loss:  0.0029819642659276724\n",
      "Policy Loss:  0.2508298456668854\n",
      "[(9e-05, 0.40664), (0.0, 0.40635), (1.0, 0.40664)]\n",
      "Alpha*: 0.0 tau*: 0.40635 Episode: 20051 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  4.109783549210988e-05\n",
      "Q Loss:  0.0025260259862989187\n",
      "Policy Loss:  -0.019315671175718307\n",
      "[(9e-05, 0.40635), (0.0, 0.40606), (1.0, 0.40635)]\n",
      "Alpha*: 0.0 tau*: 0.40606 Episode: 20058 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.49241888523101807\n",
      "Q Loss:  0.11694604158401489\n",
      "Policy Loss:  -2.5774052143096924\n",
      "[(9e-05, 0.40606), (0.0, 0.40577), (1.0, 0.40606)]\n",
      "Alpha*: 0.0 tau*: 0.40577 Episode: 20064 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.319101572036743\n",
      "Q Loss:  0.2784494161605835\n",
      "Policy Loss:  -3.4513275623321533\n",
      "[(9e-05, 0.40577), (0.0, 0.40548), (1.0, 0.40577)]\n",
      "Alpha*: 0.0 tau*: 0.40548 Episode: 20146 length: 53 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012828588485717773\n",
      "Value Loss:  4.904071829514578e-05\n",
      "Q Loss:  0.0020375768654048443\n",
      "Policy Loss:  -0.025914058089256287\n",
      "[(9e-05, 0.40548), (0.0, 0.40519), (1.0, 0.40548)]\n",
      "Alpha*: 0.0 tau*: 0.40519 Episode: 20151 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.583716948516667e-05\n",
      "Q Loss:  0.001314712455496192\n",
      "Policy Loss:  -0.0007588533917441964\n",
      "[(9e-05, 0.40519), (0.0, 0.4049), (1.0, 0.40519)]\n",
      "Alpha*: 0.0 tau*: 0.4049 Episode: 20157 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.02600574493408203\n",
      "Value Loss:  0.4672263264656067\n",
      "Q Loss:  0.2926531136035919\n",
      "Policy Loss:  -1.8565571308135986\n",
      "[(9e-05, 0.4049), (0.0, 0.40461), (1.0, 0.4049)]\n",
      "Alpha*: 0.0 tau*: 0.40461 Episode: 20162 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0003120513283647597\n",
      "Q Loss:  0.005324169527739286\n",
      "Policy Loss:  0.24467352032661438\n",
      "[(9e-05, 0.40461), (0.0, 0.40433), (1.0, 0.40461)]\n",
      "Alpha*: 0.0 tau*: 0.40433 Episode: 20167 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001988114381674677\n",
      "Q Loss:  0.001820493140257895\n",
      "Policy Loss:  -0.013500858098268509\n",
      "[(9e-05, 0.40433), (0.0, 0.40405), (1.0, 0.40433)]\n",
      "Alpha*: 0.0 tau*: 0.40405 Episode: 20172 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  7.811817646026611\n",
      "Q Loss:  3.830789804458618\n",
      "Policy Loss:  -5.738641262054443\n",
      "[(9e-05, 0.40405), (0.0, 0.40377), (1.0, 0.40405)]\n",
      "Alpha*: 0.0 tau*: 0.40377 Episode: 20215 length: 22 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  5.946036981185898e-05\n",
      "Q Loss:  0.0002849270822480321\n",
      "Policy Loss:  0.004681132268160582\n",
      "[(9e-05, 0.40377), (0.0, 0.40349), (1.0, 0.40377)]\n",
      "Alpha*: 0.0 tau*: 0.40349 Episode: 20219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011612415313720703\n",
      "Value Loss:  6.896672130096704e-05\n",
      "Q Loss:  0.0043201870284974575\n",
      "Policy Loss:  0.22913970053195953\n",
      "[(9e-05, 0.40349), (0.0, 0.40321), (1.0, 0.40349)]\n",
      "Alpha*: 0.0 tau*: 0.40321 Episode: 20224 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  19187.1875\n",
      "Q Loss:  19163.9375\n",
      "Policy Loss:  -4.965268135070801\n",
      "[(9e-05, 0.40321), (0.0, 0.40293), (1.0, 0.40321)]\n",
      "Alpha*: 0.0 tau*: 0.40293 Episode: 20334 length: 51 #teleports:59\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  29.741750717163086\n",
      "Q Loss:  33.19394302368164\n",
      "Policy Loss:  -20.654449462890625\n",
      "[(9e-05, 0.40293), (0.0, 0.40265), (1.0, 0.40293)]\n",
      "Alpha*: 0.0 tau*: 0.40265 Episode: 20339 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.6482026441954076e-05\n",
      "Q Loss:  0.09656625986099243\n",
      "Policy Loss:  0.12614715099334717\n",
      "[(9e-05, 0.40265), (0.0, 0.40237), (1.0, 0.40265)]\n",
      "Alpha*: 0.0 tau*: 0.40237 Episode: 20347 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.055169582366943\n",
      "Q Loss:  1.6828022003173828\n",
      "Policy Loss:  -4.2466254234313965\n",
      "[(9e-05, 0.40237), (0.0, 0.40209), (1.0, 0.40237)]\n",
      "Alpha*: 0.0 tau*: 0.40209 Episode: 20562 length: 134 #teleports:81\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.46490567922592163\n",
      "Q Loss:  0.010439162142574787\n",
      "Policy Loss:  -1.850340723991394\n",
      "[(9e-05, 0.40209), (0.0, 0.40181), (1.0, 0.40209)]\n",
      "Alpha*: 0.0 tau*: 0.40181 Episode: 20571 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9.600447654724121\n",
      "Q Loss:  5.490580081939697\n",
      "Policy Loss:  -9.356776237487793\n",
      "[(9e-05, 0.40181), (0.0, 0.40153), (1.0, 0.40181)]\n",
      "Alpha*: 0.0 tau*: 0.40153 Episode: 20642 length: 44 #teleports:27\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.398908019065857\n",
      "Q Loss:  0.02208237536251545\n",
      "Policy Loss:  -1.6908055543899536\n",
      "[(9e-05, 0.40153), (0.0, 0.40125), (1.0, 0.40153)]\n",
      "Alpha*: 0.0 tau*: 0.40125 Episode: 20648 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00025051322882063687\n",
      "Q Loss:  0.3757266700267792\n",
      "Policy Loss:  0.47232586145401\n",
      "[(9e-05, 0.40125), (0.0, 0.40097), (1.0, 0.40125)]\n",
      "Alpha*: 0.0 tau*: 0.40097 Episode: 20657 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00018693110905587673\n",
      "Q Loss:  0.0011577261611819267\n",
      "Policy Loss:  -0.00201828358694911\n",
      "[(9e-05, 0.40097), (0.0, 0.40069), (1.0, 0.40097)]\n",
      "Alpha*: 0.0 tau*: 0.40069 Episode: 20666 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  6.969996320549399e-05\n",
      "Q Loss:  0.0006096153520047665\n",
      "Policy Loss:  0.0035503432154655457\n",
      "[(9e-05, 0.40069), (0.0, 0.40041), (1.0, 0.40069)]\n",
      "Alpha*: 0.0 tau*: 0.40041 Episode: 20673 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.05701017379760742\n",
      "Value Loss:  4.745215846924111e-05\n",
      "Q Loss:  0.006241769064217806\n",
      "Policy Loss:  0.032862842082977295\n",
      "[(9e-05, 0.40041), (0.0, 0.40013), (1.0, 0.40041)]\n",
      "Alpha*: 0.0 tau*: 0.40013 Episode: 20679 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  6.9625630378723145\n",
      "Q Loss:  0.3874616026878357\n",
      "Policy Loss:  -4.892745018005371\n",
      "[(9e-05, 0.40013), (0.0, 0.39985), (1.0, 0.40013)]\n",
      "Alpha*: 0.0 tau*: 0.39985 Episode: 20714 length: 26 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  16.761919021606445\n",
      "Q Loss:  6.787083148956299\n",
      "Policy Loss:  -14.306610107421875\n",
      "[(9e-05, 0.39985), (0.0, 0.39957), (1.0, 0.39985)]\n",
      "Alpha*: 0.0 tau*: 0.39957 Episode: 20762 length: 33 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.091895243618637e-05\n",
      "Q Loss:  0.0028808945789933205\n",
      "Policy Loss:  0.020843852311372757\n",
      "[(9e-05, 0.39957), (0.0, 0.39929), (1.0, 0.39957)]\n",
      "Alpha*: 0.0 tau*: 0.39929 Episode: 20766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  15286.0458984375\n",
      "Q Loss:  15260.4765625\n",
      "Policy Loss:  -8.188400268554688\n",
      "[(9e-05, 0.39929), (0.0, 0.39901), (1.0, 0.39929)]\n",
      "Alpha*: 0.0 tau*: 0.39901 Episode: 20859 length: 64 #teleports:29\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  54339.08203125\n",
      "Q Loss:  54261.7265625\n",
      "Policy Loss:  -14.67569351196289\n",
      "[(9e-05, 0.39901), (0.0, 0.39873), (1.0, 0.39901)]\n",
      "Alpha*: 0.0 tau*: 0.39873 Episode: 20889 length: 18 #teleports:12\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00024249378475360572\n",
      "Q Loss:  0.09258510917425156\n",
      "Policy Loss:  0.11639949679374695\n",
      "[(9e-05, 0.39873), (0.0, 0.39845), (1.0, 0.39873)]\n",
      "Alpha*: 0.0 tau*: 0.39845 Episode: 20896 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0003749396710190922\n",
      "Q Loss:  0.003884746693074703\n",
      "Policy Loss:  0.2277093380689621\n",
      "[(9e-05, 0.39845), (0.0, 0.39817), (1.0, 0.39845)]\n",
      "Alpha*: 0.0 tau*: 0.39817 Episode: 20903 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  3.3307857513427734\n",
      "Q Loss:  0.15759287774562836\n",
      "Policy Loss:  -3.4093761444091797\n",
      "[(9e-05, 0.39817), (0.0, 0.39789), (1.0, 0.39817)]\n",
      "Alpha*: 0.0 tau*: 0.39789 Episode: 20985 length: 58 #teleports:24\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00039783091051504016\n",
      "Q Loss:  0.008071658201515675\n",
      "Policy Loss:  0.26564452052116394\n",
      "[(0.0001, 0.39789), (0.0, 0.39761), (1.0, 0.39789)]\n",
      "Alpha*: 0.0 tau*: 0.39761 Episode: 20989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.9100525379180908\n",
      "Q Loss:  0.32110896706581116\n",
      "Policy Loss:  -1.0342952013015747\n",
      "[(0.0001, 0.39761), (0.0, 0.39733), (1.0, 0.39761)]\n",
      "Alpha*: 0.0 tau*: 0.39733 Episode: 21027 length: 28 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0016165153356269002\n",
      "Q Loss:  0.0004746194463223219\n",
      "Policy Loss:  0.0024252815637737513\n",
      "[(0.0001, 0.39733), (0.0, 0.39705), (1.0, 0.39733)]\n",
      "Alpha*: 0.0 tau*: 0.39705 Episode: 21036 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0011626154882833362\n",
      "Q Loss:  0.002703857608139515\n",
      "Policy Loss:  0.011051028035581112\n",
      "[(0.0001, 0.39705), (0.0, 0.39677), (1.0, 0.39705)]\n",
      "Alpha*: 0.0 tau*: 0.39677 Episode: 21043 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.048009395599365234\n",
      "Value Loss:  4.600677013397217\n",
      "Q Loss:  2.476733922958374\n",
      "Policy Loss:  -3.6076223850250244\n",
      "[(0.0001, 0.39677), (0.0, 0.39649), (1.0, 0.39677)]\n",
      "Alpha*: 0.0 tau*: 0.39649 Episode: 21114 length: 42 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.002754179760813713\n",
      "Q Loss:  0.0015843665460124612\n",
      "Policy Loss:  0.2159445434808731\n",
      "[(0.0001, 0.39649), (0.0, 0.39621), (1.0, 0.39649)]\n",
      "Alpha*: 0.0 tau*: 0.39621 Episode: 21120 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0006844711024314165\n",
      "Q Loss:  0.00246402807533741\n",
      "Policy Loss:  0.03181125596165657\n",
      "[(0.0001, 0.39621), (0.0, 0.39593), (1.0, 0.39621)]\n",
      "Alpha*: 0.0 tau*: 0.39593 Episode: 21126 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0004207906895317137\n",
      "Q Loss:  0.3937271237373352\n",
      "Policy Loss:  0.2307482659816742\n",
      "[(0.0001, 0.39593), (0.0, 0.39565), (1.0, 0.39593)]\n",
      "Alpha*: 0.0 tau*: 0.39565 Episode: 21137 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002998619747813791\n",
      "Q Loss:  0.0071431174874305725\n",
      "Policy Loss:  0.26978349685668945\n",
      "[(0.0001, 0.39565), (0.0, 0.39537), (1.0, 0.39565)]\n",
      "Alpha*: 0.0 tau*: 0.39537 Episode: 21143 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  25681.251953125\n",
      "Q Loss:  25635.5859375\n",
      "Policy Loss:  -7.487685680389404\n",
      "[(0.0001, 0.39537), (0.0, 0.39509), (1.0, 0.39537)]\n",
      "Alpha*: 0.0 tau*: 0.39509 Episode: 21209 length: 38 #teleports:28\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  31474.107421875\n",
      "Q Loss:  31417.3671875\n",
      "Policy Loss:  -8.616570472717285\n",
      "[(0.0001, 0.39509), (0.0, 0.39481), (1.0, 0.39509)]\n",
      "Alpha*: 0.0 tau*: 0.39481 Episode: 21263 length: 31 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.025005340576171875\n",
      "Value Loss:  0.00047927122795954347\n",
      "Q Loss:  0.03448544815182686\n",
      "Policy Loss:  0.08372843265533447\n",
      "[(0.0001, 0.39481), (0.0, 0.39453), (1.0, 0.39481)]\n",
      "Alpha*: 0.0 tau*: 0.39453 Episode: 21267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002138285053661093\n",
      "Q Loss:  0.2954416871070862\n",
      "Policy Loss:  0.3298557698726654\n",
      "[(0.00011, 0.39453), (0.0, 0.39425), (1.0, 0.39453)]\n",
      "Alpha*: 0.0 tau*: 0.39425 Episode: 21272 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  8.005192648852244e-05\n",
      "Q Loss:  0.0008482906268909574\n",
      "Policy Loss:  0.2619437575340271\n",
      "[(0.00011, 0.39425), (0.0, 0.39397), (1.0, 0.39425)]\n",
      "Alpha*: 0.0 tau*: 0.39397 Episode: 21278 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.023004770278930664\n",
      "Value Loss:  6.541182665387169e-05\n",
      "Q Loss:  0.016006749123334885\n",
      "Policy Loss:  0.2896788716316223\n",
      "[(0.00011, 0.39397), (0.0, 0.39369), (1.0, 0.39397)]\n",
      "Alpha*: 0.0 tau*: 0.39369 Episode: 21286 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6840626001358032\n",
      "Q Loss:  0.026149660348892212\n",
      "Policy Loss:  -3.5091476440429688\n",
      "[(0.00011, 0.39369), (0.0, 0.39341), (1.0, 0.39369)]\n",
      "Alpha*: 0.0 tau*: 0.39341 Episode: 21291 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.7406849767430685e-06\n",
      "Q Loss:  0.01657632552087307\n",
      "Policy Loss:  0.3077683448791504\n",
      "[(0.00011, 0.39341), (0.0, 0.39313), (1.0, 0.39341)]\n",
      "Alpha*: 0.0 tau*: 0.39313 Episode: 21298 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  18039.595703125\n",
      "Q Loss:  18008.673828125\n",
      "Policy Loss:  -5.173937797546387\n",
      "[(0.00011, 0.39313), (0.0, 0.39285), (1.0, 0.39313)]\n",
      "Alpha*: 0.0 tau*: 0.39285 Episode: 21373 length: 54 #teleports:21\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  7.826150977052748e-05\n",
      "Q Loss:  0.001531439833343029\n",
      "Policy Loss:  -0.0026068370789289474\n",
      "[(0.00011, 0.39285), (0.0, 0.39257), (1.0, 0.39285)]\n",
      "Alpha*: 0.0 tau*: 0.39257 Episode: 21380 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00012660707579925656\n",
      "Q Loss:  0.00045339667121879756\n",
      "Policy Loss:  -0.006741608493030071\n",
      "[(0.00011, 0.39257), (0.0, 0.39229), (1.0, 0.39257)]\n",
      "Alpha*: 0.0 tau*: 0.39229 Episode: 21384 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001524657418485731\n",
      "Q Loss:  0.11654581874608994\n",
      "Policy Loss:  0.1768399029970169\n",
      "[(0.00012, 0.39229), (0.0, 0.39201), (1.0, 0.39229)]\n",
      "Alpha*: 0.0 tau*: 0.39201 Episode: 21388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00046004404430277646\n",
      "Q Loss:  0.10270872712135315\n",
      "Policy Loss:  0.11328500509262085\n",
      "[(0.00012, 0.39201), (0.0, 0.39173), (1.0, 0.39201)]\n",
      "Alpha*: 0.0 tau*: 0.39173 Episode: 21393 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0004160120734013617\n",
      "Q Loss:  0.0003316935617476702\n",
      "Policy Loss:  0.002137156203389168\n",
      "[(0.00012, 0.39173), (0.0, 0.39145), (1.0, 0.39173)]\n",
      "Alpha*: 0.0 tau*: 0.39145 Episode: 21401 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00013780052540823817\n",
      "Q Loss:  0.06539086252450943\n",
      "Policy Loss:  0.12977775931358337\n",
      "[(0.00012, 0.39145), (0.0, 0.39117), (1.0, 0.39145)]\n",
      "Alpha*: 0.0 tau*: 0.39117 Episode: 21406 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00014058682427275926\n",
      "Q Loss:  0.09975152462720871\n",
      "Policy Loss:  0.13635560870170593\n",
      "[(0.00012, 0.39117), (0.0, 0.39089), (1.0, 0.39117)]\n",
      "Alpha*: 0.0 tau*: 0.39089 Episode: 21412 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  12.25864028930664\n",
      "Q Loss:  2.7861151695251465\n",
      "Policy Loss:  -10.158149719238281\n",
      "[(0.00012, 0.39089), (0.0, 0.39061), (1.0, 0.39089)]\n",
      "Alpha*: 0.0 tau*: 0.39061 Episode: 21480 length: 51 #teleports:17\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  5.10623722220771e-05\n",
      "Q Loss:  32.36478805541992\n",
      "Policy Loss:  0.6920015811920166\n",
      "[(0.00012, 0.39061), (0.0, 0.39033), (1.0, 0.39061)]\n",
      "Alpha*: 0.0 tau*: 0.39033 Episode: 21491 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  49.14336013793945\n",
      "Q Loss:  0.4405440092086792\n",
      "Policy Loss:  -42.3583984375\n",
      "[(0.00012, 0.39033), (0.0, 0.39005), (1.0, 0.39033)]\n",
      "Alpha*: 0.0 tau*: 0.39005 Episode: 21498 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  3.2947034924291074e-05\n",
      "Q Loss:  0.09322388470172882\n",
      "Policy Loss:  0.12887711822986603\n",
      "[(0.00012, 0.39005), (0.0, 0.38977), (1.0, 0.39005)]\n",
      "Alpha*: 0.0 tau*: 0.38977 Episode: 21505 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  48.84070587158203\n",
      "Q Loss:  0.0067344773560762405\n",
      "Policy Loss:  -40.159812927246094\n",
      "[(0.00012, 0.38977), (0.0, 0.38949), (1.0, 0.38977)]\n",
      "Alpha*: 0.0 tau*: 0.38949 Episode: 21511 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  48.95954895019531\n",
      "Q Loss:  57.395355224609375\n",
      "Policy Loss:  -25.296573638916016\n",
      "[(0.00012, 0.38949), (0.0, 0.38921), (1.0, 0.38949)]\n",
      "Alpha*: 0.0 tau*: 0.38921 Episode: 21519 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01162266731262207\n",
      "Value Loss:  1.724014691717457e-05\n",
      "Q Loss:  0.00014551219646818936\n",
      "Policy Loss:  0.0027677342295646667\n",
      "[(0.00012, 0.38921), (0.0, 0.38893), (1.0, 0.38921)]\n",
      "Alpha*: 0.0 tau*: 0.38893 Episode: 21523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.982571601867676\n",
      "Q Loss:  0.14688526093959808\n",
      "Policy Loss:  -6.36785888671875\n",
      "[(0.00012, 0.38893), (0.0, 0.38865), (1.0, 0.38893)]\n",
      "Alpha*: 0.0 tau*: 0.38865 Episode: 21584 length: 36 #teleports:25\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.486795170232654e-05\n",
      "Q Loss:  31.905153274536133\n",
      "Policy Loss:  0.22749590873718262\n",
      "[(0.00012, 0.38865), (0.0, 0.38837), (1.0, 0.38865)]\n",
      "Alpha*: 0.0 tau*: 0.38837 Episode: 21594 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0004795026034116745\n",
      "Q Loss:  0.037549182772636414\n",
      "Policy Loss:  0.08198752254247665\n",
      "[(0.00012, 0.38837), (0.0, 0.38809), (1.0, 0.38837)]\n",
      "Alpha*: 0.0 tau*: 0.38809 Episode: 21600 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011011600494384766\n",
      "Value Loss:  8.529539627488703e-05\n",
      "Q Loss:  0.00202314555644989\n",
      "Policy Loss:  -0.007184847258031368\n",
      "[(0.00012, 0.38809), (0.0, 0.38781), (1.0, 0.38809)]\n",
      "Alpha*: 0.0 tau*: 0.38781 Episode: 21607 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.420238347956911e-05\n",
      "Q Loss:  0.05202775448560715\n",
      "Policy Loss:  0.09665677696466446\n",
      "[(0.00012, 0.38781), (0.0, 0.38753), (1.0, 0.38781)]\n",
      "Alpha*: 0.0 tau*: 0.38753 Episode: 21614 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.03500771522521973\n",
      "Value Loss:  1.3298717931320425e-05\n",
      "Q Loss:  4.4462016376201063e-05\n",
      "Policy Loss:  0.0015537911094725132\n",
      "[(0.00012, 0.38753), (0.0, 0.38725), (1.0, 0.38753)]\n",
      "Alpha*: 0.0 tau*: 0.38725 Episode: 21620 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  49.16366195678711\n",
      "Q Loss:  58.511104583740234\n",
      "Policy Loss:  -26.1427001953125\n",
      "[(0.00012, 0.38725), (0.0, 0.38697), (1.0, 0.38725)]\n",
      "Alpha*: 0.0 tau*: 0.38697 Episode: 21628 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  7.839428901672363\n",
      "Q Loss:  7.611934661865234\n",
      "Policy Loss:  -4.8355512619018555\n",
      "[(0.00012, 0.38697), (0.0, 0.38669), (1.0, 0.38697)]\n",
      "Alpha*: 0.0 tau*: 0.38669 Episode: 21674 length: 31 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.445486068725586\n",
      "Q Loss:  0.49139460921287537\n",
      "Policy Loss:  -5.5590362548828125\n",
      "[(0.00012, 0.38669), (0.0, 0.38641), (1.0, 0.38669)]\n",
      "Alpha*: 0.0 tau*: 0.38641 Episode: 21683 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  49.72238540649414\n",
      "Q Loss:  57.481903076171875\n",
      "Policy Loss:  -17.18854331970215\n",
      "[(0.00012, 0.38641), (0.0, 0.38613), (1.0, 0.38641)]\n",
      "Alpha*: 0.0 tau*: 0.38613 Episode: 21690 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00034151299041695893\n",
      "Q Loss:  30.707134246826172\n",
      "Policy Loss:  0.2541118264198303\n",
      "[(0.00012, 0.38613), (0.0, 0.38585), (1.0, 0.38613)]\n",
      "Alpha*: 0.0 tau*: 0.38585 Episode: 21695 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.2506442070007324\n",
      "Q Loss:  0.14271464943885803\n",
      "Policy Loss:  -1.5519835948944092\n",
      "[(0.00012, 0.38585), (0.0, 0.38557), (1.0, 0.38585)]\n",
      "Alpha*: 0.0 tau*: 0.38557 Episode: 21772 length: 40 #teleports:37\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0890204906463623\n",
      "Value Loss:  1.270157463295618e-05\n",
      "Q Loss:  0.027843095362186432\n",
      "Policy Loss:  0.08965697139501572\n",
      "[(0.00013, 0.38557), (0.0, 0.38529), (1.0, 0.38557)]\n",
      "Alpha*: 0.0 tau*: 0.38529 Episode: 21779 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.944004361575935e-05\n",
      "Q Loss:  0.0038833157159388065\n",
      "Policy Loss:  0.26190370321273804\n",
      "[(0.00013, 0.38529), (0.0, 0.38501), (1.0, 0.38529)]\n",
      "Alpha*: 0.0 tau*: 0.38501 Episode: 21787 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  19447.2890625\n",
      "Q Loss:  19400.513671875\n",
      "Policy Loss:  -3.743375778198242\n",
      "[(0.00013, 0.38501), (0.0, 0.38473), (1.0, 0.38501)]\n",
      "Alpha*: 0.0 tau*: 0.38473 Episode: 21862 length: 50 #teleports:25\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00017642653256189078\n",
      "Q Loss:  0.004146059975028038\n",
      "Policy Loss:  0.040037624537944794\n",
      "[(0.00013, 0.38473), (0.0, 0.38445), (1.0, 0.38473)]\n",
      "Alpha*: 0.0 tau*: 0.38445 Episode: 21869 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.3693373299902305e-05\n",
      "Q Loss:  0.04391061142086983\n",
      "Policy Loss:  0.06228954344987869\n",
      "[(0.00013, 0.38445), (0.0, 0.38417), (1.0, 0.38445)]\n",
      "Alpha*: 0.0 tau*: 0.38417 Episode: 21874 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.4712044250918552e-05\n",
      "Q Loss:  0.00046573884901590645\n",
      "Policy Loss:  0.0032683531753718853\n",
      "[(0.00013, 0.38417), (0.0, 0.38389), (1.0, 0.38417)]\n",
      "Alpha*: 0.0 tau*: 0.38389 Episode: 21881 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.547390072839335e-05\n",
      "Q Loss:  0.0009557931334711611\n",
      "Policy Loss:  -0.006039210595190525\n",
      "[(0.00013, 0.38389), (0.0, 0.38361), (1.0, 0.38389)]\n",
      "Alpha*: 0.0 tau*: 0.38361 Episode: 21886 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.10065603256225586\n",
      "Value Loss:  9.475087608734611e-06\n",
      "Q Loss:  0.05016705021262169\n",
      "Policy Loss:  0.07726878672838211\n",
      "[(0.00013, 0.38361), (0.0, 0.38333), (1.0, 0.38361)]\n",
      "Alpha*: 0.0 tau*: 0.38333 Episode: 21894 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.060013771057128906\n",
      "Value Loss:  1.4728914720762987e-05\n",
      "Q Loss:  0.09120084345340729\n",
      "Policy Loss:  0.3830983340740204\n",
      "[(0.00013, 0.38333), (0.0, 0.38305), (1.0, 0.38333)]\n",
      "Alpha*: 0.0 tau*: 0.38305 Episode: 21904 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001636649831198156\n",
      "Q Loss:  0.0005557709373533726\n",
      "Policy Loss:  -0.006924203597009182\n",
      "[(0.00013, 0.38305), (0.0, 0.38277), (1.0, 0.38305)]\n",
      "Alpha*: 0.0 tau*: 0.38277 Episode: 21909 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.467063718038844e-06\n",
      "Q Loss:  0.08830492198467255\n",
      "Policy Loss:  0.11958787590265274\n",
      "[(0.00013, 0.38277), (0.0, 0.38249), (1.0, 0.38277)]\n",
      "Alpha*: 0.0 tau*: 0.38249 Episode: 21916 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.5267122509831097e-06\n",
      "Q Loss:  0.18375395238399506\n",
      "Policy Loss:  0.2508620619773865\n",
      "[(0.00013, 0.38249), (0.0, 0.38221), (1.0, 0.38249)]\n",
      "Alpha*: 0.0 tau*: 0.38221 Episode: 21921 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  3.296773866168223e-05\n",
      "Q Loss:  0.1293068677186966\n",
      "Policy Loss:  0.17977553606033325\n",
      "[(0.00013, 0.38221), (0.0, 0.38193), (1.0, 0.38221)]\n",
      "Alpha*: 0.0 tau*: 0.38193 Episode: 21932 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.2241007172851823e-05\n",
      "Q Loss:  5.075281660538167e-05\n",
      "Policy Loss:  0.0023681859020143747\n",
      "[(0.00013, 0.38193), (0.0, 0.38165), (1.0, 0.38193)]\n",
      "Alpha*: 0.0 tau*: 0.38165 Episode: 21938 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.9754100441932678\n",
      "Q Loss:  2.5085537433624268\n",
      "Policy Loss:  -0.8960749506950378\n",
      "[(0.00013, 0.38165), (0.0, 0.38137), (1.0, 0.38165)]\n",
      "Alpha*: 0.0 tau*: 0.38137 Episode: 22018 length: 52 #teleports:28\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  50.766788482666016\n",
      "Q Loss:  59.86090087890625\n",
      "Policy Loss:  -27.849689483642578\n",
      "[(0.00013, 0.38137), (0.0, 0.38109), (1.0, 0.38137)]\n",
      "Alpha*: 0.0 tau*: 0.38109 Episode: 22025 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  50.774070739746094\n",
      "Q Loss:  0.0044240886345505714\n",
      "Policy Loss:  -40.93791961669922\n",
      "[(0.00013, 0.38109), (0.0, 0.38081), (1.0, 0.38109)]\n",
      "Alpha*: 0.0 tau*: 0.38081 Episode: 22031 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.06201362609863281\n",
      "Value Loss:  9.0975208877353e-06\n",
      "Q Loss:  0.1722600907087326\n",
      "Policy Loss:  0.24984018504619598\n",
      "[(0.00013, 0.38081), (0.0, 0.38053), (1.0, 0.38081)]\n",
      "Alpha*: 0.0 tau*: 0.38053 Episode: 22039 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  8.32160822028527e-06\n",
      "Q Loss:  0.0002036873484030366\n",
      "Policy Loss:  0.004704260267317295\n",
      "[(0.00013, 0.38053), (0.0, 0.38025), (1.0, 0.38053)]\n",
      "Alpha*: 0.0 tau*: 0.38025 Episode: 22043 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.515180535236141e-06\n",
      "Q Loss:  0.21738074719905853\n",
      "Policy Loss:  0.30438461899757385\n",
      "[(0.00013, 0.38025), (0.0, 0.37997), (1.0, 0.38025)]\n",
      "Alpha*: 0.0 tau*: 0.37997 Episode: 22049 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  25573.548828125\n",
      "Q Loss:  25508.5546875\n",
      "Policy Loss:  -4.149403095245361\n",
      "[(0.00013, 0.37997), (0.0, 0.37969), (1.0, 0.37997)]\n",
      "Alpha*: 0.0 tau*: 0.37969 Episode: 22110 length: 38 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  102.01006317138672\n",
      "Q Loss:  92.1222152709961\n",
      "Policy Loss:  -53.218589782714844\n",
      "[(0.00013, 0.37969), (0.0, 0.37941), (1.0, 0.37969)]\n",
      "Alpha*: 0.0 tau*: 0.37941 Episode: 22115 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.3674603700637817\n",
      "Q Loss:  0.542016327381134\n",
      "Policy Loss:  -2.568782329559326\n",
      "[(0.00013, 0.37941), (0.0, 0.37913), (1.0, 0.37941)]\n",
      "Alpha*: 0.0 tau*: 0.37913 Episode: 22122 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  51.51718521118164\n",
      "Q Loss:  31.07853126525879\n",
      "Policy Loss:  -39.72850799560547\n",
      "[(0.00013, 0.37913), (0.0, 0.37885), (1.0, 0.37913)]\n",
      "Alpha*: 0.0 tau*: 0.37885 Episode: 22129 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.1694245990365744e-05\n",
      "Q Loss:  6.866358307888731e-05\n",
      "Policy Loss:  -0.005540540441870689\n",
      "[(0.00013, 0.37885), (0.0, 0.37857), (1.0, 0.37885)]\n",
      "Alpha*: 0.0 tau*: 0.37857 Episode: 22133 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  14.360991477966309\n",
      "Q Loss:  8.20788288116455\n",
      "Policy Loss:  -10.316059112548828\n",
      "[(0.00013, 0.37857), (0.0, 0.37829), (1.0, 0.37857)]\n",
      "Alpha*: 0.0 tau*: 0.37829 Episode: 22216 length: 47 #teleports:36\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  2.1363621272030286e-05\n",
      "Q Loss:  0.00033925933530554175\n",
      "Policy Loss:  0.009541510604321957\n",
      "[(0.00013, 0.37829), (0.0, 0.37801), (1.0, 0.37829)]\n",
      "Alpha*: 0.0 tau*: 0.37801 Episode: 22221 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.293616100563668e-05\n",
      "Q Loss:  0.22188939154148102\n",
      "Policy Loss:  0.32034367322921753\n",
      "[(0.00013, 0.37801), (0.0, 0.37773), (1.0, 0.37801)]\n",
      "Alpha*: 0.0 tau*: 0.37773 Episode: 22227 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.04400992393493652\n",
      "Value Loss:  2.3452917957911268e-05\n",
      "Q Loss:  0.12705601751804352\n",
      "Policy Loss:  0.22176527976989746\n",
      "[(0.00013, 0.37773), (0.0, 0.37745), (1.0, 0.37773)]\n",
      "Alpha*: 0.0 tau*: 0.37745 Episode: 22234 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  5.211519692238653e-06\n",
      "Q Loss:  0.05004517361521721\n",
      "Policy Loss:  0.08646634966135025\n",
      "[(0.00012, 0.37745), (0.0, 0.37717), (1.0, 0.37745)]\n",
      "Alpha*: 0.0 tau*: 0.37717 Episode: 22240 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.6573960185050964\n",
      "Q Loss:  0.012155542150139809\n",
      "Policy Loss:  -1.9008450508117676\n",
      "[(0.00012, 0.37717), (0.0, 0.37689), (1.0, 0.37717)]\n",
      "Alpha*: 0.0 tau*: 0.37689 Episode: 22246 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012662887573242188\n",
      "Value Loss:  6.890538315929007e-06\n",
      "Q Loss:  0.013545721769332886\n",
      "Policy Loss:  0.05812646448612213\n",
      "[(0.00012, 0.37689), (0.0, 0.37661), (1.0, 0.37689)]\n",
      "Alpha*: 0.0 tau*: 0.37661 Episode: 22252 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.683363914489746\n",
      "Q Loss:  8.14033031463623\n",
      "Policy Loss:  -6.440156936645508\n",
      "[(0.00012, 0.37661), (0.0, 0.37633), (1.0, 0.37661)]\n",
      "Alpha*: 0.0 tau*: 0.37633 Episode: 22326 length: 48 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.6434423327445984\n",
      "Q Loss:  0.5671427845954895\n",
      "Policy Loss:  -2.9627082347869873\n",
      "[(0.00012, 0.37633), (0.0, 0.37605), (1.0, 0.37633)]\n",
      "Alpha*: 0.0 tau*: 0.37605 Episode: 22334 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.552062430069782e-05\n",
      "Q Loss:  0.0014827287523075938\n",
      "Policy Loss:  0.022331245243549347\n",
      "[(0.00012, 0.37605), (0.0, 0.37577), (1.0, 0.37605)]\n",
      "Alpha*: 0.0 tau*: 0.37577 Episode: 22341 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  53.07186508178711\n",
      "Q Loss:  30.6845760345459\n",
      "Policy Loss:  -40.797603607177734\n",
      "[(0.00012, 0.37577), (0.0, 0.37549), (1.0, 0.37577)]\n",
      "Alpha*: 0.0 tau*: 0.37549 Episode: 22347 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  11049.4765625\n",
      "Q Loss:  11004.1845703125\n",
      "Policy Loss:  -11.65163516998291\n",
      "[(0.00012, 0.37549), (0.0, 0.37521), (1.0, 0.37549)]\n",
      "Alpha*: 0.0 tau*: 0.37521 Episode: 22475 length: 88 #teleports:40\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  76685.9609375\n",
      "Q Loss:  76443.0546875\n",
      "Policy Loss:  -17.991825103759766\n",
      "[(0.00013, 0.37521), (0.0, 0.37493), (1.0, 0.37521)]\n",
      "Alpha*: 0.0 tau*: 0.37493 Episode: 22524 length: 38 #teleports:11\n",
      "Got not null reward 3005.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00016607690486125648\n",
      "Q Loss:  0.0004966740380041301\n",
      "Policy Loss:  -0.007004767656326294\n",
      "[(0.00013, 0.37493), (0.0, 0.37465), (1.0, 0.37493)]\n",
      "Alpha*: 0.0 tau*: 0.37465 Episode: 22528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  55.24160385131836\n",
      "Q Loss:  1.137969970703125\n",
      "Policy Loss:  -41.34748077392578\n",
      "[(0.00013, 0.37465), (0.0, 0.37437), (1.0, 0.37465)]\n",
      "Alpha*: 0.0 tau*: 0.37437 Episode: 22534 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  16732.298828125\n",
      "Q Loss:  16673.412109375\n",
      "Policy Loss:  -6.412993907928467\n",
      "[(0.00014, 0.37437), (0.0, 0.3741), (1.0, 0.37437)]\n",
      "Alpha*: 0.0 tau*: 0.3741 Episode: 22633 length: 58 #teleports:41\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6086522936820984\n",
      "Q Loss:  0.46187812089920044\n",
      "Policy Loss:  -2.0198185443878174\n",
      "[(0.00014, 0.3741), (0.0, 0.37383), (1.0, 0.3741)]\n",
      "Alpha*: 0.0 tau*: 0.37383 Episode: 22637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  58.86439514160156\n",
      "Q Loss:  34.43482208251953\n",
      "Policy Loss:  -42.65925598144531\n",
      "[(0.00014, 0.37383), (0.0, 0.37356), (1.0, 0.37383)]\n",
      "Alpha*: 0.0 tau*: 0.37356 Episode: 22643 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  59.88759994506836\n",
      "Q Loss:  76.9748306274414\n",
      "Policy Loss:  -26.173240661621094\n",
      "[(0.00014, 0.37356), (0.0, 0.37329), (1.0, 0.37356)]\n",
      "Alpha*: 0.0 tau*: 0.37329 Episode: 22649 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  1.932947039604187\n",
      "Q Loss:  0.09885038435459137\n",
      "Policy Loss:  -0.7342904806137085\n",
      "[(0.00014, 0.37329), (0.0, 0.37302), (1.0, 0.37329)]\n",
      "Alpha*: 0.0 tau*: 0.37302 Episode: 22691 length: 26 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  123.06478881835938\n",
      "Q Loss:  189.669921875\n",
      "Policy Loss:  -33.28873825073242\n",
      "[(0.00015, 0.37302), (0.0, 0.37275), (1.0, 0.37302)]\n",
      "Alpha*: 0.0 tau*: 0.37275 Episode: 22701 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  11.481534004211426\n",
      "Q Loss:  17.96249771118164\n",
      "Policy Loss:  -4.687874794006348\n",
      "[(0.00015, 0.37275), (0.0, 0.37248), (1.0, 0.37275)]\n",
      "Alpha*: 0.0 tau*: 0.37248 Episode: 22738 length: 26 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.501007080078125\n",
      "Q Loss:  0.10387475043535233\n",
      "Policy Loss:  -0.4992469251155853\n",
      "[(0.00015, 0.37248), (0.0, 0.37221), (1.0, 0.37248)]\n",
      "Alpha*: 0.0 tau*: 0.37221 Episode: 22764 length: 19 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  42121.30859375\n",
      "Q Loss:  41956.76953125\n",
      "Policy Loss:  -10.001288414001465\n",
      "[(0.00015, 0.37221), (0.0, 0.37194), (1.0, 0.37221)]\n",
      "Alpha*: 0.0 tau*: 0.37194 Episode: 22802 length: 23 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  11017.3486328125\n",
      "Q Loss:  10974.7080078125\n",
      "Policy Loss:  -10.924708366394043\n",
      "[(0.00015, 0.37194), (0.0, 0.37167), (1.0, 0.37194)]\n",
      "Alpha*: 0.0 tau*: 0.37167 Episode: 22943 length: 88 #teleports:53\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  65.52464294433594\n",
      "Q Loss:  1.522545576095581\n",
      "Policy Loss:  -44.39387893676758\n",
      "[(0.00015, 0.37167), (0.0, 0.3714), (1.0, 0.37167)]\n",
      "Alpha*: 0.0 tau*: 0.3714 Episode: 22949 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00027096763369627297\n",
      "Q Loss:  1.5317940711975098\n",
      "Policy Loss:  0.5032353401184082\n",
      "[(0.00015, 0.3714), (0.0, 0.37113), (1.0, 0.3714)]\n",
      "Alpha*: 0.0 tau*: 0.37113 Episode: 22954 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.6917997002601624\n",
      "Q Loss:  1.53476083278656\n",
      "Policy Loss:  -0.19380033016204834\n",
      "[(0.00016, 0.37113), (0.0, 0.37086), (1.0, 0.37113)]\n",
      "Alpha*: 0.0 tau*: 0.37086 Episode: 22959 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  9.513514518737793\n",
      "Q Loss:  2.1817541122436523\n",
      "Policy Loss:  -6.611573696136475\n",
      "[(0.00016, 0.37086), (0.0, 0.37059), (1.0, 0.37086)]\n",
      "Alpha*: 0.0 tau*: 0.37059 Episode: 23103 length: 92 #teleports:52\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.655945301055908\n",
      "Q Loss:  0.4602285921573639\n",
      "Policy Loss:  -4.793026447296143\n",
      "[(0.00016, 0.37059), (0.0, 0.37032), (1.0, 0.37059)]\n",
      "Alpha*: 0.0 tau*: 0.37032 Episode: 23183 length: 50 #teleports:30\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02800607681274414\n",
      "Value Loss:  7.828630259609781e-06\n",
      "Q Loss:  0.016513943672180176\n",
      "Policy Loss:  0.06333468854427338\n",
      "[(0.00016, 0.37032), (0.0, 0.37005), (1.0, 0.37032)]\n",
      "Alpha*: 0.0 tau*: 0.37005 Episode: 23187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.0230743100692052e-05\n",
      "Q Loss:  0.00764547660946846\n",
      "Policy Loss:  0.049792248755693436\n",
      "[(0.00016, 0.37005), (0.0, 0.36978), (1.0, 0.37005)]\n",
      "Alpha*: 0.0 tau*: 0.36978 Episode: 23194 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014001607894897461\n",
      "Value Loss:  5.6694760132813826e-05\n",
      "Q Loss:  0.014893394894897938\n",
      "Policy Loss:  0.058569058775901794\n",
      "[(0.00016, 0.36978), (0.0, 0.36951), (1.0, 0.36978)]\n",
      "Alpha*: 0.0 tau*: 0.36951 Episode: 23209 length: 4 #teleports:11\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  10861.8515625\n",
      "Q Loss:  10814.8720703125\n",
      "Policy Loss:  -4.6559295654296875\n",
      "[(0.00016, 0.36951), (0.0, 0.36924), (1.0, 0.36951)]\n",
      "Alpha*: 0.0 tau*: 0.36924 Episode: 23349 length: 89 #teleports:51\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  72.67967987060547\n",
      "Q Loss:  93.24005126953125\n",
      "Policy Loss:  -32.78799057006836\n",
      "[(0.00016, 0.36924), (0.0, 0.36897), (1.0, 0.36924)]\n",
      "Alpha*: 0.0 tau*: 0.36897 Episode: 23354 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  7.564649422420189e-05\n",
      "Q Loss:  0.0027300589717924595\n",
      "Policy Loss:  0.007454134989529848\n",
      "[(0.00016, 0.36897), (0.0, 0.3687), (1.0, 0.36897)]\n",
      "Alpha*: 0.0 tau*: 0.3687 Episode: 23362 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  6.38113033346599e-06\n",
      "Q Loss:  0.004586025606840849\n",
      "Policy Loss:  0.2990191578865051\n",
      "[(0.00016, 0.3687), (0.0, 0.36843), (1.0, 0.3687)]\n",
      "Alpha*: 0.0 tau*: 0.36843 Episode: 23368 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  74.24711608886719\n",
      "Q Loss:  44.033790588378906\n",
      "Policy Loss:  -45.37455749511719\n",
      "[(0.00017, 0.36843), (0.0, 0.36816), (1.0, 0.36843)]\n",
      "Alpha*: 0.0 tau*: 0.36816 Episode: 23376 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.624445500667207e-05\n",
      "Q Loss:  0.001368003897368908\n",
      "Policy Loss:  0.0203150175511837\n",
      "[(0.00017, 0.36816), (0.0, 0.36789), (1.0, 0.36816)]\n",
      "Alpha*: 0.0 tau*: 0.36789 Episode: 23384 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  15.271088600158691\n",
      "Q Loss:  9.782567977905273\n",
      "Policy Loss:  -9.26608657836914\n",
      "[(0.00017, 0.36789), (0.0, 0.36762), (1.0, 0.36789)]\n",
      "Alpha*: 0.0 tau*: 0.36762 Episode: 23550 length: 101 #teleports:65\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013031721115112305\n",
      "Value Loss:  1.9118777345283888e-05\n",
      "Q Loss:  0.01533680222928524\n",
      "Policy Loss:  0.04292811453342438\n",
      "[(0.00017, 0.36762), (0.0, 0.36735), (1.0, 0.36762)]\n",
      "Alpha*: 0.0 tau*: 0.36735 Episode: 23557 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  24148.130859375\n",
      "Q Loss:  24022.0078125\n",
      "Policy Loss:  -10.022705078125\n",
      "[(0.00017, 0.36735), (0.0, 0.36708), (1.0, 0.36735)]\n",
      "Alpha*: 0.0 tau*: 0.36708 Episode: 23616 length: 40 #teleports:19\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.640399518189952e-05\n",
      "Q Loss:  0.00034696809598244727\n",
      "Policy Loss:  -0.006271841004490852\n",
      "[(0.00017, 0.36708), (0.0, 0.36681), (1.0, 0.36708)]\n",
      "Alpha*: 0.0 tau*: 0.36681 Episode: 23620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.87173682206776e-05\n",
      "Q Loss:  0.015717769041657448\n",
      "Policy Loss:  0.05508870631456375\n",
      "[(0.00017, 0.36681), (0.0, 0.36654), (1.0, 0.36681)]\n",
      "Alpha*: 0.0 tau*: 0.36654 Episode: 23628 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  77.40434265136719\n",
      "Q Loss:  188.51856994628906\n",
      "Policy Loss:  -27.75016212463379\n",
      "[(0.00018, 0.36654), (0.0, 0.36627), (1.0, 0.36654)]\n",
      "Alpha*: 0.0 tau*: 0.36627 Episode: 23638 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  78.67504119873047\n",
      "Q Loss:  101.95954132080078\n",
      "Policy Loss:  -22.474456787109375\n",
      "[(0.00017, 0.36627), (0.0, 0.366), (1.0, 0.36627)]\n",
      "Alpha*: 0.0 tau*: 0.366 Episode: 23645 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  23566.62890625\n",
      "Q Loss:  23445.384765625\n",
      "Policy Loss:  -19.37921905517578\n",
      "[(0.00017, 0.366), (0.0, 0.36573), (1.0, 0.366)]\n",
      "Alpha*: 0.0 tau*: 0.36573 Episode: 23722 length: 41 #teleports:36\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.539710814948194e-05\n",
      "Q Loss:  0.007131221238523722\n",
      "Policy Loss:  0.041844699531793594\n",
      "[(0.00017, 0.36573), (0.0, 0.36546), (1.0, 0.36573)]\n",
      "Alpha*: 0.0 tau*: 0.36546 Episode: 23728 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.048009395599365234\n",
      "Value Loss:  3.0674123991047964e-05\n",
      "Q Loss:  0.05162259191274643\n",
      "Policy Loss:  0.09728588908910751\n",
      "[(0.00018, 0.36546), (0.0, 0.36519), (1.0, 0.36546)]\n",
      "Alpha*: 0.0 tau*: 0.36519 Episode: 23737 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0008528806501999497\n",
      "Q Loss:  0.0006889768410474062\n",
      "Policy Loss:  0.27186280488967896\n",
      "[(0.00018, 0.36519), (0.0, 0.36492), (1.0, 0.36519)]\n",
      "Alpha*: 0.0 tau*: 0.36492 Episode: 23743 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.6360408067703247\n",
      "Q Loss:  0.019873712211847305\n",
      "Policy Loss:  -3.1247434616088867\n",
      "[(0.00018, 0.36492), (0.0, 0.36465), (1.0, 0.36492)]\n",
      "Alpha*: 0.0 tau*: 0.36465 Episode: 23748 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0006995902513153851\n",
      "Q Loss:  0.006437983829528093\n",
      "Policy Loss:  0.021611589938402176\n",
      "[(0.00018, 0.36465), (0.0, 0.36438), (1.0, 0.36465)]\n",
      "Alpha*: 0.0 tau*: 0.36438 Episode: 23753 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  7.801750325597823e-05\n",
      "Q Loss:  0.0011522567365318537\n",
      "Policy Loss:  -0.013629579916596413\n",
      "[(0.00018, 0.36438), (0.0, 0.36411), (1.0, 0.36438)]\n",
      "Alpha*: 0.0 tau*: 0.36411 Episode: 23760 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8400.341796875\n",
      "Q Loss:  8346.1015625\n",
      "Policy Loss:  -12.287341117858887\n",
      "[(0.00018, 0.36411), (0.0, 0.36384), (1.0, 0.36411)]\n",
      "Alpha*: 0.0 tau*: 0.36384 Episode: 23946 length: 115 #teleports:71\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.7776769399642944\n",
      "Q Loss:  0.604232132434845\n",
      "Policy Loss:  -1.898719072341919\n",
      "[(0.00018, 0.36384), (0.0, 0.36357), (1.0, 0.36384)]\n",
      "Alpha*: 0.0 tau*: 0.36357 Episode: 23952 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  5.1768089178949594e-05\n",
      "Q Loss:  0.046521104872226715\n",
      "Policy Loss:  0.34975773096084595\n",
      "[(0.00018, 0.36357), (0.0, 0.3633), (1.0, 0.36357)]\n",
      "Alpha*: 0.0 tau*: 0.3633 Episode: 23961 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.02600574493408203\n",
      "Value Loss:  7.14349516783841e-05\n",
      "Q Loss:  0.003381588961929083\n",
      "Policy Loss:  0.02456989884376526\n",
      "[(0.00018, 0.3633), (0.0, 0.36303), (1.0, 0.3633)]\n",
      "Alpha*: 0.0 tau*: 0.36303 Episode: 23966 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  21907.58984375\n",
      "Q Loss:  21784.99609375\n",
      "Policy Loss:  -9.014817237854004\n",
      "[(0.00018, 0.36303), (0.0, 0.36276), (1.0, 0.36303)]\n",
      "Alpha*: 0.0 tau*: 0.36276 Episode: 24027 length: 44 #teleports:17\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0001716169063001871\n",
      "Q Loss:  0.0021661666687577963\n",
      "Policy Loss:  0.011972183361649513\n",
      "[(0.00018, 0.36276), (0.0, 0.36249), (1.0, 0.36276)]\n",
      "Alpha*: 0.0 tau*: 0.36249 Episode: 24034 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.1101258577546105e-05\n",
      "Q Loss:  0.002277287421748042\n",
      "Policy Loss:  0.015384790487587452\n",
      "[(0.00018, 0.36249), (0.0, 0.36222), (1.0, 0.36249)]\n",
      "Alpha*: 0.0 tau*: 0.36222 Episode: 24045 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.0765465049189515e-05\n",
      "Q Loss:  0.00947150494903326\n",
      "Policy Loss:  0.05230399966239929\n",
      "[(0.00018, 0.36222), (0.0, 0.36195), (1.0, 0.36222)]\n",
      "Alpha*: 0.0 tau*: 0.36195 Episode: 24050 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  87.87904357910156\n",
      "Q Loss:  0.0045235417783260345\n",
      "Policy Loss:  -54.011268615722656\n",
      "[(0.00019, 0.36195), (0.0, 0.36168), (1.0, 0.36195)]\n",
      "Alpha*: 0.0 tau*: 0.36168 Episode: 24055 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  88.40327453613281\n",
      "Q Loss:  52.976043701171875\n",
      "Policy Loss:  -46.34992218017578\n",
      "[(0.00019, 0.36168), (0.0, 0.36141), (1.0, 0.36168)]\n",
      "Alpha*: 0.0 tau*: 0.36141 Episode: 24059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.000916644348763e-05\n",
      "Q Loss:  0.002655228367075324\n",
      "Policy Loss:  0.023434922099113464\n",
      "[(0.00019, 0.36141), (0.0, 0.36114), (1.0, 0.36141)]\n",
      "Alpha*: 0.0 tau*: 0.36114 Episode: 24063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5.357028385333251e-06\n",
      "Q Loss:  0.004339063074439764\n",
      "Policy Loss:  0.03925003856420517\n",
      "[(0.00019, 0.36114), (0.0, 0.36087), (1.0, 0.36114)]\n",
      "Alpha*: 0.0 tau*: 0.36087 Episode: 24067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00019297988910693675\n",
      "Q Loss:  0.0021159485913813114\n",
      "Policy Loss:  0.012057492509484291\n",
      "[(0.00018, 0.36087), (0.0, 0.3606), (1.0, 0.36087)]\n",
      "Alpha*: 0.0 tau*: 0.3606 Episode: 24074 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0001239253906533122\n",
      "Q Loss:  0.0017883796244859695\n",
      "Policy Loss:  0.016908995807170868\n",
      "[(0.00017, 0.3606), (0.0, 0.36033), (1.0, 0.3606)]\n",
      "Alpha*: 0.0 tau*: 0.36033 Episode: 24080 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.018639087677001953\n",
      "Value Loss:  4.348336369730532e-05\n",
      "Q Loss:  0.0005925485165789723\n",
      "Policy Loss:  0.0019248590106144547\n",
      "[(0.00017, 0.36033), (0.0, 0.36006), (1.0, 0.36033)]\n",
      "Alpha*: 0.0 tau*: 0.36006 Episode: 24086 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.605172241805121e-05\n",
      "Q Loss:  0.039894767105579376\n",
      "Policy Loss:  0.08902635425329208\n",
      "[(0.00016, 0.36006), (0.0, 0.35979), (1.0, 0.36006)]\n",
      "Alpha*: 0.0 tau*: 0.35979 Episode: 24091 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00011627209460129961\n",
      "Q Loss:  0.0006525805220007896\n",
      "Policy Loss:  -0.004649655893445015\n",
      "[(0.00015, 0.35979), (0.0, 0.35952), (1.0, 0.35979)]\n",
      "Alpha*: 0.0 tau*: 0.35952 Episode: 24098 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.05001020431518555\n",
      "Value Loss:  90.37210845947266\n",
      "Q Loss:  123.36380004882812\n",
      "Policy Loss:  -33.26004409790039\n",
      "[(0.00017, 0.35952), (0.0, 0.35925), (1.0, 0.35952)]\n",
      "Alpha*: 0.0 tau*: 0.35925 Episode: 24105 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.4334571460494772e-05\n",
      "Q Loss:  0.0012144751381129026\n",
      "Policy Loss:  0.009468072094023228\n",
      "[(0.00018, 0.35925), (0.0, 0.35898), (1.0, 0.35925)]\n",
      "Alpha*: 0.0 tau*: 0.35898 Episode: 24109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  19.337862014770508\n",
      "Q Loss:  24.565982818603516\n",
      "Policy Loss:  -5.4778242111206055\n",
      "[(0.00018, 0.35898), (0.0, 0.35871), (1.0, 0.35898)]\n",
      "Alpha*: 0.0 tau*: 0.35871 Episode: 24141 length: 21 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00042841455433517694\n",
      "Q Loss:  0.03450608253479004\n",
      "Policy Loss:  0.06300199031829834\n",
      "[(0.00017, 0.35871), (0.0, 0.35844), (1.0, 0.35871)]\n",
      "Alpha*: 0.0 tau*: 0.35844 Episode: 24146 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003891995002049953\n",
      "Q Loss:  0.0003676156047731638\n",
      "Policy Loss:  0.004525246098637581\n",
      "[(0.00017, 0.35844), (0.0, 0.35817), (1.0, 0.35844)]\n",
      "Alpha*: 0.0 tau*: 0.35817 Episode: 24150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  90.35350036621094\n",
      "Q Loss:  0.007871057838201523\n",
      "Policy Loss:  -54.76430892944336\n",
      "[(0.00016, 0.35817), (0.0, 0.3579), (1.0, 0.35817)]\n",
      "Alpha*: 0.0 tau*: 0.3579 Episode: 24157 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.490486314054579e-05\n",
      "Q Loss:  0.0003340534458402544\n",
      "Policy Loss:  -0.004698177799582481\n",
      "[(0.00016, 0.3579), (0.0, 0.35763), (1.0, 0.3579)]\n",
      "Alpha*: 0.0 tau*: 0.35763 Episode: 24162 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.8115044440492056e-05\n",
      "Q Loss:  0.5781084895133972\n",
      "Policy Loss:  0.012088622897863388\n",
      "[(0.00015, 0.35763), (0.0, 0.35736), (1.0, 0.35763)]\n",
      "Alpha*: 0.0 tau*: 0.35736 Episode: 24166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  89.94928741455078\n",
      "Q Loss:  0.000847293995320797\n",
      "Policy Loss:  -54.505741119384766\n",
      "[(0.00015, 0.35736), (0.0, 0.35709), (1.0, 0.35736)]\n",
      "Alpha*: 0.0 tau*: 0.35709 Episode: 24172 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.7319526672363281\n",
      "Q Loss:  0.4957423210144043\n",
      "Policy Loss:  -0.9925618171691895\n",
      "[(0.00015, 0.35709), (0.0, 0.35682), (1.0, 0.35709)]\n",
      "Alpha*: 0.0 tau*: 0.35682 Episode: 24178 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0007402694318443537\n",
      "Q Loss:  0.0008499460527673364\n",
      "Policy Loss:  -0.02326226234436035\n",
      "[(0.00014, 0.35682), (0.0, 0.35655), (1.0, 0.35682)]\n",
      "Alpha*: 0.0 tau*: 0.35655 Episode: 24182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07901859283447266\n",
      "Value Loss:  8.818299647828098e-06\n",
      "Q Loss:  0.031898073852062225\n",
      "Policy Loss:  0.08899570256471634\n",
      "[(0.00014, 0.35655), (0.0, 0.35628), (1.0, 0.35655)]\n",
      "Alpha*: 0.0 tau*: 0.35628 Episode: 24187 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.214466050849296e-05\n",
      "Q Loss:  0.0004659466212615371\n",
      "Policy Loss:  -0.010383058339357376\n",
      "[(0.00014, 0.35628), (0.0, 0.35601), (1.0, 0.35628)]\n",
      "Alpha*: 0.0 tau*: 0.35601 Episode: 24195 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  88.94414520263672\n",
      "Q Loss:  121.83303833007812\n",
      "Policy Loss:  -34.057621002197266\n",
      "[(0.00015, 0.35601), (0.0, 0.35574), (1.0, 0.35601)]\n",
      "Alpha*: 0.0 tau*: 0.35574 Episode: 24203 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.7183839082717896\n",
      "Q Loss:  0.505429744720459\n",
      "Policy Loss:  -3.2157797813415527\n",
      "[(0.00016, 0.35574), (0.0, 0.35547), (1.0, 0.35574)]\n",
      "Alpha*: 0.0 tau*: 0.35547 Episode: 24209 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00010145670967176557\n",
      "Q Loss:  0.0006325678550638258\n",
      "Policy Loss:  0.0038402273785322905\n",
      "[(0.00017, 0.35547), (0.0, 0.3552), (1.0, 0.35547)]\n",
      "Alpha*: 0.0 tau*: 0.3552 Episode: 24215 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00021835605730302632\n",
      "Q Loss:  0.0010599065572023392\n",
      "Policy Loss:  0.011967355385422707\n",
      "[(0.00017, 0.3552), (0.0, 0.35493), (1.0, 0.3552)]\n",
      "Alpha*: 0.0 tau*: 0.35493 Episode: 24221 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  7.594602357130498e-05\n",
      "Q Loss:  0.004447758663445711\n",
      "Policy Loss:  0.03584133833646774\n",
      "[(0.00017, 0.35493), (0.0, 0.35466), (1.0, 0.35493)]\n",
      "Alpha*: 0.0 tau*: 0.35466 Episode: 24226 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00028741807909682393\n",
      "Q Loss:  0.000690951244905591\n",
      "Policy Loss:  0.007892463356256485\n",
      "[(0.00016, 0.35466), (0.0, 0.35439), (1.0, 0.35466)]\n",
      "Alpha*: 0.0 tau*: 0.35439 Episode: 24231 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00028794771060347557\n",
      "Q Loss:  0.0035190838389098644\n",
      "Policy Loss:  0.2897918224334717\n",
      "[(0.00015, 0.35439), (0.0, 0.35412), (1.0, 0.35439)]\n",
      "Alpha*: 0.0 tau*: 0.35412 Episode: 24235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.6798672080039978\n",
      "Q Loss:  0.3686220645904541\n",
      "Policy Loss:  -3.601720094680786\n",
      "[(0.00015, 0.35412), (0.0, 0.35385), (1.0, 0.35412)]\n",
      "Alpha*: 0.0 tau*: 0.35385 Episode: 24240 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012605428695678711\n",
      "Value Loss:  13578.3984375\n",
      "Q Loss:  13472.921875\n",
      "Policy Loss:  -12.216588020324707\n",
      "[(0.00015, 0.35385), (0.0, 0.35358), (1.0, 0.35385)]\n",
      "Alpha*: 0.0 tau*: 0.35358 Episode: 24336 length: 71 #teleports:25\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  4.102974799025105e-06\n",
      "Q Loss:  0.005883441772311926\n",
      "Policy Loss:  0.2945396900177002\n",
      "[(0.00015, 0.35358), (0.0, 0.35331), (1.0, 0.35358)]\n",
      "Alpha*: 0.0 tau*: 0.35331 Episode: 24340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.026976527413353e-05\n",
      "Q Loss:  2.4277679920196533\n",
      "Policy Loss:  0.5915723443031311\n",
      "[(0.00014, 0.35331), (0.0, 0.35304), (1.0, 0.35331)]\n",
      "Alpha*: 0.0 tau*: 0.35304 Episode: 24346 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  1.2802906036376953\n",
      "Q Loss:  0.799342930316925\n",
      "Policy Loss:  -1.2038400173187256\n",
      "[(0.00014, 0.35304), (0.0, 0.35277), (1.0, 0.35304)]\n",
      "Alpha*: 0.0 tau*: 0.35277 Episode: 24401 length: 42 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  33213.2734375\n",
      "Q Loss:  32999.06640625\n",
      "Policy Loss:  -10.072244644165039\n",
      "[(0.00014, 0.35277), (0.0, 0.3525), (1.0, 0.35277)]\n",
      "Alpha*: 0.0 tau*: 0.3525 Episode: 24448 length: 29 #teleports:18\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012617111206054688\n",
      "Value Loss:  1.9388759136199951\n",
      "Q Loss:  0.3513573408126831\n",
      "Policy Loss:  -6.720080375671387\n",
      "[(0.00014, 0.3525), (0.0, 0.35223), (1.0, 0.3525)]\n",
      "Alpha*: 0.0 tau*: 0.35223 Episode: 24455 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.39746693498455e-05\n",
      "Q Loss:  0.004855956882238388\n",
      "Policy Loss:  -0.03300010785460472\n",
      "[(0.00014, 0.35223), (0.0, 0.35196), (1.0, 0.35223)]\n",
      "Alpha*: 0.0 tau*: 0.35196 Episode: 24459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0008414238691329956\n",
      "Q Loss:  0.0027389987371861935\n",
      "Policy Loss:  -0.02541377581655979\n",
      "[(0.00014, 0.35196), (0.0, 0.35169), (1.0, 0.35196)]\n",
      "Alpha*: 0.0 tau*: 0.35169 Episode: 24463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  5.4588934290222824e-05\n",
      "Q Loss:  2.325584888458252\n",
      "Policy Loss:  0.8192589282989502\n",
      "[(0.00014, 0.35169), (0.0, 0.35142), (1.0, 0.35169)]\n",
      "Alpha*: 0.0 tau*: 0.35142 Episode: 24470 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  93.17306518554688\n",
      "Q Loss:  0.27002424001693726\n",
      "Policy Loss:  -55.966957092285156\n",
      "[(0.00014, 0.35142), (0.0, 0.35115), (1.0, 0.35142)]\n",
      "Alpha*: 0.0 tau*: 0.35115 Episode: 24481 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012965679168701172\n",
      "Value Loss:  21.617685317993164\n",
      "Q Loss:  0.3351265490055084\n",
      "Policy Loss:  -12.937383651733398\n",
      "[(0.00013, 0.35115), (0.0, 0.35088), (1.0, 0.35115)]\n",
      "Alpha*: 0.0 tau*: 0.35088 Episode: 24533 length: 37 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.9890481528127566e-05\n",
      "Q Loss:  0.005554270930588245\n",
      "Policy Loss:  0.2688688635826111\n",
      "[(0.00013, 0.35088), (0.0, 0.35061), (1.0, 0.35088)]\n",
      "Alpha*: 0.0 tau*: 0.35061 Episode: 24542 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  93.8940658569336\n",
      "Q Loss:  0.0026233934331685305\n",
      "Policy Loss:  -55.97445297241211\n",
      "[(0.00012, 0.35061), (0.0, 0.35034), (1.0, 0.35061)]\n",
      "Alpha*: 0.0 tau*: 0.35034 Episode: 24549 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00012510333908721805\n",
      "Q Loss:  52.43782424926758\n",
      "Policy Loss:  0.5642135143280029\n",
      "[(0.00012, 0.35034), (0.0, 0.35007), (1.0, 0.35034)]\n",
      "Alpha*: 0.0 tau*: 0.35007 Episode: 24555 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00012433115625754\n",
      "Q Loss:  0.0030904922168701887\n",
      "Policy Loss:  0.015621095895767212\n",
      "[(0.00012, 0.35007), (0.0, 0.3498), (1.0, 0.35007)]\n",
      "Alpha*: 0.0 tau*: 0.3498 Episode: 24562 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.5455434918403625\n",
      "Q Loss:  0.04715261235833168\n",
      "Policy Loss:  -3.2517597675323486\n",
      "[(0.00012, 0.3498), (0.0, 0.34953), (1.0, 0.3498)]\n",
      "Alpha*: 0.0 tau*: 0.34953 Episode: 24568 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  94.6016845703125\n",
      "Q Loss:  133.69033813476562\n",
      "Policy Loss:  -35.96562576293945\n",
      "[(0.00013, 0.34953), (0.0, 0.34926), (1.0, 0.34953)]\n",
      "Alpha*: 0.0 tau*: 0.34926 Episode: 24576 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.6417518854141235\n",
      "Q Loss:  0.4184788763523102\n",
      "Policy Loss:  -0.6904691457748413\n",
      "[(0.00013, 0.34926), (0.0, 0.34899), (1.0, 0.34926)]\n",
      "Alpha*: 0.0 tau*: 0.34899 Episode: 24617 length: 32 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  6.837934779468924e-05\n",
      "Q Loss:  0.0039281826466321945\n",
      "Policy Loss:  0.027954142540693283\n",
      "[(0.00013, 0.34899), (0.0, 0.34872), (1.0, 0.34899)]\n",
      "Alpha*: 0.0 tau*: 0.34872 Episode: 24623 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00013638869859278202\n",
      "Q Loss:  0.021306557580828667\n",
      "Policy Loss:  0.28844714164733887\n",
      "[(0.00012, 0.34872), (0.0, 0.34845), (1.0, 0.34872)]\n",
      "Alpha*: 0.0 tau*: 0.34845 Episode: 24628 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  6.162000499898568e-05\n",
      "Q Loss:  0.03618495911359787\n",
      "Policy Loss:  0.07276218384504318\n",
      "[(0.00012, 0.34845), (0.0, 0.34818), (1.0, 0.34845)]\n",
      "Alpha*: 0.0 tau*: 0.34818 Episode: 24632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  5.610196240013465e-05\n",
      "Q Loss:  0.007326353341341019\n",
      "Policy Loss:  -0.01880459114909172\n",
      "[(0.00011, 0.34818), (0.0, 0.34791), (1.0, 0.34818)]\n",
      "Alpha*: 0.0 tau*: 0.34791 Episode: 24638 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2.000391759793274e-05\n",
      "Q Loss:  0.029588066041469574\n",
      "Policy Loss:  0.0621197409927845\n",
      "[(0.00011, 0.34791), (0.0, 0.34764), (1.0, 0.34791)]\n",
      "Alpha*: 0.0 tau*: 0.34764 Episode: 24643 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.001776601653546095\n",
      "Q Loss:  4.968052387237549\n",
      "Policy Loss:  1.1667765378952026\n",
      "[(0.00011, 0.34764), (0.0, 0.34737), (1.0, 0.34764)]\n",
      "Alpha*: 0.0 tau*: 0.34737 Episode: 24649 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  95.04619598388672\n",
      "Q Loss:  135.47109985351562\n",
      "Policy Loss:  -22.8231201171875\n",
      "[(0.00011, 0.34737), (0.0, 0.3471), (1.0, 0.34737)]\n",
      "Alpha*: 0.0 tau*: 0.3471 Episode: 24660 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.503829300403595\n",
      "Q Loss:  0.04048127681016922\n",
      "Policy Loss:  -2.064993143081665\n",
      "[(0.00012, 0.3471), (0.0, 0.34683), (1.0, 0.3471)]\n",
      "Alpha*: 0.0 tau*: 0.34683 Episode: 24666 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00013882516941521317\n",
      "Q Loss:  0.0002965355524793267\n",
      "Policy Loss:  -0.005170872434973717\n",
      "[(0.00012, 0.34683), (0.0, 0.34656), (1.0, 0.34683)]\n",
      "Alpha*: 0.0 tau*: 0.34656 Episode: 24673 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  94.12643432617188\n",
      "Q Loss:  185.64601135253906\n",
      "Policy Loss:  -33.27249526977539\n",
      "[(0.00012, 0.34656), (0.0, 0.34629), (1.0, 0.34656)]\n",
      "Alpha*: 0.0 tau*: 0.34629 Episode: 24680 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  20.046419143676758\n",
      "Q Loss:  16.696624755859375\n",
      "Policy Loss:  -10.26867389678955\n",
      "[(0.00012, 0.34629), (0.0, 0.34602), (1.0, 0.34629)]\n",
      "Alpha*: 0.0 tau*: 0.34602 Episode: 24774 length: 59 #teleports:35\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01301121711730957\n",
      "Value Loss:  93.61445617675781\n",
      "Q Loss:  0.01998056471347809\n",
      "Policy Loss:  -55.86131286621094\n",
      "[(0.00012, 0.34602), (0.0, 0.34575), (1.0, 0.34602)]\n",
      "Alpha*: 0.0 tau*: 0.34575 Episode: 24779 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0004047899565193802\n",
      "Q Loss:  0.0007956170593388379\n",
      "Policy Loss:  0.006902593653649092\n",
      "[(0.00011, 0.34575), (0.0, 0.34548), (1.0, 0.34575)]\n",
      "Alpha*: 0.0 tau*: 0.34548 Episode: 24784 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.7231351137161255\n",
      "Q Loss:  0.7047813534736633\n",
      "Policy Loss:  -0.5201643109321594\n",
      "[(0.00011, 0.34548), (0.0, 0.34521), (1.0, 0.34548)]\n",
      "Alpha*: 0.0 tau*: 0.34521 Episode: 24841 length: 34 #teleports:23\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  43723.6875\n",
      "Q Loss:  43383.13671875\n",
      "Policy Loss:  -7.264524936676025\n",
      "[(0.00011, 0.34521), (0.0, 0.34494), (1.0, 0.34521)]\n",
      "Alpha*: 0.0 tau*: 0.34494 Episode: 24874 length: 22 #teleports:11\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  21387.65234375\n",
      "Q Loss:  21226.416015625\n",
      "Policy Loss:  -12.446276664733887\n",
      "[(0.00011, 0.34494), (0.0, 0.34467), (1.0, 0.34494)]\n",
      "Alpha*: 0.0 tau*: 0.34467 Episode: 25015 length: 90 #teleports:51\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.0008554108208045363\n",
      "Q Loss:  0.002650614595040679\n",
      "Policy Loss:  0.015761440619826317\n",
      "[(0.00012, 0.34467), (0.0, 0.3444), (1.0, 0.34467)]\n",
      "Alpha*: 0.0 tau*: 0.3444 Episode: 25019 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.5740149794728495e-05\n",
      "Q Loss:  0.016237016767263412\n",
      "Policy Loss:  0.08045966923236847\n",
      "[(0.00012, 0.3444), (0.0, 0.34413), (1.0, 0.3444)]\n",
      "Alpha*: 0.0 tau*: 0.34413 Episode: 25025 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  37002.515625\n",
      "Q Loss:  36704.1640625\n",
      "Policy Loss:  -27.787006378173828\n",
      "[(0.00013, 0.34413), (0.0, 0.34386), (1.0, 0.34413)]\n",
      "Alpha*: 0.0 tau*: 0.34386 Episode: 25102 length: 52 #teleports:25\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.4985833168029785\n",
      "Q Loss:  0.055585287511348724\n",
      "Policy Loss:  -1.6198208332061768\n",
      "[(0.00014, 0.34386), (0.0, 0.34359), (1.0, 0.34386)]\n",
      "Alpha*: 0.0 tau*: 0.34359 Episode: 25108 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  15760.1845703125\n",
      "Q Loss:  15609.544921875\n",
      "Policy Loss:  -14.791146278381348\n",
      "[(0.00015, 0.34359), (0.0, 0.34333), (1.0, 0.34359)]\n",
      "Alpha*: 0.0 tau*: 0.34333 Episode: 25201 length: 61 #teleports:32\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  103.67604064941406\n",
      "Q Loss:  2.7721073627471924\n",
      "Policy Loss:  -55.93648147583008\n",
      "[(0.00016, 0.34333), (0.0, 0.34307), (1.0, 0.34333)]\n",
      "Alpha*: 0.0 tau*: 0.34307 Episode: 25206 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0022915611043572426\n",
      "Q Loss:  0.000854985264595598\n",
      "Policy Loss:  0.00783451646566391\n",
      "[(0.00017, 0.34307), (0.0, 0.34281), (1.0, 0.34307)]\n",
      "Alpha*: 0.0 tau*: 0.34281 Episode: 25212 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.05901360511779785\n",
      "Value Loss:  0.00012410315684974194\n",
      "Q Loss:  0.03666261211037636\n",
      "Policy Loss:  0.31490427255630493\n",
      "[(0.00017, 0.34281), (0.0, 0.34255), (1.0, 0.34281)]\n",
      "Alpha*: 0.0 tau*: 0.34255 Episode: 25217 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002963804581668228\n",
      "Q Loss:  0.006373102776706219\n",
      "Policy Loss:  0.029410500079393387\n",
      "[(0.00018, 0.34255), (0.0, 0.34229), (1.0, 0.34255)]\n",
      "Alpha*: 0.0 tau*: 0.34229 Episode: 25222 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017004966735839844\n",
      "Value Loss:  0.00014037206710781902\n",
      "Q Loss:  2.8306190967559814\n",
      "Policy Loss:  0.5948117971420288\n",
      "[(0.00018, 0.34229), (0.0, 0.34203), (1.0, 0.34229)]\n",
      "Alpha*: 0.0 tau*: 0.34203 Episode: 25231 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.0605835743481293e-05\n",
      "Q Loss:  0.2873791754245758\n",
      "Policy Loss:  0.19784057140350342\n",
      "[(0.00019, 0.34203), (0.0, 0.34177), (1.0, 0.34203)]\n",
      "Alpha*: 0.0 tau*: 0.34177 Episode: 25237 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.0506856441497803\n",
      "Q Loss:  0.2864006459712982\n",
      "Policy Loss:  -3.061516284942627\n",
      "[(0.00018, 0.34177), (0.0, 0.34151), (1.0, 0.34177)]\n",
      "Alpha*: 0.0 tau*: 0.34151 Episode: 25244 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0004251104255672544\n",
      "Q Loss:  0.004484233912080526\n",
      "Policy Loss:  0.012042071670293808\n",
      "[(0.00018, 0.34151), (0.0, 0.34125), (1.0, 0.34151)]\n",
      "Alpha*: 0.0 tau*: 0.34125 Episode: 25249 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  73685.4921875\n",
      "Q Loss:  73001.15625\n",
      "Policy Loss:  -21.6871280670166\n",
      "[(0.00018, 0.34125), (0.0, 0.34099), (1.0, 0.34125)]\n",
      "Alpha*: 0.0 tau*: 0.34099 Episode: 25283 length: 26 #teleports:8\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  117.88948822021484\n",
      "Q Loss:  0.26205042004585266\n",
      "Policy Loss:  -65.76883697509766\n",
      "[(0.00018, 0.34099), (0.0, 0.34073), (1.0, 0.34099)]\n",
      "Alpha*: 0.0 tau*: 0.34073 Episode: 25290 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  6.930238305358216e-05\n",
      "Q Loss:  0.00039970746729522943\n",
      "Policy Loss:  -0.00401515094563365\n",
      "[(0.00019, 0.34073), (0.0, 0.34047), (1.0, 0.34073)]\n",
      "Alpha*: 0.0 tau*: 0.34047 Episode: 25296 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  5.437658546725288e-05\n",
      "Q Loss:  0.0004400364123284817\n",
      "Policy Loss:  -0.001810797955840826\n",
      "[(0.00019, 0.34047), (0.0, 0.34021), (1.0, 0.34047)]\n",
      "Alpha*: 0.0 tau*: 0.34021 Episode: 25300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  21.437719345092773\n",
      "Q Loss:  36.09661102294922\n",
      "Policy Loss:  -8.150282859802246\n",
      "[(0.00019, 0.34021), (0.0, 0.33995), (1.0, 0.34021)]\n",
      "Alpha*: 0.0 tau*: 0.33995 Episode: 25367 length: 49 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.00022651873587165028\n",
      "Q Loss:  0.006706169806420803\n",
      "Policy Loss:  0.2588283121585846\n",
      "[(0.00019, 0.33995), (0.0, 0.33969), (1.0, 0.33995)]\n",
      "Alpha*: 0.0 tau*: 0.33969 Episode: 25371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  14712.6982421875\n",
      "Q Loss:  14554.6220703125\n",
      "Policy Loss:  -11.26611328125\n",
      "[(0.0002, 0.33969), (0.0, 0.33943), (1.0, 0.33969)]\n",
      "Alpha*: 0.0 tau*: 0.33943 Episode: 25463 length: 65 #teleports:27\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.0012876625405624509\n",
      "Q Loss:  0.0005812698509544134\n",
      "Policy Loss:  0.004714806564152241\n",
      "[(0.0002, 0.33943), (0.0, 0.33917), (1.0, 0.33943)]\n",
      "Alpha*: 0.0 tau*: 0.33917 Episode: 25467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014135360717773438\n",
      "Value Loss:  0.00010522507363930345\n",
      "Q Loss:  0.009835967794060707\n",
      "Policy Loss:  0.030675090849399567\n",
      "[(0.00021, 0.33917), (0.0, 0.33891), (1.0, 0.33917)]\n",
      "Alpha*: 0.0 tau*: 0.33891 Episode: 25473 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  133.6703338623047\n",
      "Q Loss:  0.04314982518553734\n",
      "Policy Loss:  -66.53396606445312\n",
      "[(0.00021, 0.33891), (0.0, 0.33865), (1.0, 0.33891)]\n",
      "Alpha*: 0.0 tau*: 0.33865 Episode: 25478 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008035944774746895\n",
      "Q Loss:  2.784133195877075\n",
      "Policy Loss:  0.58054119348526\n",
      "[(0.00021, 0.33865), (0.0, 0.33839), (1.0, 0.33865)]\n",
      "Alpha*: 0.0 tau*: 0.33839 Episode: 25485 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00011720838665496558\n",
      "Q Loss:  5.581507682800293\n",
      "Policy Loss:  1.2322769165039062\n",
      "[(0.00022, 0.33839), (0.0, 0.33813), (1.0, 0.33839)]\n",
      "Alpha*: 0.0 tau*: 0.33813 Episode: 25491 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  0.00023812687140889466\n",
      "Q Loss:  0.047420088201761246\n",
      "Policy Loss:  0.10596537590026855\n",
      "[(0.00022, 0.33813), (0.0, 0.33787), (1.0, 0.33813)]\n",
      "Alpha*: 0.0 tau*: 0.33787 Episode: 25496 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00024223019136115909\n",
      "Q Loss:  0.003997813444584608\n",
      "Policy Loss:  0.02297102101147175\n",
      "[(0.00022, 0.33787), (0.0, 0.33761), (1.0, 0.33787)]\n",
      "Alpha*: 0.0 tau*: 0.33761 Episode: 25501 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017002582550048828\n",
      "Value Loss:  5.892376066185534e-05\n",
      "Q Loss:  0.030133994296193123\n",
      "Policy Loss:  0.3035459518432617\n",
      "[(0.00022, 0.33761), (0.0, 0.33735), (1.0, 0.33761)]\n",
      "Alpha*: 0.0 tau*: 0.33735 Episode: 25505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  12.506196975708008\n",
      "Q Loss:  12.338019371032715\n",
      "Policy Loss:  -5.998661041259766\n",
      "[(0.00022, 0.33735), (0.0, 0.33709), (1.0, 0.33735)]\n",
      "Alpha*: 0.0 tau*: 0.33709 Episode: 25655 length: 95 #teleports:55\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.647015495924279e-05\n",
      "Q Loss:  0.010474402457475662\n",
      "Policy Loss:  0.04837976396083832\n",
      "[(0.00023, 0.33709), (0.0, 0.33683), (1.0, 0.33709)]\n",
      "Alpha*: 0.0 tau*: 0.33683 Episode: 25659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.467412458732724e-05\n",
      "Q Loss:  0.01150817982852459\n",
      "Policy Loss:  0.04187970608472824\n",
      "[(0.00023, 0.33683), (0.0, 0.33657), (1.0, 0.33683)]\n",
      "Alpha*: 0.0 tau*: 0.33657 Episode: 25666 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  2.211876153945923\n",
      "Q Loss:  0.4864695370197296\n",
      "Policy Loss:  -0.2710672914981842\n",
      "[(0.00023, 0.33657), (0.0, 0.33631), (1.0, 0.33657)]\n",
      "Alpha*: 0.0 tau*: 0.33631 Episode: 25702 length: 25 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00034807634074240923\n",
      "Q Loss:  0.3138676583766937\n",
      "Policy Loss:  0.05692398548126221\n",
      "[(0.00023, 0.33631), (0.0, 0.33605), (1.0, 0.33631)]\n",
      "Alpha*: 0.0 tau*: 0.33605 Episode: 25707 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0005522154970094562\n",
      "Q Loss:  0.008917001076042652\n",
      "Policy Loss:  0.017689678817987442\n",
      "[(0.00024, 0.33605), (0.0, 0.33579), (1.0, 0.33605)]\n",
      "Alpha*: 0.0 tau*: 0.33579 Episode: 25715 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.5225615501403809\n",
      "Q Loss:  0.058633316308259964\n",
      "Policy Loss:  -2.115140676498413\n",
      "[(0.00024, 0.33579), (0.0, 0.33553), (1.0, 0.33579)]\n",
      "Alpha*: 0.0 tau*: 0.33553 Episode: 25720 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.092576265335083\n",
      "Q Loss:  0.06221214681863785\n",
      "Policy Loss:  -1.0899795293807983\n",
      "[(0.00024, 0.33553), (0.0, 0.33527), (1.0, 0.33553)]\n",
      "Alpha*: 0.0 tau*: 0.33527 Episode: 25793 length: 52 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00040462816832587123\n",
      "Q Loss:  0.06554292142391205\n",
      "Policy Loss:  0.32859256863594055\n",
      "[(0.00024, 0.33527), (0.0, 0.33501), (1.0, 0.33527)]\n",
      "Alpha*: 0.0 tau*: 0.33501 Episode: 25800 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  23.280683517456055\n",
      "Q Loss:  32.37393569946289\n",
      "Policy Loss:  -7.685640811920166\n",
      "[(0.00024, 0.33501), (0.0, 0.33475), (1.0, 0.33501)]\n",
      "Alpha*: 0.0 tau*: 0.33475 Episode: 25831 length: 27 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  5.7930876209866256e-05\n",
      "Q Loss:  0.004759442992508411\n",
      "Policy Loss:  -0.030866127461194992\n",
      "[(0.00024, 0.33475), (0.0, 0.33449), (1.0, 0.33475)]\n",
      "Alpha*: 0.0 tau*: 0.33449 Episode: 25835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.0002581257722340524\n",
      "Q Loss:  85.68846130371094\n",
      "Policy Loss:  0.5409912467002869\n",
      "[(0.00024, 0.33449), (0.0, 0.33423), (1.0, 0.33449)]\n",
      "Alpha*: 0.0 tau*: 0.33423 Episode: 25843 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00023218709975481033\n",
      "Q Loss:  0.001733946381136775\n",
      "Policy Loss:  -0.017666086554527283\n",
      "[(0.00024, 0.33423), (0.0, 0.33397), (1.0, 0.33423)]\n",
      "Alpha*: 0.0 tau*: 0.33397 Episode: 25847 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.5598052740097046\n",
      "Q Loss:  0.050664015114307404\n",
      "Policy Loss:  -2.385174036026001\n",
      "[(0.00024, 0.33397), (0.0, 0.33371), (1.0, 0.33397)]\n",
      "Alpha*: 0.0 tau*: 0.33371 Episode: 25851 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  21.490230560302734\n",
      "Q Loss:  21.870573043823242\n",
      "Policy Loss:  -9.148547172546387\n",
      "[(0.00024, 0.33371), (0.0, 0.33345), (1.0, 0.33371)]\n",
      "Alpha*: 0.0 tau*: 0.33345 Episode: 25935 length: 57 #teleports:27\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002092140493914485\n",
      "Q Loss:  0.0006633981829509139\n",
      "Policy Loss:  0.0033610465470701456\n",
      "[(0.00024, 0.33345), (0.0, 0.33319), (1.0, 0.33345)]\n",
      "Alpha*: 0.0 tau*: 0.33319 Episode: 25939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00027113070245832205\n",
      "Q Loss:  0.00040864289621822536\n",
      "Policy Loss:  0.0015379698015749454\n",
      "[(0.00024, 0.33319), (0.0, 0.33293), (1.0, 0.33319)]\n",
      "Alpha*: 0.0 tau*: 0.33293 Episode: 25943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  55.549232482910156\n",
      "Q Loss:  66.27324676513672\n",
      "Policy Loss:  -22.168357849121094\n",
      "[(0.00024, 0.33293), (0.0, 0.33267), (1.0, 0.33293)]\n",
      "Alpha*: 0.0 tau*: 0.33267 Episode: 26057 length: 85 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.00014939655375201255\n",
      "Q Loss:  0.007420663721859455\n",
      "Policy Loss:  -0.014932109043002129\n",
      "[(0.00024, 0.33267), (0.0, 0.33241), (1.0, 0.33267)]\n",
      "Alpha*: 0.0 tau*: 0.33241 Episode: 26064 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  6.11208743066527e-05\n",
      "Q Loss:  0.013123640790581703\n",
      "Policy Loss:  -0.03970203548669815\n",
      "[(0.00024, 0.33241), (0.0, 0.33215), (1.0, 0.33241)]\n",
      "Alpha*: 0.0 tau*: 0.33215 Episode: 26069 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0002253454294987023\n",
      "Q Loss:  0.0009150267578661442\n",
      "Policy Loss:  0.009198146872222424\n",
      "[(0.00024, 0.33215), (0.0, 0.33189), (1.0, 0.33215)]\n",
      "Alpha*: 0.0 tau*: 0.33189 Episode: 26074 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00045328005217015743\n",
      "Q Loss:  0.011352792382240295\n",
      "Policy Loss:  0.03735613822937012\n",
      "[(0.00024, 0.33189), (0.0, 0.33163), (1.0, 0.33189)]\n",
      "Alpha*: 0.0 tau*: 0.33163 Episode: 26078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.00017321128689218313\n",
      "Q Loss:  0.0011499496176838875\n",
      "Policy Loss:  0.24625447392463684\n",
      "[(0.00024, 0.33163), (0.0, 0.33137), (1.0, 0.33163)]\n",
      "Alpha*: 0.0 tau*: 0.33137 Episode: 26084 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.639684968627989e-05\n",
      "Q Loss:  0.0005011541652493179\n",
      "Policy Loss:  -0.006663276348263025\n",
      "[(0.00024, 0.33137), (0.0, 0.33111), (1.0, 0.33137)]\n",
      "Alpha*: 0.0 tau*: 0.33111 Episode: 26089 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  35946.75390625\n",
      "Q Loss:  35551.37890625\n",
      "Policy Loss:  -12.160808563232422\n",
      "[(0.00024, 0.33111), (0.0, 0.33085), (1.0, 0.33111)]\n",
      "Alpha*: 0.0 tau*: 0.33085 Episode: 26170 length: 53 #teleports:28\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.034008026123046875\n",
      "Value Loss:  4.9029291403712705e-05\n",
      "Q Loss:  0.00021264163660816848\n",
      "Policy Loss:  0.010188127867877483\n",
      "[(0.00025, 0.33085), (0.0, 0.33059), (1.0, 0.33085)]\n",
      "Alpha*: 0.0 tau*: 0.33059 Episode: 26175 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  19073.494140625\n",
      "Q Loss:  18855.6640625\n",
      "Policy Loss:  -18.948867797851562\n",
      "[(0.00025, 0.33059), (0.0, 0.33033), (1.0, 0.33059)]\n",
      "Alpha*: 0.0 tau*: 0.33033 Episode: 26256 length: 50 #teleports:31\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  150.30711364746094\n",
      "Q Loss:  3.1020405292510986\n",
      "Policy Loss:  -67.82240295410156\n",
      "[(0.00025, 0.33033), (0.0, 0.33007), (1.0, 0.33033)]\n",
      "Alpha*: 0.0 tau*: 0.33007 Episode: 26261 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0011675135465338826\n",
      "Q Loss:  0.0031325635500252247\n",
      "Policy Loss:  -0.01945996657013893\n",
      "[(0.00026, 0.33007), (0.0, 0.32981), (1.0, 0.33007)]\n",
      "Alpha*: 0.0 tau*: 0.32981 Episode: 26269 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0004406914522405714\n",
      "Q Loss:  0.0010563270188868046\n",
      "Policy Loss:  -0.003477280493825674\n",
      "[(0.00026, 0.32981), (0.0, 0.32955), (1.0, 0.32981)]\n",
      "Alpha*: 0.0 tau*: 0.32955 Episode: 26275 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.8365592956542969\n",
      "Q Loss:  0.05770224705338478\n",
      "Policy Loss:  -2.8713231086730957\n",
      "[(0.00026, 0.32955), (0.0, 0.32929), (1.0, 0.32955)]\n",
      "Alpha*: 0.0 tau*: 0.32929 Episode: 26279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.1199448108673096\n",
      "Q Loss:  0.017018072307109833\n",
      "Policy Loss:  -1.19736909866333\n",
      "[(0.00026, 0.32929), (0.0, 0.32903), (1.0, 0.32929)]\n",
      "Alpha*: 0.0 tau*: 0.32903 Episode: 26367 length: 49 #teleports:39\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  16689.48828125\n",
      "Q Loss:  16491.75\n",
      "Policy Loss:  -8.475325584411621\n",
      "[(0.00027, 0.32903), (0.0, 0.32877), (1.0, 0.32903)]\n",
      "Alpha*: 0.0 tau*: 0.32877 Episode: 26452 length: 57 #teleports:28\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00012003527081105858\n",
      "Q Loss:  3.2102746963500977\n",
      "Policy Loss:  0.63753342628479\n",
      "[(0.00027, 0.32877), (0.0, 0.32851), (1.0, 0.32877)]\n",
      "Alpha*: 0.0 tau*: 0.32851 Episode: 26457 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0003767797024920583\n",
      "Q Loss:  0.0021935587283223867\n",
      "Policy Loss:  0.03365869075059891\n",
      "[(0.00027, 0.32851), (0.0, 0.32825), (1.0, 0.32851)]\n",
      "Alpha*: 0.0 tau*: 0.32825 Episode: 26461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  79167.875\n",
      "Q Loss:  78182.125\n",
      "Policy Loss:  -9.792637825012207\n",
      "[(0.00028, 0.32825), (0.0, 0.32799), (1.0, 0.32825)]\n",
      "Alpha*: 0.0 tau*: 0.32799 Episode: 26479 length: 12 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00011955473746638745\n",
      "Q Loss:  0.04350690171122551\n",
      "Policy Loss:  0.11675384640693665\n",
      "[(0.00028, 0.32799), (0.0, 0.32773), (1.0, 0.32799)]\n",
      "Alpha*: 0.0 tau*: 0.32773 Episode: 26487 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0007777947466820478\n",
      "Q Loss:  0.0027914741076529026\n",
      "Policy Loss:  0.031594742089509964\n",
      "[(0.00029, 0.32773), (0.0, 0.32747), (1.0, 0.32773)]\n",
      "Alpha*: 0.0 tau*: 0.32747 Episode: 26491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00035713682882487774\n",
      "Q Loss:  0.0019758418202400208\n",
      "Policy Loss:  0.002789542078971863\n",
      "[(0.00029, 0.32747), (0.0, 0.32721), (1.0, 0.32747)]\n",
      "Alpha*: 0.0 tau*: 0.32721 Episode: 26496 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0001560380042064935\n",
      "Q Loss:  0.0074535151943564415\n",
      "Policy Loss:  0.04738394916057587\n",
      "[(0.00029, 0.32721), (0.0, 0.32695), (1.0, 0.32721)]\n",
      "Alpha*: 0.0 tau*: 0.32695 Episode: 26501 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.027007579803466797\n",
      "Value Loss:  0.0002941145794466138\n",
      "Q Loss:  0.004236072301864624\n",
      "Policy Loss:  0.034389056265354156\n",
      "[(0.0003, 0.32695), (0.0, 0.32669), (1.0, 0.32695)]\n",
      "Alpha*: 0.0 tau*: 0.32669 Episode: 26507 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  180.0161895751953\n",
      "Q Loss:  107.29460906982422\n",
      "Policy Loss:  -74.57301330566406\n",
      "[(0.0003, 0.32669), (0.0, 0.32643), (1.0, 0.32669)]\n",
      "Alpha*: 0.0 tau*: 0.32643 Episode: 26513 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.717827545799082e-06\n",
      "Q Loss:  0.011332446709275246\n",
      "Policy Loss:  0.06308052688837051\n",
      "[(0.0003, 0.32643), (0.0, 0.32617), (1.0, 0.32643)]\n",
      "Alpha*: 0.0 tau*: 0.32617 Episode: 26517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  183.93682861328125\n",
      "Q Loss:  283.5232238769531\n",
      "Policy Loss:  -48.316837310791016\n",
      "[(0.0003, 0.32617), (0.0, 0.32591), (1.0, 0.32617)]\n",
      "Alpha*: 0.0 tau*: 0.32591 Episode: 26525 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.462137439986691e-05\n",
      "Q Loss:  3.3825814723968506\n",
      "Policy Loss:  0.6582773923873901\n",
      "[(0.00031, 0.32591), (0.0, 0.32565), (1.0, 0.32591)]\n",
      "Alpha*: 0.0 tau*: 0.32565 Episode: 26531 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  1.257051944732666\n",
      "Q Loss:  0.443498432636261\n",
      "Policy Loss:  -0.7052786946296692\n",
      "[(0.00031, 0.32565), (0.0, 0.32539), (1.0, 0.32565)]\n",
      "Alpha*: 0.0 tau*: 0.32539 Episode: 26535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0013829001691192389\n",
      "Q Loss:  0.005089450161904097\n",
      "Policy Loss:  0.03809347376227379\n",
      "[(0.00031, 0.32539), (0.0, 0.32513), (1.0, 0.32539)]\n",
      "Alpha*: 0.0 tau*: 0.32513 Episode: 26540 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0003821779100690037\n",
      "Q Loss:  0.022921210154891014\n",
      "Policy Loss:  0.07029429078102112\n",
      "[(0.00031, 0.32513), (0.0, 0.32487), (1.0, 0.32513)]\n",
      "Alpha*: 0.0 tau*: 0.32487 Episode: 26544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01269388198852539\n",
      "Value Loss:  0.6042733192443848\n",
      "Q Loss:  0.023854387924075127\n",
      "Policy Loss:  -1.8420345783233643\n",
      "[(0.00031, 0.32487), (0.0, 0.32461), (1.0, 0.32487)]\n",
      "Alpha*: 0.0 tau*: 0.32461 Episode: 26550 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00037145440001040697\n",
      "Q Loss:  0.001205736887641251\n",
      "Policy Loss:  0.015567087568342686\n",
      "[(0.00031, 0.32461), (0.0, 0.32435), (1.0, 0.32461)]\n",
      "Alpha*: 0.0 tau*: 0.32435 Episode: 26554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00015053918468765914\n",
      "Q Loss:  0.0011900743702426553\n",
      "Policy Loss:  0.010509940795600414\n",
      "[(0.0003, 0.32435), (0.0, 0.32409), (1.0, 0.32435)]\n",
      "Alpha*: 0.0 tau*: 0.32409 Episode: 26561 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.5713521242141724\n",
      "Q Loss:  0.44617223739624023\n",
      "Policy Loss:  -2.969686985015869\n",
      "[(0.0003, 0.32409), (0.0, 0.32383), (1.0, 0.32409)]\n",
      "Alpha*: 0.0 tau*: 0.32383 Episode: 26571 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.02400517463684082\n",
      "Value Loss:  0.00018306600395590067\n",
      "Q Loss:  3.5758721828460693\n",
      "Policy Loss:  0.6664069890975952\n",
      "[(0.0003, 0.32383), (0.0, 0.32357), (1.0, 0.32383)]\n",
      "Alpha*: 0.0 tau*: 0.32357 Episode: 26582 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  22.520626068115234\n",
      "Q Loss:  0.40037286281585693\n",
      "Policy Loss:  -9.222494125366211\n",
      "[(0.0003, 0.32357), (0.0, 0.32331), (1.0, 0.32357)]\n",
      "Alpha*: 0.0 tau*: 0.32331 Episode: 26635 length: 37 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001207302266266197\n",
      "Q Loss:  0.0103413425385952\n",
      "Policy Loss:  0.04701340198516846\n",
      "[(0.0003, 0.32331), (0.0, 0.32305), (1.0, 0.32331)]\n",
      "Alpha*: 0.0 tau*: 0.32305 Episode: 26641 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  21549.990234375\n",
      "Q Loss:  21188.77734375\n",
      "Policy Loss:  -33.026485443115234\n",
      "[(0.0003, 0.32305), (0.0, 0.32279), (1.0, 0.32305)]\n",
      "Alpha*: 0.0 tau*: 0.32279 Episode: 26697 length: 44 #teleports:12\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.004483606666326523\n",
      "Q Loss:  0.003353220410645008\n",
      "Policy Loss:  -0.027128927409648895\n",
      "[(0.0003, 0.32279), (0.0, 0.32253), (1.0, 0.32279)]\n",
      "Alpha*: 0.0 tau*: 0.32253 Episode: 26702 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0015031966613605618\n",
      "Q Loss:  3.56575870513916\n",
      "Policy Loss:  0.6653722524642944\n",
      "[(0.00031, 0.32253), (0.0, 0.32227), (1.0, 0.32253)]\n",
      "Alpha*: 0.0 tau*: 0.32227 Episode: 26711 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006353792268782854\n",
      "Q Loss:  0.0012991605326533318\n",
      "Policy Loss:  -0.012436291202902794\n",
      "[(0.00031, 0.32227), (0.0, 0.32201), (1.0, 0.32227)]\n",
      "Alpha*: 0.0 tau*: 0.32201 Episode: 26715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  27008.025390625\n",
      "Q Loss:  26647.388671875\n",
      "Policy Loss:  -12.187421798706055\n",
      "[(0.00031, 0.32201), (0.0, 0.32175), (1.0, 0.32201)]\n",
      "Alpha*: 0.0 tau*: 0.32175 Episode: 26770 length: 35 #teleports:20\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.047009944915771484\n",
      "Value Loss:  0.00022498378530144691\n",
      "Q Loss:  3.5728049278259277\n",
      "Policy Loss:  0.6976643800735474\n",
      "[(0.00031, 0.32175), (0.0, 0.32149), (1.0, 0.32175)]\n",
      "Alpha*: 0.0 tau*: 0.32149 Episode: 26775 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00030431203776970506\n",
      "Q Loss:  0.005469121038913727\n",
      "Policy Loss:  0.2231476604938507\n",
      "[(0.00032, 0.32149), (0.0, 0.32123), (1.0, 0.32149)]\n",
      "Alpha*: 0.0 tau*: 0.32123 Episode: 26785 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.0006146435043774545\n",
      "Q Loss:  0.002241435693576932\n",
      "Policy Loss:  -0.01344357244670391\n",
      "[(0.00032, 0.32123), (0.0, 0.32097), (1.0, 0.32123)]\n",
      "Alpha*: 0.0 tau*: 0.32097 Episode: 26794 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  205.76502990722656\n",
      "Q Loss:  320.5595397949219\n",
      "Policy Loss:  -51.09967803955078\n",
      "[(0.00032, 0.32097), (0.0, 0.32071), (1.0, 0.32097)]\n",
      "Alpha*: 0.0 tau*: 0.32071 Episode: 26799 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  20088.740234375\n",
      "Q Loss:  19804.541015625\n",
      "Policy Loss:  -10.93840217590332\n",
      "[(0.00032, 0.32071), (0.0, 0.32045), (1.0, 0.32071)]\n",
      "Alpha*: 0.0 tau*: 0.32045 Episode: 26875 length: 47 #teleports:29\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  208.75601196289062\n",
      "Q Loss:  3.4685909748077393\n",
      "Policy Loss:  -80.32998657226562\n",
      "[(0.00032, 0.32045), (0.0, 0.32019), (1.0, 0.32045)]\n",
      "Alpha*: 0.0 tau*: 0.32019 Episode: 26883 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  1.0479357242584229\n",
      "Q Loss:  0.28777819871902466\n",
      "Policy Loss:  -3.089789390563965\n",
      "[(0.00032, 0.32019), (0.0, 0.31993), (1.0, 0.32019)]\n",
      "Alpha*: 0.0 tau*: 0.31993 Episode: 26888 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009003400802612305\n",
      "Value Loss:  12118.8203125\n",
      "Q Loss:  11946.38671875\n",
      "Policy Loss:  -14.826684951782227\n",
      "[(0.00032, 0.31993), (0.0, 0.31967), (1.0, 0.31993)]\n",
      "Alpha*: 0.0 tau*: 0.31967 Episode: 27004 length: 78 #teleports:38\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  31445.11328125\n",
      "Q Loss:  30990.701171875\n",
      "Policy Loss:  -14.387630462646484\n",
      "[(0.00032, 0.31967), (0.0, 0.31941), (1.0, 0.31967)]\n",
      "Alpha*: 0.0 tau*: 0.31941 Episode: 27049 length: 30 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  5.338282062439248e-05\n",
      "Q Loss:  0.0017367620021104813\n",
      "Policy Loss:  -0.0184565931558609\n",
      "[(0.00032, 0.31941), (0.0, 0.31915), (1.0, 0.31941)]\n",
      "Alpha*: 0.0 tau*: 0.31915 Episode: 27054 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  218.9357147216797\n",
      "Q Loss:  0.0022226839791983366\n",
      "Policy Loss:  -85.68323516845703\n",
      "[(0.00032, 0.31915), (0.0, 0.31889), (1.0, 0.31915)]\n",
      "Alpha*: 0.0 tau*: 0.31889 Episode: 27061 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00011603905295487493\n",
      "Q Loss:  3.3364949226379395\n",
      "Policy Loss:  0.6501154899597168\n",
      "[(0.00032, 0.31889), (0.0, 0.31863), (1.0, 0.31889)]\n",
      "Alpha*: 0.0 tau*: 0.31863 Episode: 27069 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00016438995953649282\n",
      "Q Loss:  0.0012955724960193038\n",
      "Policy Loss:  0.24400952458381653\n",
      "[(0.00032, 0.31863), (0.0, 0.31837), (1.0, 0.31863)]\n",
      "Alpha*: 0.0 tau*: 0.31837 Episode: 27075 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0007157791405916214\n",
      "Q Loss:  0.00031295212102122605\n",
      "Policy Loss:  -0.018191276118159294\n",
      "[(0.00032, 0.31837), (0.0, 0.31811), (1.0, 0.31837)]\n",
      "Alpha*: 0.0 tau*: 0.31811 Episode: 27083 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.540399822872132e-05\n",
      "Q Loss:  0.0002596346603240818\n",
      "Policy Loss:  0.0036245761439204216\n",
      "[(0.00032, 0.31811), (0.0, 0.31785), (1.0, 0.31811)]\n",
      "Alpha*: 0.0 tau*: 0.31785 Episode: 27093 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  26127.16015625\n",
      "Q Loss:  25725.76953125\n",
      "Policy Loss:  -7.342799186706543\n",
      "[(0.00032, 0.31785), (0.0, 0.31759), (1.0, 0.31785)]\n",
      "Alpha*: 0.0 tau*: 0.31759 Episode: 27150 length: 36 #teleports:21\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  0.5140246152877808\n",
      "Q Loss:  0.043324049562215805\n",
      "Policy Loss:  -3.271622657775879\n",
      "[(0.00033, 0.31759), (0.0, 0.31733), (1.0, 0.31759)]\n",
      "Alpha*: 0.0 tau*: 0.31733 Episode: 27157 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.00900125503540039\n",
      "Value Loss:  1.089291436073836e-05\n",
      "Q Loss:  0.0019535794854164124\n",
      "Policy Loss:  0.01589266210794449\n",
      "[(0.00033, 0.31733), (0.0, 0.31707), (1.0, 0.31733)]\n",
      "Alpha*: 0.0 tau*: 0.31707 Episode: 27162 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  117453.9375\n",
      "Q Loss:  115609.21875\n",
      "Policy Loss:  2.260378837585449\n",
      "[(0.00034, 0.31707), (0.0, 0.31681), (1.0, 0.31707)]\n",
      "Alpha*: 0.0 tau*: 0.31681 Episode: 27171 length: 8 #teleports:1\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.028006553649902344\n",
      "Value Loss:  11895.4677734375\n",
      "Q Loss:  11694.3857421875\n",
      "Policy Loss:  -8.624709129333496\n",
      "[(0.00035, 0.31681), (0.0, 0.31655), (1.0, 0.31681)]\n",
      "Alpha*: 0.0 tau*: 0.31655 Episode: 27280 length: 79 #teleports:30\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.003528088564053178\n",
      "Q Loss:  0.0011350351851433516\n",
      "Policy Loss:  -0.011887500993907452\n",
      "[(0.00035, 0.31655), (0.0, 0.31629), (1.0, 0.31655)]\n",
      "Alpha*: 0.0 tau*: 0.31629 Episode: 27285 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.003070057835429907\n",
      "Q Loss:  0.003117151325568557\n",
      "Policy Loss:  0.02045588754117489\n",
      "[(0.00036, 0.31629), (0.0, 0.31603), (1.0, 0.31629)]\n",
      "Alpha*: 0.0 tau*: 0.31603 Episode: 27289 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0003919468726962805\n",
      "Q Loss:  3.3166580200195312\n",
      "Policy Loss:  0.6707134246826172\n",
      "[(0.00037, 0.31603), (0.0, 0.31577), (1.0, 0.31603)]\n",
      "Alpha*: 0.0 tau*: 0.31577 Episode: 27294 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  42538.89453125\n",
      "Q Loss:  41802.1953125\n",
      "Policy Loss:  -11.008925437927246\n",
      "[(0.00037, 0.31577), (0.0, 0.31551), (1.0, 0.31577)]\n",
      "Alpha*: 0.0 tau*: 0.31551 Episode: 27327 length: 22 #teleports:11\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0008170712972059846\n",
      "Q Loss:  0.002152408938854933\n",
      "Policy Loss:  0.2469077706336975\n",
      "[(0.00038, 0.31551), (0.0, 0.31525), (1.0, 0.31551)]\n",
      "Alpha*: 0.0 tau*: 0.31525 Episode: 27333 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.00043545837979763746\n",
      "Q Loss:  0.0035101233515888453\n",
      "Policy Loss:  0.03409873694181442\n",
      "[(0.00039, 0.31525), (0.0, 0.31499), (1.0, 0.31525)]\n",
      "Alpha*: 0.0 tau*: 0.31499 Episode: 27337 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001182556152344\n",
      "Value Loss:  0.0005236724391579628\n",
      "Q Loss:  0.007560144644230604\n",
      "Policy Loss:  0.26888564229011536\n",
      "[(0.00039, 0.31499), (0.0, 0.31473), (1.0, 0.31499)]\n",
      "Alpha*: 0.0 tau*: 0.31473 Episode: 27344 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  35.643802642822266\n",
      "Q Loss:  76.56584167480469\n",
      "Policy Loss:  -7.937103271484375\n",
      "[(0.00039, 0.31473), (0.0, 0.31447), (1.0, 0.31473)]\n",
      "Alpha*: 0.0 tau*: 0.31447 Episode: 27389 length: 34 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0002961511490866542\n",
      "Q Loss:  0.003723530098795891\n",
      "Policy Loss:  0.036018189042806625\n",
      "[(0.0004, 0.31447), (0.0, 0.31421), (1.0, 0.31447)]\n",
      "Alpha*: 0.0 tau*: 0.31421 Episode: 27395 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  32.26475524902344\n",
      "Q Loss:  70.5606918334961\n",
      "Policy Loss:  -8.622734069824219\n",
      "[(0.0004, 0.31421), (0.0, 0.31395), (1.0, 0.31421)]\n",
      "Alpha*: 0.0 tau*: 0.31395 Episode: 27506 length: 76 #teleports:35\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  23320.7265625\n",
      "Q Loss:  22863.7421875\n",
      "Policy Loss:  -17.943811416625977\n",
      "[(0.0004, 0.31395), (0.0, 0.31369), (1.0, 0.31395)]\n",
      "Alpha*: 0.0 tau*: 0.31369 Episode: 27570 length: 40 #teleports:24\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00035371253034099936\n",
      "Q Loss:  0.003032033797353506\n",
      "Policy Loss:  0.012591030448675156\n",
      "[(0.00041, 0.31369), (0.0, 0.31343), (1.0, 0.31369)]\n",
      "Alpha*: 0.0 tau*: 0.31343 Episode: 27574 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  25850.228515625\n",
      "Q Loss:  25370.359375\n",
      "Policy Loss:  -8.945469856262207\n",
      "[(0.00041, 0.31343), (0.0, 0.31317), (1.0, 0.31343)]\n",
      "Alpha*: 0.0 tau*: 0.31317 Episode: 27631 length: 36 #teleports:21\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  19.820411682128906\n",
      "Q Loss:  7.00145959854126\n",
      "Policy Loss:  -6.832648277282715\n",
      "[(0.00042, 0.31317), (0.0, 0.31291), (1.0, 0.31317)]\n",
      "Alpha*: 0.0 tau*: 0.31291 Episode: 27820 length: 131 #teleports:58\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0002755618479568511\n",
      "Q Loss:  0.00018585612997412682\n",
      "Policy Loss:  0.0055153039284050465\n",
      "[(0.00042, 0.31291), (0.0, 0.31265), (1.0, 0.31291)]\n",
      "Alpha*: 0.0 tau*: 0.31265 Episode: 27824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.60790581908077e-05\n",
      "Q Loss:  5.052768756286241e-05\n",
      "Policy Loss:  -0.01191161572933197\n",
      "[(0.00042, 0.31265), (0.0, 0.3124), (1.0, 0.31265)]\n",
      "Alpha*: 0.0 tau*: 0.3124 Episode: 27830 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  0.00010593155457172543\n",
      "Q Loss:  0.029173649847507477\n",
      "Policy Loss:  0.08648047596216202\n",
      "[(0.00042, 0.3124), (0.0, 0.31215), (1.0, 0.3124)]\n",
      "Alpha*: 0.0 tau*: 0.31215 Episode: 27834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.000762241892516613\n",
      "Q Loss:  0.0002785642573144287\n",
      "Policy Loss:  -0.021021094173192978\n",
      "[(0.00043, 0.31215), (0.0, 0.3119), (1.0, 0.31215)]\n",
      "Alpha*: 0.0 tau*: 0.3119 Episode: 27842 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.03270998201333e-05\n",
      "Q Loss:  0.0012917723506689072\n",
      "Policy Loss:  0.006740743760019541\n",
      "[(0.00043, 0.3119), (0.0, 0.31165), (1.0, 0.3119)]\n",
      "Alpha*: 0.0 tau*: 0.31165 Episode: 27847 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0015625078231096268\n",
      "Q Loss:  0.002091271337121725\n",
      "Policy Loss:  -0.016017964109778404\n",
      "[(0.00043, 0.31165), (0.0, 0.3114), (1.0, 0.31165)]\n",
      "Alpha*: 0.0 tau*: 0.3114 Episode: 27852 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005377327324822545\n",
      "Q Loss:  0.0019883187487721443\n",
      "Policy Loss:  -0.02060568332672119\n",
      "[(0.00043, 0.3114), (0.0, 0.31115), (1.0, 0.3114)]\n",
      "Alpha*: 0.0 tau*: 0.31115 Episode: 27859 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  693.5597534179688\n",
      "Q Loss:  0.0009745232528075576\n",
      "Policy Loss:  -214.58099365234375\n",
      "[(0.00043, 0.31115), (0.0, 0.3109), (1.0, 0.31115)]\n",
      "Alpha*: 0.0 tau*: 0.3109 Episode: 27866 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.00900411605834961\n",
      "Value Loss:  0.003929992206394672\n",
      "Q Loss:  3.37160325050354\n",
      "Policy Loss:  0.6346701383590698\n",
      "[(0.00043, 0.3109), (0.0, 0.31065), (1.0, 0.3109)]\n",
      "Alpha*: 0.0 tau*: 0.31065 Episode: 27870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.00017582401051186025\n",
      "Q Loss:  0.000821188441477716\n",
      "Policy Loss:  0.010762540623545647\n",
      "[(0.00043, 0.31065), (0.0, 0.3104), (1.0, 0.31065)]\n",
      "Alpha*: 0.0 tau*: 0.3104 Episode: 27875 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  349.716796875\n",
      "Q Loss:  0.00044948782306164503\n",
      "Policy Loss:  -107.67120361328125\n",
      "[(0.00044, 0.3104), (0.0, 0.31015), (1.0, 0.3104)]\n",
      "Alpha*: 0.0 tau*: 0.31015 Episode: 27881 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  349.9046325683594\n",
      "Q Loss:  0.569782018661499\n",
      "Policy Loss:  -107.4489974975586\n",
      "[(0.00044, 0.31015), (0.0, 0.3099), (1.0, 0.31015)]\n",
      "Alpha*: 0.0 tau*: 0.3099 Episode: 27888 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0004487824917305261\n",
      "Q Loss:  0.026473872363567352\n",
      "Policy Loss:  0.06258804351091385\n",
      "[(0.00044, 0.3099), (0.0, 0.30965), (1.0, 0.3099)]\n",
      "Alpha*: 0.0 tau*: 0.30965 Episode: 27892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010003328323364258\n",
      "Value Loss:  0.0018452487420290709\n",
      "Q Loss:  0.003941930830478668\n",
      "Policy Loss:  0.02157614938914776\n",
      "[(0.00044, 0.30965), (0.0, 0.3094), (1.0, 0.30965)]\n",
      "Alpha*: 0.0 tau*: 0.3094 Episode: 27897 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  348.7220764160156\n",
      "Q Loss:  566.7797241210938\n",
      "Policy Loss:  -63.9562873840332\n",
      "[(0.00044, 0.3094), (0.0, 0.30915), (1.0, 0.3094)]\n",
      "Alpha*: 0.0 tau*: 0.30915 Episode: 27902 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0010397423757240176\n",
      "Q Loss:  0.0005231716204434633\n",
      "Policy Loss:  -0.006096947006881237\n",
      "[(0.00044, 0.30915), (0.0, 0.3089), (1.0, 0.30915)]\n",
      "Alpha*: 0.0 tau*: 0.3089 Episode: 27906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  27709.9140625\n",
      "Q Loss:  27097.30078125\n",
      "Policy Loss:  -23.491369247436523\n",
      "[(0.00044, 0.3089), (0.0, 0.30865), (1.0, 0.3089)]\n",
      "Alpha*: 0.0 tau*: 0.30865 Episode: 27997 length: 67 #teleports:24\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.000963810714893043\n",
      "Q Loss:  0.034023888409137726\n",
      "Policy Loss:  0.05846593156456947\n",
      "[(0.00044, 0.30865), (0.0, 0.3084), (1.0, 0.30865)]\n",
      "Alpha*: 0.0 tau*: 0.3084 Episode: 28002 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  697.7692260742188\n",
      "Q Loss:  796.7644653320312\n",
      "Policy Loss:  -130.84083557128906\n",
      "[(0.00044, 0.3084), (0.0, 0.30815), (1.0, 0.3084)]\n",
      "Alpha*: 0.0 tau*: 0.30815 Episode: 28009 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  16283.2763671875\n",
      "Q Loss:  15939.5146484375\n",
      "Policy Loss:  -13.786396026611328\n",
      "[(0.00044, 0.30815), (0.0, 0.3079), (1.0, 0.30815)]\n",
      "Alpha*: 0.0 tau*: 0.3079 Episode: 28084 length: 57 #teleports:18\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00034934026189148426\n",
      "Q Loss:  3.4832754135131836\n",
      "Policy Loss:  0.6174745559692383\n",
      "[(0.00044, 0.3079), (0.0, 0.30765), (1.0, 0.3079)]\n",
      "Alpha*: 0.0 tau*: 0.30765 Episode: 28089 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0014361287467181683\n",
      "Q Loss:  0.0033101122826337814\n",
      "Policy Loss:  -0.004167374223470688\n",
      "[(0.00045, 0.30765), (0.0, 0.3074), (1.0, 0.30765)]\n",
      "Alpha*: 0.0 tau*: 0.3074 Episode: 28096 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  103.62782287597656\n",
      "Q Loss:  1.196250319480896\n",
      "Policy Loss:  -25.925031661987305\n",
      "[(0.00045, 0.3074), (0.0, 0.30715), (1.0, 0.3074)]\n",
      "Alpha*: 0.0 tau*: 0.30715 Episode: 28114 length: 14 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.001486322726123035\n",
      "Q Loss:  0.004251081496477127\n",
      "Policy Loss:  0.0006513535045087337\n",
      "[(0.00045, 0.30715), (0.0, 0.3069), (1.0, 0.30715)]\n",
      "Alpha*: 0.0 tau*: 0.3069 Episode: 28119 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0020414898172020912\n",
      "Q Loss:  0.0004885206581093371\n",
      "Policy Loss:  -0.014995467849075794\n",
      "[(0.00045, 0.3069), (0.0, 0.30665), (1.0, 0.3069)]\n",
      "Alpha*: 0.0 tau*: 0.30665 Episode: 28123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  351.2684631347656\n",
      "Q Loss:  584.8751831054688\n",
      "Policy Loss:  -66.8668441772461\n",
      "[(0.00045, 0.30665), (0.0, 0.3064), (1.0, 0.30665)]\n",
      "Alpha*: 0.0 tau*: 0.3064 Episode: 28129 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0006705787382088602\n",
      "Q Loss:  0.00014438798825722188\n",
      "Policy Loss:  0.0037265049759298563\n",
      "[(0.00045, 0.3064), (0.0, 0.30615), (1.0, 0.3064)]\n",
      "Alpha*: 0.0 tau*: 0.30615 Episode: 28134 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  3.601233765948564e-05\n",
      "Q Loss:  0.07219909876585007\n",
      "Policy Loss:  0.3583275079727173\n",
      "[(0.00045, 0.30615), (0.0, 0.3059), (1.0, 0.30615)]\n",
      "Alpha*: 0.0 tau*: 0.3059 Episode: 28138 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  21122.083984375\n",
      "Q Loss:  20620.708984375\n",
      "Policy Loss:  -27.17393684387207\n",
      "[(0.00044, 0.3059), (0.0, 0.30565), (1.0, 0.3059)]\n",
      "Alpha*: 0.0 tau*: 0.30565 Episode: 28196 length: 44 #teleports:14\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.000674818002153188\n",
      "Q Loss:  0.007258974015712738\n",
      "Policy Loss:  0.04304204136133194\n",
      "[(0.00044, 0.30565), (0.0, 0.3054), (1.0, 0.30565)]\n",
      "Alpha*: 0.0 tau*: 0.3054 Episode: 28200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  11762.19140625\n",
      "Q Loss:  11500.0849609375\n",
      "Policy Loss:  -14.446647644042969\n",
      "[(0.00044, 0.3054), (0.0, 0.30515), (1.0, 0.3054)]\n",
      "Alpha*: 0.0 tau*: 0.30515 Episode: 28314 length: 79 #teleports:35\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  6.543236668221653e-05\n",
      "Q Loss:  0.006600701715797186\n",
      "Policy Loss:  0.0005771061405539513\n",
      "[(0.00044, 0.30515), (0.0, 0.3049), (1.0, 0.30515)]\n",
      "Alpha*: 0.0 tau*: 0.3049 Episode: 28319 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.0032295179553329945\n",
      "Q Loss:  0.006380296777933836\n",
      "Policy Loss:  0.05504553020000458\n",
      "[(0.00044, 0.3049), (0.0, 0.30465), (1.0, 0.3049)]\n",
      "Alpha*: 0.0 tau*: 0.30465 Episode: 28324 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0010380083695054054\n",
      "Q Loss:  0.0017228275537490845\n",
      "Policy Loss:  0.022290218621492386\n",
      "[(0.00044, 0.30465), (0.0, 0.3044), (1.0, 0.30465)]\n",
      "Alpha*: 0.0 tau*: 0.3044 Episode: 28329 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  3.960897811339237e-05\n",
      "Q Loss:  0.046363070607185364\n",
      "Policy Loss:  0.11061687767505646\n",
      "[(0.00044, 0.3044), (0.0, 0.30415), (1.0, 0.3044)]\n",
      "Alpha*: 0.0 tau*: 0.30415 Episode: 28333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  3.1764931918587536e-05\n",
      "Q Loss:  0.0023724036291241646\n",
      "Policy Loss:  0.0245490875095129\n",
      "[(0.00044, 0.30415), (0.0, 0.3039), (1.0, 0.30415)]\n",
      "Alpha*: 0.0 tau*: 0.3039 Episode: 28339 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  359.43707275390625\n",
      "Q Loss:  0.030121009796857834\n",
      "Policy Loss:  -107.728515625\n",
      "[(0.00044, 0.3039), (0.0, 0.30365), (1.0, 0.3039)]\n",
      "Alpha*: 0.0 tau*: 0.30365 Episode: 28348 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.0006162120844237506\n",
      "Q Loss:  4.044991970062256\n",
      "Policy Loss:  0.6970378160476685\n",
      "[(0.00044, 0.30365), (0.0, 0.3034), (1.0, 0.30365)]\n",
      "Alpha*: 0.0 tau*: 0.3034 Episode: 28354 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  8.539881673641503e-05\n",
      "Q Loss:  0.030972184613347054\n",
      "Policy Loss:  0.041045770049095154\n",
      "[(0.00045, 0.3034), (0.0, 0.30315), (1.0, 0.3034)]\n",
      "Alpha*: 0.0 tau*: 0.30315 Episode: 28360 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001760607265168801\n",
      "Q Loss:  0.001390534918755293\n",
      "Policy Loss:  0.009563667699694633\n",
      "[(0.00045, 0.30315), (0.0, 0.3029), (1.0, 0.30315)]\n",
      "Alpha*: 0.0 tau*: 0.3029 Episode: 28365 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0025641852989792824\n",
      "Q Loss:  0.0017419722862541676\n",
      "Policy Loss:  -0.010509192012250423\n",
      "[(0.00045, 0.3029), (0.0, 0.30265), (1.0, 0.3029)]\n",
      "Alpha*: 0.0 tau*: 0.30265 Episode: 28369 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0013859857572242618\n",
      "Q Loss:  0.038855358958244324\n",
      "Policy Loss:  0.07778625935316086\n",
      "[(0.00045, 0.30265), (0.0, 0.3024), (1.0, 0.30265)]\n",
      "Alpha*: 0.0 tau*: 0.3024 Episode: 28374 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.022005319595336914\n",
      "Value Loss:  0.0002598085848148912\n",
      "Q Loss:  0.0038633500225842\n",
      "Policy Loss:  0.025212761014699936\n",
      "[(0.00045, 0.3024), (0.0, 0.30215), (1.0, 0.3024)]\n",
      "Alpha*: 0.0 tau*: 0.30215 Episode: 28380 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00023619782587047666\n",
      "Q Loss:  4.0625715255737305\n",
      "Policy Loss:  0.7032425403594971\n",
      "[(0.00045, 0.30215), (0.0, 0.3019), (1.0, 0.30215)]\n",
      "Alpha*: 0.0 tau*: 0.3019 Episode: 28387 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  721.0821533203125\n",
      "Q Loss:  1068.258056640625\n",
      "Policy Loss:  -130.62306213378906\n",
      "[(0.00046, 0.3019), (0.0, 0.30165), (1.0, 0.3019)]\n",
      "Alpha*: 0.0 tau*: 0.30165 Episode: 28391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.002978246659040451\n",
      "Q Loss:  0.002851268043741584\n",
      "Policy Loss:  0.011708286590874195\n",
      "[(0.00045, 0.30165), (0.0, 0.3014), (1.0, 0.30165)]\n",
      "Alpha*: 0.0 tau*: 0.3014 Episode: 28397 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0029194955714046955\n",
      "Q Loss:  0.0011493100319057703\n",
      "Policy Loss:  0.021297719329595566\n",
      "[(0.00043, 0.3014), (0.0, 0.30115), (1.0, 0.3014)]\n",
      "Alpha*: 0.0 tau*: 0.30115 Episode: 28402 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  138.59364318847656\n",
      "Q Loss:  0.0710955411195755\n",
      "Policy Loss:  -41.876930236816406\n",
      "[(0.00042, 0.30115), (0.0, 0.3009), (1.0, 0.30115)]\n",
      "Alpha*: 0.0 tau*: 0.3009 Episode: 28429 length: 21 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.00035325431963428855\n",
      "Q Loss:  0.011261495761573315\n",
      "Policy Loss:  0.3105733394622803\n",
      "[(0.00041, 0.3009), (0.0, 0.30065), (1.0, 0.3009)]\n",
      "Alpha*: 0.0 tau*: 0.30065 Episode: 28434 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  41.69326400756836\n",
      "Q Loss:  48.509300231933594\n",
      "Policy Loss:  -11.88761043548584\n",
      "[(0.0004, 0.30065), (0.0, 0.3004), (1.0, 0.30065)]\n",
      "Alpha*: 0.0 tau*: 0.3004 Episode: 28532 length: 69 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  6953.923828125\n",
      "Q Loss:  6797.97265625\n",
      "Policy Loss:  -14.248045921325684\n",
      "[(0.00039, 0.3004), (0.0, 0.30015), (1.0, 0.3004)]\n",
      "Alpha*: 0.0 tau*: 0.30015 Episode: 28711 length: 134 #teleports:45\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0006947508081793785\n",
      "Q Loss:  0.0040221866220235825\n",
      "Policy Loss:  0.014334939420223236\n",
      "[(0.00039, 0.30015), (0.0, 0.2999), (1.0, 0.30015)]\n",
      "Alpha*: 0.0 tau*: 0.2999 Episode: 28716 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  8.213060937123373e-05\n",
      "Q Loss:  0.014238142408430576\n",
      "Policy Loss:  0.355745792388916\n",
      "[(0.00039, 0.2999), (0.0, 0.29965), (1.0, 0.2999)]\n",
      "Alpha*: 0.0 tau*: 0.29965 Episode: 28720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  25.52291488647461\n",
      "Q Loss:  43.05910110473633\n",
      "Policy Loss:  -7.251903057098389\n",
      "[(0.00039, 0.29965), (0.0, 0.2994), (1.0, 0.29965)]\n",
      "Alpha*: 0.0 tau*: 0.2994 Episode: 28794 length: 57 #teleports:17\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  352.67822265625\n",
      "Q Loss:  613.353515625\n",
      "Policy Loss:  -65.73065185546875\n",
      "[(0.00042, 0.2994), (0.0, 0.29915), (1.0, 0.2994)]\n",
      "Alpha*: 0.0 tau*: 0.29915 Episode: 28798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  3.0092895030975342e-05\n",
      "Q Loss:  0.005472633056342602\n",
      "Policy Loss:  0.025417733937501907\n",
      "[(0.00041, 0.29915), (0.0, 0.2989), (1.0, 0.29915)]\n",
      "Alpha*: 0.0 tau*: 0.2989 Episode: 28805 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0016397687140852213\n",
      "Q Loss:  0.002794144209474325\n",
      "Policy Loss:  0.016661712899804115\n",
      "[(0.00038, 0.2989), (0.0, 0.29865), (1.0, 0.2989)]\n",
      "Alpha*: 0.0 tau*: 0.29865 Episode: 28810 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.223767660325393e-05\n",
      "Q Loss:  0.004949362948536873\n",
      "Policy Loss:  0.04111269861459732\n",
      "[(0.00035, 0.29865), (0.0, 0.2984), (1.0, 0.29865)]\n",
      "Alpha*: 0.0 tau*: 0.2984 Episode: 28815 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001182556152344\n",
      "Value Loss:  0.0008468770538456738\n",
      "Q Loss:  0.005244172178208828\n",
      "Policy Loss:  0.03752433508634567\n",
      "[(0.00034, 0.2984), (0.0, 0.29815), (1.0, 0.2984)]\n",
      "Alpha*: 0.0 tau*: 0.29815 Episode: 28819 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002596764825284481\n",
      "Q Loss:  0.003999408334493637\n",
      "Policy Loss:  0.344368040561676\n",
      "[(0.00032, 0.29815), (0.0, 0.2979), (1.0, 0.29815)]\n",
      "Alpha*: 0.0 tau*: 0.2979 Episode: 28824 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0023827734403312206\n",
      "Q Loss:  0.00883242767304182\n",
      "Policy Loss:  0.05941154807806015\n",
      "[(0.00031, 0.2979), (0.0, 0.29765), (1.0, 0.2979)]\n",
      "Alpha*: 0.0 tau*: 0.29765 Episode: 28831 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.002308767754584551\n",
      "Q Loss:  0.007498538121581078\n",
      "Policy Loss:  0.0486413799226284\n",
      "[(0.0003, 0.29765), (0.0, 0.2974), (1.0, 0.29765)]\n",
      "Alpha*: 0.0 tau*: 0.2974 Episode: 28835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.0023002908565104008\n",
      "Q Loss:  0.004968648310750723\n",
      "Policy Loss:  0.037347085773944855\n",
      "[(0.0003, 0.2974), (0.0, 0.29715), (1.0, 0.2974)]\n",
      "Alpha*: 0.0 tau*: 0.29715 Episode: 28840 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.009002923965454102\n",
      "Value Loss:  0.00027942282031290233\n",
      "Q Loss:  0.003091815859079361\n",
      "Policy Loss:  0.01671728305518627\n",
      "[(0.00029, 0.29715), (0.0, 0.2969), (1.0, 0.29715)]\n",
      "Alpha*: 0.0 tau*: 0.2969 Episode: 28846 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  12736.3984375\n",
      "Q Loss:  12385.6865234375\n",
      "Policy Loss:  -17.220195770263672\n",
      "[(0.00029, 0.2969), (0.0, 0.29665), (1.0, 0.2969)]\n",
      "Alpha*: 0.0 tau*: 0.29665 Episode: 28952 length: 73 #teleports:33\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.001652805949561298\n",
      "Q Loss:  0.001295936293900013\n",
      "Policy Loss:  -0.02448018454015255\n",
      "[(0.00029, 0.29665), (0.0, 0.2964), (1.0, 0.29665)]\n",
      "Alpha*: 0.0 tau*: 0.2964 Episode: 28959 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  348.38458251953125\n",
      "Q Loss:  214.03233337402344\n",
      "Policy Loss:  -95.46800231933594\n",
      "[(0.0003, 0.2964), (0.0, 0.29615), (1.0, 0.2964)]\n",
      "Alpha*: 0.0 tau*: 0.29615 Episode: 28964 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  60.20948791503906\n",
      "Q Loss:  13.534256935119629\n",
      "Policy Loss:  -18.891679763793945\n",
      "[(0.00032, 0.29615), (0.0, 0.2959), (1.0, 0.29615)]\n",
      "Alpha*: 0.0 tau*: 0.2959 Episode: 29067 length: 70 #teleports:33\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009604692459106445\n",
      "Value Loss:  346.6446838378906\n",
      "Q Loss:  0.046698156744241714\n",
      "Policy Loss:  -107.06726837158203\n",
      "[(0.00033, 0.2959), (0.0, 0.29565), (1.0, 0.2959)]\n",
      "Alpha*: 0.0 tau*: 0.29565 Episode: 29071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  50.73203659057617\n",
      "Q Loss:  87.0494613647461\n",
      "Policy Loss:  -11.326766014099121\n",
      "[(0.00035, 0.29565), (0.0, 0.2954), (1.0, 0.29565)]\n",
      "Alpha*: 0.0 tau*: 0.2954 Episode: 29113 length: 28 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0010617253137752414\n",
      "Q Loss:  0.0038684667088091373\n",
      "Policy Loss:  -0.00786468293517828\n",
      "[(0.00037, 0.2954), (0.0, 0.29515), (1.0, 0.2954)]\n",
      "Alpha*: 0.0 tau*: 0.29515 Episode: 29119 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0001963513932423666\n",
      "Q Loss:  0.005144426133483648\n",
      "Policy Loss:  0.024523694068193436\n",
      "[(0.00039, 0.29515), (0.0, 0.2949), (1.0, 0.29515)]\n",
      "Alpha*: 0.0 tau*: 0.2949 Episode: 29123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0009671010193414986\n",
      "Q Loss:  0.0036338435020297766\n",
      "Policy Loss:  -0.00839176494628191\n",
      "[(0.0004, 0.2949), (0.0, 0.29465), (1.0, 0.2949)]\n",
      "Alpha*: 0.0 tau*: 0.29465 Episode: 29130 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.0014988757902756333\n",
      "Q Loss:  0.007284905761480331\n",
      "Policy Loss:  -0.01004577986896038\n",
      "[(0.00042, 0.29465), (0.0, 0.2944), (1.0, 0.29465)]\n",
      "Alpha*: 0.0 tau*: 0.2944 Episode: 29134 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0001442602660972625\n",
      "Q Loss:  0.003883392084389925\n",
      "Policy Loss:  0.010367748327553272\n",
      "[(0.00043, 0.2944), (0.0, 0.29415), (1.0, 0.2944)]\n",
      "Alpha*: 0.0 tau*: 0.29415 Episode: 29138 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  56.997615814208984\n",
      "Q Loss:  100.63785552978516\n",
      "Policy Loss:  -12.478431701660156\n",
      "[(0.00042, 0.29415), (0.0, 0.2939), (1.0, 0.29415)]\n",
      "Alpha*: 0.0 tau*: 0.2939 Episode: 29205 length: 49 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  0.0005684093339368701\n",
      "Q Loss:  0.0005256364238448441\n",
      "Policy Loss:  -1.125875860452652e-05\n",
      "[(0.00041, 0.2939), (0.0, 0.29365), (1.0, 0.2939)]\n",
      "Alpha*: 0.0 tau*: 0.29365 Episode: 29212 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00025647241272963583\n",
      "Q Loss:  0.004793752916157246\n",
      "Policy Loss:  0.00634977500885725\n",
      "[(0.00041, 0.29365), (0.0, 0.2934), (1.0, 0.29365)]\n",
      "Alpha*: 0.0 tau*: 0.2934 Episode: 29217 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  340.0328674316406\n",
      "Q Loss:  12.84211540222168\n",
      "Policy Loss:  -98.96221160888672\n",
      "[(0.0004, 0.2934), (0.0, 0.29315), (1.0, 0.2934)]\n",
      "Alpha*: 0.0 tau*: 0.29315 Episode: 29225 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  0.00029676774283871055\n",
      "Q Loss:  0.010158693417906761\n",
      "Policy Loss:  -0.008765578269958496\n",
      "[(0.00039, 0.29315), (0.0, 0.2929), (1.0, 0.29315)]\n",
      "Alpha*: 0.0 tau*: 0.2929 Episode: 29230 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.9644818305969238\n",
      "Q Loss:  0.15718179941177368\n",
      "Policy Loss:  -1.669508457183838\n",
      "[(0.00039, 0.2929), (0.0, 0.29265), (1.0, 0.2929)]\n",
      "Alpha*: 0.0 tau*: 0.29265 Episode: 29287 length: 39 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  54.53308868408203\n",
      "Q Loss:  22.46885871887207\n",
      "Policy Loss:  -17.30543327331543\n",
      "[(0.00039, 0.29265), (0.0, 0.2924), (1.0, 0.29265)]\n",
      "Alpha*: 0.0 tau*: 0.2924 Episode: 29397 length: 75 #teleports:35\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.00016041503113228828\n",
      "Q Loss:  0.0028170582372695208\n",
      "Policy Loss:  0.03072063997387886\n",
      "[(0.00038, 0.2924), (0.0, 0.29215), (1.0, 0.2924)]\n",
      "Alpha*: 0.0 tau*: 0.29215 Episode: 29402 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0001249660854227841\n",
      "Q Loss:  0.0030235350131988525\n",
      "Policy Loss:  0.34096166491508484\n",
      "[(0.00038, 0.29215), (0.0, 0.2919), (1.0, 0.29215)]\n",
      "Alpha*: 0.0 tau*: 0.2919 Episode: 29408 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010597705841064453\n",
      "Value Loss:  6.301907433226006e-06\n",
      "Q Loss:  0.009433727711439133\n",
      "Policy Loss:  0.06168701499700546\n",
      "[(0.00038, 0.2919), (0.0, 0.29165), (1.0, 0.2919)]\n",
      "Alpha*: 0.0 tau*: 0.29165 Episode: 29412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.00012084039917681366\n",
      "Q Loss:  0.002895958023145795\n",
      "Policy Loss:  0.017748894169926643\n",
      "[(0.00038, 0.29165), (0.0, 0.2914), (1.0, 0.29165)]\n",
      "Alpha*: 0.0 tau*: 0.2914 Episode: 29422 length: 4 #teleports:6\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0004912493750452995\n",
      "Q Loss:  0.003178393468260765\n",
      "Policy Loss:  -0.003875895868986845\n",
      "[(0.00038, 0.2914), (0.0, 0.29115), (1.0, 0.2914)]\n",
      "Alpha*: 0.0 tau*: 0.29115 Episode: 29428 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  9.190350101562217e-05\n",
      "Q Loss:  0.0024442127905786037\n",
      "Policy Loss:  0.035534460097551346\n",
      "[(0.00038, 0.29115), (0.0, 0.2909), (1.0, 0.29115)]\n",
      "Alpha*: 0.0 tau*: 0.2909 Episode: 29432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  14589.3349609375\n",
      "Q Loss:  14222.6455078125\n",
      "Policy Loss:  -26.481563568115234\n",
      "[(0.00039, 0.2909), (0.0, 0.29065), (1.0, 0.2909)]\n",
      "Alpha*: 0.0 tau*: 0.29065 Episode: 29511 length: 64 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.3417186737060547\n",
      "Q Loss:  0.06528377532958984\n",
      "Policy Loss:  -4.543732166290283\n",
      "[(0.0004, 0.29065), (0.0, 0.2904), (1.0, 0.29065)]\n",
      "Alpha*: 0.0 tau*: 0.2904 Episode: 29519 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  42255.84375\n",
      "Q Loss:  41068.171875\n",
      "Policy Loss:  -30.274925231933594\n",
      "[(0.00041, 0.2904), (0.0, 0.29015), (1.0, 0.2904)]\n",
      "Alpha*: 0.0 tau*: 0.29015 Episode: 29548 length: 22 #teleports:7\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  7.093208841979504e-05\n",
      "Q Loss:  0.0014558705734089017\n",
      "Policy Loss:  0.010038475506007671\n",
      "[(0.00041, 0.29015), (0.0, 0.2899), (1.0, 0.29015)]\n",
      "Alpha*: 0.0 tau*: 0.2899 Episode: 29552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011136807734146714\n",
      "Q Loss:  0.003734542755410075\n",
      "Policy Loss:  0.026480261236429214\n",
      "[(0.00041, 0.2899), (0.0, 0.28965), (1.0, 0.2899)]\n",
      "Alpha*: 0.0 tau*: 0.28965 Episode: 29558 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  109192.8515625\n",
      "Q Loss:  106348.8671875\n",
      "Policy Loss:  -32.46715545654297\n",
      "[(0.00041, 0.28965), (0.0, 0.2894), (1.0, 0.28965)]\n",
      "Alpha*: 0.0 tau*: 0.2894 Episode: 29582 length: 17 #teleports:7\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  2.4872391804819927e-05\n",
      "Q Loss:  0.014412998221814632\n",
      "Policy Loss:  0.08154439181089401\n",
      "[(0.0004, 0.2894), (0.0, 0.28915), (1.0, 0.2894)]\n",
      "Alpha*: 0.0 tau*: 0.28915 Episode: 29586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0006278882501646876\n",
      "Q Loss:  9.805055742617697e-05\n",
      "Policy Loss:  0.009847516193985939\n",
      "[(0.0004, 0.28915), (0.0, 0.2889), (1.0, 0.28915)]\n",
      "Alpha*: 0.0 tau*: 0.2889 Episode: 29591 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0017238219734281301\n",
      "Q Loss:  0.0009337107185274363\n",
      "Policy Loss:  -0.016636572778224945\n",
      "[(0.00039, 0.2889), (0.0, 0.28865), (1.0, 0.2889)]\n",
      "Alpha*: 0.0 tau*: 0.28865 Episode: 29595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  368.9964599609375\n",
      "Q Loss:  0.032107412815093994\n",
      "Policy Loss:  -110.9481430053711\n",
      "[(0.00039, 0.28865), (0.0, 0.2884), (1.0, 0.28865)]\n",
      "Alpha*: 0.0 tau*: 0.2884 Episode: 29602 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  373.87127685546875\n",
      "Q Loss:  6.204803466796875\n",
      "Policy Loss:  -107.32958984375\n",
      "[(0.00039, 0.2884), (0.0, 0.28815), (1.0, 0.2884)]\n",
      "Alpha*: 0.0 tau*: 0.28815 Episode: 29610 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  3.4123142540920526e-05\n",
      "Q Loss:  0.00040034265839494765\n",
      "Policy Loss:  0.004401202779263258\n",
      "[(0.00038, 0.28815), (0.0, 0.2879), (1.0, 0.28815)]\n",
      "Alpha*: 0.0 tau*: 0.2879 Episode: 29617 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0008345646783709526\n",
      "Q Loss:  0.0027152705006301403\n",
      "Policy Loss:  0.017198767513036728\n",
      "[(0.00038, 0.2879), (0.0, 0.28765), (1.0, 0.2879)]\n",
      "Alpha*: 0.0 tau*: 0.28765 Episode: 29621 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.815126183326356e-05\n",
      "Q Loss:  0.0240425206720829\n",
      "Policy Loss:  0.09160248935222626\n",
      "[(0.00038, 0.28765), (0.0, 0.2874), (1.0, 0.28765)]\n",
      "Alpha*: 0.0 tau*: 0.2874 Episode: 29626 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  103.97773742675781\n",
      "Q Loss:  0.4618806540966034\n",
      "Policy Loss:  -30.982322692871094\n",
      "[(0.00038, 0.2874), (0.0, 0.28715), (1.0, 0.2874)]\n",
      "Alpha*: 0.0 tau*: 0.28715 Episode: 29708 length: 60 #teleports:22\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  389.68731689453125\n",
      "Q Loss:  0.7478392124176025\n",
      "Policy Loss:  -113.67426300048828\n",
      "[(0.00038, 0.28715), (0.0, 0.2869), (1.0, 0.28715)]\n",
      "Alpha*: 0.0 tau*: 0.2869 Episode: 29714 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.000179200796992518\n",
      "Q Loss:  0.0010410386603325605\n",
      "Policy Loss:  -0.008400460705161095\n",
      "[(0.00038, 0.2869), (0.0, 0.28665), (1.0, 0.2869)]\n",
      "Alpha*: 0.0 tau*: 0.28665 Episode: 29720 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  392.6982727050781\n",
      "Q Loss:  0.002434388268738985\n",
      "Policy Loss:  -114.25594329833984\n",
      "[(0.00038, 0.28665), (0.0, 0.2864), (1.0, 0.28665)]\n",
      "Alpha*: 0.0 tau*: 0.2864 Episode: 29726 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  393.36083984375\n",
      "Q Loss:  739.20556640625\n",
      "Policy Loss:  -67.62496948242188\n",
      "[(0.0004, 0.2864), (0.0, 0.28615), (1.0, 0.2864)]\n",
      "Alpha*: 0.0 tau*: 0.28615 Episode: 29732 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.00900125503540039\n",
      "Value Loss:  4.7947425628080964e-05\n",
      "Q Loss:  0.018293030560016632\n",
      "Policy Loss:  0.04035920649766922\n",
      "[(0.00041, 0.28615), (0.0, 0.2859), (1.0, 0.28615)]\n",
      "Alpha*: 0.0 tau*: 0.2859 Episode: 29736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  1.0982965230941772\n",
      "Q Loss:  0.7636510133743286\n",
      "Policy Loss:  -2.9991302490234375\n",
      "[(0.00039, 0.2859), (0.0, 0.28565), (1.0, 0.2859)]\n",
      "Alpha*: 0.0 tau*: 0.28565 Episode: 29742 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001182556152344\n",
      "Value Loss:  289.11517333984375\n",
      "Q Loss:  85.85072326660156\n",
      "Policy Loss:  -74.61011505126953\n",
      "[(0.00038, 0.28565), (0.0, 0.2854), (1.0, 0.28565)]\n",
      "Alpha*: 0.0 tau*: 0.2854 Episode: 29760 length: 11 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  392.80126953125\n",
      "Q Loss:  0.006715611554682255\n",
      "Policy Loss:  -114.13496398925781\n",
      "[(0.00038, 0.2854), (0.0, 0.28515), (1.0, 0.2854)]\n",
      "Alpha*: 0.0 tau*: 0.28515 Episode: 29765 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  15713.94140625\n",
      "Q Loss:  15297.4482421875\n",
      "Policy Loss:  -23.634077072143555\n",
      "[(0.00038, 0.28515), (0.0, 0.2849), (1.0, 0.28515)]\n",
      "Alpha*: 0.0 tau*: 0.2849 Episode: 29848 length: 59 #teleports:24\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.2481218576431274\n",
      "Q Loss:  0.0761079341173172\n",
      "Policy Loss:  -2.4258177280426025\n",
      "[(0.00039, 0.2849), (0.0, 0.28465), (1.0, 0.2849)]\n",
      "Alpha*: 0.0 tau*: 0.28465 Episode: 29903 length: 41 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00038343475898727775\n",
      "Q Loss:  0.001145954942330718\n",
      "Policy Loss:  -0.02219054102897644\n",
      "[(0.0004, 0.28465), (0.0, 0.2844), (1.0, 0.28465)]\n",
      "Alpha*: 0.0 tau*: 0.2844 Episode: 29909 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  391.5882568359375\n",
      "Q Loss:  757.9793090820312\n",
      "Policy Loss:  -65.26646423339844\n",
      "[(0.00042, 0.2844), (0.0, 0.28415), (1.0, 0.2844)]\n",
      "Alpha*: 0.0 tau*: 0.28415 Episode: 29916 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.00999140739440918\n",
      "Value Loss:  1.1633450984954834\n",
      "Q Loss:  0.6305420398712158\n",
      "Policy Loss:  -3.410654306411743\n",
      "[(0.00044, 0.28415), (0.0, 0.2839), (1.0, 0.28415)]\n",
      "Alpha*: 0.0 tau*: 0.2839 Episode: 29921 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.7534036040306091\n",
      "Q Loss:  0.6477922201156616\n",
      "Policy Loss:  -1.0776829719543457\n",
      "[(0.00044, 0.2839), (0.0, 0.28365), (1.0, 0.2839)]\n",
      "Alpha*: 0.0 tau*: 0.28365 Episode: 29985 length: 43 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0005363969248719513\n",
      "Q Loss:  0.0008907271549105644\n",
      "Policy Loss:  0.009085512720048428\n",
      "[(0.00044, 0.28365), (0.0, 0.2834), (1.0, 0.28365)]\n",
      "Alpha*: 0.0 tau*: 0.2834 Episode: 29989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0004642491112463176\n",
      "Q Loss:  0.6167282462120056\n",
      "Policy Loss:  0.08035768568515778\n",
      "[(0.00042, 0.2834), (0.0, 0.28315), (1.0, 0.2834)]\n",
      "Alpha*: 0.0 tau*: 0.28315 Episode: 29993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.00040632751188240945\n",
      "Q Loss:  0.0009338439558632672\n",
      "Policy Loss:  -0.012646987102925777\n",
      "[(0.00041, 0.28315), (0.0, 0.2829), (1.0, 0.28315)]\n",
      "Alpha*: 0.0 tau*: 0.2829 Episode: 30000 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.03500819206237793\n",
      "Value Loss:  6.899172149132937e-05\n",
      "Q Loss:  0.05491868406534195\n",
      "Policy Loss:  0.09061753749847412\n",
      "[(0.0004, 0.2829), (0.0, 0.28265), (1.0, 0.2829)]\n",
      "Alpha*: 0.0 tau*: 0.28265 Episode: 30004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  4.348938091425225e-06\n",
      "Q Loss:  0.06193028762936592\n",
      "Policy Loss:  0.43163833022117615\n",
      "[(0.0004, 0.28265), (0.0, 0.2824), (1.0, 0.28265)]\n",
      "Alpha*: 0.0 tau*: 0.2824 Episode: 30008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010998010635375977\n",
      "Value Loss:  19257.70703125\n",
      "Q Loss:  18617.67578125\n",
      "Policy Loss:  -17.304025650024414\n",
      "[(0.0004, 0.2824), (0.0, 0.28215), (1.0, 0.2824)]\n",
      "Alpha*: 0.0 tau*: 0.28215 Episode: 30069 length: 48 #teleports:13\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.5634070223313756e-05\n",
      "Q Loss:  0.02724374085664749\n",
      "Policy Loss:  -0.06146540492773056\n",
      "[(0.00039, 0.28215), (0.0, 0.2819), (1.0, 0.28215)]\n",
      "Alpha*: 0.0 tau*: 0.2819 Episode: 30074 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00091544259339571\n",
      "Q Loss:  0.004180155694484711\n",
      "Policy Loss:  -0.026313960552215576\n",
      "[(0.00039, 0.2819), (0.0, 0.28165), (1.0, 0.2819)]\n",
      "Alpha*: 0.0 tau*: 0.28165 Episode: 30078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  390.16571044921875\n",
      "Q Loss:  232.6463623046875\n",
      "Policy Loss:  -109.212646484375\n",
      "[(0.0004, 0.28165), (0.0, 0.2814), (1.0, 0.28165)]\n",
      "Alpha*: 0.0 tau*: 0.2814 Episode: 30083 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00041463077650405467\n",
      "Q Loss:  0.07091573625802994\n",
      "Policy Loss:  0.08568261563777924\n",
      "[(0.0004, 0.2814), (0.0, 0.28115), (1.0, 0.2814)]\n",
      "Alpha*: 0.0 tau*: 0.28115 Episode: 30090 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0011138751870021224\n",
      "Q Loss:  0.0004384084604680538\n",
      "Policy Loss:  0.0028543006628751755\n",
      "[(0.0004, 0.28115), (0.0, 0.2809), (1.0, 0.28115)]\n",
      "Alpha*: 0.0 tau*: 0.2809 Episode: 30095 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0014336915919557214\n",
      "Q Loss:  0.0009442740119993687\n",
      "Policy Loss:  0.3457488417625427\n",
      "[(0.0004, 0.2809), (0.0, 0.28065), (1.0, 0.2809)]\n",
      "Alpha*: 0.0 tau*: 0.28065 Episode: 30099 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01060938835144043\n",
      "Value Loss:  0.00025830508093349636\n",
      "Q Loss:  0.13095612823963165\n",
      "Policy Loss:  0.17635279893875122\n",
      "[(0.0004, 0.28065), (0.0, 0.2804), (1.0, 0.28065)]\n",
      "Alpha*: 0.0 tau*: 0.2804 Episode: 30105 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009003162384033203\n",
      "Value Loss:  0.0002062738494714722\n",
      "Q Loss:  0.0029585566371679306\n",
      "Policy Loss:  0.03082691691815853\n",
      "[(0.0004, 0.2804), (0.0, 0.28015), (1.0, 0.2804)]\n",
      "Alpha*: 0.0 tau*: 0.28015 Episode: 30112 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  390.2799072265625\n",
      "Q Loss:  229.02662658691406\n",
      "Policy Loss:  -108.95977020263672\n",
      "[(0.00041, 0.28015), (0.0, 0.2799), (1.0, 0.28015)]\n",
      "Alpha*: 0.0 tau*: 0.2799 Episode: 30118 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00025357233243994415\n",
      "Q Loss:  227.69664001464844\n",
      "Policy Loss:  1.0090148448944092\n",
      "[(0.00042, 0.2799), (0.0, 0.27965), (1.0, 0.2799)]\n",
      "Alpha*: 0.0 tau*: 0.27965 Episode: 30124 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  17438.53515625\n",
      "Q Loss:  16896.619140625\n",
      "Policy Loss:  -13.793622016906738\n",
      "[(0.00043, 0.27965), (0.0, 0.2794), (1.0, 0.27965)]\n",
      "Alpha*: 0.0 tau*: 0.2794 Episode: 30192 length: 53 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.001761587685905397\n",
      "Q Loss:  0.010210085660219193\n",
      "Policy Loss:  0.0545751228928566\n",
      "[(0.00044, 0.2794), (0.0, 0.27915), (1.0, 0.2794)]\n",
      "Alpha*: 0.0 tau*: 0.27915 Episode: 30197 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.002432921901345253\n",
      "Q Loss:  0.0038797655142843723\n",
      "Policy Loss:  0.040690645575523376\n",
      "[(0.00045, 0.27915), (0.0, 0.2789), (1.0, 0.27915)]\n",
      "Alpha*: 0.0 tau*: 0.2789 Episode: 30208 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  390.6947021484375\n",
      "Q Loss:  0.0012696505291387439\n",
      "Policy Loss:  -113.72775268554688\n",
      "[(0.00045, 0.2789), (0.0, 0.27865), (1.0, 0.2789)]\n",
      "Alpha*: 0.0 tau*: 0.27865 Episode: 30214 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0005219013546593487\n",
      "Q Loss:  0.0022893596906214952\n",
      "Policy Loss:  -0.009180521592497826\n",
      "[(0.00045, 0.27865), (0.0, 0.2784), (1.0, 0.27865)]\n",
      "Alpha*: 0.0 tau*: 0.2784 Episode: 30220 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.002185479272156954\n",
      "Q Loss:  0.002706092083826661\n",
      "Policy Loss:  0.02349892631173134\n",
      "[(0.00045, 0.2784), (0.0, 0.27815), (1.0, 0.2784)]\n",
      "Alpha*: 0.0 tau*: 0.27815 Episode: 30227 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.8541467296890914e-05\n",
      "Q Loss:  0.003127679694443941\n",
      "Policy Loss:  0.03141249716281891\n",
      "[(0.00044, 0.27815), (0.0, 0.2779), (1.0, 0.27815)]\n",
      "Alpha*: 0.0 tau*: 0.2779 Episode: 30231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  44.74037551879883\n",
      "Q Loss:  90.16697692871094\n",
      "Policy Loss:  -8.292055130004883\n",
      "[(0.00044, 0.2779), (0.0, 0.27765), (1.0, 0.2779)]\n",
      "Alpha*: 0.0 tau*: 0.27765 Episode: 30280 length: 36 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  52.82783889770508\n",
      "Q Loss:  82.22086334228516\n",
      "Policy Loss:  -14.0859956741333\n",
      "[(0.00044, 0.27765), (0.0, 0.2774), (1.0, 0.27765)]\n",
      "Alpha*: 0.0 tau*: 0.2774 Episode: 30473 length: 149 #teleports:44\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00341603672131896\n",
      "Q Loss:  0.005264068953692913\n",
      "Policy Loss:  -0.047928716987371445\n",
      "[(0.00044, 0.2774), (0.0, 0.27715), (1.0, 0.2774)]\n",
      "Alpha*: 0.0 tau*: 0.27715 Episode: 30478 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  6.432302143366542e-06\n",
      "Q Loss:  0.0015345343854278326\n",
      "Policy Loss:  0.35427120327949524\n",
      "[(0.00044, 0.27715), (0.0, 0.2769), (1.0, 0.27715)]\n",
      "Alpha*: 0.0 tau*: 0.2769 Episode: 30484 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.008994102478027344\n",
      "Value Loss:  24.953125\n",
      "Q Loss:  2.324383497238159\n",
      "Policy Loss:  -7.837032318115234\n",
      "[(0.00044, 0.2769), (0.0, 0.27665), (1.0, 0.2769)]\n",
      "Alpha*: 0.0 tau*: 0.27665 Episode: 30581 length: 64 #teleports:33\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.4817986488342285\n",
      "Q Loss:  0.11047132313251495\n",
      "Policy Loss:  -7.882453918457031\n",
      "[(0.00044, 0.27665), (0.0, 0.2764), (1.0, 0.27665)]\n",
      "Alpha*: 0.0 tau*: 0.2764 Episode: 30588 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.2169148921966553\n",
      "Q Loss:  0.07728765904903412\n",
      "Policy Loss:  -4.582979202270508\n",
      "[(0.00045, 0.2764), (0.0, 0.27615), (1.0, 0.2764)]\n",
      "Alpha*: 0.0 tau*: 0.27615 Episode: 30597 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.009001016616821289\n",
      "Value Loss:  9.616310126148164e-05\n",
      "Q Loss:  0.02126191183924675\n",
      "Policy Loss:  0.07822456955909729\n",
      "[(0.00045, 0.27615), (0.0, 0.2759), (1.0, 0.27615)]\n",
      "Alpha*: 0.0 tau*: 0.2759 Episode: 30601 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0004212300409562886\n",
      "Q Loss:  0.00029597547836601734\n",
      "Policy Loss:  0.00630171550437808\n",
      "[(0.00045, 0.2759), (0.0, 0.27565), (1.0, 0.2759)]\n",
      "Alpha*: 0.0 tau*: 0.27565 Episode: 30606 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0004765895428135991\n",
      "Q Loss:  0.013770629651844501\n",
      "Policy Loss:  0.049800023436546326\n",
      "[(0.00045, 0.27565), (0.0, 0.2754), (1.0, 0.27565)]\n",
      "Alpha*: 0.0 tau*: 0.2754 Episode: 30612 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0017163190059363842\n",
      "Q Loss:  0.011696269735693932\n",
      "Policy Loss:  0.016722355037927628\n",
      "[(0.00046, 0.2754), (0.0, 0.27515), (1.0, 0.2754)]\n",
      "Alpha*: 0.0 tau*: 0.27515 Episode: 30616 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.001589429099112749\n",
      "Q Loss:  0.004528847988694906\n",
      "Policy Loss:  0.34718871116638184\n",
      "[(0.00046, 0.27515), (0.0, 0.2749), (1.0, 0.27515)]\n",
      "Alpha*: 0.0 tau*: 0.2749 Episode: 30620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.048277497291565\n",
      "Q Loss:  4.236922264099121\n",
      "Policy Loss:  -0.16813263297080994\n",
      "[(0.00047, 0.2749), (0.0, 0.27465), (1.0, 0.2749)]\n",
      "Alpha*: 0.0 tau*: 0.27465 Episode: 30668 length: 37 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.3390382528305054\n",
      "Q Loss:  3.393467664718628\n",
      "Policy Loss:  -0.9140211939811707\n",
      "[(0.00047, 0.27465), (0.0, 0.2744), (1.0, 0.27465)]\n",
      "Alpha*: 0.0 tau*: 0.2744 Episode: 30743 length: 48 #teleports:27\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00047079651267267764\n",
      "Q Loss:  0.00073722202796489\n",
      "Policy Loss:  0.005461728200316429\n",
      "[(0.00048, 0.2744), (0.0, 0.27416), (1.0, 0.2744)]\n",
      "Alpha*: 0.0 tau*: 0.27416 Episode: 30748 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.267866849899292\n",
      "Q Loss:  0.39450201392173767\n",
      "Policy Loss:  -1.612738847732544\n",
      "[(0.00048, 0.27416), (0.0, 0.27392), (1.0, 0.27416)]\n",
      "Alpha*: 0.0 tau*: 0.27392 Episode: 30776 length: 21 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.0584492683410645\n",
      "Q Loss:  1.2674202919006348\n",
      "Policy Loss:  -6.126379013061523\n",
      "[(0.00048, 0.27392), (0.0, 0.27368), (1.0, 0.27392)]\n",
      "Alpha*: 0.0 tau*: 0.27368 Episode: 30780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  80.779541015625\n",
      "Q Loss:  112.62378692626953\n",
      "Policy Loss:  -19.3515567779541\n",
      "[(0.00049, 0.27368), (0.0, 0.27344), (1.0, 0.27368)]\n",
      "Alpha*: 0.0 tau*: 0.27344 Episode: 30864 length: 58 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  76.17598724365234\n",
      "Q Loss:  1.8466819524765015\n",
      "Policy Loss:  -20.53642463684082\n",
      "[(0.00049, 0.27344), (0.0, 0.2732), (1.0, 0.27344)]\n",
      "Alpha*: 0.0 tau*: 0.2732 Episode: 30892 length: 21 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00048485671868547797\n",
      "Q Loss:  0.00808663945645094\n",
      "Policy Loss:  0.3318879008293152\n",
      "[(0.0005, 0.2732), (0.0, 0.27296), (1.0, 0.2732)]\n",
      "Alpha*: 0.0 tau*: 0.27296 Episode: 30899 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0016315244138240814\n",
      "Q Loss:  0.008105491288006306\n",
      "Policy Loss:  0.33935171365737915\n",
      "[(0.0005, 0.27296), (0.0, 0.27272), (1.0, 0.27296)]\n",
      "Alpha*: 0.0 tau*: 0.27272 Episode: 30905 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  9.746630530571565e-05\n",
      "Q Loss:  0.0015130372485145926\n",
      "Policy Loss:  -0.021789129823446274\n",
      "[(0.00051, 0.27272), (0.0, 0.27248), (1.0, 0.27272)]\n",
      "Alpha*: 0.0 tau*: 0.27248 Episode: 30910 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03900933265686035\n",
      "Value Loss:  0.0010120505467057228\n",
      "Q Loss:  0.0006118790479376912\n",
      "Policy Loss:  0.0035504219122231007\n",
      "[(0.00051, 0.27248), (0.0, 0.27224), (1.0, 0.27248)]\n",
      "Alpha*: 0.0 tau*: 0.27224 Episode: 30914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0006996214506216347\n",
      "Q Loss:  0.007703969720751047\n",
      "Policy Loss:  0.34983325004577637\n",
      "[(0.00051, 0.27224), (0.0, 0.272), (1.0, 0.27224)]\n",
      "Alpha*: 0.0 tau*: 0.272 Episode: 30918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0177614688873291\n",
      "Value Loss:  1.4548797607421875\n",
      "Q Loss:  0.09211761504411697\n",
      "Policy Loss:  -1.5735224485397339\n",
      "[(0.00051, 0.272), (0.0, 0.27176), (1.0, 0.272)]\n",
      "Alpha*: 0.0 tau*: 0.27176 Episode: 30956 length: 31 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0002292221033712849\n",
      "Q Loss:  0.04597146436572075\n",
      "Policy Loss:  0.3899478316307068\n",
      "[(0.00051, 0.27176), (0.0, 0.27152), (1.0, 0.27176)]\n",
      "Alpha*: 0.0 tau*: 0.27152 Episode: 30960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  387.8988342285156\n",
      "Q Loss:  0.042884711176157\n",
      "Policy Loss:  -116.72118377685547\n",
      "[(0.00051, 0.27152), (0.0, 0.27128), (1.0, 0.27152)]\n",
      "Alpha*: 0.0 tau*: 0.27128 Episode: 30965 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.9073582887649536\n",
      "Q Loss:  0.014049162156879902\n",
      "Policy Loss:  -4.315767288208008\n",
      "[(0.00051, 0.27128), (0.0, 0.27104), (1.0, 0.27128)]\n",
      "Alpha*: 0.0 tau*: 0.27104 Episode: 30970 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  62.0925407409668\n",
      "Q Loss:  11.85649299621582\n",
      "Policy Loss:  -19.03928565979004\n",
      "[(0.0005, 0.27104), (0.0, 0.2708), (1.0, 0.27104)]\n",
      "Alpha*: 0.0 tau*: 0.2708 Episode: 31074 length: 75 #teleports:29\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013591766357421875\n",
      "Value Loss:  0.0014674339909106493\n",
      "Q Loss:  0.0012662227964028716\n",
      "Policy Loss:  -0.018353387713432312\n",
      "[(0.0005, 0.2708), (0.0, 0.27056), (1.0, 0.2708)]\n",
      "Alpha*: 0.0 tau*: 0.27056 Episode: 31079 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.8280492424964905\n",
      "Q Loss:  0.5724860429763794\n",
      "Policy Loss:  -0.8620583415031433\n",
      "[(0.0005, 0.27056), (0.0, 0.27032), (1.0, 0.27056)]\n",
      "Alpha*: 0.0 tau*: 0.27032 Episode: 31084 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  87.8192367553711\n",
      "Q Loss:  147.1210174560547\n",
      "Policy Loss:  -20.913602828979492\n",
      "[(0.0005, 0.27032), (0.0, 0.27008), (1.0, 0.27032)]\n",
      "Alpha*: 0.0 tau*: 0.27008 Episode: 31219 length: 105 #teleports:30\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.7771900296211243\n",
      "Q Loss:  0.5328022837638855\n",
      "Policy Loss:  -2.3769266605377197\n",
      "[(0.00049, 0.27008), (0.0, 0.26984), (1.0, 0.27008)]\n",
      "Alpha*: 0.0 tau*: 0.26984 Episode: 31224 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.8472704887390137\n",
      "Q Loss:  0.017403138801455498\n",
      "Policy Loss:  0.033937904983758926\n",
      "[(0.00049, 0.26984), (0.0, 0.2696), (1.0, 0.26984)]\n",
      "Alpha*: 0.0 tau*: 0.2696 Episode: 31241 length: 15 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0002918572863563895\n",
      "Q Loss:  0.0012887923512607813\n",
      "Policy Loss:  -0.021756794303655624\n",
      "[(0.00048, 0.2696), (0.0, 0.26936), (1.0, 0.2696)]\n",
      "Alpha*: 0.0 tau*: 0.26936 Episode: 31247 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.027005910873413086\n",
      "Value Loss:  0.001392226666212082\n",
      "Q Loss:  0.004273930098861456\n",
      "Policy Loss:  -0.034046053886413574\n",
      "[(0.00048, 0.26936), (0.0, 0.26912), (1.0, 0.26936)]\n",
      "Alpha*: 0.0 tau*: 0.26912 Episode: 31251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  88.50650024414062\n",
      "Q Loss:  217.14065551757812\n",
      "Policy Loss:  -16.21844482421875\n",
      "[(0.00048, 0.26912), (0.0, 0.26888), (1.0, 0.26912)]\n",
      "Alpha*: 0.0 tau*: 0.26888 Episode: 31319 length: 52 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00022257299860939384\n",
      "Q Loss:  0.0002693849673960358\n",
      "Policy Loss:  -0.005467674229294062\n",
      "[(0.00048, 0.26888), (0.0, 0.26864), (1.0, 0.26888)]\n",
      "Alpha*: 0.0 tau*: 0.26864 Episode: 31324 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.7072680592536926\n",
      "Q Loss:  0.4316517114639282\n",
      "Policy Loss:  -2.1071579456329346\n",
      "[(0.00048, 0.26864), (0.0, 0.2684), (1.0, 0.26864)]\n",
      "Alpha*: 0.0 tau*: 0.2684 Episode: 31328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0001868290564743802\n",
      "Q Loss:  0.005596624221652746\n",
      "Policy Loss:  -0.04151226580142975\n",
      "[(0.00047, 0.2684), (0.0, 0.26816), (1.0, 0.2684)]\n",
      "Alpha*: 0.0 tau*: 0.26816 Episode: 31333 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00021224466036073864\n",
      "Q Loss:  0.008663925342261791\n",
      "Policy Loss:  0.28027719259262085\n",
      "[(0.00047, 0.26816), (0.0, 0.26792), (1.0, 0.26816)]\n",
      "Alpha*: 0.0 tau*: 0.26792 Episode: 31340 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  376.6849365234375\n",
      "Q Loss:  0.0035875067114830017\n",
      "Policy Loss:  -111.71810150146484\n",
      "[(0.00047, 0.26792), (0.0, 0.26768), (1.0, 0.26792)]\n",
      "Alpha*: 0.0 tau*: 0.26768 Episode: 31348 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001997730869334191\n",
      "Q Loss:  0.002228342927992344\n",
      "Policy Loss:  -0.01589752919971943\n",
      "[(0.00047, 0.26768), (0.0, 0.26744), (1.0, 0.26768)]\n",
      "Alpha*: 0.0 tau*: 0.26744 Episode: 31353 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.3260211944580078\n",
      "Q Loss:  0.07134350389242172\n",
      "Policy Loss:  -3.5396645069122314\n",
      "[(0.00047, 0.26744), (0.0, 0.2672), (1.0, 0.26744)]\n",
      "Alpha*: 0.0 tau*: 0.2672 Episode: 31358 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.3102481365203857\n",
      "Q Loss:  0.10069987177848816\n",
      "Policy Loss:  -1.4700183868408203\n",
      "[(0.00046, 0.2672), (0.0, 0.26696), (1.0, 0.2672)]\n",
      "Alpha*: 0.0 tau*: 0.26696 Episode: 31409 length: 45 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03800845146179199\n",
      "Value Loss:  0.0003430141368880868\n",
      "Q Loss:  0.0012184242950752378\n",
      "Policy Loss:  -0.010220985859632492\n",
      "[(0.00046, 0.26696), (0.0, 0.26672), (1.0, 0.26696)]\n",
      "Alpha*: 0.0 tau*: 0.26672 Episode: 31415 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00024543647305108607\n",
      "Q Loss:  0.008447695523500443\n",
      "Policy Loss:  0.266083300113678\n",
      "[(0.00046, 0.26672), (0.0, 0.26648), (1.0, 0.26672)]\n",
      "Alpha*: 0.0 tau*: 0.26648 Episode: 31420 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  62.04779052734375\n",
      "Q Loss:  83.0557632446289\n",
      "Policy Loss:  -14.900578498840332\n",
      "[(0.00047, 0.26648), (0.0, 0.26624), (1.0, 0.26648)]\n",
      "Alpha*: 0.0 tau*: 0.26624 Episode: 31489 length: 49 #teleports:20\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.97061558032874e-05\n",
      "Q Loss:  0.019350435584783554\n",
      "Policy Loss:  0.29286855459213257\n",
      "[(0.00047, 0.26624), (0.0, 0.266), (1.0, 0.26624)]\n",
      "Alpha*: 0.0 tau*: 0.266 Episode: 31495 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  371.7571105957031\n",
      "Q Loss:  0.2825023829936981\n",
      "Policy Loss:  -113.06166076660156\n",
      "[(0.00047, 0.266), (0.0, 0.26576), (1.0, 0.266)]\n",
      "Alpha*: 0.0 tau*: 0.26576 Episode: 31501 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0003805318265222013\n",
      "Q Loss:  0.00037593775778077543\n",
      "Policy Loss:  -0.004447902552783489\n",
      "[(0.00047, 0.26576), (0.0, 0.26552), (1.0, 0.26576)]\n",
      "Alpha*: 0.0 tau*: 0.26552 Episode: 31507 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.8797261115396395e-05\n",
      "Q Loss:  0.00041051581501960754\n",
      "Policy Loss:  -0.006770313251763582\n",
      "[(0.00047, 0.26552), (0.0, 0.26528), (1.0, 0.26552)]\n",
      "Alpha*: 0.0 tau*: 0.26528 Episode: 31512 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  368.2371520996094\n",
      "Q Loss:  802.6434326171875\n",
      "Policy Loss:  -57.19192123413086\n",
      "[(0.00047, 0.26528), (0.0, 0.26504), (1.0, 0.26528)]\n",
      "Alpha*: 0.0 tau*: 0.26504 Episode: 31518 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.0003303191333543509\n",
      "Q Loss:  0.0004162873956374824\n",
      "Policy Loss:  -0.004381353966891766\n",
      "[(0.00047, 0.26504), (0.0, 0.2648), (1.0, 0.26504)]\n",
      "Alpha*: 0.0 tau*: 0.2648 Episode: 31523 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004600886895786971\n",
      "Q Loss:  0.003782639279961586\n",
      "Policy Loss:  0.010657153092324734\n",
      "[(0.00047, 0.2648), (0.0, 0.26456), (1.0, 0.2648)]\n",
      "Alpha*: 0.0 tau*: 0.26456 Episode: 31527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  17.015766143798828\n",
      "Q Loss:  37.17534637451172\n",
      "Policy Loss:  -4.2300944328308105\n",
      "[(0.00046, 0.26456), (0.0, 0.26432), (1.0, 0.26456)]\n",
      "Alpha*: 0.0 tau*: 0.26432 Episode: 31644 length: 89 #teleports:28\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  51.66290283203125\n",
      "Q Loss:  77.23969268798828\n",
      "Policy Loss:  -13.326643943786621\n",
      "[(0.00046, 0.26432), (0.0, 0.26408), (1.0, 0.26432)]\n",
      "Alpha*: 0.0 tau*: 0.26408 Episode: 31797 length: 114 #teleports:39\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0006961503531783819\n",
      "Q Loss:  0.0003558183088898659\n",
      "Policy Loss:  0.00023176707327365875\n",
      "[(0.00046, 0.26408), (0.0, 0.26384), (1.0, 0.26408)]\n",
      "Alpha*: 0.0 tau*: 0.26384 Episode: 31802 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0004496537731029093\n",
      "Q Loss:  0.00031233677873387933\n",
      "Policy Loss:  -0.009705688804388046\n",
      "[(0.00045, 0.26384), (0.0, 0.2636), (1.0, 0.26384)]\n",
      "Alpha*: 0.0 tau*: 0.2636 Episode: 31806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  72.02359008789062\n",
      "Q Loss:  63.058128356933594\n",
      "Policy Loss:  -19.70960235595703\n",
      "[(0.00045, 0.2636), (0.0, 0.26336), (1.0, 0.2636)]\n",
      "Alpha*: 0.0 tau*: 0.26336 Episode: 31949 length: 101 #teleports:42\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.7823601365089417\n",
      "Q Loss:  0.469963014125824\n",
      "Policy Loss:  -1.4422951936721802\n",
      "[(0.00045, 0.26336), (0.0, 0.26312), (1.0, 0.26336)]\n",
      "Alpha*: 0.0 tau*: 0.26312 Episode: 32086 length: 94 #teleports:43\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.5198917388916016\n",
      "Q Loss:  0.057687267661094666\n",
      "Policy Loss:  -3.4329171180725098\n",
      "[(0.00044, 0.26312), (0.0, 0.26288), (1.0, 0.26312)]\n",
      "Alpha*: 0.0 tau*: 0.26288 Episode: 32092 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.680010559037328e-05\n",
      "Q Loss:  0.00041177679668180645\n",
      "Policy Loss:  0.0088441027328372\n",
      "[(0.00044, 0.26288), (0.0, 0.26264), (1.0, 0.26288)]\n",
      "Alpha*: 0.0 tau*: 0.26264 Episode: 32100 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.02100539207458496\n",
      "Value Loss:  0.0002879257663153112\n",
      "Q Loss:  0.00039372380706481636\n",
      "Policy Loss:  -0.00986971240490675\n",
      "[(0.00044, 0.26264), (0.0, 0.2624), (1.0, 0.26264)]\n",
      "Alpha*: 0.0 tau*: 0.2624 Episode: 32107 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.00045984669122844934\n",
      "Q Loss:  0.0014074797509238124\n",
      "Policy Loss:  0.001049185637384653\n",
      "[(0.00044, 0.2624), (0.0, 0.26216), (1.0, 0.2624)]\n",
      "Alpha*: 0.0 tau*: 0.26216 Episode: 32111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  9574.935546875\n",
      "Q Loss:  9227.939453125\n",
      "Policy Loss:  -11.397364616394043\n",
      "[(0.00044, 0.26216), (0.0, 0.26192), (1.0, 0.26216)]\n",
      "Alpha*: 0.0 tau*: 0.26192 Episode: 32257 length: 97 #teleports:49\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  356.8712158203125\n",
      "Q Loss:  0.007376864552497864\n",
      "Policy Loss:  -107.453125\n",
      "[(0.00044, 0.26192), (0.0, 0.26168), (1.0, 0.26192)]\n",
      "Alpha*: 0.0 tau*: 0.26168 Episode: 32264 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  39.03129577636719\n",
      "Q Loss:  0.08336986601352692\n",
      "Policy Loss:  -12.407867431640625\n",
      "[(0.00044, 0.26168), (0.0, 0.26144), (1.0, 0.26168)]\n",
      "Alpha*: 0.0 tau*: 0.26144 Episode: 32316 length: 38 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00038217270048335195\n",
      "Q Loss:  0.0025985408574342728\n",
      "Policy Loss:  0.02179485559463501\n",
      "[(0.00044, 0.26144), (0.0, 0.2612), (1.0, 0.26144)]\n",
      "Alpha*: 0.0 tau*: 0.2612 Episode: 32320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005378806381486356\n",
      "Q Loss:  0.0004882297362200916\n",
      "Policy Loss:  0.010786829516291618\n",
      "[(0.00044, 0.2612), (0.0, 0.26096), (1.0, 0.2612)]\n",
      "Alpha*: 0.0 tau*: 0.26096 Episode: 32325 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  355.0302734375\n",
      "Q Loss:  191.62208557128906\n",
      "Policy Loss:  -103.03626251220703\n",
      "[(0.00044, 0.26096), (0.0, 0.26072), (1.0, 0.26096)]\n",
      "Alpha*: 0.0 tau*: 0.26072 Episode: 32330 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000246618379605934\n",
      "Q Loss:  0.0016497611068189144\n",
      "Policy Loss:  0.020968155935406685\n",
      "[(0.00044, 0.26072), (0.0, 0.26048), (1.0, 0.26072)]\n",
      "Alpha*: 0.0 tau*: 0.26048 Episode: 32334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00013978684728499502\n",
      "Q Loss:  0.0003117876185569912\n",
      "Policy Loss:  -0.00648527080193162\n",
      "[(0.00044, 0.26048), (0.0, 0.26024), (1.0, 0.26048)]\n",
      "Alpha*: 0.0 tau*: 0.26024 Episode: 32340 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00017916156502906233\n",
      "Q Loss:  0.00016593454347457737\n",
      "Policy Loss:  -0.012776345014572144\n",
      "[(0.00044, 0.26024), (0.0, 0.26), (1.0, 0.26024)]\n",
      "Alpha*: 0.0 tau*: 0.26 Episode: 32344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0003261184028815478\n",
      "Q Loss:  0.0006227606208994985\n",
      "Policy Loss:  0.002151036635041237\n",
      "[(0.00044, 0.26), (0.0, 0.25976), (1.0, 0.26)]\n",
      "Alpha*: 0.0 tau*: 0.25976 Episode: 32348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015254020690917969\n",
      "Value Loss:  0.49523067474365234\n",
      "Q Loss:  0.5644146203994751\n",
      "Policy Loss:  -1.9940999746322632\n",
      "[(0.00044, 0.25976), (0.0, 0.25952), (1.0, 0.25976)]\n",
      "Alpha*: 0.0 tau*: 0.25952 Episode: 32352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.9822680354118347\n",
      "Q Loss:  0.23182842135429382\n",
      "Policy Loss:  -5.336464881896973\n",
      "[(0.00044, 0.25952), (0.0, 0.25928), (1.0, 0.25952)]\n",
      "Alpha*: 0.0 tau*: 0.25928 Episode: 32357 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.2041828632354736\n",
      "Q Loss:  0.029398690909147263\n",
      "Policy Loss:  -0.6406419277191162\n",
      "[(0.00044, 0.25928), (0.0, 0.25904), (1.0, 0.25928)]\n",
      "Alpha*: 0.0 tau*: 0.25904 Episode: 32413 length: 45 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.47369635105133057\n",
      "Q Loss:  0.038595687597990036\n",
      "Policy Loss:  -1.998921513557434\n",
      "[(0.00044, 0.25904), (0.0, 0.2588), (1.0, 0.25904)]\n",
      "Alpha*: 0.0 tau*: 0.2588 Episode: 32418 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.04201006889343262\n",
      "Value Loss:  32050.685546875\n",
      "Q Loss:  30900.443359375\n",
      "Policy Loss:  -31.99736213684082\n",
      "[(0.00044, 0.2588), (0.0, 0.25856), (1.0, 0.2588)]\n",
      "Alpha*: 0.0 tau*: 0.25856 Episode: 32458 length: 29 #teleports:11\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011469364166259766\n",
      "Value Loss:  65.02030181884766\n",
      "Q Loss:  20.780302047729492\n",
      "Policy Loss:  -18.246938705444336\n",
      "[(0.00044, 0.25856), (0.0, 0.25832), (1.0, 0.25856)]\n",
      "Alpha*: 0.0 tau*: 0.25832 Episode: 32514 length: 44 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  24379.279296875\n",
      "Q Loss:  23467.08984375\n",
      "Policy Loss:  -8.492888450622559\n",
      "[(0.00044, 0.25832), (0.0, 0.25808), (1.0, 0.25832)]\n",
      "Alpha*: 0.0 tau*: 0.25808 Episode: 32566 length: 38 #teleports:14\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  354.424560546875\n",
      "Q Loss:  0.0005138838896527886\n",
      "Policy Loss:  -108.59542846679688\n",
      "[(0.00045, 0.25808), (0.0, 0.25784), (1.0, 0.25808)]\n",
      "Alpha*: 0.0 tau*: 0.25784 Episode: 32572 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  5.7159944844897836e-05\n",
      "Q Loss:  0.0035807082895189524\n",
      "Policy Loss:  0.022431571036577225\n",
      "[(0.00045, 0.25784), (0.0, 0.2576), (1.0, 0.25784)]\n",
      "Alpha*: 0.0 tau*: 0.2576 Episode: 32578 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  45.01639938354492\n",
      "Q Loss:  0.01596534252166748\n",
      "Policy Loss:  -13.681449890136719\n",
      "[(0.00045, 0.2576), (0.0, 0.25736), (1.0, 0.2576)]\n",
      "Alpha*: 0.0 tau*: 0.25736 Episode: 32629 length: 33 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0009807145688682795\n",
      "Q Loss:  0.001628777594305575\n",
      "Policy Loss:  0.01334063895046711\n",
      "[(0.00045, 0.25736), (0.0, 0.25712), (1.0, 0.25736)]\n",
      "Alpha*: 0.0 tau*: 0.25712 Episode: 32637 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00010578653746051714\n",
      "Q Loss:  0.0005405917763710022\n",
      "Policy Loss:  -0.000868458766490221\n",
      "[(0.00045, 0.25712), (0.0, 0.25688), (1.0, 0.25712)]\n",
      "Alpha*: 0.0 tau*: 0.25688 Episode: 32641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  79.63958740234375\n",
      "Q Loss:  108.90673065185547\n",
      "Policy Loss:  -19.003055572509766\n",
      "[(0.00045, 0.25688), (0.0, 0.25664), (1.0, 0.25688)]\n",
      "Alpha*: 0.0 tau*: 0.25664 Episode: 32692 length: 37 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.7553400034084916e-05\n",
      "Q Loss:  0.002753184176981449\n",
      "Policy Loss:  0.027532562613487244\n",
      "[(0.00045, 0.25664), (0.0, 0.2564), (1.0, 0.25664)]\n",
      "Alpha*: 0.0 tau*: 0.2564 Episode: 32696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  8.464557322440669e-05\n",
      "Q Loss:  0.0015880151186138391\n",
      "Policy Loss:  0.2293039858341217\n",
      "[(0.00045, 0.2564), (0.0, 0.25616), (1.0, 0.2564)]\n",
      "Alpha*: 0.0 tau*: 0.25616 Episode: 32700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  70.81586456298828\n",
      "Q Loss:  138.87619018554688\n",
      "Policy Loss:  -16.4638671875\n",
      "[(0.00046, 0.25616), (0.0, 0.25592), (1.0, 0.25616)]\n",
      "Alpha*: 0.0 tau*: 0.25592 Episode: 32811 length: 83 #teleports:28\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  364.16082763671875\n",
      "Q Loss:  0.0006082397885620594\n",
      "Policy Loss:  -109.7877197265625\n",
      "[(0.00046, 0.25592), (0.0, 0.25568), (1.0, 0.25592)]\n",
      "Alpha*: 0.0 tau*: 0.25568 Episode: 32817 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  728.0848999023438\n",
      "Q Loss:  829.3678588867188\n",
      "Policy Loss:  -131.30648803710938\n",
      "[(0.00046, 0.25568), (0.0, 0.25544), (1.0, 0.25568)]\n",
      "Alpha*: 0.0 tau*: 0.25544 Episode: 32824 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  3.058667425648309e-05\n",
      "Q Loss:  0.0023759896866977215\n",
      "Policy Loss:  0.010212615132331848\n",
      "[(0.00046, 0.25544), (0.0, 0.2552), (1.0, 0.25544)]\n",
      "Alpha*: 0.0 tau*: 0.2552 Episode: 32829 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0007593879709020257\n",
      "Q Loss:  0.00018574042769614607\n",
      "Policy Loss:  0.0019491792190819979\n",
      "[(0.00046, 0.2552), (0.0, 0.25496), (1.0, 0.2552)]\n",
      "Alpha*: 0.0 tau*: 0.25496 Episode: 32833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  360.6393737792969\n",
      "Q Loss:  187.22972106933594\n",
      "Policy Loss:  -103.31433868408203\n",
      "[(0.00046, 0.25496), (0.0, 0.25472), (1.0, 0.25496)]\n",
      "Alpha*: 0.0 tau*: 0.25472 Episode: 32841 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.3372517824172974\n",
      "Q Loss:  0.06632140278816223\n",
      "Policy Loss:  -0.7097584009170532\n",
      "[(0.00046, 0.25472), (0.0, 0.25448), (1.0, 0.25472)]\n",
      "Alpha*: 0.0 tau*: 0.25448 Episode: 32902 length: 39 #teleports:22\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0004739731375593692\n",
      "Q Loss:  0.03532951697707176\n",
      "Policy Loss:  0.06808213144540787\n",
      "[(0.00046, 0.25448), (0.0, 0.25424), (1.0, 0.25448)]\n",
      "Alpha*: 0.0 tau*: 0.25424 Episode: 32907 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014627456665039062\n",
      "Value Loss:  3.646141067292774e-06\n",
      "Q Loss:  0.000729682738892734\n",
      "Policy Loss:  0.004569642245769501\n",
      "[(0.00046, 0.25424), (0.0, 0.254), (1.0, 0.25424)]\n",
      "Alpha*: 0.0 tau*: 0.254 Episode: 32913 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.496801572415279e-06\n",
      "Q Loss:  0.004132643807679415\n",
      "Policy Loss:  -0.027586326003074646\n",
      "[(0.00046, 0.254), (0.0, 0.25376), (1.0, 0.254)]\n",
      "Alpha*: 0.0 tau*: 0.25376 Episode: 32917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.212159405549755e-06\n",
      "Q Loss:  0.0007590160821564496\n",
      "Policy Loss:  0.011181586422026157\n",
      "[(0.00046, 0.25376), (0.0, 0.25352), (1.0, 0.25376)]\n",
      "Alpha*: 0.0 tau*: 0.25352 Episode: 32921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.753314897243399e-06\n",
      "Q Loss:  0.035880524665117264\n",
      "Policy Loss:  0.07579067349433899\n",
      "[(0.00046, 0.25352), (0.0, 0.25328), (1.0, 0.25352)]\n",
      "Alpha*: 0.0 tau*: 0.25328 Episode: 32926 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.6655781269073486\n",
      "Q Loss:  0.12283802032470703\n",
      "Policy Loss:  -0.9249967336654663\n",
      "[(0.00046, 0.25328), (0.0, 0.25304), (1.0, 0.25328)]\n",
      "Alpha*: 0.0 tau*: 0.25304 Episode: 32965 length: 32 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1544389724731445\n",
      "Q Loss:  0.5403252840042114\n",
      "Policy Loss:  -3.552156925201416\n",
      "[(0.00046, 0.25304), (0.0, 0.2528), (1.0, 0.25304)]\n",
      "Alpha*: 0.0 tau*: 0.2528 Episode: 32970 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  118.29698181152344\n",
      "Q Loss:  169.66204833984375\n",
      "Policy Loss:  -27.679311752319336\n",
      "[(0.00046, 0.2528), (0.0, 0.25256), (1.0, 0.2528)]\n",
      "Alpha*: 0.0 tau*: 0.25256 Episode: 33034 length: 48 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.5763000249862671\n",
      "Q Loss:  0.036254096776247025\n",
      "Policy Loss:  -2.3453214168548584\n",
      "[(0.00046, 0.25256), (0.0, 0.25232), (1.0, 0.25256)]\n",
      "Alpha*: 0.0 tau*: 0.25232 Episode: 33042 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.1454843282699585\n",
      "Q Loss:  0.07441159337759018\n",
      "Policy Loss:  -5.805820941925049\n",
      "[(0.00046, 0.25232), (0.0, 0.25208), (1.0, 0.25232)]\n",
      "Alpha*: 0.0 tau*: 0.25208 Episode: 33047 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.4318638932309113e-05\n",
      "Q Loss:  0.00039936802932061255\n",
      "Policy Loss:  -0.002412884496152401\n",
      "[(0.00045, 0.25208), (0.0, 0.25184), (1.0, 0.25208)]\n",
      "Alpha*: 0.0 tau*: 0.25184 Episode: 33051 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  42.46914291381836\n",
      "Q Loss:  3.872776746749878\n",
      "Policy Loss:  -12.437332153320312\n",
      "[(0.00045, 0.25184), (0.0, 0.2516), (1.0, 0.25184)]\n",
      "Alpha*: 0.0 tau*: 0.2516 Episode: 33146 length: 67 #teleports:28\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  16.10871696472168\n",
      "Q Loss:  54.49989318847656\n",
      "Policy Loss:  -3.7548296451568604\n",
      "[(0.00045, 0.2516), (0.0, 0.25136), (1.0, 0.2516)]\n",
      "Alpha*: 0.0 tau*: 0.25136 Episode: 33261 length: 90 #teleports:25\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.5987097615143284e-05\n",
      "Q Loss:  0.0010808740044012666\n",
      "Policy Loss:  -0.0032896441407501698\n",
      "[(0.00045, 0.25136), (0.0, 0.25112), (1.0, 0.25136)]\n",
      "Alpha*: 0.0 tau*: 0.25112 Episode: 33266 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  7.176132203312591e-05\n",
      "Q Loss:  0.0018304247641935945\n",
      "Policy Loss:  0.020318109542131424\n",
      "[(0.00045, 0.25112), (0.0, 0.25088), (1.0, 0.25112)]\n",
      "Alpha*: 0.0 tau*: 0.25088 Episode: 33270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400090217590332\n",
      "Value Loss:  30943.6875\n",
      "Q Loss:  29637.51171875\n",
      "Policy Loss:  -23.516324996948242\n",
      "[(0.00045, 0.25088), (0.0, 0.25064), (1.0, 0.25088)]\n",
      "Alpha*: 0.0 tau*: 0.25064 Episode: 33312 length: 30 #teleports:12\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00013611390022560954\n",
      "Q Loss:  0.0013033038703724742\n",
      "Policy Loss:  0.24209687113761902\n",
      "[(0.00045, 0.25064), (0.0, 0.2504), (1.0, 0.25064)]\n",
      "Alpha*: 0.0 tau*: 0.2504 Episode: 33316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00012321793474256992\n",
      "Q Loss:  0.004859227687120438\n",
      "Policy Loss:  0.02473900094628334\n",
      "[(0.00045, 0.2504), (0.0, 0.25016), (1.0, 0.2504)]\n",
      "Alpha*: 0.0 tau*: 0.25016 Episode: 33324 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.0009522359032417e-06\n",
      "Q Loss:  0.00122991728130728\n",
      "Policy Loss:  0.2344474494457245\n",
      "[(0.00045, 0.25016), (0.0, 0.24992), (1.0, 0.25016)]\n",
      "Alpha*: 0.0 tau*: 0.24992 Episode: 33329 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00016527020488865674\n",
      "Q Loss:  0.0007234709337353706\n",
      "Policy Loss:  0.015667609870433807\n",
      "[(0.00045, 0.24992), (0.0, 0.24968), (1.0, 0.24992)]\n",
      "Alpha*: 0.0 tau*: 0.24968 Episode: 33334 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.109107976546511e-05\n",
      "Q Loss:  0.0001466629619244486\n",
      "Policy Loss:  0.0005308986874297261\n",
      "[(0.00045, 0.24968), (0.0, 0.24944), (1.0, 0.24968)]\n",
      "Alpha*: 0.0 tau*: 0.24944 Episode: 33339 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  7.49843311496079e-05\n",
      "Q Loss:  0.0005312064895406365\n",
      "Policy Loss:  0.009498318657279015\n",
      "[(0.00045, 0.24944), (0.0, 0.2492), (1.0, 0.24944)]\n",
      "Alpha*: 0.0 tau*: 0.2492 Episode: 33344 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.401656042318791e-05\n",
      "Q Loss:  0.017565833404660225\n",
      "Policy Loss:  0.04886958748102188\n",
      "[(0.00045, 0.2492), (0.0, 0.24896), (1.0, 0.2492)]\n",
      "Alpha*: 0.0 tau*: 0.24896 Episode: 33350 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.3788416001480073e-05\n",
      "Q Loss:  0.016616731882095337\n",
      "Policy Loss:  0.28178268671035767\n",
      "[(0.00045, 0.24896), (0.0, 0.24872), (1.0, 0.24896)]\n",
      "Alpha*: 0.0 tau*: 0.24872 Episode: 33358 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  37.00295639038086\n",
      "Q Loss:  1.3761557340621948\n",
      "Policy Loss:  -11.408788681030273\n",
      "[(0.00045, 0.24872), (0.0, 0.24848), (1.0, 0.24872)]\n",
      "Alpha*: 0.0 tau*: 0.24848 Episode: 33406 length: 40 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  711.6708984375\n",
      "Q Loss:  190.13174438476562\n",
      "Policy Loss:  -194.4989013671875\n",
      "[(0.00045, 0.24848), (0.0, 0.24824), (1.0, 0.24848)]\n",
      "Alpha*: 0.0 tau*: 0.24824 Episode: 33411 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.031006813049316406\n",
      "Value Loss:  355.684326171875\n",
      "Q Loss:  0.24027258157730103\n",
      "Policy Loss:  -108.944580078125\n",
      "[(0.00045, 0.24824), (0.0, 0.24801), (1.0, 0.24824)]\n",
      "Alpha*: 0.0 tau*: 0.24801 Episode: 33417 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  80.50518035888672\n",
      "Q Loss:  50.429534912109375\n",
      "Policy Loss:  -22.36901092529297\n",
      "[(0.00045, 0.24801), (0.0, 0.24778), (1.0, 0.24801)]\n",
      "Alpha*: 0.0 tau*: 0.24778 Episode: 33514 length: 71 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0007361710886470973\n",
      "Q Loss:  0.019737977534532547\n",
      "Policy Loss:  0.07470212131738663\n",
      "[(0.00045, 0.24778), (0.0, 0.24755), (1.0, 0.24778)]\n",
      "Alpha*: 0.0 tau*: 0.24755 Episode: 33519 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  351.73309326171875\n",
      "Q Loss:  0.0016898884205147624\n",
      "Policy Loss:  -106.51531219482422\n",
      "[(0.00045, 0.24755), (0.0, 0.24732), (1.0, 0.24755)]\n",
      "Alpha*: 0.0 tau*: 0.24732 Episode: 33525 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0005088805919513106\n",
      "Q Loss:  0.0002550556091591716\n",
      "Policy Loss:  0.0040608663111925125\n",
      "[(0.00045, 0.24732), (0.0, 0.24709), (1.0, 0.24732)]\n",
      "Alpha*: 0.0 tau*: 0.24709 Episode: 33531 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.5315814018249512\n",
      "Q Loss:  0.03510257601737976\n",
      "Policy Loss:  -2.268078565597534\n",
      "[(0.00045, 0.24709), (0.0, 0.24686), (1.0, 0.24709)]\n",
      "Alpha*: 0.0 tau*: 0.24686 Episode: 33535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  69.28874206542969\n",
      "Q Loss:  128.32057189941406\n",
      "Policy Loss:  -15.515050888061523\n",
      "[(0.00045, 0.24686), (0.0, 0.24663), (1.0, 0.24686)]\n",
      "Alpha*: 0.0 tau*: 0.24663 Episode: 33612 length: 61 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.751345452154055e-05\n",
      "Q Loss:  0.0008946768357418478\n",
      "Policy Loss:  0.23777645826339722\n",
      "[(0.00045, 0.24663), (0.0, 0.2464), (1.0, 0.24663)]\n",
      "Alpha*: 0.0 tau*: 0.2464 Episode: 33618 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  345.3940734863281\n",
      "Q Loss:  28.636432647705078\n",
      "Policy Loss:  -93.9029312133789\n",
      "[(0.00045, 0.2464), (0.0, 0.24617), (1.0, 0.2464)]\n",
      "Alpha*: 0.0 tau*: 0.24617 Episode: 33623 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  343.8936767578125\n",
      "Q Loss:  872.6970825195312\n",
      "Policy Loss:  -50.342140197753906\n",
      "[(0.00045, 0.24617), (0.0, 0.24594), (1.0, 0.24617)]\n",
      "Alpha*: 0.0 tau*: 0.24594 Episode: 33630 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.234403266105801e-05\n",
      "Q Loss:  0.0004011584387626499\n",
      "Policy Loss:  -0.013572224415838718\n",
      "[(0.00045, 0.24594), (0.0, 0.24571), (1.0, 0.24594)]\n",
      "Alpha*: 0.0 tau*: 0.24571 Episode: 33634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  3.391233258298598e-05\n",
      "Q Loss:  0.0004193581407889724\n",
      "Policy Loss:  -0.01099688932299614\n",
      "[(0.00045, 0.24571), (0.0, 0.24548), (1.0, 0.24571)]\n",
      "Alpha*: 0.0 tau*: 0.24548 Episode: 33638 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  5.6897246395237744e-05\n",
      "Q Loss:  0.00032976249349303544\n",
      "Policy Loss:  -0.009588171727955341\n",
      "[(0.00045, 0.24548), (0.0, 0.24525), (1.0, 0.24548)]\n",
      "Alpha*: 0.0 tau*: 0.24525 Episode: 33643 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.165522790979594e-05\n",
      "Q Loss:  0.0003747064620256424\n",
      "Policy Loss:  -0.010145639069378376\n",
      "[(0.00044, 0.24525), (0.0, 0.24502), (1.0, 0.24525)]\n",
      "Alpha*: 0.0 tau*: 0.24502 Episode: 33647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  29936.6171875\n",
      "Q Loss:  28604.197265625\n",
      "Policy Loss:  -10.158440589904785\n",
      "[(0.00044, 0.24502), (0.0, 0.24479), (1.0, 0.24502)]\n",
      "Alpha*: 0.0 tau*: 0.24479 Episode: 33693 length: 31 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01107025146484375\n",
      "Value Loss:  4.386712680570781e-05\n",
      "Q Loss:  0.001134357531554997\n",
      "Policy Loss:  -0.014208541251718998\n",
      "[(0.00044, 0.24479), (0.0, 0.24456), (1.0, 0.24479)]\n",
      "Alpha*: 0.0 tau*: 0.24456 Episode: 33697 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.870825068792328e-05\n",
      "Q Loss:  0.0013779968721792102\n",
      "Policy Loss:  -0.012963928282260895\n",
      "[(0.00044, 0.24456), (0.0, 0.24433), (1.0, 0.24456)]\n",
      "Alpha*: 0.0 tau*: 0.24433 Episode: 33701 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.8260172510053962e-05\n",
      "Q Loss:  0.0006614207522943616\n",
      "Policy Loss:  -0.009030099958181381\n",
      "[(0.00044, 0.24433), (0.0, 0.2441), (1.0, 0.24433)]\n",
      "Alpha*: 0.0 tau*: 0.2441 Episode: 33706 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00011560438724700361\n",
      "Q Loss:  0.0007120642112568021\n",
      "Policy Loss:  0.21597185730934143\n",
      "[(0.00044, 0.2441), (0.0, 0.24387), (1.0, 0.2441)]\n",
      "Alpha*: 0.0 tau*: 0.24387 Episode: 33711 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  34.487998962402344\n",
      "Q Loss:  2.630953550338745\n",
      "Policy Loss:  -10.43007755279541\n",
      "[(0.00044, 0.24387), (0.0, 0.24364), (1.0, 0.24387)]\n",
      "Alpha*: 0.0 tau*: 0.24364 Episode: 33765 length: 41 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  4.319533036323264e-05\n",
      "Q Loss:  0.00010891402780544013\n",
      "Policy Loss:  -0.005248542875051498\n",
      "[(0.00044, 0.24364), (0.0, 0.24341), (1.0, 0.24364)]\n",
      "Alpha*: 0.0 tau*: 0.24341 Episode: 33772 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  16892.220703125\n",
      "Q Loss:  16107.8515625\n",
      "Policy Loss:  -12.203339576721191\n",
      "[(0.00044, 0.24341), (0.0, 0.24318), (1.0, 0.24341)]\n",
      "Alpha*: 0.0 tau*: 0.24318 Episode: 33853 length: 55 #teleports:26\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.941904540421092e-06\n",
      "Q Loss:  0.0017148804618045688\n",
      "Policy Loss:  0.02067289501428604\n",
      "[(0.00044, 0.24318), (0.0, 0.24295), (1.0, 0.24318)]\n",
      "Alpha*: 0.0 tau*: 0.24295 Episode: 33857 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  9.503515684627928e-06\n",
      "Q Loss:  0.0006594259175471961\n",
      "Policy Loss:  -0.00783940963447094\n",
      "[(0.00044, 0.24295), (0.0, 0.24272), (1.0, 0.24295)]\n",
      "Alpha*: 0.0 tau*: 0.24272 Episode: 33861 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.5479770302772522\n",
      "Q Loss:  0.6295238137245178\n",
      "Policy Loss:  -2.464057445526123\n",
      "[(0.00044, 0.24272), (0.0, 0.24249), (1.0, 0.24272)]\n",
      "Alpha*: 0.0 tau*: 0.24249 Episode: 33865 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  66430.5\n",
      "Q Loss:  63256.05078125\n",
      "Policy Loss:  -49.49021530151367\n",
      "[(0.00045, 0.24249), (0.0, 0.24226), (1.0, 0.24249)]\n",
      "Alpha*: 0.0 tau*: 0.24226 Episode: 33883 length: 14 #teleports:4\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.553669810295105\n",
      "Q Loss:  0.1644783318042755\n",
      "Policy Loss:  -3.511570453643799\n",
      "[(0.00045, 0.24226), (0.0, 0.24203), (1.0, 0.24226)]\n",
      "Alpha*: 0.0 tau*: 0.24203 Episode: 33888 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  351.60162353515625\n",
      "Q Loss:  13.257330894470215\n",
      "Policy Loss:  -102.06975555419922\n",
      "[(0.00045, 0.24203), (0.0, 0.2418), (1.0, 0.24203)]\n",
      "Alpha*: 0.0 tau*: 0.2418 Episode: 33893 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  354.5626220703125\n",
      "Q Loss:  913.42529296875\n",
      "Policy Loss:  -57.150821685791016\n",
      "[(0.00045, 0.2418), (0.0, 0.24157), (1.0, 0.2418)]\n",
      "Alpha*: 0.0 tau*: 0.24157 Episode: 33898 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.5322834921535105e-05\n",
      "Q Loss:  0.0025277351960539818\n",
      "Policy Loss:  0.01694759912788868\n",
      "[(0.00045, 0.24157), (0.0, 0.24134), (1.0, 0.24157)]\n",
      "Alpha*: 0.0 tau*: 0.24134 Episode: 33902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00014344550436362624\n",
      "Q Loss:  0.0002686919760890305\n",
      "Policy Loss:  0.007524465210735798\n",
      "[(0.00045, 0.24134), (0.0, 0.24111), (1.0, 0.24134)]\n",
      "Alpha*: 0.0 tau*: 0.24111 Episode: 33906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  9.029910142999142e-05\n",
      "Q Loss:  0.00013088108971714973\n",
      "Policy Loss:  -0.005312455352395773\n",
      "[(0.00045, 0.24111), (0.0, 0.24088), (1.0, 0.24111)]\n",
      "Alpha*: 0.0 tau*: 0.24088 Episode: 33910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  3.572912828531116e-05\n",
      "Q Loss:  0.004751288332045078\n",
      "Policy Loss:  0.02403593435883522\n",
      "[(0.00045, 0.24088), (0.0, 0.24065), (1.0, 0.24088)]\n",
      "Alpha*: 0.0 tau*: 0.24065 Episode: 33914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  363.4062805175781\n",
      "Q Loss:  942.3826293945312\n",
      "Policy Loss:  -56.568363189697266\n",
      "[(0.00045, 0.24065), (0.0, 0.24042), (1.0, 0.24065)]\n",
      "Alpha*: 0.0 tau*: 0.24042 Episode: 33922 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.479338768869638e-05\n",
      "Q Loss:  0.0008216891437768936\n",
      "Policy Loss:  -0.00032279291190207005\n",
      "[(0.00045, 0.24042), (0.0, 0.24019), (1.0, 0.24042)]\n",
      "Alpha*: 0.0 tau*: 0.24019 Episode: 33928 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  364.7908935546875\n",
      "Q Loss:  0.0028058558236807585\n",
      "Policy Loss:  -109.90486907958984\n",
      "[(0.00046, 0.24019), (0.0, 0.23996), (1.0, 0.24019)]\n",
      "Alpha*: 0.0 tau*: 0.23996 Episode: 33934 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  364.8207092285156\n",
      "Q Loss:  1143.6707763671875\n",
      "Policy Loss:  -45.44211959838867\n",
      "[(0.00045, 0.23996), (0.0, 0.23973), (1.0, 0.23996)]\n",
      "Alpha*: 0.0 tau*: 0.23973 Episode: 33939 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.00017651579400990158\n",
      "Q Loss:  0.004356552846729755\n",
      "Policy Loss:  0.020743582397699356\n",
      "[(0.00045, 0.23973), (0.0, 0.2395), (1.0, 0.23973)]\n",
      "Alpha*: 0.0 tau*: 0.2395 Episode: 33944 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00014377658953890204\n",
      "Q Loss:  0.00585011625662446\n",
      "Policy Loss:  0.023799177259206772\n",
      "[(0.00045, 0.2395), (0.0, 0.23927), (1.0, 0.2395)]\n",
      "Alpha*: 0.0 tau*: 0.23927 Episode: 33948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.5622568130493164\n",
      "Q Loss:  0.11232900619506836\n",
      "Policy Loss:  -2.583467483520508\n",
      "[(0.00045, 0.23927), (0.0, 0.23904), (1.0, 0.23927)]\n",
      "Alpha*: 0.0 tau*: 0.23904 Episode: 33953 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0003500355815049261\n",
      "Q Loss:  1.8924682080978528e-05\n",
      "Policy Loss:  0.003484236542135477\n",
      "[(0.00045, 0.23904), (0.0, 0.23881), (1.0, 0.23904)]\n",
      "Alpha*: 0.0 tau*: 0.23881 Episode: 33957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.5540075302124023\n",
      "Q Loss:  0.10647652298212051\n",
      "Policy Loss:  -2.3464269638061523\n",
      "[(0.00044, 0.23881), (0.0, 0.23858), (1.0, 0.23881)]\n",
      "Alpha*: 0.0 tau*: 0.23858 Episode: 33961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  2.736373517109314e-06\n",
      "Q Loss:  0.00018381800327915698\n",
      "Policy Loss:  0.0004725177423097193\n",
      "[(0.00044, 0.23858), (0.0, 0.23835), (1.0, 0.23858)]\n",
      "Alpha*: 0.0 tau*: 0.23835 Episode: 33967 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  362.53973388671875\n",
      "Q Loss:  937.8225708007812\n",
      "Policy Loss:  -16.995941162109375\n",
      "[(0.00044, 0.23835), (0.0, 0.23812), (1.0, 0.23835)]\n",
      "Alpha*: 0.0 tau*: 0.23812 Episode: 33973 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  361.1795959472656\n",
      "Q Loss:  935.3838500976562\n",
      "Policy Loss:  -56.77686309814453\n",
      "[(0.00045, 0.23812), (0.0, 0.23789), (1.0, 0.23812)]\n",
      "Alpha*: 0.0 tau*: 0.23789 Episode: 33978 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.003945899661630392\n",
      "Q Loss:  26.735939025878906\n",
      "Policy Loss:  2.5076375007629395\n",
      "[(0.00045, 0.23789), (0.0, 0.23766), (1.0, 0.23789)]\n",
      "Alpha*: 0.0 tau*: 0.23766 Episode: 33982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0003587176906876266\n",
      "Q Loss:  0.005318138748407364\n",
      "Policy Loss:  -0.019041696563363075\n",
      "[(0.00045, 0.23766), (0.0, 0.23743), (1.0, 0.23766)]\n",
      "Alpha*: 0.0 tau*: 0.23743 Episode: 33987 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  99.73136138916016\n",
      "Q Loss:  141.74539184570312\n",
      "Policy Loss:  -23.0305118560791\n",
      "[(0.00045, 0.23743), (0.0, 0.2372), (1.0, 0.23743)]\n",
      "Alpha*: 0.0 tau*: 0.2372 Episode: 34071 length: 58 #teleports:26\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00029247032944113016\n",
      "Q Loss:  0.006557980552315712\n",
      "Policy Loss:  0.20661801099777222\n",
      "[(0.00045, 0.2372), (0.0, 0.23697), (1.0, 0.2372)]\n",
      "Alpha*: 0.0 tau*: 0.23697 Episode: 34079 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  104.46598052978516\n",
      "Q Loss:  213.42103576660156\n",
      "Policy Loss:  -22.914506912231445\n",
      "[(0.00044, 0.23697), (0.0, 0.23674), (1.0, 0.23697)]\n",
      "Alpha*: 0.0 tau*: 0.23674 Episode: 34154 length: 55 #teleports:20\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  2.3917418729979545e-05\n",
      "Q Loss:  0.0003559800097718835\n",
      "Policy Loss:  0.0008521832060068846\n",
      "[(0.00044, 0.23674), (0.0, 0.23651), (1.0, 0.23674)]\n",
      "Alpha*: 0.0 tau*: 0.23651 Episode: 34158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.032733002328314e-05\n",
      "Q Loss:  0.00018771288159769028\n",
      "Policy Loss:  -0.004196016117930412\n",
      "[(0.00044, 0.23651), (0.0, 0.23628), (1.0, 0.23651)]\n",
      "Alpha*: 0.0 tau*: 0.23628 Episode: 34162 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100396156311035\n",
      "Value Loss:  64.99372863769531\n",
      "Q Loss:  67.49581146240234\n",
      "Policy Loss:  -17.641450881958008\n",
      "[(0.00044, 0.23628), (0.0, 0.23605), (1.0, 0.23628)]\n",
      "Alpha*: 0.0 tau*: 0.23605 Episode: 34244 length: 66 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  351.9470520019531\n",
      "Q Loss:  27.104318618774414\n",
      "Policy Loss:  -94.39359283447266\n",
      "[(0.00044, 0.23605), (0.0, 0.23582), (1.0, 0.23605)]\n",
      "Alpha*: 0.0 tau*: 0.23582 Episode: 34251 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  13296.400390625\n",
      "Q Loss:  12695.4296875\n",
      "Policy Loss:  -20.72549057006836\n",
      "[(0.00044, 0.23582), (0.0, 0.23559), (1.0, 0.23582)]\n",
      "Alpha*: 0.0 tau*: 0.23559 Episode: 34337 length: 70 #teleports:16\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.9763048887252808\n",
      "Q Loss:  0.1999056190252304\n",
      "Policy Loss:  -1.7462859153747559\n",
      "[(0.00044, 0.23559), (0.0, 0.23536), (1.0, 0.23559)]\n",
      "Alpha*: 0.0 tau*: 0.23536 Episode: 34343 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  96.64317321777344\n",
      "Q Loss:  126.66441345214844\n",
      "Policy Loss:  -25.13192367553711\n",
      "[(0.00043, 0.23536), (0.0, 0.23513), (1.0, 0.23536)]\n",
      "Alpha*: 0.0 tau*: 0.23513 Episode: 34478 length: 102 #teleports:33\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00021177831513341516\n",
      "Q Loss:  0.0001789844100130722\n",
      "Policy Loss:  -0.008765541017055511\n",
      "[(0.00043, 0.23513), (0.0, 0.2349), (1.0, 0.23513)]\n",
      "Alpha*: 0.0 tau*: 0.2349 Episode: 34482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  53.657752990722656\n",
      "Q Loss:  1.9471412897109985\n",
      "Policy Loss:  -16.10733985900879\n",
      "[(0.00043, 0.2349), (0.0, 0.23467), (1.0, 0.2349)]\n",
      "Alpha*: 0.0 tau*: 0.23467 Episode: 34550 length: 53 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  348.1588134765625\n",
      "Q Loss:  12.764188766479492\n",
      "Policy Loss:  -101.10865020751953\n",
      "[(0.00042, 0.23467), (0.0, 0.23444), (1.0, 0.23467)]\n",
      "Alpha*: 0.0 tau*: 0.23444 Episode: 34556 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  347.1661682128906\n",
      "Q Loss:  185.81736755371094\n",
      "Policy Loss:  -94.87427520751953\n",
      "[(0.00042, 0.23444), (0.0, 0.23421), (1.0, 0.23444)]\n",
      "Alpha*: 0.0 tau*: 0.23421 Episode: 34561 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  345.7519836425781\n",
      "Q Loss:  0.00020985447918064892\n",
      "Policy Loss:  -106.73422241210938\n",
      "[(0.00041, 0.23421), (0.0, 0.23398), (1.0, 0.23421)]\n",
      "Alpha*: 0.0 tau*: 0.23398 Episode: 34568 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00016424103523604572\n",
      "Q Loss:  6.701475649606436e-05\n",
      "Policy Loss:  0.005606738850474358\n",
      "[(0.00041, 0.23398), (0.0, 0.23375), (1.0, 0.23398)]\n",
      "Alpha*: 0.0 tau*: 0.23375 Episode: 34574 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.8046571211889386e-05\n",
      "Q Loss:  0.004235825967043638\n",
      "Policy Loss:  0.021791625767946243\n",
      "[(0.00041, 0.23375), (0.0, 0.23352), (1.0, 0.23375)]\n",
      "Alpha*: 0.0 tau*: 0.23352 Episode: 34578 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0003338124370202422\n",
      "Q Loss:  0.0005492512136697769\n",
      "Policy Loss:  0.012977443635463715\n",
      "[(0.00041, 0.23352), (0.0, 0.23329), (1.0, 0.23352)]\n",
      "Alpha*: 0.0 tau*: 0.23329 Episode: 34582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5.7523197028785944e-05\n",
      "Q Loss:  0.00261968863196671\n",
      "Policy Loss:  0.017541998997330666\n",
      "[(0.0004, 0.23329), (0.0, 0.23306), (1.0, 0.23329)]\n",
      "Alpha*: 0.0 tau*: 0.23306 Episode: 34587 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00010691604256862774\n",
      "Q Loss:  0.0012166413944214582\n",
      "Policy Loss:  0.009614791721105576\n",
      "[(0.0004, 0.23306), (0.0, 0.23283), (1.0, 0.23306)]\n",
      "Alpha*: 0.0 tau*: 0.23283 Episode: 34592 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.46379104256629944\n",
      "Q Loss:  0.0600004643201828\n",
      "Policy Loss:  -2.180402994155884\n",
      "[(0.0004, 0.23283), (0.0, 0.2326), (1.0, 0.23283)]\n",
      "Alpha*: 0.0 tau*: 0.2326 Episode: 34598 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  40.07643508911133\n",
      "Q Loss:  23.45380401611328\n",
      "Policy Loss:  -10.435714721679688\n",
      "[(0.0004, 0.2326), (0.0, 0.23237), (1.0, 0.2326)]\n",
      "Alpha*: 0.0 tau*: 0.23237 Episode: 34646 length: 35 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.936691998911556e-05\n",
      "Q Loss:  0.020322147756814957\n",
      "Policy Loss:  0.04412493482232094\n",
      "[(0.0004, 0.23237), (0.0, 0.23214), (1.0, 0.23237)]\n",
      "Alpha*: 0.0 tau*: 0.23214 Episode: 34650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.9177744388580322\n",
      "Q Loss:  0.10371308028697968\n",
      "Policy Loss:  -3.4255759716033936\n",
      "[(0.0004, 0.23214), (0.0, 0.23191), (1.0, 0.23214)]\n",
      "Alpha*: 0.0 tau*: 0.23191 Episode: 34655 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.040009498596191406\n",
      "Value Loss:  0.4516442120075226\n",
      "Q Loss:  0.0470566563308239\n",
      "Policy Loss:  -0.9932291507720947\n",
      "[(0.0004, 0.23191), (0.0, 0.23168), (1.0, 0.23191)]\n",
      "Alpha*: 0.0 tau*: 0.23168 Episode: 34660 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  4.145922660827637\n",
      "Q Loss:  0.011503986082971096\n",
      "Policy Loss:  2.1588592529296875\n",
      "[(0.00041, 0.23168), (0.0, 0.23145), (1.0, 0.23168)]\n",
      "Alpha*: 0.0 tau*: 0.23145 Episode: 34677 length: 13 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.2473679817048833e-05\n",
      "Q Loss:  0.00019834632985293865\n",
      "Policy Loss:  -0.0016795361880213022\n",
      "[(0.00041, 0.23145), (0.0, 0.23122), (1.0, 0.23145)]\n",
      "Alpha*: 0.0 tau*: 0.23122 Episode: 34682 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  0.0003799390105996281\n",
      "Q Loss:  13.235308647155762\n",
      "Policy Loss:  1.2413370609283447\n",
      "[(0.00041, 0.23122), (0.0, 0.23099), (1.0, 0.23122)]\n",
      "Alpha*: 0.0 tau*: 0.23099 Episode: 34688 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0010273419320583344\n",
      "Q Loss:  0.00032406128593720496\n",
      "Policy Loss:  -0.0006051487289369106\n",
      "[(0.00041, 0.23099), (0.0, 0.23076), (1.0, 0.23099)]\n",
      "Alpha*: 0.0 tau*: 0.23076 Episode: 34693 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  331.2734680175781\n",
      "Q Loss:  0.024866165593266487\n",
      "Policy Loss:  -104.43312072753906\n",
      "[(0.00041, 0.23076), (0.0, 0.23053), (1.0, 0.23076)]\n",
      "Alpha*: 0.0 tau*: 0.23053 Episode: 34700 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.4524882733821869\n",
      "Q Loss:  0.1925193816423416\n",
      "Policy Loss:  -2.082552194595337\n",
      "[(0.00042, 0.23053), (0.0, 0.2303), (1.0, 0.23053)]\n",
      "Alpha*: 0.0 tau*: 0.2303 Episode: 34705 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.0871303857129533e-05\n",
      "Q Loss:  0.03933718055486679\n",
      "Policy Loss:  0.07354584336280823\n",
      "[(0.00042, 0.2303), (0.0, 0.23007), (1.0, 0.2303)]\n",
      "Alpha*: 0.0 tau*: 0.23007 Episode: 34710 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  4.200339026283473e-05\n",
      "Q Loss:  0.00034685918944887817\n",
      "Policy Loss:  -0.007332032546401024\n",
      "[(0.00042, 0.23007), (0.0, 0.22984), (1.0, 0.23007)]\n",
      "Alpha*: 0.0 tau*: 0.22984 Episode: 34715 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  67.03093719482422\n",
      "Q Loss:  109.531005859375\n",
      "Policy Loss:  -15.3687162399292\n",
      "[(0.00042, 0.22984), (0.0, 0.22961), (1.0, 0.22984)]\n",
      "Alpha*: 0.0 tau*: 0.22961 Episode: 34766 length: 40 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0290067195892334\n",
      "Value Loss:  34.228477478027344\n",
      "Q Loss:  106.89786529541016\n",
      "Policy Loss:  -5.858909606933594\n",
      "[(0.00042, 0.22961), (0.0, 0.22938), (1.0, 0.22961)]\n",
      "Alpha*: 0.0 tau*: 0.22938 Episode: 34814 length: 40 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00010356269922340289\n",
      "Q Loss:  0.00026869287830777466\n",
      "Policy Loss:  -0.0023214106913655996\n",
      "[(0.00042, 0.22938), (0.0, 0.22915), (1.0, 0.22938)]\n",
      "Alpha*: 0.0 tau*: 0.22915 Episode: 34818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.050445103435777e-06\n",
      "Q Loss:  0.00011626975174294785\n",
      "Policy Loss:  0.21279898285865784\n",
      "[(0.00042, 0.22915), (0.0, 0.22892), (1.0, 0.22915)]\n",
      "Alpha*: 0.0 tau*: 0.22892 Episode: 34824 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0001829417742555961\n",
      "Q Loss:  0.0010771631496027112\n",
      "Policy Loss:  0.01301987748593092\n",
      "[(0.00042, 0.22892), (0.0, 0.22869), (1.0, 0.22892)]\n",
      "Alpha*: 0.0 tau*: 0.22869 Episode: 34831 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.925404260167852e-06\n",
      "Q Loss:  0.0002342755178688094\n",
      "Policy Loss:  0.0007068642880767584\n",
      "[(0.00042, 0.22869), (0.0, 0.22846), (1.0, 0.22869)]\n",
      "Alpha*: 0.0 tau*: 0.22846 Episode: 34835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  7.444988295901567e-05\n",
      "Q Loss:  0.0006374194053933024\n",
      "Policy Loss:  0.0017670691013336182\n",
      "[(0.00043, 0.22846), (0.0, 0.22823), (1.0, 0.22846)]\n",
      "Alpha*: 0.0 tau*: 0.22823 Episode: 34842 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.6977373838453786e-06\n",
      "Q Loss:  0.0027176837902516127\n",
      "Policy Loss:  -0.02191341295838356\n",
      "[(0.00043, 0.22823), (0.0, 0.228), (1.0, 0.22823)]\n",
      "Alpha*: 0.0 tau*: 0.228 Episode: 34847 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  324.0619201660156\n",
      "Q Loss:  891.4490356445312\n",
      "Policy Loss:  -52.79637908935547\n",
      "[(0.00042, 0.228), (0.0, 0.22777), (1.0, 0.228)]\n",
      "Alpha*: 0.0 tau*: 0.22777 Episode: 34853 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.2283771866350435e-05\n",
      "Q Loss:  0.0002881099935621023\n",
      "Policy Loss:  0.20862776041030884\n",
      "[(0.00042, 0.22777), (0.0, 0.22754), (1.0, 0.22777)]\n",
      "Alpha*: 0.0 tau*: 0.22754 Episode: 34857 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  8735.208984375\n",
      "Q Loss:  8273.4453125\n",
      "Policy Loss:  -18.076387405395508\n",
      "[(0.00042, 0.22754), (0.0, 0.22731), (1.0, 0.22754)]\n",
      "Alpha*: 0.0 tau*: 0.22731 Episode: 34995 length: 107 #teleports:31\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  5.332697128324071e-06\n",
      "Q Loss:  1.909468301164452e-05\n",
      "Policy Loss:  -0.0021015829406678677\n",
      "[(0.00042, 0.22731), (0.0, 0.22708), (1.0, 0.22731)]\n",
      "Alpha*: 0.0 tau*: 0.22708 Episode: 35002 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.9566720128059387\n",
      "Q Loss:  0.2108439803123474\n",
      "Policy Loss:  -5.425498962402344\n",
      "[(0.00042, 0.22708), (0.0, 0.22685), (1.0, 0.22708)]\n",
      "Alpha*: 0.0 tau*: 0.22685 Episode: 35010 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.7854428026330424e-06\n",
      "Q Loss:  0.00012124938075430691\n",
      "Policy Loss:  -0.005270164459943771\n",
      "[(0.00042, 0.22685), (0.0, 0.22662), (1.0, 0.22685)]\n",
      "Alpha*: 0.0 tau*: 0.22662 Episode: 35015 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  18.682308197021484\n",
      "Q Loss:  60.78734588623047\n",
      "Policy Loss:  -3.9684200286865234\n",
      "[(0.00042, 0.22662), (0.0, 0.22639), (1.0, 0.22662)]\n",
      "Alpha*: 0.0 tau*: 0.22639 Episode: 35100 length: 72 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  1.8952587197418325e-05\n",
      "Q Loss:  0.005699935369193554\n",
      "Policy Loss:  0.034037135541439056\n",
      "[(0.00042, 0.22639), (0.0, 0.22616), (1.0, 0.22639)]\n",
      "Alpha*: 0.0 tau*: 0.22616 Episode: 35105 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.2592149687407073e-05\n",
      "Q Loss:  0.00010613768972689286\n",
      "Policy Loss:  0.00048189720837399364\n",
      "[(0.00041, 0.22616), (0.0, 0.22593), (1.0, 0.22616)]\n",
      "Alpha*: 0.0 tau*: 0.22593 Episode: 35109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  1.7217849745065905e-05\n",
      "Q Loss:  3.831903813988902e-05\n",
      "Policy Loss:  0.21223093569278717\n",
      "[(0.00041, 0.22593), (0.0, 0.2257), (1.0, 0.22593)]\n",
      "Alpha*: 0.0 tau*: 0.2257 Episode: 35115 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  6.950525403226493e-06\n",
      "Q Loss:  0.0020497962832450867\n",
      "Policy Loss:  0.022351376712322235\n",
      "[(0.00041, 0.2257), (0.0, 0.22547), (1.0, 0.2257)]\n",
      "Alpha*: 0.0 tau*: 0.22547 Episode: 35120 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  4.688594344770536e-06\n",
      "Q Loss:  0.0006126436637714505\n",
      "Policy Loss:  0.007123691961169243\n",
      "[(0.00041, 0.22547), (0.0, 0.22524), (1.0, 0.22547)]\n",
      "Alpha*: 0.0 tau*: 0.22524 Episode: 35124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  6.125357231212547e-06\n",
      "Q Loss:  0.0005613726680167019\n",
      "Policy Loss:  0.005878747440874577\n",
      "[(0.00041, 0.22524), (0.0, 0.22501), (1.0, 0.22524)]\n",
      "Alpha*: 0.0 tau*: 0.22501 Episode: 35130 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.8040058612823486\n",
      "Q Loss:  0.034268736839294434\n",
      "Policy Loss:  0.06270259618759155\n",
      "[(0.00041, 0.22501), (0.0, 0.22478), (1.0, 0.22501)]\n",
      "Alpha*: 0.0 tau*: 0.22478 Episode: 35154 length: 21 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1.0080295396619476e-05\n",
      "Q Loss:  2.884652894863393e-05\n",
      "Policy Loss:  0.2141285091638565\n",
      "[(0.00041, 0.22478), (0.0, 0.22455), (1.0, 0.22478)]\n",
      "Alpha*: 0.0 tau*: 0.22455 Episode: 35159 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.45836707949638367\n",
      "Q Loss:  0.058108873665332794\n",
      "Policy Loss:  -2.2002551555633545\n",
      "[(0.00041, 0.22455), (0.0, 0.22432), (1.0, 0.22455)]\n",
      "Alpha*: 0.0 tau*: 0.22432 Episode: 35163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  40.9321403503418\n",
      "Q Loss:  15.449484825134277\n",
      "Policy Loss:  -11.771282196044922\n",
      "[(0.00041, 0.22432), (0.0, 0.22409), (1.0, 0.22432)]\n",
      "Alpha*: 0.0 tau*: 0.22409 Episode: 35249 length: 64 #teleports:22\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.8217766561720055e-06\n",
      "Q Loss:  0.0027602699119597673\n",
      "Policy Loss:  -0.01971295475959778\n",
      "[(0.00041, 0.22409), (0.0, 0.22386), (1.0, 0.22409)]\n",
      "Alpha*: 0.0 tau*: 0.22386 Episode: 35253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  9.17919896892272e-06\n",
      "Q Loss:  8.052227349253371e-05\n",
      "Policy Loss:  -0.0021229840349406004\n",
      "[(0.00041, 0.22386), (0.0, 0.22363), (1.0, 0.22386)]\n",
      "Alpha*: 0.0 tau*: 0.22363 Episode: 35257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.4148889931675512e-05\n",
      "Q Loss:  4.32962151535321e-05\n",
      "Policy Loss:  0.0009985866490751505\n",
      "[(0.0004, 0.22363), (0.0, 0.2234), (1.0, 0.22363)]\n",
      "Alpha*: 0.0 tau*: 0.2234 Episode: 35261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  4.1205606976291165e-05\n",
      "Q Loss:  25.731473922729492\n",
      "Policy Loss:  2.4800186157226562\n",
      "[(0.00041, 0.2234), (0.0, 0.22317), (1.0, 0.2234)]\n",
      "Alpha*: 0.0 tau*: 0.22317 Episode: 35266 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  6.706437034154078e-06\n",
      "Q Loss:  0.0006703926483169198\n",
      "Policy Loss:  0.01679082214832306\n",
      "[(0.00041, 0.22317), (0.0, 0.22294), (1.0, 0.22317)]\n",
      "Alpha*: 0.0 tau*: 0.22294 Episode: 35275 length: 4 #teleports:5\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.46432629227638245\n",
      "Q Loss:  0.056007400155067444\n",
      "Policy Loss:  -2.1877994537353516\n",
      "[(0.00041, 0.22294), (0.0, 0.22271), (1.0, 0.22294)]\n",
      "Alpha*: 0.0 tau*: 0.22271 Episode: 35282 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  320.5153503417969\n",
      "Q Loss:  0.20691192150115967\n",
      "Policy Loss:  -104.92584991455078\n",
      "[(0.00041, 0.22271), (0.0, 0.22249), (1.0, 0.22271)]\n",
      "Alpha*: 0.0 tau*: 0.22249 Episode: 35288 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  5.442015753942542e-05\n",
      "Q Loss:  0.001283080317080021\n",
      "Policy Loss:  0.013781208544969559\n",
      "[(0.00041, 0.22249), (0.0, 0.22227), (1.0, 0.22249)]\n",
      "Alpha*: 0.0 tau*: 0.22227 Episode: 35293 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  318.5523986816406\n",
      "Q Loss:  0.003626891877502203\n",
      "Policy Loss:  -102.65953826904297\n",
      "[(0.00041, 0.22227), (0.0, 0.22205), (1.0, 0.22227)]\n",
      "Alpha*: 0.0 tau*: 0.22205 Episode: 35298 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.9130133043508977e-05\n",
      "Q Loss:  0.0001604195567779243\n",
      "Policy Loss:  0.001958014676347375\n",
      "[(0.00041, 0.22205), (0.0, 0.22183), (1.0, 0.22205)]\n",
      "Alpha*: 0.0 tau*: 0.22183 Episode: 35304 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  71.60303497314453\n",
      "Q Loss:  143.76031494140625\n",
      "Policy Loss:  -15.208480834960938\n",
      "[(0.00041, 0.22183), (0.0, 0.22161), (1.0, 0.22183)]\n",
      "Alpha*: 0.0 tau*: 0.22161 Episode: 35374 length: 54 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0400087833404541\n",
      "Value Loss:  19432.015625\n",
      "Q Loss:  18512.17578125\n",
      "Policy Loss:  -17.71118927001953\n",
      "[(0.0004, 0.22161), (0.0, 0.22139), (1.0, 0.22161)]\n",
      "Alpha*: 0.0 tau*: 0.22139 Episode: 35437 length: 48 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  3.5432447475614026e-05\n",
      "Q Loss:  0.0001869263796834275\n",
      "Policy Loss:  -0.0030574577394872904\n",
      "[(0.0004, 0.22139), (0.0, 0.22117), (1.0, 0.22139)]\n",
      "Alpha*: 0.0 tau*: 0.22117 Episode: 35441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  1.080292122423998e-06\n",
      "Q Loss:  0.00020083258277736604\n",
      "Policy Loss:  -0.004648067057132721\n",
      "[(0.0004, 0.22117), (0.0, 0.22095), (1.0, 0.22117)]\n",
      "Alpha*: 0.0 tau*: 0.22095 Episode: 35448 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.6953850717982277e-05\n",
      "Q Loss:  0.0006148886168375611\n",
      "Policy Loss:  -0.012788433581590652\n",
      "[(0.0004, 0.22095), (0.0, 0.22073), (1.0, 0.22095)]\n",
      "Alpha*: 0.0 tau*: 0.22073 Episode: 35452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  20.153310775756836\n",
      "Q Loss:  0.751965343952179\n",
      "Policy Loss:  -7.013437747955322\n",
      "[(0.00039, 0.22073), (0.0, 0.22051), (1.0, 0.22073)]\n",
      "Alpha*: 0.0 tau*: 0.22051 Episode: 35528 length: 66 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  316.7834777832031\n",
      "Q Loss:  888.231689453125\n",
      "Policy Loss:  -51.76736068725586\n",
      "[(0.00039, 0.22051), (0.0, 0.22029), (1.0, 0.22051)]\n",
      "Alpha*: 0.0 tau*: 0.22029 Episode: 35533 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  7.090880535542965e-05\n",
      "Q Loss:  0.0001464968518121168\n",
      "Policy Loss:  -0.003876243019476533\n",
      "[(0.00039, 0.22029), (0.0, 0.22007), (1.0, 0.22029)]\n",
      "Alpha*: 0.0 tau*: 0.22007 Episode: 35537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.413343220949173\n",
      "Q Loss:  0.14995259046554565\n",
      "Policy Loss:  -2.0107715129852295\n",
      "[(0.00039, 0.22007), (0.0, 0.21985), (1.0, 0.22007)]\n",
      "Alpha*: 0.0 tau*: 0.21985 Episode: 35541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  21398.390625\n",
      "Q Loss:  20340.205078125\n",
      "Policy Loss:  -12.24718189239502\n",
      "[(0.00038, 0.21985), (0.0, 0.21963), (1.0, 0.21985)]\n",
      "Alpha*: 0.0 tau*: 0.21963 Episode: 35653 length: 87 #teleports:25\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  5.741716449847445e-05\n",
      "Q Loss:  0.00017354426381643862\n",
      "Policy Loss:  -0.0062725236639380455\n",
      "[(0.00038, 0.21963), (0.0, 0.21941), (1.0, 0.21963)]\n",
      "Alpha*: 0.0 tau*: 0.21941 Episode: 35658 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  35.85734558105469\n",
      "Q Loss:  17.16165542602539\n",
      "Policy Loss:  -11.081894874572754\n",
      "[(0.00038, 0.21941), (0.0, 0.21919), (1.0, 0.21941)]\n",
      "Alpha*: 0.0 tau*: 0.21919 Episode: 35709 length: 37 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  9.0830035333056e-06\n",
      "Q Loss:  0.0008534146472811699\n",
      "Policy Loss:  -0.012091854587197304\n",
      "[(0.00038, 0.21919), (0.0, 0.21897), (1.0, 0.21919)]\n",
      "Alpha*: 0.0 tau*: 0.21897 Episode: 35715 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  318.60467529296875\n",
      "Q Loss:  12.067018508911133\n",
      "Policy Loss:  -96.65597534179688\n",
      "[(0.00038, 0.21897), (0.0, 0.21875), (1.0, 0.21897)]\n",
      "Alpha*: 0.0 tau*: 0.21875 Episode: 35720 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.7218735218048096\n",
      "Q Loss:  0.0163729228079319\n",
      "Policy Loss:  -0.9617769718170166\n",
      "[(0.00039, 0.21875), (0.0, 0.21853), (1.0, 0.21875)]\n",
      "Alpha*: 0.0 tau*: 0.21853 Episode: 35764 length: 35 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.8276444673538208\n",
      "Q Loss:  0.17753930389881134\n",
      "Policy Loss:  -5.184310436248779\n",
      "[(0.00039, 0.21853), (0.0, 0.21831), (1.0, 0.21853)]\n",
      "Alpha*: 0.0 tau*: 0.21831 Episode: 35769 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.41135042905807495\n",
      "Q Loss:  0.1296360045671463\n",
      "Policy Loss:  -2.0765738487243652\n",
      "[(0.00039, 0.21831), (0.0, 0.21809), (1.0, 0.21831)]\n",
      "Alpha*: 0.0 tau*: 0.21809 Episode: 35773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  13151.095703125\n",
      "Q Loss:  12517.7724609375\n",
      "Policy Loss:  -18.763612747192383\n",
      "[(0.00039, 0.21809), (0.0, 0.21787), (1.0, 0.21809)]\n",
      "Alpha*: 0.0 tau*: 0.21787 Episode: 35854 length: 71 #teleports:10\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00011585188622120768\n",
      "Q Loss:  5.8940317103406414e-05\n",
      "Policy Loss:  0.0026401083450764418\n",
      "[(0.00039, 0.21787), (0.0, 0.21765), (1.0, 0.21787)]\n",
      "Alpha*: 0.0 tau*: 0.21765 Episode: 35859 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  5.134733146405779e-05\n",
      "Q Loss:  0.00014515116345137358\n",
      "Policy Loss:  -0.006113155744969845\n",
      "[(0.00039, 0.21765), (0.0, 0.21743), (1.0, 0.21765)]\n",
      "Alpha*: 0.0 tau*: 0.21743 Episode: 35863 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.711827260616701e-06\n",
      "Q Loss:  0.0009105389472097158\n",
      "Policy Loss:  0.2038365751504898\n",
      "[(0.00039, 0.21743), (0.0, 0.21721), (1.0, 0.21743)]\n",
      "Alpha*: 0.0 tau*: 0.21721 Episode: 35867 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  55.97027587890625\n",
      "Q Loss:  92.18578338623047\n",
      "Policy Loss:  -13.67146110534668\n",
      "[(0.00039, 0.21721), (0.0, 0.21699), (1.0, 0.21721)]\n",
      "Alpha*: 0.0 tau*: 0.21699 Episode: 35925 length: 47 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.5989251136779785\n",
      "Q Loss:  16.574981689453125\n",
      "Policy Loss:  -0.5549042820930481\n",
      "[(0.00039, 0.21699), (0.0, 0.21677), (1.0, 0.21699)]\n",
      "Alpha*: 0.0 tau*: 0.21677 Episode: 35979 length: 39 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  7.878865915245115e-08\n",
      "Q Loss:  0.0003551577392499894\n",
      "Policy Loss:  0.00779490452259779\n",
      "[(0.0004, 0.21677), (0.0, 0.21655), (1.0, 0.21677)]\n",
      "Alpha*: 0.0 tau*: 0.21655 Episode: 35983 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.00015478068962693214\n",
      "Q Loss:  0.00041755923302844167\n",
      "Policy Loss:  0.0031390604563057423\n",
      "[(0.0004, 0.21655), (0.0, 0.21633), (1.0, 0.21655)]\n",
      "Alpha*: 0.0 tau*: 0.21633 Episode: 35991 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.399105379590765e-05\n",
      "Q Loss:  6.374045915436e-05\n",
      "Policy Loss:  -0.004573462065309286\n",
      "[(0.0004, 0.21633), (0.0, 0.21611), (1.0, 0.21633)]\n",
      "Alpha*: 0.0 tau*: 0.21611 Episode: 35995 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.507196307182312\n",
      "Q Loss:  0.008010183461010456\n",
      "Policy Loss:  -0.6240341663360596\n",
      "[(0.0004, 0.21611), (0.0, 0.21589), (1.0, 0.21611)]\n",
      "Alpha*: 0.0 tau*: 0.21589 Episode: 36040 length: 38 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  37.48045349121094\n",
      "Q Loss:  0.05820464342832565\n",
      "Policy Loss:  -12.356536865234375\n",
      "[(0.0004, 0.21589), (0.0, 0.21567), (1.0, 0.21589)]\n",
      "Alpha*: 0.0 tau*: 0.21567 Episode: 36082 length: 36 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  2.0027238178954576e-07\n",
      "Q Loss:  0.00043733062921091914\n",
      "Policy Loss:  0.006576293148100376\n",
      "[(0.0004, 0.21567), (0.0, 0.21545), (1.0, 0.21567)]\n",
      "Alpha*: 0.0 tau*: 0.21545 Episode: 36086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  322.88739013671875\n",
      "Q Loss:  954.956298828125\n",
      "Policy Loss:  -34.414878845214844\n",
      "[(0.0004, 0.21545), (0.0, 0.21523), (1.0, 0.21545)]\n",
      "Alpha*: 0.0 tau*: 0.21523 Episode: 36093 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  322.5030822753906\n",
      "Q Loss:  173.35040283203125\n",
      "Policy Loss:  -91.77008819580078\n",
      "[(0.00039, 0.21523), (0.0, 0.21501), (1.0, 0.21523)]\n",
      "Alpha*: 0.0 tau*: 0.21501 Episode: 36098 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  7.101945084286854e-05\n",
      "Q Loss:  0.0003012120723724365\n",
      "Policy Loss:  0.20213288068771362\n",
      "[(0.00039, 0.21501), (0.0, 0.21479), (1.0, 0.21501)]\n",
      "Alpha*: 0.0 tau*: 0.21479 Episode: 36103 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00019288843031972647\n",
      "Q Loss:  0.00010677406680770218\n",
      "Policy Loss:  0.00665518082678318\n",
      "[(0.00039, 0.21479), (0.0, 0.21457), (1.0, 0.21479)]\n",
      "Alpha*: 0.0 tau*: 0.21457 Episode: 36109 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  5.272191992844455e-05\n",
      "Q Loss:  6.814985681558028e-05\n",
      "Policy Loss:  0.0032667918130755424\n",
      "[(0.00039, 0.21457), (0.0, 0.21435), (1.0, 0.21457)]\n",
      "Alpha*: 0.0 tau*: 0.21435 Episode: 36114 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  5.1598730351543054e-05\n",
      "Q Loss:  0.00034416571725159883\n",
      "Policy Loss:  0.002658004406839609\n",
      "[(0.00039, 0.21435), (0.0, 0.21413), (1.0, 0.21435)]\n",
      "Alpha*: 0.0 tau*: 0.21413 Episode: 36119 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.1202053428860381e-05\n",
      "Q Loss:  2.4939556169556454e-05\n",
      "Policy Loss:  -0.0019416154827922583\n",
      "[(0.00039, 0.21413), (0.0, 0.21391), (1.0, 0.21413)]\n",
      "Alpha*: 0.0 tau*: 0.21391 Episode: 36124 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.972297695829184e-06\n",
      "Q Loss:  0.0013000728795304894\n",
      "Policy Loss:  -0.01706250011920929\n",
      "[(0.00039, 0.21391), (0.0, 0.21369), (1.0, 0.21391)]\n",
      "Alpha*: 0.0 tau*: 0.21369 Episode: 36129 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.7312584077444626e-06\n",
      "Q Loss:  0.00018400646513327956\n",
      "Policy Loss:  4.367608926258981e-05\n",
      "[(0.00038, 0.21369), (0.0, 0.21347), (1.0, 0.21369)]\n",
      "Alpha*: 0.0 tau*: 0.21347 Episode: 36135 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  317.7579345703125\n",
      "Q Loss:  11.813424110412598\n",
      "Policy Loss:  -96.63848876953125\n",
      "[(0.00038, 0.21347), (0.0, 0.21325), (1.0, 0.21347)]\n",
      "Alpha*: 0.0 tau*: 0.21325 Episode: 36141 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.2127665286243428e-05\n",
      "Q Loss:  4.0124428778653964e-05\n",
      "Policy Loss:  0.0027767422143369913\n",
      "[(0.00038, 0.21325), (0.0, 0.21303), (1.0, 0.21325)]\n",
      "Alpha*: 0.0 tau*: 0.21303 Episode: 36145 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  3.9017155359033495e-05\n",
      "Q Loss:  0.00023554611834697425\n",
      "Policy Loss:  0.004481469746679068\n",
      "[(0.00038, 0.21303), (0.0, 0.21281), (1.0, 0.21303)]\n",
      "Alpha*: 0.0 tau*: 0.21281 Episode: 36149 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011295318603515625\n",
      "Value Loss:  2.4344733901671134e-05\n",
      "Q Loss:  4.182705015409738e-05\n",
      "Policy Loss:  0.002597728744149208\n",
      "[(0.00038, 0.21281), (0.0, 0.21259), (1.0, 0.21281)]\n",
      "Alpha*: 0.0 tau*: 0.21259 Episode: 36156 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.76753310370259e-05\n",
      "Q Loss:  1.5510373486904427e-05\n",
      "Policy Loss:  -0.0029818452894687653\n",
      "[(0.00038, 0.21259), (0.0, 0.21237), (1.0, 0.21259)]\n",
      "Alpha*: 0.0 tau*: 0.21237 Episode: 36160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  6.656508048763499e-05\n",
      "Q Loss:  0.00010244246368529275\n",
      "Policy Loss:  1.4653895050287247e-05\n",
      "[(0.00038, 0.21237), (0.0, 0.21215), (1.0, 0.21237)]\n",
      "Alpha*: 0.0 tau*: 0.21215 Episode: 36165 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  1.7658492652117275e-05\n",
      "Q Loss:  5.2777839300688356e-05\n",
      "Policy Loss:  0.0006179905030876398\n",
      "[(0.00038, 0.21215), (0.0, 0.21193), (1.0, 0.21215)]\n",
      "Alpha*: 0.0 tau*: 0.21193 Episode: 36171 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  313.3758544921875\n",
      "Q Loss:  0.003069022437557578\n",
      "Policy Loss:  -101.70384979248047\n",
      "[(0.00038, 0.21193), (0.0, 0.21171), (1.0, 0.21193)]\n",
      "Alpha*: 0.0 tau*: 0.21171 Episode: 36177 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  3.839417695417069e-05\n",
      "Q Loss:  167.48268127441406\n",
      "Policy Loss:  2.37148380279541\n",
      "[(0.00038, 0.21171), (0.0, 0.21149), (1.0, 0.21171)]\n",
      "Alpha*: 0.0 tau*: 0.21149 Episode: 36182 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.6428216844797134e-05\n",
      "Q Loss:  3.679327346617356e-05\n",
      "Policy Loss:  0.003232839284464717\n",
      "[(0.00038, 0.21149), (0.0, 0.21127), (1.0, 0.21149)]\n",
      "Alpha*: 0.0 tau*: 0.21127 Episode: 36187 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.4370723874890245e-05\n",
      "Q Loss:  9.962583862943575e-05\n",
      "Policy Loss:  -0.004664421081542969\n",
      "[(0.00038, 0.21127), (0.0, 0.21105), (1.0, 0.21127)]\n",
      "Alpha*: 0.0 tau*: 0.21105 Episode: 36193 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.6615925889927894e-05\n",
      "Q Loss:  5.645895726047456e-05\n",
      "Policy Loss:  -0.0008629988878965378\n",
      "[(0.00038, 0.21105), (0.0, 0.21083), (1.0, 0.21105)]\n",
      "Alpha*: 0.0 tau*: 0.21083 Episode: 36198 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  39.63439178466797\n",
      "Q Loss:  114.60274505615234\n",
      "Policy Loss:  -8.797079086303711\n",
      "[(0.00038, 0.21083), (0.0, 0.21061), (1.0, 0.21083)]\n",
      "Alpha*: 0.0 tau*: 0.21061 Episode: 36282 length: 64 #teleports:20\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  8.382328815059736e-06\n",
      "Q Loss:  0.0001392463454976678\n",
      "Policy Loss:  0.0051972344517707825\n",
      "[(0.00038, 0.21061), (0.0, 0.21039), (1.0, 0.21061)]\n",
      "Alpha*: 0.0 tau*: 0.21039 Episode: 36288 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.634337074094219e-06\n",
      "Q Loss:  0.0009881359292194247\n",
      "Policy Loss:  0.012817611917853355\n",
      "[(0.00038, 0.21039), (0.0, 0.21017), (1.0, 0.21039)]\n",
      "Alpha*: 0.0 tau*: 0.21017 Episode: 36293 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.403099410410505e-06\n",
      "Q Loss:  0.0001543575490359217\n",
      "Policy Loss:  -0.0002735340385697782\n",
      "[(0.00038, 0.21017), (0.0, 0.20995), (1.0, 0.21017)]\n",
      "Alpha*: 0.0 tau*: 0.20995 Episode: 36298 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4693854609504342e-05\n",
      "Q Loss:  0.00010440284677315503\n",
      "Policy Loss:  0.0020990173798054457\n",
      "[(0.00037, 0.20995), (0.0, 0.20973), (1.0, 0.20995)]\n",
      "Alpha*: 0.0 tau*: 0.20973 Episode: 36304 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  6.696333002764732e-05\n",
      "Q Loss:  0.00012106501526432112\n",
      "Policy Loss:  0.003999650478363037\n",
      "[(0.00037, 0.20973), (0.0, 0.20951), (1.0, 0.20973)]\n",
      "Alpha*: 0.0 tau*: 0.20951 Episode: 36309 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  2.3208558559417725e-05\n",
      "Q Loss:  1.3113609384163283e-05\n",
      "Policy Loss:  0.0008633448742330074\n",
      "[(0.00037, 0.20951), (0.0, 0.20929), (1.0, 0.20951)]\n",
      "Alpha*: 0.0 tau*: 0.20929 Episode: 36314 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.8493887991062365e-06\n",
      "Q Loss:  0.0017078043892979622\n",
      "Policy Loss:  0.20699650049209595\n",
      "[(0.00037, 0.20929), (0.0, 0.20907), (1.0, 0.20929)]\n",
      "Alpha*: 0.0 tau*: 0.20907 Episode: 36320 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.911389740096638e-06\n",
      "Q Loss:  7.393148553092033e-05\n",
      "Policy Loss:  0.0012522239703685045\n",
      "[(0.00037, 0.20907), (0.0, 0.20885), (1.0, 0.20907)]\n",
      "Alpha*: 0.0 tau*: 0.20885 Episode: 36327 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.8228623705217615e-06\n",
      "Q Loss:  5.771855649072677e-05\n",
      "Policy Loss:  0.003988546319305897\n",
      "[(0.00037, 0.20885), (0.0, 0.20863), (1.0, 0.20885)]\n",
      "Alpha*: 0.0 tau*: 0.20863 Episode: 36331 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.4770621419302188e-05\n",
      "Q Loss:  4.092576273251325e-05\n",
      "Policy Loss:  0.0006394239608198404\n",
      "[(0.00037, 0.20863), (0.0, 0.20841), (1.0, 0.20863)]\n",
      "Alpha*: 0.0 tau*: 0.20841 Episode: 36336 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.068410700914683e-06\n",
      "Q Loss:  9.76567534962669e-05\n",
      "Policy Loss:  0.006704888306558132\n",
      "[(0.00037, 0.20841), (0.0, 0.20819), (1.0, 0.20841)]\n",
      "Alpha*: 0.0 tau*: 0.20819 Episode: 36341 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  9.674577086116187e-06\n",
      "Q Loss:  2.1346029825508595e-05\n",
      "Policy Loss:  0.0002643025363795459\n",
      "[(0.00037, 0.20819), (0.0, 0.20797), (1.0, 0.20819)]\n",
      "Alpha*: 0.0 tau*: 0.20797 Episode: 36345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.0358143299527e-05\n",
      "Q Loss:  0.3655948340892792\n",
      "Policy Loss:  0.22290822863578796\n",
      "[(0.00037, 0.20797), (0.0, 0.20775), (1.0, 0.20797)]\n",
      "Alpha*: 0.0 tau*: 0.20775 Episode: 36350 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  18262.2734375\n",
      "Q Loss:  17324.728515625\n",
      "Policy Loss:  -6.261067867279053\n",
      "[(0.00037, 0.20775), (0.0, 0.20753), (1.0, 0.20775)]\n",
      "Alpha*: 0.0 tau*: 0.20753 Episode: 36415 length: 51 #teleports:14\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.0520022846758366e-05\n",
      "Q Loss:  8.07557808002457e-05\n",
      "Policy Loss:  0.0018248516134917736\n",
      "[(0.00037, 0.20753), (0.0, 0.20731), (1.0, 0.20753)]\n",
      "Alpha*: 0.0 tau*: 0.20731 Episode: 36420 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.3316047443368006e-05\n",
      "Q Loss:  6.807095815020148e-06\n",
      "Policy Loss:  0.0008285460062325001\n",
      "[(0.00037, 0.20731), (0.0, 0.20709), (1.0, 0.20731)]\n",
      "Alpha*: 0.0 tau*: 0.20709 Episode: 36425 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.5304689441109076e-05\n",
      "Q Loss:  5.8619771152734756e-05\n",
      "Policy Loss:  0.0028322110883891582\n",
      "[(0.00037, 0.20709), (0.0, 0.20687), (1.0, 0.20709)]\n",
      "Alpha*: 0.0 tau*: 0.20687 Episode: 36429 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  66592.1640625\n",
      "Q Loss:  63375.0703125\n",
      "Policy Loss:  -14.615408897399902\n",
      "[(0.00038, 0.20687), (0.0, 0.20665), (1.0, 0.20687)]\n",
      "Alpha*: 0.0 tau*: 0.20665 Episode: 36445 length: 14 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.00018027510668616742\n",
      "Q Loss:  12.25004768371582\n",
      "Policy Loss:  1.2039473056793213\n",
      "[(0.00038, 0.20665), (0.0, 0.20643), (1.0, 0.20665)]\n",
      "Alpha*: 0.0 tau*: 0.20643 Episode: 36450 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  9.09657173906453e-05\n",
      "Q Loss:  0.0005120651330798864\n",
      "Policy Loss:  -0.002937507349997759\n",
      "[(0.00038, 0.20643), (0.0, 0.20621), (1.0, 0.20643)]\n",
      "Alpha*: 0.0 tau*: 0.20621 Episode: 36455 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.029006481170654297\n",
      "Value Loss:  0.0006322296103462577\n",
      "Q Loss:  4.399782119435258e-05\n",
      "Policy Loss:  -0.005394500680267811\n",
      "[(0.00039, 0.20621), (0.0, 0.20599), (1.0, 0.20621)]\n",
      "Alpha*: 0.0 tau*: 0.20599 Episode: 36461 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  65.55158996582031\n",
      "Q Loss:  115.67684173583984\n",
      "Policy Loss:  -15.298585891723633\n",
      "[(0.00039, 0.20599), (0.0, 0.20577), (1.0, 0.20599)]\n",
      "Alpha*: 0.0 tau*: 0.20577 Episode: 36515 length: 40 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.00013294599193613976\n",
      "Q Loss:  0.0002945902815554291\n",
      "Policy Loss:  0.009281915612518787\n",
      "[(0.00039, 0.20577), (0.0, 0.20555), (1.0, 0.20577)]\n",
      "Alpha*: 0.0 tau*: 0.20555 Episode: 36521 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01700115203857422\n",
      "Value Loss:  37.02748489379883\n",
      "Q Loss:  122.91254425048828\n",
      "Policy Loss:  -4.426671028137207\n",
      "[(0.00039, 0.20555), (0.0, 0.20533), (1.0, 0.20555)]\n",
      "Alpha*: 0.0 tau*: 0.20533 Episode: 36567 length: 37 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  2.2967822587816045e-05\n",
      "Q Loss:  0.0006305604474619031\n",
      "Policy Loss:  0.004940461367368698\n",
      "[(0.00039, 0.20533), (0.0, 0.20511), (1.0, 0.20533)]\n",
      "Alpha*: 0.0 tau*: 0.20511 Episode: 36571 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  6.525992648676038e-05\n",
      "Q Loss:  0.0006543423514813185\n",
      "Policy Loss:  0.010028926655650139\n",
      "[(0.00039, 0.20511), (0.0, 0.20489), (1.0, 0.20511)]\n",
      "Alpha*: 0.0 tau*: 0.20489 Episode: 36575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.8612927198410034\n",
      "Q Loss:  0.026741549372673035\n",
      "Policy Loss:  -1.1592111587524414\n",
      "[(0.0004, 0.20489), (0.0, 0.20467), (1.0, 0.20489)]\n",
      "Alpha*: 0.0 tau*: 0.20467 Episode: 36652 length: 64 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.1947882175445557\n",
      "Q Loss:  0.24970784783363342\n",
      "Policy Loss:  -4.676914691925049\n",
      "[(0.0004, 0.20467), (0.0, 0.20445), (1.0, 0.20467)]\n",
      "Alpha*: 0.0 tau*: 0.20445 Episode: 36657 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.00017403211677446961\n",
      "Q Loss:  0.0003618237969931215\n",
      "Policy Loss:  0.013964076526463032\n",
      "[(0.0004, 0.20445), (0.0, 0.20423), (1.0, 0.20445)]\n",
      "Alpha*: 0.0 tau*: 0.20423 Episode: 36661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  3.407792974030599e-05\n",
      "Q Loss:  0.04305620491504669\n",
      "Policy Loss:  0.2879983186721802\n",
      "[(0.0004, 0.20423), (0.0, 0.20401), (1.0, 0.20423)]\n",
      "Alpha*: 0.0 tau*: 0.20401 Episode: 36666 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  29041.30078125\n",
      "Q Loss:  27567.65625\n",
      "Policy Loss:  -13.44909381866455\n",
      "[(0.0004, 0.20401), (0.0, 0.20379), (1.0, 0.20401)]\n",
      "Alpha*: 0.0 tau*: 0.20379 Episode: 36705 length: 32 #teleports:7\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  339.4433288574219\n",
      "Q Loss:  995.9796752929688\n",
      "Policy Loss:  -52.60205841064453\n",
      "[(0.00039, 0.20379), (0.0, 0.20357), (1.0, 0.20379)]\n",
      "Alpha*: 0.0 tau*: 0.20357 Episode: 36711 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.09130960481707e-05\n",
      "Q Loss:  0.07210858166217804\n",
      "Policy Loss:  0.13018274307250977\n",
      "[(0.00038, 0.20357), (0.0, 0.20335), (1.0, 0.20357)]\n",
      "Alpha*: 0.0 tau*: 0.20335 Episode: 36715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  2.8621343517443165e-05\n",
      "Q Loss:  0.035003285855054855\n",
      "Policy Loss:  0.2835547924041748\n",
      "[(0.00038, 0.20335), (0.0, 0.20313), (1.0, 0.20335)]\n",
      "Alpha*: 0.0 tau*: 0.20313 Episode: 36720 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.519144254620187e-05\n",
      "Q Loss:  0.00022051266569178551\n",
      "Policy Loss:  0.0003329527098685503\n",
      "[(0.00037, 0.20313), (0.0, 0.20291), (1.0, 0.20313)]\n",
      "Alpha*: 0.0 tau*: 0.20291 Episode: 36724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.415621151565574e-05\n",
      "Q Loss:  0.0002775890752673149\n",
      "Policy Loss:  0.0005081441486254334\n",
      "[(0.00037, 0.20291), (0.0, 0.20269), (1.0, 0.20291)]\n",
      "Alpha*: 0.0 tau*: 0.20269 Episode: 36728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00014522852143272758\n",
      "Q Loss:  0.00030382454860955477\n",
      "Policy Loss:  -0.0007464413065463305\n",
      "[(0.00037, 0.20269), (0.0, 0.20247), (1.0, 0.20269)]\n",
      "Alpha*: 0.0 tau*: 0.20247 Episode: 36733 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002455999201629311\n",
      "Q Loss:  0.0003601715143304318\n",
      "Policy Loss:  0.0025515654124319553\n",
      "[(0.00036, 0.20247), (0.0, 0.20225), (1.0, 0.20247)]\n",
      "Alpha*: 0.0 tau*: 0.20225 Episode: 36738 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.6098867058753967\n",
      "Q Loss:  0.12206251174211502\n",
      "Policy Loss:  -2.52200984954834\n",
      "[(0.00036, 0.20225), (0.0, 0.20203), (1.0, 0.20225)]\n",
      "Alpha*: 0.0 tau*: 0.20203 Episode: 36744 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.2126826047897339\n",
      "Q Loss:  0.2927291989326477\n",
      "Policy Loss:  -4.340803623199463\n",
      "[(0.00036, 0.20203), (0.0, 0.20181), (1.0, 0.20203)]\n",
      "Alpha*: 0.0 tau*: 0.20181 Episode: 36748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.6795761585235596\n",
      "Q Loss:  0.0029978842940181494\n",
      "Policy Loss:  1.6724871397018433\n",
      "[(0.00036, 0.20181), (0.0, 0.20159), (1.0, 0.20181)]\n",
      "Alpha*: 0.0 tau*: 0.20159 Episode: 36762 length: 13 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  17.151737213134766\n",
      "Q Loss:  0.611398458480835\n",
      "Policy Loss:  -5.719881534576416\n",
      "[(0.00036, 0.20159), (0.0, 0.20137), (1.0, 0.20159)]\n",
      "Alpha*: 0.0 tau*: 0.20137 Episode: 36859 length: 85 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.000128691885038279\n",
      "Q Loss:  0.0016554850153625011\n",
      "Policy Loss:  0.013796844519674778\n",
      "[(0.00036, 0.20137), (0.0, 0.20115), (1.0, 0.20137)]\n",
      "Alpha*: 0.0 tau*: 0.20115 Episode: 36864 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.6009284257888794\n",
      "Q Loss:  0.1268736720085144\n",
      "Policy Loss:  -3.84551739692688\n",
      "[(0.00036, 0.20115), (0.0, 0.20093), (1.0, 0.20115)]\n",
      "Alpha*: 0.0 tau*: 0.20093 Episode: 36871 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  46315.1171875\n",
      "Q Loss:  43804.390625\n",
      "Policy Loss:  -8.14810562133789\n",
      "[(0.00036, 0.20093), (0.0, 0.20071), (1.0, 0.20093)]\n",
      "Alpha*: 0.0 tau*: 0.20071 Episode: 36897 length: 20 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.57426145253703e-05\n",
      "Q Loss:  0.00016427383525297046\n",
      "Policy Loss:  0.23822319507598877\n",
      "[(0.00037, 0.20071), (0.0, 0.20049), (1.0, 0.20071)]\n",
      "Alpha*: 0.0 tau*: 0.20049 Episode: 36901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  71.63648223876953\n",
      "Q Loss:  61.75554656982422\n",
      "Policy Loss:  -20.017349243164062\n",
      "[(0.00038, 0.20049), (0.0, 0.20027), (1.0, 0.20049)]\n",
      "Alpha*: 0.0 tau*: 0.20027 Episode: 36997 length: 81 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001150462994701229\n",
      "Q Loss:  0.0010395677527412772\n",
      "Policy Loss:  -0.011670002713799477\n",
      "[(0.00038, 0.20027), (0.0, 0.20005), (1.0, 0.20027)]\n",
      "Alpha*: 0.0 tau*: 0.20005 Episode: 37001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  6.314202619250864e-05\n",
      "Q Loss:  0.0006602047942578793\n",
      "Policy Loss:  -0.011582443490624428\n",
      "[(0.00039, 0.20005), (0.0, 0.19983), (1.0, 0.20005)]\n",
      "Alpha*: 0.0 tau*: 0.19983 Episode: 37005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00017873117758426815\n",
      "Q Loss:  0.0008194775437004864\n",
      "Policy Loss:  -0.01642262563109398\n",
      "[(0.00039, 0.19983), (0.0, 0.19961), (1.0, 0.19983)]\n",
      "Alpha*: 0.0 tau*: 0.19961 Episode: 37010 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.609153282013722e-05\n",
      "Q Loss:  0.0007144545670598745\n",
      "Policy Loss:  0.011847751215100288\n",
      "[(0.00039, 0.19961), (0.0, 0.19939), (1.0, 0.19961)]\n",
      "Alpha*: 0.0 tau*: 0.19939 Episode: 37015 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.6994396193913417e-06\n",
      "Q Loss:  0.000636753102298826\n",
      "Policy Loss:  0.010369157418608665\n",
      "[(0.00039, 0.19939), (0.0, 0.19917), (1.0, 0.19939)]\n",
      "Alpha*: 0.0 tau*: 0.19917 Episode: 37020 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  370.9703063964844\n",
      "Q Loss:  1263.9609375\n",
      "Policy Loss:  -49.263824462890625\n",
      "[(0.00039, 0.19917), (0.0, 0.19895), (1.0, 0.19917)]\n",
      "Alpha*: 0.0 tau*: 0.19895 Episode: 37024 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  17805.599609375\n",
      "Q Loss:  16822.908203125\n",
      "Policy Loss:  -14.695273399353027\n",
      "[(0.00039, 0.19895), (0.0, 0.19873), (1.0, 0.19895)]\n",
      "Alpha*: 0.0 tau*: 0.19873 Episode: 37091 length: 52 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03900718688964844\n",
      "Value Loss:  1.874821464298293e-05\n",
      "Q Loss:  12.578518867492676\n",
      "Policy Loss:  1.4814784526824951\n",
      "[(0.0004, 0.19873), (0.0, 0.19851), (1.0, 0.19873)]\n",
      "Alpha*: 0.0 tau*: 0.19851 Episode: 37096 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  4.987619468010962e-05\n",
      "Q Loss:  0.0008400810766033828\n",
      "Policy Loss:  0.013123298063874245\n",
      "[(0.0004, 0.19851), (0.0, 0.19829), (1.0, 0.19851)]\n",
      "Alpha*: 0.0 tau*: 0.19829 Episode: 37100 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  7.086448022164404e-05\n",
      "Q Loss:  0.0005408107535913587\n",
      "Policy Loss:  -0.00023639120627194643\n",
      "[(0.0004, 0.19829), (0.0, 0.19807), (1.0, 0.19829)]\n",
      "Alpha*: 0.0 tau*: 0.19807 Episode: 37104 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00011209121294086799\n",
      "Q Loss:  0.0006077596917748451\n",
      "Policy Loss:  0.007679487578570843\n",
      "[(0.0004, 0.19807), (0.0, 0.19785), (1.0, 0.19807)]\n",
      "Alpha*: 0.0 tau*: 0.19785 Episode: 37108 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0001330174127360806\n",
      "Q Loss:  0.00029676491976715624\n",
      "Policy Loss:  -0.002626853995025158\n",
      "[(0.0004, 0.19785), (0.0, 0.19763), (1.0, 0.19785)]\n",
      "Alpha*: 0.0 tau*: 0.19763 Episode: 37112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.6331528425216675\n",
      "Q Loss:  0.13469241559505463\n",
      "Policy Loss:  -3.9955861568450928\n",
      "[(0.0004, 0.19763), (0.0, 0.19742), (1.0, 0.19763)]\n",
      "Alpha*: 0.0 tau*: 0.19742 Episode: 37118 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.2647290532186162e-05\n",
      "Q Loss:  0.000851050135679543\n",
      "Policy Loss:  -0.007264923769980669\n",
      "[(0.0004, 0.19742), (0.0, 0.19721), (1.0, 0.19742)]\n",
      "Alpha*: 0.0 tau*: 0.19721 Episode: 37123 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.4125497727945913e-05\n",
      "Q Loss:  0.001759666483849287\n",
      "Policy Loss:  -0.0167179424315691\n",
      "[(0.0004, 0.19721), (0.0, 0.197), (1.0, 0.19721)]\n",
      "Alpha*: 0.0 tau*: 0.197 Episode: 37127 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  5.1257869927212596e-05\n",
      "Q Loss:  3.0741284717805684e-05\n",
      "Policy Loss:  -0.0010460169287398458\n",
      "[(0.0004, 0.197), (0.0, 0.19679), (1.0, 0.197)]\n",
      "Alpha*: 0.0 tau*: 0.19679 Episode: 37131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  5.6022829085122794e-05\n",
      "Q Loss:  0.00014529841428156942\n",
      "Policy Loss:  0.008097133599221706\n",
      "[(0.0004, 0.19679), (0.0, 0.19658), (1.0, 0.19679)]\n",
      "Alpha*: 0.0 tau*: 0.19658 Episode: 37135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.301989585859701e-05\n",
      "Q Loss:  0.0005006012506783009\n",
      "Policy Loss:  0.007619231473654509\n",
      "[(0.0004, 0.19658), (0.0, 0.19637), (1.0, 0.19658)]\n",
      "Alpha*: 0.0 tau*: 0.19637 Episode: 37139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.8062025308609009\n",
      "Q Loss:  2.04946231842041\n",
      "Policy Loss:  -0.05261664092540741\n",
      "[(0.0004, 0.19637), (0.0, 0.19616), (1.0, 0.19637)]\n",
      "Alpha*: 0.0 tau*: 0.19616 Episode: 37180 length: 26 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.1679994713631459e-05\n",
      "Q Loss:  0.0002020570682361722\n",
      "Policy Loss:  0.0012795754009857774\n",
      "[(0.0004, 0.19616), (0.0, 0.19595), (1.0, 0.19616)]\n",
      "Alpha*: 0.0 tau*: 0.19595 Episode: 37186 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  44.20222091674805\n",
      "Q Loss:  0.015561910346150398\n",
      "Policy Loss:  -13.484408378601074\n",
      "[(0.0004, 0.19595), (0.0, 0.19574), (1.0, 0.19595)]\n",
      "Alpha*: 0.0 tau*: 0.19574 Episode: 37237 length: 36 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  34.67234420776367\n",
      "Q Loss:  1.185957908630371\n",
      "Policy Loss:  -10.720454216003418\n",
      "[(0.0004, 0.19574), (0.0, 0.19553), (1.0, 0.19574)]\n",
      "Alpha*: 0.0 tau*: 0.19553 Episode: 37300 length: 46 #teleports:17\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.75441811431665e-05\n",
      "Q Loss:  13.348505973815918\n",
      "Policy Loss:  1.2601828575134277\n",
      "[(0.0004, 0.19553), (0.0, 0.19532), (1.0, 0.19553)]\n",
      "Alpha*: 0.0 tau*: 0.19532 Episode: 37307 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  56029.31640625\n",
      "Q Loss:  52952.49609375\n",
      "Policy Loss:  -34.50979232788086\n",
      "[(0.0004, 0.19532), (0.0, 0.19511), (1.0, 0.19532)]\n",
      "Alpha*: 0.0 tau*: 0.19511 Episode: 37349 length: 33 #teleports:9\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00014408495917450637\n",
      "Q Loss:  0.00012850106577388942\n",
      "Policy Loss:  -0.0028101536445319653\n",
      "[(0.0004, 0.19511), (0.0, 0.1949), (1.0, 0.19511)]\n",
      "Alpha*: 0.0 tau*: 0.1949 Episode: 37353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  20996.681640625\n",
      "Q Loss:  19886.3828125\n",
      "Policy Loss:  -14.241349220275879\n",
      "[(0.0004, 0.1949), (0.0, 0.19469), (1.0, 0.1949)]\n",
      "Alpha*: 0.0 tau*: 0.19469 Episode: 37405 length: 44 #teleports:8\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  397.6477966308594\n",
      "Q Loss:  0.0001601584954187274\n",
      "Policy Loss:  -115.2177505493164\n",
      "[(0.00041, 0.19469), (0.0, 0.19448), (1.0, 0.19469)]\n",
      "Alpha*: 0.0 tau*: 0.19448 Episode: 37413 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.0005976975080557168\n",
      "Q Loss:  0.0005161017179489136\n",
      "Policy Loss:  -0.00950558576732874\n",
      "[(0.00041, 0.19448), (0.0, 0.19427), (1.0, 0.19448)]\n",
      "Alpha*: 0.0 tau*: 0.19427 Episode: 37417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.000315978832077235\n",
      "Q Loss:  0.00016266755119431764\n",
      "Policy Loss:  0.004977679345756769\n",
      "[(0.00041, 0.19427), (0.0, 0.19406), (1.0, 0.19427)]\n",
      "Alpha*: 0.0 tau*: 0.19406 Episode: 37422 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  406.5942077636719\n",
      "Q Loss:  12.912318229675293\n",
      "Policy Loss:  -110.21959686279297\n",
      "[(0.00041, 0.19406), (0.0, 0.19385), (1.0, 0.19406)]\n",
      "Alpha*: 0.0 tau*: 0.19385 Episode: 37427 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.06301450729370117\n",
      "Value Loss:  5.415168925537728e-05\n",
      "Q Loss:  0.0006327591836452484\n",
      "Policy Loss:  0.010482139885425568\n",
      "[(0.00041, 0.19385), (0.0, 0.19364), (1.0, 0.19385)]\n",
      "Alpha*: 0.0 tau*: 0.19364 Episode: 37431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0005972810322418809\n",
      "Q Loss:  0.0008494360954500735\n",
      "Policy Loss:  0.016938326880335808\n",
      "[(0.00041, 0.19364), (0.0, 0.19343), (1.0, 0.19364)]\n",
      "Alpha*: 0.0 tau*: 0.19343 Episode: 37435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00020541569392662495\n",
      "Q Loss:  0.0007666937308385968\n",
      "Policy Loss:  0.003931062296032906\n",
      "[(0.00041, 0.19343), (0.0, 0.19322), (1.0, 0.19343)]\n",
      "Alpha*: 0.0 tau*: 0.19322 Episode: 37439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.212717900983989e-05\n",
      "Q Loss:  0.0002090424532070756\n",
      "Policy Loss:  0.004901164211332798\n",
      "[(0.00041, 0.19322), (0.0, 0.19301), (1.0, 0.19322)]\n",
      "Alpha*: 0.0 tau*: 0.19301 Episode: 37443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.7461549639701843\n",
      "Q Loss:  0.10724493116140366\n",
      "Policy Loss:  -3.194493532180786\n",
      "[(0.00041, 0.19301), (0.0, 0.1928), (1.0, 0.19301)]\n",
      "Alpha*: 0.0 tau*: 0.1928 Episode: 37447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  34.784156799316406\n",
      "Q Loss:  49.52910232543945\n",
      "Policy Loss:  -9.438111305236816\n",
      "[(0.00042, 0.1928), (0.0, 0.19259), (1.0, 0.1928)]\n",
      "Alpha*: 0.0 tau*: 0.19259 Episode: 37571 length: 97 #teleports:27\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  23045.154296875\n",
      "Q Loss:  21770.80078125\n",
      "Policy Loss:  -14.033504486083984\n",
      "[(0.00042, 0.19259), (0.0, 0.19238), (1.0, 0.19259)]\n",
      "Alpha*: 0.0 tau*: 0.19238 Episode: 37619 length: 40 #teleports:8\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  12624.6376953125\n",
      "Q Loss:  11858.2939453125\n",
      "Policy Loss:  -11.987508773803711\n",
      "[(0.00042, 0.19238), (0.0, 0.19217), (1.0, 0.19238)]\n",
      "Alpha*: 0.0 tau*: 0.19217 Episode: 37715 length: 73 #teleports:23\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  5.4657444707117975e-05\n",
      "Q Loss:  0.003167445305734873\n",
      "Policy Loss:  0.24838608503341675\n",
      "[(0.00042, 0.19217), (0.0, 0.19196), (1.0, 0.19217)]\n",
      "Alpha*: 0.0 tau*: 0.19196 Episode: 37720 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.025602340698242188\n",
      "Value Loss:  0.0001906389807118103\n",
      "Q Loss:  0.0015669555868953466\n",
      "Policy Loss:  -0.019802985712885857\n",
      "[(0.00042, 0.19196), (0.0, 0.19175), (1.0, 0.19196)]\n",
      "Alpha*: 0.0 tau*: 0.19175 Episode: 37724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  37.37324142456055\n",
      "Q Loss:  105.3573226928711\n",
      "Policy Loss:  -7.88846492767334\n",
      "[(0.00042, 0.19175), (0.0, 0.19154), (1.0, 0.19175)]\n",
      "Alpha*: 0.0 tau*: 0.19154 Episode: 37783 length: 47 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  428.3408508300781\n",
      "Q Loss:  12.171581268310547\n",
      "Policy Loss:  -113.33430480957031\n",
      "[(0.00042, 0.19154), (0.0, 0.19133), (1.0, 0.19154)]\n",
      "Alpha*: 0.0 tau*: 0.19133 Episode: 37791 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  5.830013833474368e-05\n",
      "Q Loss:  0.0021947885397821665\n",
      "Policy Loss:  0.26235365867614746\n",
      "[(0.00042, 0.19133), (0.0, 0.19112), (1.0, 0.19133)]\n",
      "Alpha*: 0.0 tau*: 0.19112 Episode: 37796 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.000497889646794647\n",
      "Q Loss:  0.0008426242275163531\n",
      "Policy Loss:  -0.01670694723725319\n",
      "[(0.00042, 0.19112), (0.0, 0.19091), (1.0, 0.19112)]\n",
      "Alpha*: 0.0 tau*: 0.19091 Episode: 37800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00014154748350847512\n",
      "Q Loss:  0.0022487076930701733\n",
      "Policy Loss:  0.2558623254299164\n",
      "[(0.00042, 0.19091), (0.0, 0.1907), (1.0, 0.19091)]\n",
      "Alpha*: 0.0 tau*: 0.1907 Episode: 37807 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  4.130317392991856e-05\n",
      "Q Loss:  0.006727500353008509\n",
      "Policy Loss:  0.028305642306804657\n",
      "[(0.00042, 0.1907), (0.0, 0.19049), (1.0, 0.1907)]\n",
      "Alpha*: 0.0 tau*: 0.19049 Episode: 37813 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  9.753687481861562e-05\n",
      "Q Loss:  0.0007528290734626353\n",
      "Policy Loss:  -0.007488633971661329\n",
      "[(0.00042, 0.19049), (0.0, 0.19028), (1.0, 0.19049)]\n",
      "Alpha*: 0.0 tau*: 0.19028 Episode: 37817 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.250011938391253e-05\n",
      "Q Loss:  0.0033802147954702377\n",
      "Policy Loss:  0.018406789749860764\n",
      "[(0.00042, 0.19028), (0.0, 0.19007), (1.0, 0.19028)]\n",
      "Alpha*: 0.0 tau*: 0.19007 Episode: 37821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  8380.671875\n",
      "Q Loss:  7949.1923828125\n",
      "Policy Loss:  -10.339303016662598\n",
      "[(0.00042, 0.19007), (0.0, 0.18986), (1.0, 0.19007)]\n",
      "Alpha*: 0.0 tau*: 0.18986 Episode: 37958 length: 110 #teleports:27\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  435.7331237792969\n",
      "Q Loss:  11.756426811218262\n",
      "Policy Loss:  -114.35407257080078\n",
      "[(0.00042, 0.18986), (0.0, 0.18965), (1.0, 0.18986)]\n",
      "Alpha*: 0.0 tau*: 0.18965 Episode: 37964 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0001868796971393749\n",
      "Q Loss:  0.0002420511154923588\n",
      "Policy Loss:  0.010046572424471378\n",
      "[(0.00042, 0.18965), (0.0, 0.18944), (1.0, 0.18965)]\n",
      "Alpha*: 0.0 tau*: 0.18944 Episode: 37968 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.0261495113372803\n",
      "Q Loss:  0.09132815152406693\n",
      "Policy Loss:  -1.9079910516738892\n",
      "[(0.00042, 0.18944), (0.0, 0.18923), (1.0, 0.18944)]\n",
      "Alpha*: 0.0 tau*: 0.18923 Episode: 38030 length: 53 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.935941099873162e-06\n",
      "Q Loss:  4.183311830274761e-06\n",
      "Policy Loss:  -0.0017022332176566124\n",
      "[(0.00042, 0.18923), (0.0, 0.18902), (1.0, 0.18923)]\n",
      "Alpha*: 0.0 tau*: 0.18902 Episode: 38034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024286746978759766\n",
      "Value Loss:  13459.185546875\n",
      "Q Loss:  12618.390625\n",
      "Policy Loss:  -40.746849060058594\n",
      "[(0.00042, 0.18902), (0.0, 0.18881), (1.0, 0.18902)]\n",
      "Alpha*: 0.0 tau*: 0.18881 Episode: 38122 length: 69 #teleports:19\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  9.594310540705919e-05\n",
      "Q Loss:  2.8637688956223428e-05\n",
      "Policy Loss:  -0.0033211749978363514\n",
      "[(0.00042, 0.18881), (0.0, 0.1886), (1.0, 0.18881)]\n",
      "Alpha*: 0.0 tau*: 0.1886 Episode: 38128 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  3.2603813451714814e-05\n",
      "Q Loss:  0.00021017460676375777\n",
      "Policy Loss:  -0.005260122939944267\n",
      "[(0.00042, 0.1886), (0.0, 0.18839), (1.0, 0.1886)]\n",
      "Alpha*: 0.0 tau*: 0.18839 Episode: 38132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  7.206843292806298e-05\n",
      "Q Loss:  0.00041949463775381446\n",
      "Policy Loss:  -0.0035587865859270096\n",
      "[(0.00042, 0.18839), (0.0, 0.18818), (1.0, 0.18839)]\n",
      "Alpha*: 0.0 tau*: 0.18818 Episode: 38137 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00012712621537502855\n",
      "Q Loss:  8.77174170454964e-05\n",
      "Policy Loss:  -0.00946696288883686\n",
      "[(0.00042, 0.18818), (0.0, 0.18797), (1.0, 0.18818)]\n",
      "Alpha*: 0.0 tau*: 0.18797 Episode: 38141 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  10947.96875\n",
      "Q Loss:  10254.193359375\n",
      "Policy Loss:  -10.642386436462402\n",
      "[(0.00042, 0.18797), (0.0, 0.18776), (1.0, 0.18797)]\n",
      "Alpha*: 0.0 tau*: 0.18776 Episode: 38250 length: 84 #teleports:25\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.0251305103302002\n",
      "Q Loss:  0.87995845079422\n",
      "Policy Loss:  -1.785365343093872\n",
      "[(0.00042, 0.18776), (0.0, 0.18755), (1.0, 0.18776)]\n",
      "Alpha*: 0.0 tau*: 0.18755 Episode: 38321 length: 59 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.0001835423317970708\n",
      "Q Loss:  5.312393477652222e-05\n",
      "Policy Loss:  -0.0011296303709968925\n",
      "[(0.00042, 0.18755), (0.0, 0.18734), (1.0, 0.18755)]\n",
      "Alpha*: 0.0 tau*: 0.18734 Episode: 38327 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.03700709342956543\n",
      "Value Loss:  75.71182250976562\n",
      "Q Loss:  1.9084489345550537\n",
      "Policy Loss:  -19.797607421875\n",
      "[(0.00042, 0.18734), (0.0, 0.18713), (1.0, 0.18734)]\n",
      "Alpha*: 0.0 tau*: 0.18713 Episode: 38361 length: 24 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  10709.51953125\n",
      "Q Loss:  10006.068359375\n",
      "Policy Loss:  -15.655730247497559\n",
      "[(0.00043, 0.18713), (0.0, 0.18692), (1.0, 0.18713)]\n",
      "Alpha*: 0.0 tau*: 0.18692 Episode: 38465 length: 86 #teleports:18\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  39.125732421875\n",
      "Q Loss:  2.0382797718048096\n",
      "Policy Loss:  -11.321709632873535\n",
      "[(0.00043, 0.18692), (0.0, 0.18671), (1.0, 0.18692)]\n",
      "Alpha*: 0.0 tau*: 0.18671 Episode: 38526 length: 47 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.7752683162689209\n",
      "Q Loss:  0.05369916558265686\n",
      "Policy Loss:  -1.5782548189163208\n",
      "[(0.00043, 0.18671), (0.0, 0.1865), (1.0, 0.18671)]\n",
      "Alpha*: 0.0 tau*: 0.1865 Episode: 38602 length: 65 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.8389334082603455\n",
      "Q Loss:  0.28597599267959595\n",
      "Policy Loss:  -3.322680950164795\n",
      "[(0.00043, 0.1865), (0.0, 0.18629), (1.0, 0.1865)]\n",
      "Alpha*: 0.0 tau*: 0.18629 Episode: 38606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  2.181011199951172\n",
      "Q Loss:  0.11460711807012558\n",
      "Policy Loss:  -1.4514139890670776\n",
      "[(0.00043, 0.18629), (0.0, 0.18608), (1.0, 0.18629)]\n",
      "Alpha*: 0.0 tau*: 0.18608 Episode: 38631 length: 23 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00012205857638036832\n",
      "Q Loss:  0.00045418983791023493\n",
      "Policy Loss:  0.00807128194719553\n",
      "[(0.00043, 0.18608), (0.0, 0.18587), (1.0, 0.18608)]\n",
      "Alpha*: 0.0 tau*: 0.18587 Episode: 38635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.674889244895894e-05\n",
      "Q Loss:  0.0005096145323477685\n",
      "Policy Loss:  0.001737705315463245\n",
      "[(0.00044, 0.18587), (0.0, 0.18566), (1.0, 0.18587)]\n",
      "Alpha*: 0.0 tau*: 0.18566 Episode: 38640 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  3.525718057062477e-05\n",
      "Q Loss:  0.0015815100632607937\n",
      "Policy Loss:  0.019749274477362633\n",
      "[(0.00044, 0.18566), (0.0, 0.18545), (1.0, 0.18566)]\n",
      "Alpha*: 0.0 tau*: 0.18545 Episode: 38645 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.11762022972106934\n",
      "Value Loss:  4.3373504013288766e-05\n",
      "Q Loss:  11.331130027770996\n",
      "Policy Loss:  1.1755108833312988\n",
      "[(0.00044, 0.18545), (0.0, 0.18524), (1.0, 0.18545)]\n",
      "Alpha*: 0.0 tau*: 0.18524 Episode: 38651 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.1150586033181753e-05\n",
      "Q Loss:  0.0062768361531198025\n",
      "Policy Loss:  0.030532997101545334\n",
      "[(0.00044, 0.18524), (0.0, 0.18503), (1.0, 0.18524)]\n",
      "Alpha*: 0.0 tau*: 0.18503 Episode: 38656 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  77.45553588867188\n",
      "Q Loss:  228.35235595703125\n",
      "Policy Loss:  -11.253623008728027\n",
      "[(0.00044, 0.18503), (0.0, 0.18482), (1.0, 0.18503)]\n",
      "Alpha*: 0.0 tau*: 0.18482 Episode: 38688 length: 24 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  177.39288330078125\n",
      "Q Loss:  36.75369644165039\n",
      "Policy Loss:  -45.3326301574707\n",
      "[(0.00044, 0.18482), (0.0, 0.18461), (1.0, 0.18482)]\n",
      "Alpha*: 0.0 tau*: 0.18461 Episode: 38725 length: 31 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.825893923523836e-05\n",
      "Q Loss:  0.00036630098475143313\n",
      "Policy Loss:  0.0037503584753721952\n",
      "[(0.00044, 0.18461), (0.0, 0.1844), (1.0, 0.18461)]\n",
      "Alpha*: 0.0 tau*: 0.1844 Episode: 38729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  9.130592661676928e-05\n",
      "Q Loss:  0.00019438051094766706\n",
      "Policy Loss:  -0.004251744598150253\n",
      "[(0.00044, 0.1844), (0.0, 0.18419), (1.0, 0.1844)]\n",
      "Alpha*: 0.0 tau*: 0.18419 Episode: 38733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0002742783981375396\n",
      "Q Loss:  0.0003883734461851418\n",
      "Policy Loss:  -0.009124369360506535\n",
      "[(0.00044, 0.18419), (0.0, 0.18398), (1.0, 0.18419)]\n",
      "Alpha*: 0.0 tau*: 0.18398 Episode: 38737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00011147381155751646\n",
      "Q Loss:  6.629050767514855e-05\n",
      "Policy Loss:  2.266024239361286e-06\n",
      "[(0.00044, 0.18398), (0.0, 0.18377), (1.0, 0.18398)]\n",
      "Alpha*: 0.0 tau*: 0.18377 Episode: 38741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.0497623558621854e-05\n",
      "Q Loss:  3.2594060030533e-05\n",
      "Policy Loss:  0.002785131335258484\n",
      "[(0.00044, 0.18377), (0.0, 0.18356), (1.0, 0.18377)]\n",
      "Alpha*: 0.0 tau*: 0.18356 Episode: 38746 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03000640869140625\n",
      "Value Loss:  1.7253973484039307\n",
      "Q Loss:  0.16711615025997162\n",
      "Policy Loss:  -3.1600000858306885\n",
      "[(0.00044, 0.18356), (0.0, 0.18335), (1.0, 0.18356)]\n",
      "Alpha*: 0.0 tau*: 0.18335 Episode: 38790 length: 37 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.7884382009506226\n",
      "Q Loss:  0.623970627784729\n",
      "Policy Loss:  -1.8713239431381226\n",
      "[(0.00044, 0.18335), (0.0, 0.18314), (1.0, 0.18335)]\n",
      "Alpha*: 0.0 tau*: 0.18314 Episode: 38891 length: 81 #teleports:20\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.033594369888305664\n",
      "Value Loss:  20044.216796875\n",
      "Q Loss:  18773.462890625\n",
      "Policy Loss:  -34.73467254638672\n",
      "[(0.00044, 0.18314), (0.0, 0.18293), (1.0, 0.18314)]\n",
      "Alpha*: 0.0 tau*: 0.18293 Episode: 38948 length: 46 #teleports:11\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015004634857177734\n",
      "Value Loss:  911.531982421875\n",
      "Q Loss:  1393.1531982421875\n",
      "Policy Loss:  -122.0934066772461\n",
      "[(0.00044, 0.18293), (0.0, 0.18272), (1.0, 0.18293)]\n",
      "Alpha*: 0.0 tau*: 0.18272 Episode: 38953 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  133.5476531982422\n",
      "Q Loss:  0.18784019351005554\n",
      "Policy Loss:  -31.98932647705078\n",
      "[(0.00044, 0.18272), (0.0, 0.18251), (1.0, 0.18272)]\n",
      "Alpha*: 0.0 tau*: 0.18251 Episode: 38973 length: 14 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  41.58047866821289\n",
      "Q Loss:  22.455421447753906\n",
      "Policy Loss:  -12.601143836975098\n",
      "[(0.00044, 0.18251), (0.0, 0.1823), (1.0, 0.18251)]\n",
      "Alpha*: 0.0 tau*: 0.1823 Episode: 39029 length: 45 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.00019638183584902436\n",
      "Q Loss:  0.0012509222142398357\n",
      "Policy Loss:  -0.0002956376411020756\n",
      "[(0.00044, 0.1823), (0.0, 0.18209), (1.0, 0.1823)]\n",
      "Alpha*: 0.0 tau*: 0.18209 Episode: 39033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  453.6190185546875\n",
      "Q Loss:  0.00014521389675792307\n",
      "Policy Loss:  -122.4087905883789\n",
      "[(0.00044, 0.18209), (0.0, 0.18188), (1.0, 0.18209)]\n",
      "Alpha*: 0.0 tau*: 0.18188 Episode: 39038 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.2886750937468605e-06\n",
      "Q Loss:  10.947343826293945\n",
      "Policy Loss:  1.1597423553466797\n",
      "[(0.00044, 0.18188), (0.0, 0.18167), (1.0, 0.18188)]\n",
      "Alpha*: 0.0 tau*: 0.18167 Episode: 39043 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.9701245037140325e-05\n",
      "Q Loss:  0.0004914687015116215\n",
      "Policy Loss:  -0.005198168568313122\n",
      "[(0.00044, 0.18167), (0.0, 0.18146), (1.0, 0.18167)]\n",
      "Alpha*: 0.0 tau*: 0.18146 Episode: 39048 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03200721740722656\n",
      "Value Loss:  3.169523552060127e-05\n",
      "Q Loss:  6.133432907518e-05\n",
      "Policy Loss:  0.0031705540604889393\n",
      "[(0.00044, 0.18146), (0.0, 0.18125), (1.0, 0.18146)]\n",
      "Alpha*: 0.0 tau*: 0.18125 Episode: 39052 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.400851584156044e-06\n",
      "Q Loss:  0.00011992700456175953\n",
      "Policy Loss:  -0.007552820723503828\n",
      "[(0.00044, 0.18125), (0.0, 0.18104), (1.0, 0.18125)]\n",
      "Alpha*: 0.0 tau*: 0.18104 Episode: 39056 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  4.6369227675313596e-06\n",
      "Q Loss:  0.010745481587946415\n",
      "Policy Loss:  0.2892199754714966\n",
      "[(0.00043, 0.18104), (0.0, 0.18083), (1.0, 0.18104)]\n",
      "Alpha*: 0.0 tau*: 0.18083 Episode: 39061 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  11072.2666015625\n",
      "Q Loss:  10349.01953125\n",
      "Policy Loss:  -10.715447425842285\n",
      "[(0.00043, 0.18083), (0.0, 0.18062), (1.0, 0.18083)]\n",
      "Alpha*: 0.0 tau*: 0.18062 Episode: 39172 length: 83 #teleports:28\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  36687.51953125\n",
      "Q Loss:  34269.19921875\n",
      "Policy Loss:  -12.54111385345459\n",
      "[(0.00044, 0.18062), (0.0, 0.18041), (1.0, 0.18062)]\n",
      "Alpha*: 0.0 tau*: 0.18041 Episode: 39203 length: 25 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013658523559570312\n",
      "Value Loss:  3.474461118457839e-05\n",
      "Q Loss:  10.691843032836914\n",
      "Policy Loss:  1.1630326509475708\n",
      "[(0.00044, 0.18041), (0.0, 0.1802), (1.0, 0.18041)]\n",
      "Alpha*: 0.0 tau*: 0.1802 Episode: 39210 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.0003362784627825022\n",
      "Q Loss:  0.010618756525218487\n",
      "Policy Loss:  0.2958976626396179\n",
      "[(0.00044, 0.1802), (0.0, 0.17999), (1.0, 0.1802)]\n",
      "Alpha*: 0.0 tau*: 0.17999 Episode: 39221 length: 4 #teleports:7\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1201308965682983\n",
      "Q Loss:  0.24450524151325226\n",
      "Policy Loss:  -3.7984814643859863\n",
      "[(0.00044, 0.17999), (0.0, 0.17978), (1.0, 0.17999)]\n",
      "Alpha*: 0.0 tau*: 0.17978 Episode: 39227 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  24.30206871032715\n",
      "Q Loss:  14.3720064163208\n",
      "Policy Loss:  -8.083222389221191\n",
      "[(0.00044, 0.17978), (0.0, 0.17957), (1.0, 0.17978)]\n",
      "Alpha*: 0.0 tau*: 0.17957 Episode: 39317 length: 78 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00017508423479739577\n",
      "Q Loss:  0.0021467197220772505\n",
      "Policy Loss:  0.018986664712429047\n",
      "[(0.00045, 0.17957), (0.0, 0.17936), (1.0, 0.17957)]\n",
      "Alpha*: 0.0 tau*: 0.17936 Episode: 39322 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.5327444745926186e-05\n",
      "Q Loss:  0.0008909665048122406\n",
      "Policy Loss:  0.019815288484096527\n",
      "[(0.00045, 0.17936), (0.0, 0.17915), (1.0, 0.17936)]\n",
      "Alpha*: 0.0 tau*: 0.17915 Episode: 39327 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  9.559789032209665e-05\n",
      "Q Loss:  0.000394570583011955\n",
      "Policy Loss:  0.011772001162171364\n",
      "[(0.00045, 0.17915), (0.0, 0.17894), (1.0, 0.17915)]\n",
      "Alpha*: 0.0 tau*: 0.17894 Episode: 39333 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  4.3159790948266163e-05\n",
      "Q Loss:  0.008208982646465302\n",
      "Policy Loss:  0.03927457705140114\n",
      "[(0.00045, 0.17894), (0.0, 0.17873), (1.0, 0.17894)]\n",
      "Alpha*: 0.0 tau*: 0.17873 Episode: 39340 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.224359898013063e-05\n",
      "Q Loss:  0.013986066915094852\n",
      "Policy Loss:  0.06301926076412201\n",
      "[(0.00045, 0.17873), (0.0, 0.17852), (1.0, 0.17873)]\n",
      "Alpha*: 0.0 tau*: 0.17852 Episode: 39344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  3.575415030354634e-05\n",
      "Q Loss:  10.422065734863281\n",
      "Policy Loss:  1.4398527145385742\n",
      "[(0.00045, 0.17852), (0.0, 0.17831), (1.0, 0.17852)]\n",
      "Alpha*: 0.0 tau*: 0.17831 Episode: 39349 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.028006315231323242\n",
      "Value Loss:  3.2405470847152174e-05\n",
      "Q Loss:  0.0019480856135487556\n",
      "Policy Loss:  0.025337060913443565\n",
      "[(0.00045, 0.17831), (0.0, 0.1781), (1.0, 0.17831)]\n",
      "Alpha*: 0.0 tau*: 0.1781 Episode: 39354 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.00012712633179035038\n",
      "Q Loss:  0.0012713281903415918\n",
      "Policy Loss:  0.00862949714064598\n",
      "[(0.00045, 0.1781), (0.0, 0.17789), (1.0, 0.1781)]\n",
      "Alpha*: 0.0 tau*: 0.17789 Episode: 39360 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.754678123688791e-05\n",
      "Q Loss:  0.0019467574311420321\n",
      "Policy Loss:  0.009130911901593208\n",
      "[(0.00045, 0.17789), (0.0, 0.17768), (1.0, 0.17789)]\n",
      "Alpha*: 0.0 tau*: 0.17768 Episode: 39368 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.03800606727600098\n",
      "Value Loss:  80.83084106445312\n",
      "Q Loss:  126.33103942871094\n",
      "Policy Loss:  -17.93131446838379\n",
      "[(0.00045, 0.17768), (0.0, 0.17747), (1.0, 0.17768)]\n",
      "Alpha*: 0.0 tau*: 0.17747 Episode: 39421 length: 47 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  29520.578125\n",
      "Q Loss:  27541.982421875\n",
      "Policy Loss:  -10.35649299621582\n",
      "[(0.00045, 0.17747), (0.0, 0.17726), (1.0, 0.17747)]\n",
      "Alpha*: 0.0 tau*: 0.17726 Episode: 39459 length: 31 #teleports:7\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.1196882724761963\n",
      "Q Loss:  0.2812516987323761\n",
      "Policy Loss:  -3.5838828086853027\n",
      "[(0.00045, 0.17726), (0.0, 0.17705), (1.0, 0.17726)]\n",
      "Alpha*: 0.0 tau*: 0.17705 Episode: 39463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  8.40427092043683e-05\n",
      "Q Loss:  0.0008475044742226601\n",
      "Policy Loss:  -0.007355973124504089\n",
      "[(0.00045, 0.17705), (0.0, 0.17684), (1.0, 0.17705)]\n",
      "Alpha*: 0.0 tau*: 0.17684 Episode: 39468 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  2.2258846759796143\n",
      "Q Loss:  1.3005279302597046\n",
      "Policy Loss:  -8.833163261413574\n",
      "[(0.00045, 0.17684), (0.0, 0.17663), (1.0, 0.17684)]\n",
      "Alpha*: 0.0 tau*: 0.17663 Episode: 39476 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  142.01458740234375\n",
      "Q Loss:  402.8982849121094\n",
      "Policy Loss:  -24.891767501831055\n",
      "[(0.00045, 0.17663), (0.0, 0.17642), (1.0, 0.17663)]\n",
      "Alpha*: 0.0 tau*: 0.17642 Episode: 39553 length: 68 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.041010141372680664\n",
      "Value Loss:  7.775805715937167e-05\n",
      "Q Loss:  0.01026269793510437\n",
      "Policy Loss:  0.06298556923866272\n",
      "[(0.00045, 0.17642), (0.0, 0.17621), (1.0, 0.17642)]\n",
      "Alpha*: 0.0 tau*: 0.17621 Episode: 39557 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  11082.0185546875\n",
      "Q Loss:  10495.6318359375\n",
      "Policy Loss:  -17.90616226196289\n",
      "[(0.00045, 0.17621), (0.0, 0.176), (1.0, 0.17621)]\n",
      "Alpha*: 0.0 tau*: 0.176 Episode: 39660 length: 83 #teleports:20\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  7.109485159162432e-05\n",
      "Q Loss:  0.010541641153395176\n",
      "Policy Loss:  0.03849637508392334\n",
      "[(0.00045, 0.176), (0.0, 0.17579), (1.0, 0.176)]\n",
      "Alpha*: 0.0 tau*: 0.17579 Episode: 39666 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  85.41529846191406\n",
      "Q Loss:  169.2313995361328\n",
      "Policy Loss:  -19.034807205200195\n",
      "[(0.00045, 0.17579), (0.0, 0.17558), (1.0, 0.17579)]\n",
      "Alpha*: 0.0 tau*: 0.17558 Episode: 39776 length: 92 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015230655670166016\n",
      "Value Loss:  48.17144775390625\n",
      "Q Loss:  74.34310913085938\n",
      "Policy Loss:  -11.710686683654785\n",
      "[(0.00046, 0.17558), (0.0, 0.17537), (1.0, 0.17558)]\n",
      "Alpha*: 0.0 tau*: 0.17537 Episode: 39876 length: 83 #teleports:17\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.064828342758119e-05\n",
      "Q Loss:  0.01730494387447834\n",
      "Policy Loss:  0.045164402574300766\n",
      "[(0.00046, 0.17537), (0.0, 0.17516), (1.0, 0.17537)]\n",
      "Alpha*: 0.0 tau*: 0.17516 Episode: 39882 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  4.3504351197043434e-05\n",
      "Q Loss:  0.019545309245586395\n",
      "Policy Loss:  0.042877309024333954\n",
      "[(0.00046, 0.17516), (0.0, 0.17495), (1.0, 0.17516)]\n",
      "Alpha*: 0.0 tau*: 0.17495 Episode: 39887 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.807223816285841e-05\n",
      "Q Loss:  0.018993975594639778\n",
      "Policy Loss:  0.04758131504058838\n",
      "[(0.00046, 0.17495), (0.0, 0.17474), (1.0, 0.17495)]\n",
      "Alpha*: 0.0 tau*: 0.17474 Episode: 39892 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  493.78375244140625\n",
      "Q Loss:  1542.9400634765625\n",
      "Policy Loss:  -54.18880844116211\n",
      "[(0.00046, 0.17474), (0.0, 0.17453), (1.0, 0.17474)]\n",
      "Alpha*: 0.0 tau*: 0.17453 Episode: 39897 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  132.30911254882812\n",
      "Q Loss:  179.938720703125\n",
      "Policy Loss:  -29.186189651489258\n",
      "[(0.00046, 0.17453), (0.0, 0.17432), (1.0, 0.17453)]\n",
      "Alpha*: 0.0 tau*: 0.17432 Episode: 39993 length: 75 #teleports:21\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6.108172237873077e-05\n",
      "Q Loss:  10.395742416381836\n",
      "Policy Loss:  1.1147544384002686\n",
      "[(0.00046, 0.17432), (0.0, 0.17411), (1.0, 0.17432)]\n",
      "Alpha*: 0.0 tau*: 0.17411 Episode: 39999 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  2.977150143124163e-05\n",
      "Q Loss:  0.00018168060341849923\n",
      "Policy Loss:  -0.006238692440092564\n",
      "[(0.00045, 0.17411), (0.0, 0.1739), (1.0, 0.17411)]\n",
      "Alpha*: 0.0 tau*: 0.1739 Episode: 40004 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  492.96697998046875\n",
      "Q Loss:  1533.0101318359375\n",
      "Policy Loss:  -56.10783386230469\n",
      "[(0.00045, 0.1739), (0.0, 0.17369), (1.0, 0.1739)]\n",
      "Alpha*: 0.0 tau*: 0.17369 Episode: 40009 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  983.691650390625\n",
      "Q Loss:  558.2982177734375\n",
      "Policy Loss:  -234.87796020507812\n",
      "[(0.00045, 0.17369), (0.0, 0.17348), (1.0, 0.17369)]\n",
      "Alpha*: 0.0 tau*: 0.17348 Episode: 40013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  489.0447082519531\n",
      "Q Loss:  1796.18505859375\n",
      "Policy Loss:  -49.919769287109375\n",
      "[(0.00045, 0.17348), (0.0, 0.17327), (1.0, 0.17348)]\n",
      "Alpha*: 0.0 tau*: 0.17327 Episode: 40017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  6.854142702650279e-05\n",
      "Q Loss:  0.0004636272497009486\n",
      "Policy Loss:  -0.008884596638381481\n",
      "[(0.00045, 0.17327), (0.0, 0.17306), (1.0, 0.17327)]\n",
      "Alpha*: 0.0 tau*: 0.17306 Episode: 40021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.00016848085215315223\n",
      "Q Loss:  0.0009779379470273852\n",
      "Policy Loss:  0.014649363234639168\n",
      "[(0.00045, 0.17306), (0.0, 0.17285), (1.0, 0.17306)]\n",
      "Alpha*: 0.0 tau*: 0.17285 Episode: 40026 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0002299716288689524\n",
      "Q Loss:  0.001215801341459155\n",
      "Policy Loss:  -0.0039876773953437805\n",
      "[(0.00044, 0.17285), (0.0, 0.17264), (1.0, 0.17285)]\n",
      "Alpha*: 0.0 tau*: 0.17264 Episode: 40034 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00023574901570100337\n",
      "Q Loss:  0.0012342906557023525\n",
      "Policy Loss:  0.016034947708249092\n",
      "[(0.00044, 0.17264), (0.0, 0.17243), (1.0, 0.17264)]\n",
      "Alpha*: 0.0 tau*: 0.17243 Episode: 40038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00016737967962399125\n",
      "Q Loss:  0.0007135617779567838\n",
      "Policy Loss:  0.00012642797082662582\n",
      "[(0.00044, 0.17243), (0.0, 0.17222), (1.0, 0.17243)]\n",
      "Alpha*: 0.0 tau*: 0.17222 Episode: 40043 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.08144545555114746\n",
      "Value Loss:  0.00013084715465083718\n",
      "Q Loss:  0.0038035456091165543\n",
      "Policy Loss:  0.018216514959931374\n",
      "[(0.00044, 0.17222), (0.0, 0.17201), (1.0, 0.17222)]\n",
      "Alpha*: 0.0 tau*: 0.17201 Episode: 40047 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.9215139150619507\n",
      "Q Loss:  0.0668729841709137\n",
      "Policy Loss:  -2.862227439880371\n",
      "[(0.00044, 0.17201), (0.0, 0.1718), (1.0, 0.17201)]\n",
      "Alpha*: 0.0 tau*: 0.1718 Episode: 40052 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  30.49602508544922\n",
      "Q Loss:  0.04601134732365608\n",
      "Policy Loss:  -8.794227600097656\n",
      "[(0.00044, 0.1718), (0.0, 0.17159), (1.0, 0.1718)]\n",
      "Alpha*: 0.0 tau*: 0.17159 Episode: 40128 length: 63 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.7856521026260452e-06\n",
      "Q Loss:  12.555778503417969\n",
      "Policy Loss:  1.2226310968399048\n",
      "[(0.00044, 0.17159), (0.0, 0.17138), (1.0, 0.17159)]\n",
      "Alpha*: 0.0 tau*: 0.17138 Episode: 40133 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.000139765499625355\n",
      "Q Loss:  0.000527133815921843\n",
      "Policy Loss:  0.004018661566078663\n",
      "[(0.00044, 0.17138), (0.0, 0.17117), (1.0, 0.17138)]\n",
      "Alpha*: 0.0 tau*: 0.17117 Episode: 40137 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.460383570403792e-05\n",
      "Q Loss:  0.00031848641810938716\n",
      "Policy Loss:  -4.5100459828972816e-05\n",
      "[(0.00044, 0.17117), (0.0, 0.17096), (1.0, 0.17117)]\n",
      "Alpha*: 0.0 tau*: 0.17096 Episode: 40141 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0007108255522325635\n",
      "Q Loss:  0.0002558173146098852\n",
      "Policy Loss:  -0.006085203494876623\n",
      "[(0.00044, 0.17096), (0.0, 0.17075), (1.0, 0.17096)]\n",
      "Alpha*: 0.0 tau*: 0.17075 Episode: 40145 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.1651999950408936\n",
      "Q Loss:  0.04810072109103203\n",
      "Policy Loss:  -0.49568191170692444\n",
      "[(0.00044, 0.17075), (0.0, 0.17054), (1.0, 0.17075)]\n",
      "Alpha*: 0.0 tau*: 0.17054 Episode: 40169 length: 19 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.037007808685302734\n",
      "Value Loss:  0.00013293919619172812\n",
      "Q Loss:  0.004838204476982355\n",
      "Policy Loss:  0.3101327419281006\n",
      "[(0.00044, 0.17054), (0.0, 0.17033), (1.0, 0.17054)]\n",
      "Alpha*: 0.0 tau*: 0.17033 Episode: 40173 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.304611086845398\n",
      "Q Loss:  0.057385895401239395\n",
      "Policy Loss:  -1.740778923034668\n",
      "[(0.00044, 0.17033), (0.0, 0.17012), (1.0, 0.17033)]\n",
      "Alpha*: 0.0 tau*: 0.17012 Episode: 40219 length: 38 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00027135098935104907\n",
      "Q Loss:  0.00012772170885000378\n",
      "Policy Loss:  0.0052588926628232\n",
      "[(0.00044, 0.17012), (0.0, 0.16991), (1.0, 0.17012)]\n",
      "Alpha*: 0.0 tau*: 0.16991 Episode: 40223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00010804030898725614\n",
      "Q Loss:  0.0007557753706350923\n",
      "Policy Loss:  -0.008382325991988182\n",
      "[(0.00044, 0.16991), (0.0, 0.1697), (1.0, 0.16991)]\n",
      "Alpha*: 0.0 tau*: 0.1697 Episode: 40227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.4529490726999938e-05\n",
      "Q Loss:  3.812891009147279e-05\n",
      "Policy Loss:  0.0014903333503752947\n",
      "[(0.00044, 0.1697), (0.0, 0.16949), (1.0, 0.1697)]\n",
      "Alpha*: 0.0 tau*: 0.16949 Episode: 40233 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.983952749171294e-05\n",
      "Q Loss:  0.004067735746502876\n",
      "Policy Loss:  0.3179359436035156\n",
      "[(0.00044, 0.16949), (0.0, 0.16928), (1.0, 0.16949)]\n",
      "Alpha*: 0.0 tau*: 0.16928 Episode: 40237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.7673903703689575\n",
      "Q Loss:  0.5474412441253662\n",
      "Policy Loss:  -3.30676007270813\n",
      "[(0.00044, 0.16928), (0.0, 0.16907), (1.0, 0.16928)]\n",
      "Alpha*: 0.0 tau*: 0.16907 Episode: 40241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.8702863454818726\n",
      "Q Loss:  0.503506600856781\n",
      "Policy Loss:  -4.122992992401123\n",
      "[(0.00044, 0.16907), (0.0, 0.16886), (1.0, 0.16907)]\n",
      "Alpha*: 0.0 tau*: 0.16886 Episode: 40246 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.7456579118734226e-05\n",
      "Q Loss:  0.004908212926238775\n",
      "Policy Loss:  0.015271781012415886\n",
      "[(0.00043, 0.16886), (0.0, 0.16865), (1.0, 0.16886)]\n",
      "Alpha*: 0.0 tau*: 0.16865 Episode: 40251 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  7.13958143023774e-05\n",
      "Q Loss:  40.24312210083008\n",
      "Policy Loss:  3.7915077209472656\n",
      "[(0.00043, 0.16865), (0.0, 0.16844), (1.0, 0.16865)]\n",
      "Alpha*: 0.0 tau*: 0.16844 Episode: 40257 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.237022272311151e-05\n",
      "Q Loss:  0.0026003180537372828\n",
      "Policy Loss:  0.009409070946276188\n",
      "[(0.00043, 0.16844), (0.0, 0.16823), (1.0, 0.16844)]\n",
      "Alpha*: 0.0 tau*: 0.16823 Episode: 40263 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.04201006889343262\n",
      "Value Loss:  1.3423481505014934e-05\n",
      "Q Loss:  8.703165804035962e-05\n",
      "Policy Loss:  -0.008121315389871597\n",
      "[(0.00043, 0.16823), (0.0, 0.16802), (1.0, 0.16823)]\n",
      "Alpha*: 0.0 tau*: 0.16802 Episode: 40267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01819634437561035\n",
      "Value Loss:  1.8540451492299326e-05\n",
      "Q Loss:  0.0008848969009704888\n",
      "Policy Loss:  -0.012007949873805046\n",
      "[(0.00043, 0.16802), (0.0, 0.16781), (1.0, 0.16802)]\n",
      "Alpha*: 0.0 tau*: 0.16781 Episode: 40272 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.084910870005842e-06\n",
      "Q Loss:  26.119009017944336\n",
      "Policy Loss:  2.474794864654541\n",
      "[(0.00042, 0.16781), (0.0, 0.1676), (1.0, 0.16781)]\n",
      "Alpha*: 0.0 tau*: 0.1676 Episode: 40278 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  3.9522194128949195e-05\n",
      "Q Loss:  12.921211242675781\n",
      "Policy Loss:  1.2104047536849976\n",
      "[(0.00042, 0.1676), (0.0, 0.16739), (1.0, 0.1676)]\n",
      "Alpha*: 0.0 tau*: 0.16739 Episode: 40285 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  9.758486703503877e-05\n",
      "Q Loss:  0.0005237447330728173\n",
      "Policy Loss:  -0.016053320840001106\n",
      "[(0.00042, 0.16739), (0.0, 0.16718), (1.0, 0.16739)]\n",
      "Alpha*: 0.0 tau*: 0.16718 Episode: 40289 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.0003142961068079e-05\n",
      "Q Loss:  0.00040169653948396444\n",
      "Policy Loss:  -0.007745856419205666\n",
      "[(0.00042, 0.16718), (0.0, 0.16697), (1.0, 0.16718)]\n",
      "Alpha*: 0.0 tau*: 0.16697 Episode: 40293 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0002022935077548027\n",
      "Q Loss:  0.0006344472640193999\n",
      "Policy Loss:  0.011878004297614098\n",
      "[(0.00042, 0.16697), (0.0, 0.16676), (1.0, 0.16697)]\n",
      "Alpha*: 0.0 tau*: 0.16676 Episode: 40297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  9.001110447570682e-05\n",
      "Q Loss:  0.00017038252553902566\n",
      "Policy Loss:  -0.0029973650816828012\n",
      "[(0.00042, 0.16676), (0.0, 0.16655), (1.0, 0.16676)]\n",
      "Alpha*: 0.0 tau*: 0.16655 Episode: 40303 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.03300833702087402\n",
      "Value Loss:  0.000439170136814937\n",
      "Q Loss:  0.00047407884267158806\n",
      "Policy Loss:  0.0019547701813280582\n",
      "[(0.00042, 0.16655), (0.0, 0.16635), (1.0, 0.16655)]\n",
      "Alpha*: 0.0 tau*: 0.16635 Episode: 40307 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0008451878093183041\n",
      "Q Loss:  0.009471986442804337\n",
      "Policy Loss:  0.3071739673614502\n",
      "[(0.00041, 0.16635), (0.0, 0.16615), (1.0, 0.16635)]\n",
      "Alpha*: 0.0 tau*: 0.16615 Episode: 40313 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  4.20812466472853e-05\n",
      "Q Loss:  0.001982221845537424\n",
      "Policy Loss:  -0.02247990481555462\n",
      "[(0.00041, 0.16615), (0.0, 0.16595), (1.0, 0.16615)]\n",
      "Alpha*: 0.0 tau*: 0.16595 Episode: 40317 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00028160822694189847\n",
      "Q Loss:  0.0005099701811559498\n",
      "Policy Loss:  -0.009672198444604874\n",
      "[(0.00041, 0.16595), (0.0, 0.16575), (1.0, 0.16595)]\n",
      "Alpha*: 0.0 tau*: 0.16575 Episode: 40321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0003253372269682586\n",
      "Q Loss:  0.007548852823674679\n",
      "Policy Loss:  0.28055769205093384\n",
      "[(0.00041, 0.16575), (0.0, 0.16555), (1.0, 0.16575)]\n",
      "Alpha*: 0.0 tau*: 0.16555 Episode: 40325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.257476806640625\n",
      "Q Loss:  5.151339530944824\n",
      "Policy Loss:  0.3137398660182953\n",
      "[(0.00041, 0.16555), (0.0, 0.16535), (1.0, 0.16555)]\n",
      "Alpha*: 0.0 tau*: 0.16535 Episode: 40364 length: 37 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  454.9938659667969\n",
      "Q Loss:  1423.3765869140625\n",
      "Policy Loss:  -53.059696197509766\n",
      "[(0.00041, 0.16535), (0.0, 0.16515), (1.0, 0.16535)]\n",
      "Alpha*: 0.0 tau*: 0.16515 Episode: 40368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015710951993241906\n",
      "Q Loss:  0.0006892277160659432\n",
      "Policy Loss:  -0.006312971003353596\n",
      "[(0.00041, 0.16515), (0.0, 0.16495), (1.0, 0.16515)]\n",
      "Alpha*: 0.0 tau*: 0.16495 Episode: 40373 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  2.7319395542144775\n",
      "Q Loss:  0.026895426213741302\n",
      "Policy Loss:  -0.35515713691711426\n",
      "[(0.00041, 0.16495), (0.0, 0.16475), (1.0, 0.16495)]\n",
      "Alpha*: 0.0 tau*: 0.16475 Episode: 40394 length: 17 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00011230367817915976\n",
      "Q Loss:  0.003832775168120861\n",
      "Policy Loss:  -0.020885897800326347\n",
      "[(0.0004, 0.16475), (0.0, 0.16455), (1.0, 0.16475)]\n",
      "Alpha*: 0.0 tau*: 0.16455 Episode: 40398 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.5204359889030457\n",
      "Q Loss:  2.500185012817383\n",
      "Policy Loss:  -0.378978967666626\n",
      "[(0.0004, 0.16455), (0.0, 0.16435), (1.0, 0.16455)]\n",
      "Alpha*: 0.0 tau*: 0.16435 Episode: 40511 length: 94 #teleports:19\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.9335236831684597e-05\n",
      "Q Loss:  11.516464233398438\n",
      "Policy Loss:  1.1744415760040283\n",
      "[(0.0004, 0.16435), (0.0, 0.16415), (1.0, 0.16435)]\n",
      "Alpha*: 0.0 tau*: 0.16415 Episode: 40516 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.5054707527160645\n",
      "Q Loss:  0.12189363688230515\n",
      "Policy Loss:  -1.7560763359069824\n",
      "[(0.0004, 0.16415), (0.0, 0.16395), (1.0, 0.16415)]\n",
      "Alpha*: 0.0 tau*: 0.16395 Episode: 40543 length: 23 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.027005910873413086\n",
      "Value Loss:  0.00018476488185115159\n",
      "Q Loss:  0.000734884524717927\n",
      "Policy Loss:  -0.01319492794573307\n",
      "[(0.0004, 0.16395), (0.0, 0.16375), (1.0, 0.16395)]\n",
      "Alpha*: 0.0 tau*: 0.16375 Episode: 40547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  81.18217468261719\n",
      "Q Loss:  0.04947775974869728\n",
      "Policy Loss:  -23.21936798095703\n",
      "[(0.0004, 0.16375), (0.0, 0.16355), (1.0, 0.16375)]\n",
      "Alpha*: 0.0 tau*: 0.16355 Episode: 40600 length: 45 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  153.0697479248047\n",
      "Q Loss:  225.1130828857422\n",
      "Policy Loss:  -33.562103271484375\n",
      "[(0.0004, 0.16355), (0.0, 0.16335), (1.0, 0.16355)]\n",
      "Alpha*: 0.0 tau*: 0.16335 Episode: 40667 length: 59 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  43842.84765625\n",
      "Q Loss:  40804.484375\n",
      "Policy Loss:  -51.99009704589844\n",
      "[(0.0004, 0.16335), (0.0, 0.16315), (1.0, 0.16335)]\n",
      "Alpha*: 0.0 tau*: 0.16315 Episode: 40694 length: 21 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.233077147044241e-05\n",
      "Q Loss:  0.0007695575477555394\n",
      "Policy Loss:  0.01593049243092537\n",
      "[(0.0004, 0.16315), (0.0, 0.16295), (1.0, 0.16315)]\n",
      "Alpha*: 0.0 tau*: 0.16295 Episode: 40698 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.632650234270841e-05\n",
      "Q Loss:  0.002953725401312113\n",
      "Policy Loss:  -0.011308431625366211\n",
      "[(0.0004, 0.16295), (0.0, 0.16275), (1.0, 0.16295)]\n",
      "Alpha*: 0.0 tau*: 0.16275 Episode: 40702 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.423789727705298e-06\n",
      "Q Loss:  0.0035296673886477947\n",
      "Policy Loss:  0.024744508787989616\n",
      "[(0.0004, 0.16275), (0.0, 0.16255), (1.0, 0.16275)]\n",
      "Alpha*: 0.0 tau*: 0.16255 Episode: 40707 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  7.951896986924112e-05\n",
      "Q Loss:  0.0010291137732565403\n",
      "Policy Loss:  0.2802882790565491\n",
      "[(0.0004, 0.16255), (0.0, 0.16235), (1.0, 0.16255)]\n",
      "Alpha*: 0.0 tau*: 0.16235 Episode: 40712 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  41646.30078125\n",
      "Q Loss:  38876.984375\n",
      "Policy Loss:  -12.712267875671387\n",
      "[(0.0004, 0.16235), (0.0, 0.16215), (1.0, 0.16235)]\n",
      "Alpha*: 0.0 tau*: 0.16215 Episode: 40736 length: 22 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.683384006260894e-05\n",
      "Q Loss:  0.0001967138086911291\n",
      "Policy Loss:  -0.0062598297372460365\n",
      "[(0.00041, 0.16215), (0.0, 0.16195), (1.0, 0.16215)]\n",
      "Alpha*: 0.0 tau*: 0.16195 Episode: 40741 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  467.38580322265625\n",
      "Q Loss:  1448.9725341796875\n",
      "Policy Loss:  -54.670841217041016\n",
      "[(0.00041, 0.16195), (0.0, 0.16175), (1.0, 0.16195)]\n",
      "Alpha*: 0.0 tau*: 0.16175 Episode: 40746 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.599901770532597e-05\n",
      "Q Loss:  0.00018378326785750687\n",
      "Policy Loss:  0.00511303311213851\n",
      "[(0.00041, 0.16175), (0.0, 0.16155), (1.0, 0.16175)]\n",
      "Alpha*: 0.0 tau*: 0.16155 Episode: 40750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00014764346997253597\n",
      "Q Loss:  0.00044620977132581174\n",
      "Policy Loss:  -0.010777847841382027\n",
      "[(0.00041, 0.16155), (0.0, 0.16135), (1.0, 0.16155)]\n",
      "Alpha*: 0.0 tau*: 0.16135 Episode: 40754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.037007808685302734\n",
      "Value Loss:  51133.92578125\n",
      "Q Loss:  48230.12109375\n",
      "Policy Loss:  -31.53689193725586\n",
      "[(0.00041, 0.16135), (0.0, 0.16115), (1.0, 0.16135)]\n",
      "Alpha*: 0.0 tau*: 0.16115 Episode: 40774 length: 18 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.8733282558969222e-05\n",
      "Q Loss:  9.163674258161336e-05\n",
      "Policy Loss:  0.003924364224076271\n",
      "[(0.00041, 0.16115), (0.0, 0.16095), (1.0, 0.16115)]\n",
      "Alpha*: 0.0 tau*: 0.16095 Episode: 40778 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.00019283502479083836\n",
      "Q Loss:  0.00013476068852469325\n",
      "Policy Loss:  -0.005370772909373045\n",
      "[(0.00041, 0.16095), (0.0, 0.16075), (1.0, 0.16095)]\n",
      "Alpha*: 0.0 tau*: 0.16075 Episode: 40782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  6.636585749220103e-05\n",
      "Q Loss:  0.0008192281238734722\n",
      "Policy Loss:  0.022940069437026978\n",
      "[(0.00042, 0.16075), (0.0, 0.16055), (1.0, 0.16075)]\n",
      "Alpha*: 0.0 tau*: 0.16055 Episode: 40786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  495.35687255859375\n",
      "Q Loss:  0.0008705313666723669\n",
      "Policy Loss:  -128.4546661376953\n",
      "[(0.00042, 0.16055), (0.0, 0.16035), (1.0, 0.16055)]\n",
      "Alpha*: 0.0 tau*: 0.16035 Episode: 40793 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.0188790559768677\n",
      "Q Loss:  0.20118434727191925\n",
      "Policy Loss:  -3.585437059402466\n",
      "[(0.00042, 0.16035), (0.0, 0.16015), (1.0, 0.16035)]\n",
      "Alpha*: 0.0 tau*: 0.16015 Episode: 40798 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.256808784295572e-06\n",
      "Q Loss:  8.10999990790151e-05\n",
      "Policy Loss:  0.005831629037857056\n",
      "[(0.00042, 0.16015), (0.0, 0.15995), (1.0, 0.16015)]\n",
      "Alpha*: 0.0 tau*: 0.15995 Episode: 40803 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.2446343791671097e-05\n",
      "Q Loss:  0.0001801300677470863\n",
      "Policy Loss:  0.011860761791467667\n",
      "[(0.00042, 0.15995), (0.0, 0.15975), (1.0, 0.15995)]\n",
      "Alpha*: 0.0 tau*: 0.15975 Episode: 40807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.089486537850462e-05\n",
      "Q Loss:  0.00010675178054952994\n",
      "Policy Loss:  0.0066538117825984955\n",
      "[(0.00042, 0.15975), (0.0, 0.15955), (1.0, 0.15975)]\n",
      "Alpha*: 0.0 tau*: 0.15955 Episode: 40812 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  3.321287294966169e-05\n",
      "Q Loss:  0.00015127245569601655\n",
      "Policy Loss:  0.006241088733077049\n",
      "[(0.00043, 0.15955), (0.0, 0.15935), (1.0, 0.15955)]\n",
      "Alpha*: 0.0 tau*: 0.15935 Episode: 40816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.113143849186599e-05\n",
      "Q Loss:  0.0002787546254694462\n",
      "Policy Loss:  0.00450761616230011\n",
      "[(0.00043, 0.15935), (0.0, 0.15915), (1.0, 0.15935)]\n",
      "Alpha*: 0.0 tau*: 0.15915 Episode: 40821 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  24.795961380004883\n",
      "Q Loss:  0.10813288390636444\n",
      "Policy Loss:  -8.176209449768066\n",
      "[(0.00043, 0.15915), (0.0, 0.15895), (1.0, 0.15915)]\n",
      "Alpha*: 0.0 tau*: 0.15895 Episode: 40924 length: 85 #teleports:18\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.520665293559432e-05\n",
      "Q Loss:  0.00023011243320070207\n",
      "Policy Loss:  -0.0003800126723945141\n",
      "[(0.00043, 0.15895), (0.0, 0.15875), (1.0, 0.15895)]\n",
      "Alpha*: 0.0 tau*: 0.15875 Episode: 40929 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.5686046835035086e-05\n",
      "Q Loss:  0.0004999040393158793\n",
      "Policy Loss:  0.011509752832353115\n",
      "[(0.00043, 0.15875), (0.0, 0.15855), (1.0, 0.15875)]\n",
      "Alpha*: 0.0 tau*: 0.15855 Episode: 40935 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  3.0936977863311768\n",
      "Q Loss:  0.4100305438041687\n",
      "Policy Loss:  -10.019426345825195\n",
      "[(0.00043, 0.15855), (0.0, 0.15835), (1.0, 0.15855)]\n",
      "Alpha*: 0.0 tau*: 0.15835 Episode: 40940 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  61.72010803222656\n",
      "Q Loss:  35.91987991333008\n",
      "Policy Loss:  -15.569580078125\n",
      "[(0.00043, 0.15835), (0.0, 0.15815), (1.0, 0.15835)]\n",
      "Alpha*: 0.0 tau*: 0.15815 Episode: 40983 length: 34 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  63.698429107666016\n",
      "Q Loss:  191.07791137695312\n",
      "Policy Loss:  -11.327364921569824\n",
      "[(0.00043, 0.15815), (0.0, 0.15795), (1.0, 0.15815)]\n",
      "Alpha*: 0.0 tau*: 0.15795 Episode: 41022 length: 33 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.6776207202346995e-06\n",
      "Q Loss:  0.00041819611215032637\n",
      "Policy Loss:  -0.006222104653716087\n",
      "[(0.00043, 0.15795), (0.0, 0.15775), (1.0, 0.15795)]\n",
      "Alpha*: 0.0 tau*: 0.15775 Episode: 41029 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  517.602783203125\n",
      "Q Loss:  1580.3262939453125\n",
      "Policy Loss:  -63.40826416015625\n",
      "[(0.00043, 0.15775), (0.0, 0.15755), (1.0, 0.15775)]\n",
      "Alpha*: 0.0 tau*: 0.15755 Episode: 41034 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.5561153292655945\n",
      "Q Loss:  0.02735338732600212\n",
      "Policy Loss:  -1.2371535301208496\n",
      "[(0.00043, 0.15755), (0.0, 0.15735), (1.0, 0.15755)]\n",
      "Alpha*: 0.0 tau*: 0.15735 Episode: 41135 length: 87 #teleports:14\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.7833826541900635\n",
      "Q Loss:  0.010532592423260212\n",
      "Policy Loss:  -1.1697583198547363\n",
      "[(0.00043, 0.15735), (0.0, 0.15715), (1.0, 0.15735)]\n",
      "Alpha*: 0.0 tau*: 0.15715 Episode: 41190 length: 52 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04400968551635742\n",
      "Value Loss:  4.8881905968301e-05\n",
      "Q Loss:  0.0011580646969377995\n",
      "Policy Loss:  0.015519644133746624\n",
      "[(0.00043, 0.15715), (0.0, 0.15695), (1.0, 0.15715)]\n",
      "Alpha*: 0.0 tau*: 0.15695 Episode: 41194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.6051992133725435e-05\n",
      "Q Loss:  0.00012316058564465493\n",
      "Policy Loss:  -0.0046669673174619675\n",
      "[(0.00043, 0.15695), (0.0, 0.15675), (1.0, 0.15695)]\n",
      "Alpha*: 0.0 tau*: 0.15675 Episode: 41198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.7898902266751975e-05\n",
      "Q Loss:  0.0015606335364282131\n",
      "Policy Loss:  0.28793197870254517\n",
      "[(0.00043, 0.15675), (0.0, 0.15655), (1.0, 0.15675)]\n",
      "Alpha*: 0.0 tau*: 0.15655 Episode: 41202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.9580671787261963\n",
      "Q Loss:  0.03972766175866127\n",
      "Policy Loss:  -4.365303993225098\n",
      "[(0.00043, 0.15655), (0.0, 0.15635), (1.0, 0.15655)]\n",
      "Alpha*: 0.0 tau*: 0.15635 Episode: 41207 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.8649053496774286e-05\n",
      "Q Loss:  0.0003540724574122578\n",
      "Policy Loss:  0.005529377609491348\n",
      "[(0.00043, 0.15635), (0.0, 0.15615), (1.0, 0.15635)]\n",
      "Alpha*: 0.0 tau*: 0.15615 Episode: 41211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.2612429145519855e-06\n",
      "Q Loss:  9.457157284487039e-05\n",
      "Policy Loss:  0.000415793270803988\n",
      "[(0.00043, 0.15615), (0.0, 0.15595), (1.0, 0.15615)]\n",
      "Alpha*: 0.0 tau*: 0.15595 Episode: 41215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.0782417777809314e-06\n",
      "Q Loss:  6.226919504115358e-05\n",
      "Policy Loss:  0.005219305865466595\n",
      "[(0.00043, 0.15595), (0.0, 0.15575), (1.0, 0.15595)]\n",
      "Alpha*: 0.0 tau*: 0.15575 Episode: 41220 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  40.36547088623047\n",
      "Q Loss:  121.69164276123047\n",
      "Policy Loss:  -7.751923084259033\n",
      "[(0.00043, 0.15575), (0.0, 0.15555), (1.0, 0.15575)]\n",
      "Alpha*: 0.0 tau*: 0.15555 Episode: 41287 length: 52 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.462057742988691e-06\n",
      "Q Loss:  0.0008710334659554064\n",
      "Policy Loss:  0.008277771063148975\n",
      "[(0.00043, 0.15555), (0.0, 0.15535), (1.0, 0.15555)]\n",
      "Alpha*: 0.0 tau*: 0.15535 Episode: 41291 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.055866596288979e-05\n",
      "Q Loss:  0.0001057500921888277\n",
      "Policy Loss:  0.004489149898290634\n",
      "[(0.00043, 0.15535), (0.0, 0.15515), (1.0, 0.15535)]\n",
      "Alpha*: 0.0 tau*: 0.15515 Episode: 41295 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019610166549682617\n",
      "Value Loss:  4.511943552643061e-05\n",
      "Q Loss:  0.0001904792443383485\n",
      "Policy Loss:  0.3007047772407532\n",
      "[(0.00043, 0.15515), (0.0, 0.15495), (1.0, 0.15515)]\n",
      "Alpha*: 0.0 tau*: 0.15495 Episode: 41299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.9193532466888428\n",
      "Q Loss:  0.5598164796829224\n",
      "Policy Loss:  -4.222746849060059\n",
      "[(0.00043, 0.15495), (0.0, 0.15475), (1.0, 0.15495)]\n",
      "Alpha*: 0.0 tau*: 0.15475 Episode: 41304 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.04100847244262695\n",
      "Value Loss:  9.007351764012128e-06\n",
      "Q Loss:  0.00010417825978947803\n",
      "Policy Loss:  0.007289936766028404\n",
      "[(0.00042, 0.15475), (0.0, 0.15455), (1.0, 0.15475)]\n",
      "Alpha*: 0.0 tau*: 0.15455 Episode: 41308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  5.941183189861476e-06\n",
      "Q Loss:  8.057539525907487e-05\n",
      "Policy Loss:  0.004976094700396061\n",
      "[(0.00042, 0.15455), (0.0, 0.15435), (1.0, 0.15455)]\n",
      "Alpha*: 0.0 tau*: 0.15435 Episode: 41314 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  95.02279663085938\n",
      "Q Loss:  0.0018398566171526909\n",
      "Policy Loss:  -23.75969123840332\n",
      "[(0.00042, 0.15435), (0.0, 0.15415), (1.0, 0.15435)]\n",
      "Alpha*: 0.0 tau*: 0.15415 Episode: 41338 length: 22 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  2.2898891529621324e-06\n",
      "Q Loss:  0.0001115372433559969\n",
      "Policy Loss:  -0.003147137351334095\n",
      "[(0.00042, 0.15415), (0.0, 0.15395), (1.0, 0.15415)]\n",
      "Alpha*: 0.0 tau*: 0.15395 Episode: 41342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  32628.4453125\n",
      "Q Loss:  30532.025390625\n",
      "Policy Loss:  -16.871782302856445\n",
      "[(0.00042, 0.15395), (0.0, 0.15375), (1.0, 0.15395)]\n",
      "Alpha*: 0.0 tau*: 0.15375 Episode: 41375 length: 28 #teleports:5\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.0813222363358364e-05\n",
      "Q Loss:  9.15033888304606e-06\n",
      "Policy Loss:  -0.0005342314252629876\n",
      "[(0.00042, 0.15375), (0.0, 0.15355), (1.0, 0.15375)]\n",
      "Alpha*: 0.0 tau*: 0.15355 Episode: 41379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  49.15680694580078\n",
      "Q Loss:  74.05570983886719\n",
      "Policy Loss:  -11.478290557861328\n",
      "[(0.00042, 0.15355), (0.0, 0.15335), (1.0, 0.15355)]\n",
      "Alpha*: 0.0 tau*: 0.15335 Episode: 41483 length: 85 #teleports:19\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.036008358001708984\n",
      "Value Loss:  0.00012379353574942797\n",
      "Q Loss:  0.0015467343619093299\n",
      "Policy Loss:  -0.023296190425753593\n",
      "[(0.00042, 0.15335), (0.0, 0.15315), (1.0, 0.15335)]\n",
      "Alpha*: 0.0 tau*: 0.15315 Episode: 41487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  6.714556366205215e-05\n",
      "Q Loss:  0.00018704068497754633\n",
      "Policy Loss:  0.0051469276659190655\n",
      "[(0.00042, 0.15315), (0.0, 0.15295), (1.0, 0.15315)]\n",
      "Alpha*: 0.0 tau*: 0.15295 Episode: 41491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  29961.48828125\n",
      "Q Loss:  27910.2890625\n",
      "Policy Loss:  -34.53395080566406\n",
      "[(0.00042, 0.15295), (0.0, 0.15275), (1.0, 0.15295)]\n",
      "Alpha*: 0.0 tau*: 0.15275 Episode: 41560 length: 61 #teleports:8\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  6.544378265971318e-06\n",
      "Q Loss:  0.0004359909798949957\n",
      "Policy Loss:  -0.0002759414492174983\n",
      "[(0.00043, 0.15275), (0.0, 0.15255), (1.0, 0.15275)]\n",
      "Alpha*: 0.0 tau*: 0.15255 Episode: 41565 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1059.1806640625\n",
      "Q Loss:  1898.0439453125\n",
      "Policy Loss:  -132.9067840576172\n",
      "[(0.00043, 0.15255), (0.0, 0.15235), (1.0, 0.15255)]\n",
      "Alpha*: 0.0 tau*: 0.15235 Episode: 41570 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.63734101888258e-05\n",
      "Q Loss:  0.001815131981857121\n",
      "Policy Loss:  -0.012466957792639732\n",
      "[(0.00042, 0.15235), (0.0, 0.15215), (1.0, 0.15235)]\n",
      "Alpha*: 0.0 tau*: 0.15215 Episode: 41575 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.126673229620792e-05\n",
      "Q Loss:  6.021693116053939e-05\n",
      "Policy Loss:  0.001099421177059412\n",
      "[(0.00042, 0.15215), (0.0, 0.15195), (1.0, 0.15215)]\n",
      "Alpha*: 0.0 tau*: 0.15195 Episode: 41580 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  3.605460733524524e-05\n",
      "Q Loss:  0.00010812382970470935\n",
      "Policy Loss:  0.0016818195581436157\n",
      "[(0.00042, 0.15195), (0.0, 0.15175), (1.0, 0.15195)]\n",
      "Alpha*: 0.0 tau*: 0.15175 Episode: 41585 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.131905436515808\n",
      "Q Loss:  0.054994549602270126\n",
      "Policy Loss:  -1.6385269165039062\n",
      "[(0.00042, 0.15175), (0.0, 0.15155), (1.0, 0.15175)]\n",
      "Alpha*: 0.0 tau*: 0.15155 Episode: 41632 length: 43 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  3.142381683574058e-05\n",
      "Q Loss:  0.0004691309295594692\n",
      "Policy Loss:  0.0009909520158544183\n",
      "[(0.00042, 0.15155), (0.0, 0.15135), (1.0, 0.15155)]\n",
      "Alpha*: 0.0 tau*: 0.15135 Episode: 41636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  3.513511910568923e-05\n",
      "Q Loss:  0.00018180558981839567\n",
      "Policy Loss:  0.0016308649210259318\n",
      "[(0.00042, 0.15135), (0.0, 0.15115), (1.0, 0.15135)]\n",
      "Alpha*: 0.0 tau*: 0.15115 Episode: 41640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00013903078797739\n",
      "Q Loss:  0.0008114129886962473\n",
      "Policy Loss:  0.012860243208706379\n",
      "[(0.00042, 0.15115), (0.0, 0.15095), (1.0, 0.15115)]\n",
      "Alpha*: 0.0 tau*: 0.15095 Episode: 41644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  2.2237936718738638e-06\n",
      "Q Loss:  0.022529715672135353\n",
      "Policy Loss:  0.3651629090309143\n",
      "[(0.00042, 0.15095), (0.0, 0.15075), (1.0, 0.15095)]\n",
      "Alpha*: 0.0 tau*: 0.15075 Episode: 41648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  2.900116205215454\n",
      "Q Loss:  0.5430291891098022\n",
      "Policy Loss:  -4.018057823181152\n",
      "[(0.00042, 0.15075), (0.0, 0.15055), (1.0, 0.15075)]\n",
      "Alpha*: 0.0 tau*: 0.15055 Episode: 41652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.8151211738586426\n",
      "Q Loss:  18.288923263549805\n",
      "Policy Loss:  -1.3359792232513428\n",
      "[(0.00042, 0.15055), (0.0, 0.15035), (1.0, 0.15055)]\n",
      "Alpha*: 0.0 tau*: 0.15035 Episode: 41730 length: 69 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.8035959732951596e-05\n",
      "Q Loss:  8.541122952010483e-05\n",
      "Policy Loss:  0.0017322672065347433\n",
      "[(0.00042, 0.15035), (0.0, 0.15015), (1.0, 0.15035)]\n",
      "Alpha*: 0.0 tau*: 0.15015 Episode: 41734 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.669597051863093e-05\n",
      "Q Loss:  0.0009783032583072782\n",
      "Policy Loss:  -0.008681952953338623\n",
      "[(0.00041, 0.15015), (0.0, 0.14995), (1.0, 0.15015)]\n",
      "Alpha*: 0.0 tau*: 0.14995 Episode: 41738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.3870521797798574e-05\n",
      "Q Loss:  0.0019204295240342617\n",
      "Policy Loss:  0.013030815869569778\n",
      "[(0.00041, 0.14995), (0.0, 0.14975), (1.0, 0.14995)]\n",
      "Alpha*: 0.0 tau*: 0.14975 Episode: 41743 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.5339719286421314e-05\n",
      "Q Loss:  0.00026628701016306877\n",
      "Policy Loss:  -0.004120238590985537\n",
      "[(0.00041, 0.14975), (0.0, 0.14955), (1.0, 0.14975)]\n",
      "Alpha*: 0.0 tau*: 0.14955 Episode: 41748 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  0.0002154711983166635\n",
      "Q Loss:  25.129920959472656\n",
      "Policy Loss:  2.4539783000946045\n",
      "[(0.00041, 0.14955), (0.0, 0.14935), (1.0, 0.14955)]\n",
      "Alpha*: 0.0 tau*: 0.14935 Episode: 41754 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  538.8784790039062\n",
      "Q Loss:  1927.681396484375\n",
      "Policy Loss:  -57.452980041503906\n",
      "[(0.00041, 0.14935), (0.0, 0.14915), (1.0, 0.14935)]\n",
      "Alpha*: 0.0 tau*: 0.14915 Episode: 41760 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015196800231933594\n",
      "Value Loss:  53494.41796875\n",
      "Q Loss:  49729.47265625\n",
      "Policy Loss:  -10.680350303649902\n",
      "[(0.00041, 0.14915), (0.0, 0.14895), (1.0, 0.14915)]\n",
      "Alpha*: 0.0 tau*: 0.14895 Episode: 41781 length: 17 #teleports:4\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  542.114501953125\n",
      "Q Loss:  1630.47509765625\n",
      "Policy Loss:  -65.70295715332031\n",
      "[(0.00041, 0.14895), (0.0, 0.14875), (1.0, 0.14895)]\n",
      "Alpha*: 0.0 tau*: 0.14875 Episode: 41785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.227737604698632e-05\n",
      "Q Loss:  12.857988357543945\n",
      "Policy Loss:  1.245955228805542\n",
      "[(0.00041, 0.14875), (0.0, 0.14855), (1.0, 0.14875)]\n",
      "Alpha*: 0.0 tau*: 0.14855 Episode: 41789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00033747160341590643\n",
      "Q Loss:  0.0011117769172415137\n",
      "Policy Loss:  0.009211448952555656\n",
      "[(0.00041, 0.14855), (0.0, 0.14835), (1.0, 0.14855)]\n",
      "Alpha*: 0.0 tau*: 0.14835 Episode: 41793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00017399904027115554\n",
      "Q Loss:  0.023799851536750793\n",
      "Policy Loss:  0.05025692284107208\n",
      "[(0.00041, 0.14835), (0.0, 0.14815), (1.0, 0.14835)]\n",
      "Alpha*: 0.0 tau*: 0.14815 Episode: 41797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0001326035853708163\n",
      "Q Loss:  0.0024533013347536325\n",
      "Policy Loss:  0.5938857793807983\n",
      "[(0.00041, 0.14815), (0.0, 0.14795), (1.0, 0.14815)]\n",
      "Alpha*: 0.0 tau*: 0.14795 Episode: 41802 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.02900552749633789\n",
      "Value Loss:  83.79414367675781\n",
      "Q Loss:  47.841915130615234\n",
      "Policy Loss:  -19.18691062927246\n",
      "[(0.00041, 0.14795), (0.0, 0.14775), (1.0, 0.14795)]\n",
      "Alpha*: 0.0 tau*: 0.14775 Episode: 41833 length: 27 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.841876084858086e-05\n",
      "Q Loss:  0.0012642008950933814\n",
      "Policy Loss:  0.01455440279096365\n",
      "[(0.00041, 0.14775), (0.0, 0.14755), (1.0, 0.14775)]\n",
      "Alpha*: 0.0 tau*: 0.14755 Episode: 41838 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  9.374591172672808e-06\n",
      "Q Loss:  0.03330016881227493\n",
      "Policy Loss:  0.06767746806144714\n",
      "[(0.00041, 0.14755), (0.0, 0.14735), (1.0, 0.14755)]\n",
      "Alpha*: 0.0 tau*: 0.14735 Episode: 41843 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011003732681274414\n",
      "Value Loss:  556.9989624023438\n",
      "Q Loss:  1648.8116455078125\n",
      "Policy Loss:  -66.83918762207031\n",
      "[(0.00041, 0.14735), (0.0, 0.14715), (1.0, 0.14735)]\n",
      "Alpha*: 0.0 tau*: 0.14715 Episode: 41848 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  556.996826171875\n",
      "Q Loss:  1954.513916015625\n",
      "Policy Loss:  -60.716941833496094\n",
      "[(0.0004, 0.14715), (0.0, 0.14695), (1.0, 0.14715)]\n",
      "Alpha*: 0.0 tau*: 0.14695 Episode: 41852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.0178237062064e-05\n",
      "Q Loss:  0.0007811469258740544\n",
      "Policy Loss:  0.001088748686015606\n",
      "[(0.00038, 0.14695), (0.0, 0.14675), (1.0, 0.14695)]\n",
      "Alpha*: 0.0 tau*: 0.14675 Episode: 41856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012005805969238281\n",
      "Value Loss:  0.0003040399751625955\n",
      "Q Loss:  0.033770520240068436\n",
      "Policy Loss:  0.07635006308555603\n",
      "[(0.00037, 0.14675), (0.0, 0.14655), (1.0, 0.14675)]\n",
      "Alpha*: 0.0 tau*: 0.14655 Episode: 41861 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.8624453544616699\n",
      "Q Loss:  0.024123262614011765\n",
      "Policy Loss:  -2.6882078647613525\n",
      "[(0.00036, 0.14655), (0.0, 0.14635), (1.0, 0.14655)]\n",
      "Alpha*: 0.0 tau*: 0.14635 Episode: 41866 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002683210768736899\n",
      "Q Loss:  0.0008345996611751616\n",
      "Policy Loss:  -0.014447137713432312\n",
      "[(0.00035, 0.14635), (0.0, 0.14615), (1.0, 0.14635)]\n",
      "Alpha*: 0.0 tau*: 0.14615 Episode: 41873 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00012498207797762007\n",
      "Q Loss:  0.0009892347734421492\n",
      "Policy Loss:  0.010055556893348694\n",
      "[(0.00034, 0.14615), (0.0, 0.14595), (1.0, 0.14615)]\n",
      "Alpha*: 0.0 tau*: 0.14595 Episode: 41877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  7.442553760483861e-05\n",
      "Q Loss:  0.001332281855866313\n",
      "Policy Loss:  0.30019399523735046\n",
      "[(0.00034, 0.14595), (0.0, 0.14575), (1.0, 0.14595)]\n",
      "Alpha*: 0.0 tau*: 0.14575 Episode: 41881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  56769.14453125\n",
      "Q Loss:  52885.453125\n",
      "Policy Loss:  -13.500441551208496\n",
      "[(0.00035, 0.14575), (0.0, 0.14555), (1.0, 0.14575)]\n",
      "Alpha*: 0.0 tau*: 0.14555 Episode: 41899 length: 16 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.02300405502319336\n",
      "Value Loss:  99.81475830078125\n",
      "Q Loss:  174.7758331298828\n",
      "Policy Loss:  -19.211902618408203\n",
      "[(0.00036, 0.14555), (0.0, 0.14535), (1.0, 0.14555)]\n",
      "Alpha*: 0.0 tau*: 0.14535 Episode: 41947 length: 45 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  0.0005974851083010435\n",
      "Q Loss:  0.00030175611027516425\n",
      "Policy Loss:  0.003946451470255852\n",
      "[(0.00038, 0.14535), (0.0, 0.14515), (1.0, 0.14535)]\n",
      "Alpha*: 0.0 tau*: 0.14515 Episode: 41951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00038067862624302506\n",
      "Q Loss:  0.001499171950854361\n",
      "Policy Loss:  -0.017032386735081673\n",
      "[(0.00039, 0.14515), (0.0, 0.14495), (1.0, 0.14515)]\n",
      "Alpha*: 0.0 tau*: 0.14495 Episode: 41955 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00018953366088680923\n",
      "Q Loss:  0.0006741289980709553\n",
      "Policy Loss:  0.011059699580073357\n",
      "[(0.0004, 0.14495), (0.0, 0.14475), (1.0, 0.14495)]\n",
      "Alpha*: 0.0 tau*: 0.14475 Episode: 41959 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  72.66446685791016\n",
      "Q Loss:  210.94906616210938\n",
      "Policy Loss:  -8.524483680725098\n",
      "[(0.00041, 0.14475), (0.0, 0.14455), (1.0, 0.14475)]\n",
      "Alpha*: 0.0 tau*: 0.14455 Episode: 41995 length: 32 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.00015527906361967325\n",
      "Q Loss:  14.953204154968262\n",
      "Policy Loss:  1.4395283460617065\n",
      "[(0.00041, 0.14455), (0.0, 0.14435), (1.0, 0.14455)]\n",
      "Alpha*: 0.0 tau*: 0.14435 Episode: 42001 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0007168524898588657\n",
      "Q Loss:  0.0012436879333108664\n",
      "Policy Loss:  0.017074327915906906\n",
      "[(0.00041, 0.14435), (0.0, 0.14415), (1.0, 0.14435)]\n",
      "Alpha*: 0.0 tau*: 0.14415 Episode: 42005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0007478531915694475\n",
      "Q Loss:  0.00011303844075882807\n",
      "Policy Loss:  0.0042769755236804485\n",
      "[(0.00041, 0.14415), (0.0, 0.14395), (1.0, 0.14415)]\n",
      "Alpha*: 0.0 tau*: 0.14395 Episode: 42009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0009657234768383205\n",
      "Q Loss:  0.0003679422661662102\n",
      "Policy Loss:  -0.0044448357075452805\n",
      "[(0.0004, 0.14395), (0.0, 0.14375), (1.0, 0.14395)]\n",
      "Alpha*: 0.0 tau*: 0.14375 Episode: 42013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.7371082305908203\n",
      "Q Loss:  0.061915405094623566\n",
      "Policy Loss:  -3.209014654159546\n",
      "[(0.0004, 0.14375), (0.0, 0.14355), (1.0, 0.14375)]\n",
      "Alpha*: 0.0 tau*: 0.14355 Episode: 42017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06801533699035645\n",
      "Value Loss:  43136.9921875\n",
      "Q Loss:  40168.0\n",
      "Policy Loss:  -18.174821853637695\n",
      "[(0.0004, 0.14355), (0.0, 0.14335), (1.0, 0.14355)]\n",
      "Alpha*: 0.0 tau*: 0.14335 Episode: 42066 length: 42 #teleports:7\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  45508.37890625\n",
      "Q Loss:  42549.0390625\n",
      "Policy Loss:  -45.0938606262207\n",
      "[(0.00041, 0.14335), (0.0, 0.14315), (1.0, 0.14335)]\n",
      "Alpha*: 0.0 tau*: 0.14315 Episode: 42090 length: 20 #teleports:4\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00015812329365871847\n",
      "Q Loss:  0.033892810344696045\n",
      "Policy Loss:  0.08885027468204498\n",
      "[(0.00041, 0.14315), (0.0, 0.14295), (1.0, 0.14315)]\n",
      "Alpha*: 0.0 tau*: 0.14295 Episode: 42094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.3671610355377197\n",
      "Q Loss:  0.11476004123687744\n",
      "Policy Loss:  -1.7282235622406006\n",
      "[(0.0004, 0.14295), (0.0, 0.14275), (1.0, 0.14295)]\n",
      "Alpha*: 0.0 tau*: 0.14275 Episode: 42121 length: 21 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.002269626362249255\n",
      "Q Loss:  0.0006117478478699923\n",
      "Policy Loss:  0.0018202997744083405\n",
      "[(0.00039, 0.14275), (0.0, 0.14255), (1.0, 0.14275)]\n",
      "Alpha*: 0.0 tau*: 0.14255 Episode: 42125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.595148468273692e-05\n",
      "Q Loss:  0.0002757134207058698\n",
      "Policy Loss:  0.009022552520036697\n",
      "[(0.00039, 0.14255), (0.0, 0.14235), (1.0, 0.14255)]\n",
      "Alpha*: 0.0 tau*: 0.14235 Episode: 42129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.9856891632080078\n",
      "Q Loss:  55.96955490112305\n",
      "Policy Loss:  -0.3674582839012146\n",
      "[(0.00038, 0.14235), (0.0, 0.14215), (1.0, 0.14235)]\n",
      "Alpha*: 0.0 tau*: 0.14215 Episode: 42156 length: 25 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04801058769226074\n",
      "Value Loss:  9.197893814416602e-05\n",
      "Q Loss:  0.000927719462197274\n",
      "Policy Loss:  0.004859814420342445\n",
      "[(0.00038, 0.14215), (0.0, 0.14195), (1.0, 0.14215)]\n",
      "Alpha*: 0.0 tau*: 0.14195 Episode: 42160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04700970649719238\n",
      "Value Loss:  32.628211975097656\n",
      "Q Loss:  0.8307334780693054\n",
      "Policy Loss:  -8.133685111999512\n",
      "[(0.00038, 0.14195), (0.0, 0.14175), (1.0, 0.14195)]\n",
      "Alpha*: 0.0 tau*: 0.14175 Episode: 42249 length: 79 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0001412414276273921\n",
      "Q Loss:  0.020027734339237213\n",
      "Policy Loss:  0.055487729609012604\n",
      "[(0.00037, 0.14175), (0.0, 0.14156), (1.0, 0.14175)]\n",
      "Alpha*: 0.0 tau*: 0.14156 Episode: 42255 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0001736336707836017\n",
      "Q Loss:  0.0063188327476382256\n",
      "Policy Loss:  0.31969019770622253\n",
      "[(0.00037, 0.14156), (0.0, 0.14137), (1.0, 0.14156)]\n",
      "Alpha*: 0.0 tau*: 0.14137 Episode: 42260 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0008384236134588718\n",
      "Q Loss:  0.00028815263067372143\n",
      "Policy Loss:  0.01279488019645214\n",
      "[(0.00036, 0.14137), (0.0, 0.14118), (1.0, 0.14137)]\n",
      "Alpha*: 0.0 tau*: 0.14118 Episode: 42264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001937337074195966\n",
      "Q Loss:  0.0002550522913224995\n",
      "Policy Loss:  -0.0031764102168381214\n",
      "[(0.00036, 0.14118), (0.0, 0.14099), (1.0, 0.14118)]\n",
      "Alpha*: 0.0 tau*: 0.14099 Episode: 42268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0003232593007851392\n",
      "Q Loss:  5.75767808186356e-05\n",
      "Policy Loss:  -0.006152511574327946\n",
      "[(0.00036, 0.14099), (0.0, 0.1408), (1.0, 0.14099)]\n",
      "Alpha*: 0.0 tau*: 0.1408 Episode: 42272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  49.36308670043945\n",
      "Q Loss:  137.08013916015625\n",
      "Policy Loss:  -8.227143287658691\n",
      "[(0.00036, 0.1408), (0.0, 0.14061), (1.0, 0.1408)]\n",
      "Alpha*: 0.0 tau*: 0.14061 Episode: 42331 length: 54 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  12439.9541015625\n",
      "Q Loss:  11512.9951171875\n",
      "Policy Loss:  -29.597572326660156\n",
      "[(0.00037, 0.14061), (0.0, 0.14042), (1.0, 0.14061)]\n",
      "Alpha*: 0.0 tau*: 0.14042 Episode: 42412 length: 73 #teleports:8\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0290067195892334\n",
      "Value Loss:  4.7042824007803574e-05\n",
      "Q Loss:  0.00011383309902157634\n",
      "Policy Loss:  0.0015920773148536682\n",
      "[(0.00037, 0.14042), (0.0, 0.14023), (1.0, 0.14042)]\n",
      "Alpha*: 0.0 tau*: 0.14023 Episode: 42417 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  9.68055974226445e-05\n",
      "Q Loss:  0.00017273423145525157\n",
      "Policy Loss:  -0.0041733416728675365\n",
      "[(0.00038, 0.14023), (0.0, 0.14004), (1.0, 0.14023)]\n",
      "Alpha*: 0.0 tau*: 0.14004 Episode: 42421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0002027114969678223\n",
      "Q Loss:  0.00016342202434316278\n",
      "Policy Loss:  0.0038905120454728603\n",
      "[(0.00038, 0.14004), (0.0, 0.13985), (1.0, 0.14004)]\n",
      "Alpha*: 0.0 tau*: 0.13985 Episode: 42426 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.52189987199381e-05\n",
      "Q Loss:  0.00015630692359991372\n",
      "Policy Loss:  0.003460918553173542\n",
      "[(0.00039, 0.13985), (0.0, 0.13966), (1.0, 0.13985)]\n",
      "Alpha*: 0.0 tau*: 0.13966 Episode: 42430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00035017330083064735\n",
      "Q Loss:  9.768035670276731e-05\n",
      "Policy Loss:  0.006497745402157307\n",
      "[(0.00039, 0.13966), (0.0, 0.13947), (1.0, 0.13966)]\n",
      "Alpha*: 0.0 tau*: 0.13947 Episode: 42434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00010619329987093806\n",
      "Q Loss:  375.3831787109375\n",
      "Policy Loss:  1.6856718063354492\n",
      "[(0.0004, 0.13947), (0.0, 0.13928), (1.0, 0.13947)]\n",
      "Alpha*: 0.0 tau*: 0.13928 Episode: 42440 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  671.7579345703125\n",
      "Q Loss:  1879.3489990234375\n",
      "Policy Loss:  -75.5584945678711\n",
      "[(0.0004, 0.13928), (0.0, 0.13909), (1.0, 0.13928)]\n",
      "Alpha*: 0.0 tau*: 0.13909 Episode: 42447 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  671.9102172851562\n",
      "Q Loss:  0.00011823706154245883\n",
      "Policy Loss:  -149.09188842773438\n",
      "[(0.00039, 0.13909), (0.0, 0.1389), (1.0, 0.13909)]\n",
      "Alpha*: 0.0 tau*: 0.1389 Episode: 42453 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00011715656728483737\n",
      "Q Loss:  0.0003332384512759745\n",
      "Policy Loss:  -0.006364225409924984\n",
      "[(0.00038, 0.1389), (0.0, 0.13871), (1.0, 0.1389)]\n",
      "Alpha*: 0.0 tau*: 0.13871 Episode: 42457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00015132197586353868\n",
      "Q Loss:  0.00041260660509578884\n",
      "Policy Loss:  0.005461788270622492\n",
      "[(0.00037, 0.13871), (0.0, 0.13852), (1.0, 0.13871)]\n",
      "Alpha*: 0.0 tau*: 0.13852 Episode: 42463 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00019957295444328338\n",
      "Q Loss:  0.0003591669665183872\n",
      "Policy Loss:  -0.0076162549667060375\n",
      "[(0.00036, 0.13852), (0.0, 0.13833), (1.0, 0.13852)]\n",
      "Alpha*: 0.0 tau*: 0.13833 Episode: 42467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052011728286743164\n",
      "Value Loss:  0.9065133929252625\n",
      "Q Loss:  0.12469761818647385\n",
      "Policy Loss:  -1.9026387929916382\n",
      "[(0.00036, 0.13833), (0.0, 0.13814), (1.0, 0.13833)]\n",
      "Alpha*: 0.0 tau*: 0.13814 Episode: 42538 length: 62 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.9578955173492432\n",
      "Q Loss:  0.6384965777397156\n",
      "Policy Loss:  -2.7211592197418213\n",
      "[(0.00035, 0.13814), (0.0, 0.13795), (1.0, 0.13814)]\n",
      "Alpha*: 0.0 tau*: 0.13795 Episode: 42543 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.9511036276817322\n",
      "Q Loss:  0.6197199821472168\n",
      "Policy Loss:  -1.2868684530258179\n",
      "[(0.00035, 0.13795), (0.0, 0.13776), (1.0, 0.13795)]\n",
      "Alpha*: 0.0 tau*: 0.13776 Episode: 42547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.9371920228004456\n",
      "Q Loss:  0.010376052930951118\n",
      "Policy Loss:  -4.238036632537842\n",
      "[(0.00035, 0.13776), (0.0, 0.13757), (1.0, 0.13776)]\n",
      "Alpha*: 0.0 tau*: 0.13757 Episode: 42552 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  118.27889251708984\n",
      "Q Loss:  136.34437561035156\n",
      "Policy Loss:  -22.155759811401367\n",
      "[(0.00036, 0.13757), (0.0, 0.13738), (1.0, 0.13757)]\n",
      "Alpha*: 0.0 tau*: 0.13738 Episode: 42639 length: 68 #teleports:19\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.3549280166625977\n",
      "Q Loss:  0.2689851224422455\n",
      "Policy Loss:  -1.0275977849960327\n",
      "[(0.00037, 0.13738), (0.0, 0.13719), (1.0, 0.13738)]\n",
      "Alpha*: 0.0 tau*: 0.13719 Episode: 42663 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.086487312335521e-05\n",
      "Q Loss:  0.0018540509045124054\n",
      "Policy Loss:  0.01974870264530182\n",
      "[(0.00038, 0.13719), (0.0, 0.137), (1.0, 0.13719)]\n",
      "Alpha*: 0.0 tau*: 0.137 Episode: 42667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  0.0005189807270653546\n",
      "Q Loss:  0.000650857575237751\n",
      "Policy Loss:  0.01633436232805252\n",
      "[(0.00038, 0.137), (0.0, 0.13681), (1.0, 0.137)]\n",
      "Alpha*: 0.0 tau*: 0.13681 Episode: 42671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04201006889343262\n",
      "Value Loss:  0.8589921593666077\n",
      "Q Loss:  0.4434567093849182\n",
      "Policy Loss:  -2.757944345474243\n",
      "[(0.00037, 0.13681), (0.0, 0.13662), (1.0, 0.13681)]\n",
      "Alpha*: 0.0 tau*: 0.13662 Episode: 42675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  3.540473699104041e-05\n",
      "Q Loss:  0.0006063032196834683\n",
      "Policy Loss:  0.0003015827387571335\n",
      "[(0.00037, 0.13662), (0.0, 0.13643), (1.0, 0.13662)]\n",
      "Alpha*: 0.0 tau*: 0.13643 Episode: 42679 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.810469206655398e-05\n",
      "Q Loss:  7.359233859460801e-05\n",
      "Policy Loss:  0.006124044768512249\n",
      "[(0.00037, 0.13643), (0.0, 0.13624), (1.0, 0.13643)]\n",
      "Alpha*: 0.0 tau*: 0.13624 Episode: 42683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  3.334823850309476e-05\n",
      "Q Loss:  0.006459493190050125\n",
      "Policy Loss:  0.2739163339138031\n",
      "[(0.00036, 0.13624), (0.0, 0.13605), (1.0, 0.13624)]\n",
      "Alpha*: 0.0 tau*: 0.13605 Episode: 42688 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  6.935879355296493e-05\n",
      "Q Loss:  0.004161481745541096\n",
      "Policy Loss:  -0.03987782448530197\n",
      "[(0.00036, 0.13605), (0.0, 0.13586), (1.0, 0.13605)]\n",
      "Alpha*: 0.0 tau*: 0.13586 Episode: 42692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  660.0692138671875\n",
      "Q Loss:  1878.3138427734375\n",
      "Policy Loss:  -65.99612426757812\n",
      "[(0.00036, 0.13586), (0.0, 0.13567), (1.0, 0.13586)]\n",
      "Alpha*: 0.0 tau*: 0.13567 Episode: 42697 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.5552350282669067\n",
      "Q Loss:  0.35777974128723145\n",
      "Policy Loss:  -4.226377010345459\n",
      "[(0.00035, 0.13567), (0.0, 0.13548), (1.0, 0.13567)]\n",
      "Alpha*: 0.0 tau*: 0.13548 Episode: 42702 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.0838394165039062\n",
      "Q Loss:  6.331097602844238\n",
      "Policy Loss:  -0.17369835078716278\n",
      "[(0.00034, 0.13548), (0.0, 0.13529), (1.0, 0.13548)]\n",
      "Alpha*: 0.0 tau*: 0.13529 Episode: 42763 length: 56 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01135706901550293\n",
      "Value Loss:  0.00036354552139528096\n",
      "Q Loss:  7.666718011023477e-05\n",
      "Policy Loss:  -0.001345186261460185\n",
      "[(0.00033, 0.13529), (0.0, 0.1351), (1.0, 0.13529)]\n",
      "Alpha*: 0.0 tau*: 0.1351 Episode: 42767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0001344936463283375\n",
      "Q Loss:  6.112895061960444e-05\n",
      "Policy Loss:  -0.0035973333287984133\n",
      "[(0.00032, 0.1351), (0.0, 0.13491), (1.0, 0.1351)]\n",
      "Alpha*: 0.0 tau*: 0.13491 Episode: 42771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100918769836426\n",
      "Value Loss:  4.347356298239902e-05\n",
      "Q Loss:  5.817233613925055e-05\n",
      "Policy Loss:  0.0006383126019500196\n",
      "[(0.00031, 0.13491), (0.0, 0.13472), (1.0, 0.13491)]\n",
      "Alpha*: 0.0 tau*: 0.13472 Episode: 42775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  652.3522338867188\n",
      "Q Loss:  1831.65283203125\n",
      "Policy Loss:  -74.155517578125\n",
      "[(0.00031, 0.13472), (0.0, 0.13453), (1.0, 0.13472)]\n",
      "Alpha*: 0.0 tau*: 0.13453 Episode: 42781 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.693653939582873e-05\n",
      "Q Loss:  0.041342172771692276\n",
      "Policy Loss:  -0.08408500999212265\n",
      "[(0.00029, 0.13453), (0.0, 0.13434), (1.0, 0.13453)]\n",
      "Alpha*: 0.0 tau*: 0.13434 Episode: 42785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00011885758431162685\n",
      "Q Loss:  0.0008831415325403214\n",
      "Policy Loss:  -0.016073361039161682\n",
      "[(0.00027, 0.13434), (0.0, 0.13415), (1.0, 0.13434)]\n",
      "Alpha*: 0.0 tau*: 0.13415 Episode: 42790 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00034259838867001235\n",
      "Q Loss:  5.4758591431891546e-05\n",
      "Policy Loss:  0.0014745882945135236\n",
      "[(0.00025, 0.13415), (0.0, 0.13396), (1.0, 0.13415)]\n",
      "Alpha*: 0.0 tau*: 0.13396 Episode: 42794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014590024948120117\n",
      "Value Loss:  29.556421279907227\n",
      "Q Loss:  18.0080509185791\n",
      "Policy Loss:  -6.7571258544921875\n",
      "[(0.00024, 0.13396), (0.0, 0.13377), (1.0, 0.13396)]\n",
      "Alpha*: 0.0 tau*: 0.13377 Episode: 42896 length: 89 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.2508922815322876\n",
      "Q Loss:  4.930304050445557\n",
      "Policy Loss:  0.018322231248021126\n",
      "[(0.00023, 0.13377), (0.0, 0.13358), (1.0, 0.13377)]\n",
      "Alpha*: 0.0 tau*: 0.13358 Episode: 42944 length: 43 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.846841380232945e-05\n",
      "Q Loss:  0.010947894304990768\n",
      "Policy Loss:  -0.04129309952259064\n",
      "[(0.00023, 0.13358), (0.0, 0.13339), (1.0, 0.13358)]\n",
      "Alpha*: 0.0 tau*: 0.13339 Episode: 42950 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  41.50244140625\n",
      "Q Loss:  114.63976287841797\n",
      "Policy Loss:  -7.403629302978516\n",
      "[(0.00023, 0.13339), (0.0, 0.1332), (1.0, 0.13339)]\n",
      "Alpha*: 0.0 tau*: 0.1332 Episode: 43028 length: 63 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  4.970858572050929e-05\n",
      "Q Loss:  0.00020483657135628164\n",
      "Policy Loss:  -0.010530149564146996\n",
      "[(0.00022, 0.1332), (0.0, 0.13301), (1.0, 0.1332)]\n",
      "Alpha*: 0.0 tau*: 0.13301 Episode: 43032 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  9.606636740500107e-05\n",
      "Q Loss:  17.180036544799805\n",
      "Policy Loss:  1.5236907005310059\n",
      "[(0.00023, 0.13301), (0.0, 0.13282), (1.0, 0.13301)]\n",
      "Alpha*: 0.0 tau*: 0.13282 Episode: 43038 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.5170756998704746e-05\n",
      "Q Loss:  0.0008256729342974722\n",
      "Policy Loss:  -0.004949797410517931\n",
      "[(0.00024, 0.13282), (0.0, 0.13263), (1.0, 0.13282)]\n",
      "Alpha*: 0.0 tau*: 0.13263 Episode: 43042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  7.342144817812368e-05\n",
      "Q Loss:  0.00010971185838570818\n",
      "Policy Loss:  -0.004962441511452198\n",
      "[(0.00025, 0.13263), (0.0, 0.13244), (1.0, 0.13263)]\n",
      "Alpha*: 0.0 tau*: 0.13244 Episode: 43046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.2121410438558087e-05\n",
      "Q Loss:  0.0020839599892497063\n",
      "Policy Loss:  -0.021867362782359123\n",
      "[(0.00025, 0.13244), (0.0, 0.13225), (1.0, 0.13244)]\n",
      "Alpha*: 0.0 tau*: 0.13225 Episode: 43052 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  4.4168391468701884e-05\n",
      "Q Loss:  0.0006423905724659562\n",
      "Policy Loss:  0.007235703989863396\n",
      "[(0.00026, 0.13225), (0.0, 0.13206), (1.0, 0.13225)]\n",
      "Alpha*: 0.0 tau*: 0.13206 Episode: 43056 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.6391340494155884\n",
      "Q Loss:  0.11860853433609009\n",
      "Policy Loss:  -2.5368170738220215\n",
      "[(0.00027, 0.13206), (0.0, 0.13187), (1.0, 0.13206)]\n",
      "Alpha*: 0.0 tau*: 0.13187 Episode: 43060 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801011085510254\n",
      "Value Loss:  2.146552085876465\n",
      "Q Loss:  0.14673642814159393\n",
      "Policy Loss:  -1.0855833292007446\n",
      "[(0.00028, 0.13187), (0.0, 0.13168), (1.0, 0.13187)]\n",
      "Alpha*: 0.0 tau*: 0.13168 Episode: 43085 length: 24 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  3.6484748306975234e-06\n",
      "Q Loss:  0.04508374631404877\n",
      "Policy Loss:  0.09859558939933777\n",
      "[(0.00028, 0.13168), (0.0, 0.13149), (1.0, 0.13168)]\n",
      "Alpha*: 0.0 tau*: 0.13149 Episode: 43089 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021059751510620117\n",
      "Value Loss:  7.458410891558742e-06\n",
      "Q Loss:  0.0005598930292762816\n",
      "Policy Loss:  0.0019318665144965053\n",
      "[(0.00029, 0.13149), (0.0, 0.1313), (1.0, 0.13149)]\n",
      "Alpha*: 0.0 tau*: 0.1313 Episode: 43093 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  6.82845275150612e-05\n",
      "Q Loss:  0.00022064863878767937\n",
      "Policy Loss:  -0.0009402717696502805\n",
      "[(0.0003, 0.1313), (0.0, 0.13111), (1.0, 0.1313)]\n",
      "Alpha*: 0.0 tau*: 0.13111 Episode: 43097 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  4.927291229250841e-05\n",
      "Q Loss:  0.00018266818369738758\n",
      "Policy Loss:  0.0014176417607814074\n",
      "[(0.0003, 0.13111), (0.0, 0.13092), (1.0, 0.13111)]\n",
      "Alpha*: 0.0 tau*: 0.13092 Episode: 43102 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  8.69168434292078e-06\n",
      "Q Loss:  0.006546984426677227\n",
      "Policy Loss:  0.27471134066581726\n",
      "[(0.00031, 0.13092), (0.0, 0.13073), (1.0, 0.13092)]\n",
      "Alpha*: 0.0 tau*: 0.13073 Episode: 43107 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  9.402733667229768e-06\n",
      "Q Loss:  0.00012646793038584292\n",
      "Policy Loss:  -0.005729383789002895\n",
      "[(0.00031, 0.13073), (0.0, 0.13054), (1.0, 0.13073)]\n",
      "Alpha*: 0.0 tau*: 0.13054 Episode: 43111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  39220.1484375\n",
      "Q Loss:  36504.46875\n",
      "Policy Loss:  -12.916557312011719\n",
      "[(0.00032, 0.13054), (0.0, 0.13035), (1.0, 0.13054)]\n",
      "Alpha*: 0.0 tau*: 0.13035 Episode: 43136 length: 23 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  1.3230331205704715e-05\n",
      "Q Loss:  0.08114083856344223\n",
      "Policy Loss:  0.3689843416213989\n",
      "[(0.00033, 0.13035), (0.0, 0.13016), (1.0, 0.13035)]\n",
      "Alpha*: 0.0 tau*: 0.13016 Episode: 43142 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  219.59078979492188\n",
      "Q Loss:  368.1834411621094\n",
      "Policy Loss:  -39.56083679199219\n",
      "[(0.00034, 0.13016), (0.0, 0.12997), (1.0, 0.13016)]\n",
      "Alpha*: 0.0 tau*: 0.12997 Episode: 43225 length: 70 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04501008987426758\n",
      "Value Loss:  641.0890502929688\n",
      "Q Loss:  1774.96630859375\n",
      "Policy Loss:  -74.18968200683594\n",
      "[(0.00035, 0.12997), (0.0, 0.12978), (1.0, 0.12997)]\n",
      "Alpha*: 0.0 tau*: 0.12978 Episode: 43230 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  642.2113037109375\n",
      "Q Loss:  0.018753526732325554\n",
      "Policy Loss:  -145.77487182617188\n",
      "[(0.00036, 0.12978), (0.0, 0.12959), (1.0, 0.12978)]\n",
      "Alpha*: 0.0 tau*: 0.12959 Episode: 43235 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.6839416275615804e-05\n",
      "Q Loss:  0.007332851178944111\n",
      "Policy Loss:  -0.02497943863272667\n",
      "[(0.00036, 0.12959), (0.0, 0.1294), (1.0, 0.12959)]\n",
      "Alpha*: 0.0 tau*: 0.1294 Episode: 43242 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0001599524257471785\n",
      "Q Loss:  0.001377358566969633\n",
      "Policy Loss:  -0.021694686263799667\n",
      "[(0.00036, 0.1294), (0.0, 0.12921), (1.0, 0.1294)]\n",
      "Alpha*: 0.0 tau*: 0.12921 Episode: 43246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00017236785788554698\n",
      "Q Loss:  8.292676648125052e-05\n",
      "Policy Loss:  -0.0037857028655707836\n",
      "[(0.00036, 0.12921), (0.0, 0.12902), (1.0, 0.12921)]\n",
      "Alpha*: 0.0 tau*: 0.12902 Episode: 43251 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  641.3304443359375\n",
      "Q Loss:  9.245767432730645e-05\n",
      "Policy Loss:  -145.59169006347656\n",
      "[(0.00035, 0.12902), (0.0, 0.12883), (1.0, 0.12902)]\n",
      "Alpha*: 0.0 tau*: 0.12883 Episode: 43257 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00013478242908604443\n",
      "Q Loss:  0.005987514741718769\n",
      "Policy Loss:  0.023791885003447533\n",
      "[(0.00035, 0.12883), (0.0, 0.12864), (1.0, 0.12883)]\n",
      "Alpha*: 0.0 tau*: 0.12864 Episode: 43261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012587785720825195\n",
      "Value Loss:  5.13041959493421e-05\n",
      "Q Loss:  0.0005174357793293893\n",
      "Policy Loss:  0.2640655040740967\n",
      "[(0.00035, 0.12864), (0.0, 0.12845), (1.0, 0.12864)]\n",
      "Alpha*: 0.0 tau*: 0.12845 Episode: 43266 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010846138000488281\n",
      "Value Loss:  1.3149740880180616e-05\n",
      "Q Loss:  0.026263508945703506\n",
      "Policy Loss:  0.09845345467329025\n",
      "[(0.00034, 0.12845), (0.0, 0.12826), (1.0, 0.12845)]\n",
      "Alpha*: 0.0 tau*: 0.12826 Episode: 43271 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.3203994035720825\n",
      "Q Loss:  0.021520111709833145\n",
      "Policy Loss:  -1.0237046480178833\n",
      "[(0.00034, 0.12826), (0.0, 0.12807), (1.0, 0.12826)]\n",
      "Alpha*: 0.0 tau*: 0.12807 Episode: 43314 length: 36 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0007210385520011187\n",
      "Q Loss:  0.0001305567129747942\n",
      "Policy Loss:  0.005321237724274397\n",
      "[(0.00034, 0.12807), (0.0, 0.12788), (1.0, 0.12807)]\n",
      "Alpha*: 0.0 tau*: 0.12788 Episode: 43319 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  76.64387512207031\n",
      "Q Loss:  22.68344497680664\n",
      "Policy Loss:  -18.055606842041016\n",
      "[(0.00033, 0.12788), (0.0, 0.12769), (1.0, 0.12788)]\n",
      "Alpha*: 0.0 tau*: 0.12769 Episode: 43390 length: 67 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0027539818547666073\n",
      "Q Loss:  0.0004388857923913747\n",
      "Policy Loss:  0.00960802473127842\n",
      "[(0.00033, 0.12769), (0.0, 0.1275), (1.0, 0.12769)]\n",
      "Alpha*: 0.0 tau*: 0.1275 Episode: 43394 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1265.6927490234375\n",
      "Q Loss:  359.1562805175781\n",
      "Policy Loss:  -263.7402038574219\n",
      "[(0.00033, 0.1275), (0.0, 0.12731), (1.0, 0.1275)]\n",
      "Alpha*: 0.0 tau*: 0.12731 Episode: 43399 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  629.6549072265625\n",
      "Q Loss:  2131.93603515625\n",
      "Policy Loss:  -58.48491668701172\n",
      "[(0.00033, 0.12731), (0.0, 0.12712), (1.0, 0.12731)]\n",
      "Alpha*: 0.0 tau*: 0.12712 Episode: 43404 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00028475141152739525\n",
      "Q Loss:  0.0005078590475022793\n",
      "Policy Loss:  -0.015306558459997177\n",
      "[(0.00031, 0.12712), (0.0, 0.12693), (1.0, 0.12712)]\n",
      "Alpha*: 0.0 tau*: 0.12693 Episode: 43408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.001794284675270319\n",
      "Q Loss:  0.0003971667028963566\n",
      "Policy Loss:  -0.004985229577869177\n",
      "[(0.00029, 0.12693), (0.0, 0.12674), (1.0, 0.12693)]\n",
      "Alpha*: 0.0 tau*: 0.12674 Episode: 43412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.7208592295646667\n",
      "Q Loss:  0.09255542606115341\n",
      "Policy Loss:  -2.819483995437622\n",
      "[(0.00028, 0.12674), (0.0, 0.12655), (1.0, 0.12674)]\n",
      "Alpha*: 0.0 tau*: 0.12655 Episode: 43418 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013004541397094727\n",
      "Value Loss:  7.96233507571742e-05\n",
      "Q Loss:  3.9795751945348457e-05\n",
      "Policy Loss:  -0.0016369024524465203\n",
      "[(0.00027, 0.12655), (0.0, 0.12636), (1.0, 0.12655)]\n",
      "Alpha*: 0.0 tau*: 0.12636 Episode: 43423 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03800773620605469\n",
      "Value Loss:  0.0017747828969731927\n",
      "Q Loss:  0.012911348603665829\n",
      "Policy Loss:  0.2536701560020447\n",
      "[(0.00025, 0.12636), (0.0, 0.12617), (1.0, 0.12636)]\n",
      "Alpha*: 0.0 tau*: 0.12617 Episode: 43428 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.00016428905655629933\n",
      "Q Loss:  0.004665373358875513\n",
      "Policy Loss:  0.2952313721179962\n",
      "[(0.00025, 0.12617), (0.0, 0.12598), (1.0, 0.12617)]\n",
      "Alpha*: 0.0 tau*: 0.12598 Episode: 43434 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0008104745647870004\n",
      "Q Loss:  0.0004238180990796536\n",
      "Policy Loss:  0.004582527559250593\n",
      "[(0.00024, 0.12598), (0.0, 0.12579), (1.0, 0.12598)]\n",
      "Alpha*: 0.0 tau*: 0.12579 Episode: 43438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.8175562024116516\n",
      "Q Loss:  0.03829485923051834\n",
      "Policy Loss:  -0.7159634828567505\n",
      "[(0.00023, 0.12579), (0.0, 0.1256), (1.0, 0.12579)]\n",
      "Alpha*: 0.0 tau*: 0.1256 Episode: 43500 length: 54 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.001100946799851954\n",
      "Q Loss:  0.004299868363887072\n",
      "Policy Loss:  0.026400286704301834\n",
      "[(0.00023, 0.1256), (0.0, 0.12541), (1.0, 0.1256)]\n",
      "Alpha*: 0.0 tau*: 0.12541 Episode: 43506 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  9.201427747029811e-05\n",
      "Q Loss:  0.019398478791117668\n",
      "Policy Loss:  0.0774478018283844\n",
      "[(0.00023, 0.12541), (0.0, 0.12522), (1.0, 0.12541)]\n",
      "Alpha*: 0.0 tau*: 0.12522 Episode: 43510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  601.9547119140625\n",
      "Q Loss:  311.16943359375\n",
      "Policy Loss:  -133.19180297851562\n",
      "[(0.00023, 0.12522), (0.0, 0.12503), (1.0, 0.12522)]\n",
      "Alpha*: 0.0 tau*: 0.12503 Episode: 43515 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0008955193334259093\n",
      "Q Loss:  0.0019978026393800974\n",
      "Policy Loss:  0.031147010624408722\n",
      "[(0.00023, 0.12503), (0.0, 0.12484), (1.0, 0.12503)]\n",
      "Alpha*: 0.0 tau*: 0.12484 Episode: 43519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00024761719396337867\n",
      "Q Loss:  0.0007363707409240305\n",
      "Policy Loss:  0.016807662323117256\n",
      "[(0.00023, 0.12484), (0.0, 0.12465), (1.0, 0.12484)]\n",
      "Alpha*: 0.0 tau*: 0.12465 Episode: 43524 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0012682315427809954\n",
      "Q Loss:  0.006291172467172146\n",
      "Policy Loss:  0.02930862084031105\n",
      "[(0.00023, 0.12465), (0.0, 0.12446), (1.0, 0.12465)]\n",
      "Alpha*: 0.0 tau*: 0.12446 Episode: 43528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016194820404052734\n",
      "Value Loss:  0.007467469200491905\n",
      "Q Loss:  0.002625832101330161\n",
      "Policy Loss:  0.25351572036743164\n",
      "[(0.00023, 0.12446), (0.0, 0.12427), (1.0, 0.12446)]\n",
      "Alpha*: 0.0 tau*: 0.12427 Episode: 43532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.9024184346199036\n",
      "Q Loss:  0.041981857270002365\n",
      "Policy Loss:  -1.878947377204895\n",
      "[(0.00023, 0.12427), (0.0, 0.12408), (1.0, 0.12427)]\n",
      "Alpha*: 0.0 tau*: 0.12408 Episode: 43616 length: 74 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.3039506673812866\n",
      "Q Loss:  2.186568021774292\n",
      "Policy Loss:  -0.7638809680938721\n",
      "[(0.00024, 0.12408), (0.0, 0.12389), (1.0, 0.12408)]\n",
      "Alpha*: 0.0 tau*: 0.12389 Episode: 43658 length: 38 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04300999641418457\n",
      "Value Loss:  0.0005227578803896904\n",
      "Q Loss:  0.005015311762690544\n",
      "Policy Loss:  0.03353920578956604\n",
      "[(0.00024, 0.12389), (0.0, 0.1237), (1.0, 0.12389)]\n",
      "Alpha*: 0.0 tau*: 0.1237 Episode: 43662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.9270365238189697\n",
      "Q Loss:  0.024741243571043015\n",
      "Policy Loss:  -0.8446115851402283\n",
      "[(0.00024, 0.1237), (0.0, 0.12351), (1.0, 0.1237)]\n",
      "Alpha*: 0.0 tau*: 0.12351 Episode: 43714 length: 47 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0003128992975689471\n",
      "Q Loss:  0.013171955943107605\n",
      "Policy Loss:  0.0694538801908493\n",
      "[(0.00024, 0.12351), (0.0, 0.12332), (1.0, 0.12351)]\n",
      "Alpha*: 0.0 tau*: 0.12332 Episode: 43720 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  50436.21484375\n",
      "Q Loss:  46957.546875\n",
      "Policy Loss:  -32.593055725097656\n",
      "[(0.00025, 0.12332), (0.0, 0.12313), (1.0, 0.12332)]\n",
      "Alpha*: 0.0 tau*: 0.12313 Episode: 43765 length: 36 #teleports:9\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.7437183856964111\n",
      "Q Loss:  0.4628405272960663\n",
      "Policy Loss:  -2.449037790298462\n",
      "[(0.00026, 0.12313), (0.0, 0.12294), (1.0, 0.12313)]\n",
      "Alpha*: 0.0 tau*: 0.12294 Episode: 43769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.7431727051734924\n",
      "Q Loss:  0.4472743570804596\n",
      "Policy Loss:  -2.426379442214966\n",
      "[(0.00026, 0.12294), (0.0, 0.12275), (1.0, 0.12294)]\n",
      "Alpha*: 0.0 tau*: 0.12275 Episode: 43773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  596.8782348632812\n",
      "Q Loss:  1776.8741455078125\n",
      "Policy Loss:  -0.4688835144042969\n",
      "[(0.00027, 0.12275), (0.0, 0.12256), (1.0, 0.12275)]\n",
      "Alpha*: 0.0 tau*: 0.12256 Episode: 43779 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00035098643274977803\n",
      "Q Loss:  0.000785498064942658\n",
      "Policy Loss:  -0.002021512947976589\n",
      "[(0.00028, 0.12256), (0.0, 0.12237), (1.0, 0.12256)]\n",
      "Alpha*: 0.0 tau*: 0.12237 Episode: 43784 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00014943322457838804\n",
      "Q Loss:  0.0007801126921549439\n",
      "Policy Loss:  0.01273810863494873\n",
      "[(0.00029, 0.12237), (0.0, 0.12218), (1.0, 0.12237)]\n",
      "Alpha*: 0.0 tau*: 0.12218 Episode: 43790 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  90.67562103271484\n",
      "Q Loss:  104.4278335571289\n",
      "Policy Loss:  -19.507659912109375\n",
      "[(0.00029, 0.12218), (0.0, 0.12199), (1.0, 0.12218)]\n",
      "Alpha*: 0.0 tau*: 0.12199 Episode: 43879 length: 80 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.029006004333496094\n",
      "Value Loss:  0.0005459979875013232\n",
      "Q Loss:  0.000233304628636688\n",
      "Policy Loss:  -0.0005492963246069849\n",
      "[(0.00029, 0.12199), (0.0, 0.1218), (1.0, 0.12199)]\n",
      "Alpha*: 0.0 tau*: 0.1218 Episode: 43884 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.6387388061266392e-05\n",
      "Q Loss:  4.013747093267739e-05\n",
      "Policy Loss:  0.0030470378696918488\n",
      "[(0.00028, 0.1218), (0.0, 0.12161), (1.0, 0.1218)]\n",
      "Alpha*: 0.0 tau*: 0.12161 Episode: 43888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00038679910358041525\n",
      "Q Loss:  22.337360382080078\n",
      "Policy Loss:  1.5605854988098145\n",
      "[(0.00028, 0.12161), (0.0, 0.12142), (1.0, 0.12161)]\n",
      "Alpha*: 0.0 tau*: 0.12142 Episode: 43893 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0001686487375991419\n",
      "Q Loss:  0.0008265495416708291\n",
      "Policy Loss:  0.014578616246581078\n",
      "[(0.00027, 0.12142), (0.0, 0.12123), (1.0, 0.12142)]\n",
      "Alpha*: 0.0 tau*: 0.12123 Episode: 43897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005558509728871286\n",
      "Q Loss:  0.0033496106043457985\n",
      "Policy Loss:  -0.005712432786822319\n",
      "[(0.00027, 0.12123), (0.0, 0.12104), (1.0, 0.12123)]\n",
      "Alpha*: 0.0 tau*: 0.12104 Episode: 43901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00037427630741149187\n",
      "Q Loss:  0.0002419402007944882\n",
      "Policy Loss:  -6.644672248512506e-05\n",
      "[(0.00027, 0.12104), (0.0, 0.12085), (1.0, 0.12104)]\n",
      "Alpha*: 0.0 tau*: 0.12085 Episode: 43905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00011486586299724877\n",
      "Q Loss:  0.0002147640334442258\n",
      "Policy Loss:  0.0019452358828857541\n",
      "[(0.00027, 0.12085), (0.0, 0.12066), (1.0, 0.12085)]\n",
      "Alpha*: 0.0 tau*: 0.12066 Episode: 43909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00098171248100698\n",
      "Q Loss:  0.0008559856796637177\n",
      "Policy Loss:  0.007003352511674166\n",
      "[(0.00026, 0.12066), (0.0, 0.12047), (1.0, 0.12066)]\n",
      "Alpha*: 0.0 tau*: 0.12047 Episode: 43914 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0014760697958990932\n",
      "Q Loss:  0.0005507093737833202\n",
      "Policy Loss:  -0.003224576124921441\n",
      "[(0.00026, 0.12047), (0.0, 0.12028), (1.0, 0.12047)]\n",
      "Alpha*: 0.0 tau*: 0.12028 Episode: 43918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  0.0017095182556658983\n",
      "Q Loss:  0.0021402486599981785\n",
      "Policy Loss:  0.28094783425331116\n",
      "[(0.00026, 0.12028), (0.0, 0.12009), (1.0, 0.12028)]\n",
      "Alpha*: 0.0 tau*: 0.12009 Episode: 43922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  46.09117889404297\n",
      "Q Loss:  133.6391143798828\n",
      "Policy Loss:  -7.333384037017822\n",
      "[(0.00026, 0.12009), (0.0, 0.1199), (1.0, 0.12009)]\n",
      "Alpha*: 0.0 tau*: 0.1199 Episode: 43980 length: 54 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0004686436150223017\n",
      "Q Loss:  0.0018258843338117003\n",
      "Policy Loss:  -0.021889157593250275\n",
      "[(0.00027, 0.1199), (0.0, 0.11971), (1.0, 0.1199)]\n",
      "Alpha*: 0.0 tau*: 0.11971 Episode: 43984 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.001853298395872116\n",
      "Q Loss:  0.035637788474559784\n",
      "Policy Loss:  -0.035113394260406494\n",
      "[(0.00027, 0.11971), (0.0, 0.11952), (1.0, 0.11971)]\n",
      "Alpha*: 0.0 tau*: 0.11952 Episode: 43989 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0016041079070419073\n",
      "Q Loss:  0.0019795570988208055\n",
      "Policy Loss:  -0.030965033918619156\n",
      "[(0.00027, 0.11952), (0.0, 0.11933), (1.0, 0.11952)]\n",
      "Alpha*: 0.0 tau*: 0.11933 Episode: 43993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027005672454833984\n",
      "Value Loss:  0.00038692826637998223\n",
      "Q Loss:  0.0019052998395636678\n",
      "Policy Loss:  0.26241374015808105\n",
      "[(0.00027, 0.11933), (0.0, 0.11914), (1.0, 0.11933)]\n",
      "Alpha*: 0.0 tau*: 0.11914 Episode: 43997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.605832576751709\n",
      "Q Loss:  0.37961438298225403\n",
      "Policy Loss:  -6.1092610359191895\n",
      "[(0.00028, 0.11914), (0.0, 0.11895), (1.0, 0.11914)]\n",
      "Alpha*: 0.0 tau*: 0.11895 Episode: 44001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0004954616306349635\n",
      "Q Loss:  0.0046934508718550205\n",
      "Policy Loss:  -0.04176865518093109\n",
      "[(0.00028, 0.11895), (0.0, 0.11876), (1.0, 0.11895)]\n",
      "Alpha*: 0.0 tau*: 0.11876 Episode: 44005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  50.68269729614258\n",
      "Q Loss:  26.894641876220703\n",
      "Policy Loss:  -11.605427742004395\n",
      "[(0.00028, 0.11876), (0.0, 0.11857), (1.0, 0.11876)]\n",
      "Alpha*: 0.0 tau*: 0.11857 Episode: 44055 length: 49 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0026100522372871637\n",
      "Q Loss:  0.0016857101581990719\n",
      "Policy Loss:  -0.013951531611382961\n",
      "[(0.00028, 0.11857), (0.0, 0.11838), (1.0, 0.11857)]\n",
      "Alpha*: 0.0 tau*: 0.11838 Episode: 44059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0005797334015369415\n",
      "Q Loss:  0.00040651054587215185\n",
      "Policy Loss:  0.011310575529932976\n",
      "[(0.00029, 0.11838), (0.0, 0.11819), (1.0, 0.11838)]\n",
      "Alpha*: 0.0 tau*: 0.11819 Episode: 44063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7.422775524901226e-05\n",
      "Q Loss:  0.006620121654123068\n",
      "Policy Loss:  0.25513166189193726\n",
      "[(0.00029, 0.11819), (0.0, 0.11801), (1.0, 0.11819)]\n",
      "Alpha*: 0.0 tau*: 0.11801 Episode: 44067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  1.13718581199646\n",
      "Q Loss:  0.5865036249160767\n",
      "Policy Loss:  -3.1614277362823486\n",
      "[(0.00029, 0.11801), (0.0, 0.11783), (1.0, 0.11801)]\n",
      "Alpha*: 0.0 tau*: 0.11783 Episode: 44071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.1967133283615112\n",
      "Q Loss:  0.013225412927567959\n",
      "Policy Loss:  -0.916741669178009\n",
      "[(0.0003, 0.11783), (0.0, 0.11765), (1.0, 0.11783)]\n",
      "Alpha*: 0.0 tau*: 0.11765 Episode: 44119 length: 45 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04200863838195801\n",
      "Value Loss:  607.7109985351562\n",
      "Q Loss:  1802.2794189453125\n",
      "Policy Loss:  -56.73841094970703\n",
      "[(0.0003, 0.11765), (0.0, 0.11747), (1.0, 0.11765)]\n",
      "Alpha*: 0.0 tau*: 0.11747 Episode: 44124 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0032600427512079477\n",
      "Q Loss:  0.0027473154477775097\n",
      "Policy Loss:  0.019164428114891052\n",
      "[(0.00031, 0.11747), (0.0, 0.11729), (1.0, 0.11747)]\n",
      "Alpha*: 0.0 tau*: 0.11729 Episode: 44128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0002847862197086215\n",
      "Q Loss:  0.007965970784425735\n",
      "Policy Loss:  0.2450246810913086\n",
      "[(0.00031, 0.11729), (0.0, 0.11711), (1.0, 0.11729)]\n",
      "Alpha*: 0.0 tau*: 0.11711 Episode: 44132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.5099455714225769\n",
      "Q Loss:  0.22200968861579895\n",
      "Policy Loss:  -3.4384098052978516\n",
      "[(0.00031, 0.11711), (0.0, 0.11693), (1.0, 0.11711)]\n",
      "Alpha*: 0.0 tau*: 0.11693 Episode: 44136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  39417.30859375\n",
      "Q Loss:  36485.27734375\n",
      "Policy Loss:  -31.449344635009766\n",
      "[(0.0003, 0.11693), (0.0, 0.11675), (1.0, 0.11693)]\n",
      "Alpha*: 0.0 tau*: 0.11675 Episode: 44162 length: 23 #teleports:3\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0015286453999578953\n",
      "Q Loss:  0.008152511902153492\n",
      "Policy Loss:  0.024145375937223434\n",
      "[(0.00027, 0.11675), (0.0, 0.11657), (1.0, 0.11675)]\n",
      "Alpha*: 0.0 tau*: 0.11657 Episode: 44168 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.001052374835126102\n",
      "Q Loss:  0.0014971811324357986\n",
      "Policy Loss:  -0.023082643747329712\n",
      "[(0.00024, 0.11657), (0.0, 0.11639), (1.0, 0.11657)]\n",
      "Alpha*: 0.0 tau*: 0.11639 Episode: 44172 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013990402221679688\n",
      "Value Loss:  0.4781041145324707\n",
      "Q Loss:  0.18017813563346863\n",
      "Policy Loss:  -2.1052868366241455\n",
      "[(0.00022, 0.11639), (0.0, 0.11621), (1.0, 0.11639)]\n",
      "Alpha*: 0.0 tau*: 0.11621 Episode: 44176 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  63.827598571777344\n",
      "Q Loss:  94.57757568359375\n",
      "Policy Loss:  -12.034317016601562\n",
      "[(0.00021, 0.11621), (0.0, 0.11603), (1.0, 0.11621)]\n",
      "Alpha*: 0.0 tau*: 0.11603 Episode: 44265 length: 78 #teleports:11\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  95.7265396118164\n",
      "Q Loss:  50.15489959716797\n",
      "Policy Loss:  -21.28361701965332\n",
      "[(0.0002, 0.11603), (0.0, 0.11585), (1.0, 0.11603)]\n",
      "Alpha*: 0.0 tau*: 0.11585 Episode: 44324 length: 52 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01157689094543457\n",
      "Value Loss:  0.0007934636087156832\n",
      "Q Loss:  0.0014357767067849636\n",
      "Policy Loss:  -0.022200901061296463\n",
      "[(0.00019, 0.11585), (0.0, 0.11567), (1.0, 0.11585)]\n",
      "Alpha*: 0.0 tau*: 0.11567 Episode: 44330 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0009527315851300955\n",
      "Q Loss:  0.00185515102930367\n",
      "Policy Loss:  -0.021866030991077423\n",
      "[(0.00019, 0.11567), (0.0, 0.11549), (1.0, 0.11567)]\n",
      "Alpha*: 0.0 tau*: 0.11549 Episode: 44334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.0662541389465332\n",
      "Q Loss:  1.6219886541366577\n",
      "Policy Loss:  -0.28066763281822205\n",
      "[(0.00018, 0.11549), (0.0, 0.11531), (1.0, 0.11549)]\n",
      "Alpha*: 0.0 tau*: 0.11531 Episode: 44389 length: 52 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.7069643139839172\n",
      "Q Loss:  0.011280732229351997\n",
      "Policy Loss:  -0.676563560962677\n",
      "[(0.00018, 0.11531), (0.0, 0.11513), (1.0, 0.11531)]\n",
      "Alpha*: 0.0 tau*: 0.11513 Episode: 44477 length: 81 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01259303092956543\n",
      "Value Loss:  9.316630894318223e-05\n",
      "Q Loss:  0.002899853279814124\n",
      "Policy Loss:  -0.005286004394292831\n",
      "[(0.00017, 0.11513), (0.0, 0.11495), (1.0, 0.11513)]\n",
      "Alpha*: 0.0 tau*: 0.11495 Episode: 44482 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  8.448538574157283e-05\n",
      "Q Loss:  0.002525904681533575\n",
      "Policy Loss:  -0.021035965532064438\n",
      "[(0.00017, 0.11495), (0.0, 0.11477), (1.0, 0.11495)]\n",
      "Alpha*: 0.0 tau*: 0.11477 Episode: 44487 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  7359.65576171875\n",
      "Q Loss:  6810.4541015625\n",
      "Policy Loss:  -8.429147720336914\n",
      "[(0.00017, 0.11477), (0.0, 0.11459), (1.0, 0.11477)]\n",
      "Alpha*: 0.0 tau*: 0.11459 Episode: 44625 length: 123 #teleports:15\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  1.3496214151382446\n",
      "Q Loss:  0.2594493329524994\n",
      "Policy Loss:  -4.2375168800354\n",
      "[(0.00017, 0.11459), (0.0, 0.11441), (1.0, 0.11459)]\n",
      "Alpha*: 0.0 tau*: 0.11441 Episode: 44630 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.8809398412704468\n",
      "Q Loss:  0.17602498829364777\n",
      "Policy Loss:  -5.697636604309082\n",
      "[(0.00017, 0.11441), (0.0, 0.11423), (1.0, 0.11441)]\n",
      "Alpha*: 0.0 tau*: 0.11423 Episode: 44635 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0020401710644364357\n",
      "Q Loss:  0.0010085434187203646\n",
      "Policy Loss:  0.005006636492908001\n",
      "[(0.00017, 0.11423), (0.0, 0.11405), (1.0, 0.11423)]\n",
      "Alpha*: 0.0 tau*: 0.11405 Episode: 44639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0003480667364783585\n",
      "Q Loss:  20.90871238708496\n",
      "Policy Loss:  1.7881470918655396\n",
      "[(0.00017, 0.11405), (0.0, 0.11387), (1.0, 0.11405)]\n",
      "Alpha*: 0.0 tau*: 0.11387 Episode: 44644 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00045643269550055265\n",
      "Q Loss:  20.83978271484375\n",
      "Policy Loss:  2.247084856033325\n",
      "[(0.00017, 0.11387), (0.0, 0.11369), (1.0, 0.11387)]\n",
      "Alpha*: 0.0 tau*: 0.11369 Episode: 44649 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  0.0001152975601144135\n",
      "Q Loss:  0.0012055793777108192\n",
      "Policy Loss:  -0.015164567157626152\n",
      "[(0.00017, 0.11369), (0.0, 0.11351), (1.0, 0.11369)]\n",
      "Alpha*: 0.0 tau*: 0.11351 Episode: 44653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.6768364906311035\n",
      "Q Loss:  0.023041723296046257\n",
      "Policy Loss:  4.506309986114502\n",
      "[(0.00018, 0.11351), (0.0, 0.11333), (1.0, 0.11351)]\n",
      "Alpha*: 0.0 tau*: 0.11333 Episode: 44664 length: 10 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00040582322981208563\n",
      "Q Loss:  0.0003512887342367321\n",
      "Policy Loss:  -0.014529258012771606\n",
      "[(0.00018, 0.11333), (0.0, 0.11315), (1.0, 0.11333)]\n",
      "Alpha*: 0.0 tau*: 0.11315 Episode: 44668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  0.39172154664993286\n",
      "Q Loss:  0.09329140186309814\n",
      "Policy Loss:  -2.0817482471466064\n",
      "[(0.00018, 0.11315), (0.0, 0.11297), (1.0, 0.11315)]\n",
      "Alpha*: 0.0 tau*: 0.11297 Episode: 44672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  29.75185775756836\n",
      "Q Loss:  4.666479110717773\n",
      "Policy Loss:  -6.411497116088867\n",
      "[(0.00018, 0.11297), (0.0, 0.11279), (1.0, 0.11297)]\n",
      "Alpha*: 0.0 tau*: 0.11279 Episode: 44769 length: 87 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00015179664478637278\n",
      "Q Loss:  40.123069763183594\n",
      "Policy Loss:  4.715464115142822\n",
      "[(0.00018, 0.11279), (0.0, 0.11261), (1.0, 0.11279)]\n",
      "Alpha*: 0.0 tau*: 0.11261 Episode: 44774 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0007030966226011515\n",
      "Q Loss:  0.004296043887734413\n",
      "Policy Loss:  0.20700086653232574\n",
      "[(0.00019, 0.11261), (0.0, 0.11243), (1.0, 0.11261)]\n",
      "Alpha*: 0.0 tau*: 0.11243 Episode: 44779 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.786773920059204\n",
      "Q Loss:  42.642024993896484\n",
      "Policy Loss:  0.6678304672241211\n",
      "[(0.00019, 0.11243), (0.0, 0.11225), (1.0, 0.11243)]\n",
      "Alpha*: 0.0 tau*: 0.11225 Episode: 44825 length: 33 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  106.63348388671875\n",
      "Q Loss:  30.94811248779297\n",
      "Policy Loss:  -23.195125579833984\n",
      "[(0.00019, 0.11225), (0.0, 0.11207), (1.0, 0.11225)]\n",
      "Alpha*: 0.0 tau*: 0.11207 Episode: 44877 length: 48 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0001940873044077307\n",
      "Q Loss:  0.005069932900369167\n",
      "Policy Loss:  0.0014137369580566883\n",
      "[(0.00019, 0.11207), (0.0, 0.11189), (1.0, 0.11207)]\n",
      "Alpha*: 0.0 tau*: 0.11189 Episode: 44881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00012378797691781074\n",
      "Q Loss:  0.0011960288975387812\n",
      "Policy Loss:  -0.02127673849463463\n",
      "[(0.0002, 0.11189), (0.0, 0.11171), (1.0, 0.11189)]\n",
      "Alpha*: 0.0 tau*: 0.11171 Episode: 44885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011588335037231445\n",
      "Value Loss:  0.4277598261833191\n",
      "Q Loss:  0.12062007188796997\n",
      "Policy Loss:  -2.3389792442321777\n",
      "[(0.0002, 0.11171), (0.0, 0.11153), (1.0, 0.11171)]\n",
      "Alpha*: 0.0 tau*: 0.11153 Episode: 44889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.4407684803009033\n",
      "Q Loss:  0.1540275514125824\n",
      "Policy Loss:  -0.4959561228752136\n",
      "[(0.0002, 0.11153), (0.0, 0.11135), (1.0, 0.11153)]\n",
      "Alpha*: 0.0 tau*: 0.11135 Episode: 44914 length: 23 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00028627904248423874\n",
      "Q Loss:  0.0010827031219378114\n",
      "Policy Loss:  0.0076844473369419575\n",
      "[(0.0002, 0.11135), (0.0, 0.11117), (1.0, 0.11135)]\n",
      "Alpha*: 0.0 tau*: 0.11117 Episode: 44919 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0018511794041842222\n",
      "Q Loss:  0.00043508136877790093\n",
      "Policy Loss:  -0.005989646539092064\n",
      "[(0.0002, 0.11117), (0.0, 0.11099), (1.0, 0.11117)]\n",
      "Alpha*: 0.0 tau*: 0.11099 Episode: 44923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  24.335350036621094\n",
      "Q Loss:  3.5262677669525146\n",
      "Policy Loss:  -5.909101963043213\n",
      "[(0.00021, 0.11099), (0.0, 0.11081), (1.0, 0.11099)]\n",
      "Alpha*: 0.0 tau*: 0.11081 Episode: 45047 length: 107 #teleports:17\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  3.379854388185777e-05\n",
      "Q Loss:  0.002623895648866892\n",
      "Policy Loss:  0.0012513562105596066\n",
      "[(0.00021, 0.11081), (0.0, 0.11063), (1.0, 0.11081)]\n",
      "Alpha*: 0.0 tau*: 0.11063 Episode: 45053 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  5.02254806633573e-05\n",
      "Q Loss:  0.002756108995527029\n",
      "Policy Loss:  0.014044936746358871\n",
      "[(0.00021, 0.11063), (0.0, 0.11045), (1.0, 0.11063)]\n",
      "Alpha*: 0.0 tau*: 0.11045 Episode: 45061 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.4680360335623845e-05\n",
      "Q Loss:  0.00612502358853817\n",
      "Policy Loss:  0.022846024483442307\n",
      "[(0.00021, 0.11045), (0.0, 0.11027), (1.0, 0.11045)]\n",
      "Alpha*: 0.0 tau*: 0.11027 Episode: 45065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  141.38314819335938\n",
      "Q Loss:  244.0641632080078\n",
      "Policy Loss:  -25.416820526123047\n",
      "[(0.00021, 0.11027), (0.0, 0.11009), (1.0, 0.11027)]\n",
      "Alpha*: 0.0 tau*: 0.11009 Episode: 45149 length: 72 #teleports:12\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04000973701477051\n",
      "Value Loss:  0.0011698735179379582\n",
      "Q Loss:  0.0018684080569073558\n",
      "Policy Loss:  -0.010686500929296017\n",
      "[(0.00021, 0.11009), (0.0, 0.10991), (1.0, 0.11009)]\n",
      "Alpha*: 0.0 tau*: 0.10991 Episode: 45153 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0021041783038526773\n",
      "Q Loss:  0.0017010616138577461\n",
      "Policy Loss:  -0.02389569580554962\n",
      "[(0.00021, 0.10991), (0.0, 0.10973), (1.0, 0.10991)]\n",
      "Alpha*: 0.0 tau*: 0.10973 Episode: 45157 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0004633998905774206\n",
      "Q Loss:  0.000700858945492655\n",
      "Policy Loss:  0.008043271489441395\n",
      "[(0.00022, 0.10973), (0.0, 0.10955), (1.0, 0.10973)]\n",
      "Alpha*: 0.0 tau*: 0.10955 Episode: 45163 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.0351455532363616e-05\n",
      "Q Loss:  0.00010404903878225014\n",
      "Policy Loss:  0.006886684335768223\n",
      "[(0.00022, 0.10955), (0.0, 0.10937), (1.0, 0.10955)]\n",
      "Alpha*: 0.0 tau*: 0.10937 Episode: 45167 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.4941100776195526\n",
      "Q Loss:  0.45576098561286926\n",
      "Policy Loss:  -3.28391170501709\n",
      "[(0.00022, 0.10937), (0.0, 0.10919), (1.0, 0.10937)]\n",
      "Alpha*: 0.0 tau*: 0.10919 Episode: 45171 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  43.853126525878906\n",
      "Q Loss:  124.14777374267578\n",
      "Policy Loss:  -7.146286964416504\n",
      "[(0.00022, 0.10919), (0.0, 0.10901), (1.0, 0.10919)]\n",
      "Alpha*: 0.0 tau*: 0.10901 Episode: 45237 length: 59 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00014462645049206913\n",
      "Q Loss:  0.0011135865934193134\n",
      "Policy Loss:  0.009066691622138023\n",
      "[(0.00023, 0.10901), (0.0, 0.10883), (1.0, 0.10901)]\n",
      "Alpha*: 0.0 tau*: 0.10883 Episode: 45242 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00017030458548106253\n",
      "Q Loss:  0.00024538469733670354\n",
      "Policy Loss:  0.005040677729994059\n",
      "[(0.00023, 0.10883), (0.0, 0.10865), (1.0, 0.10883)]\n",
      "Alpha*: 0.0 tau*: 0.10865 Episode: 45246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  630.1992797851562\n",
      "Q Loss:  0.0031199627555906773\n",
      "Policy Loss:  -144.25022888183594\n",
      "[(0.00023, 0.10865), (0.0, 0.10847), (1.0, 0.10865)]\n",
      "Alpha*: 0.0 tau*: 0.10847 Episode: 45251 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  0.0001832115522120148\n",
      "Q Loss:  0.00048470779438503087\n",
      "Policy Loss:  0.013096533715724945\n",
      "[(0.00023, 0.10847), (0.0, 0.10829), (1.0, 0.10847)]\n",
      "Alpha*: 0.0 tau*: 0.10829 Episode: 45256 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  9.913370013237e-05\n",
      "Q Loss:  0.0002966090105473995\n",
      "Policy Loss:  -0.008730696514248848\n",
      "[(0.00023, 0.10829), (0.0, 0.10811), (1.0, 0.10829)]\n",
      "Alpha*: 0.0 tau*: 0.10811 Episode: 45262 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  36.124000549316406\n",
      "Q Loss:  122.78663635253906\n",
      "Policy Loss:  -6.019533634185791\n",
      "[(0.00024, 0.10811), (0.0, 0.10793), (1.0, 0.10811)]\n",
      "Alpha*: 0.0 tau*: 0.10793 Episode: 45337 length: 71 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  625.1730346679688\n",
      "Q Loss:  18.22215461730957\n",
      "Policy Loss:  -136.32972717285156\n",
      "[(0.00024, 0.10793), (0.0, 0.10775), (1.0, 0.10793)]\n",
      "Alpha*: 0.0 tau*: 0.10775 Episode: 45341 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031006574630737305\n",
      "Value Loss:  622.9448852539062\n",
      "Q Loss:  1844.879638671875\n",
      "Policy Loss:  -62.885414123535156\n",
      "[(0.00025, 0.10775), (0.0, 0.10757), (1.0, 0.10775)]\n",
      "Alpha*: 0.0 tau*: 0.10757 Episode: 45346 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016059160232543945\n",
      "Value Loss:  0.0002681582700461149\n",
      "Q Loss:  0.004258432891219854\n",
      "Policy Loss:  -0.012162451632320881\n",
      "[(0.00026, 0.10757), (0.0, 0.10739), (1.0, 0.10757)]\n",
      "Alpha*: 0.0 tau*: 0.10739 Episode: 45350 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.003861099947243929\n",
      "Q Loss:  0.0009982322808355093\n",
      "Policy Loss:  0.0034338925033807755\n",
      "[(0.00026, 0.10739), (0.0, 0.10721), (1.0, 0.10739)]\n",
      "Alpha*: 0.0 tau*: 0.10721 Episode: 45354 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  142.7443389892578\n",
      "Q Loss:  307.7274475097656\n",
      "Policy Loss:  -24.687713623046875\n",
      "[(0.00027, 0.10721), (0.0, 0.10703), (1.0, 0.10721)]\n",
      "Alpha*: 0.0 tau*: 0.10703 Episode: 45413 length: 52 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04200887680053711\n",
      "Value Loss:  7.800193270668387e-05\n",
      "Q Loss:  0.0004004381480626762\n",
      "Policy Loss:  -0.0074302032589912415\n",
      "[(0.00027, 0.10703), (0.0, 0.10685), (1.0, 0.10703)]\n",
      "Alpha*: 0.0 tau*: 0.10685 Episode: 45417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  4.783163603860885e-05\n",
      "Q Loss:  0.0002580538857728243\n",
      "Policy Loss:  -0.004985444247722626\n",
      "[(0.00027, 0.10685), (0.0, 0.10667), (1.0, 0.10685)]\n",
      "Alpha*: 0.0 tau*: 0.10667 Episode: 45421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013604164123535156\n",
      "Value Loss:  0.00012178128235973418\n",
      "Q Loss:  0.034186240285634995\n",
      "Policy Loss:  0.05466742068529129\n",
      "[(0.00027, 0.10667), (0.0, 0.10649), (1.0, 0.10667)]\n",
      "Alpha*: 0.0 tau*: 0.10649 Episode: 45427 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.5128729343414307\n",
      "Q Loss:  0.11546109616756439\n",
      "Policy Loss:  -2.5657007694244385\n",
      "[(0.00026, 0.10649), (0.0, 0.10631), (1.0, 0.10649)]\n",
      "Alpha*: 0.0 tau*: 0.10631 Episode: 45431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  14352.07421875\n",
      "Q Loss:  13304.19921875\n",
      "Policy Loss:  -6.712922096252441\n",
      "[(0.00026, 0.10631), (0.0, 0.10613), (1.0, 0.10631)]\n",
      "Alpha*: 0.0 tau*: 0.10613 Episode: 45506 length: 63 #teleports:12\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  5.993235026835464e-05\n",
      "Q Loss:  0.000348752859281376\n",
      "Policy Loss:  -0.004435849376022816\n",
      "[(0.00026, 0.10613), (0.0, 0.10595), (1.0, 0.10613)]\n",
      "Alpha*: 0.0 tau*: 0.10595 Episode: 45511 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.5718672275543213\n",
      "Q Loss:  0.0742376297712326\n",
      "Policy Loss:  -0.9640010595321655\n",
      "[(0.00026, 0.10595), (0.0, 0.10577), (1.0, 0.10595)]\n",
      "Alpha*: 0.0 tau*: 0.10577 Episode: 45536 length: 23 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.00011188590724486858\n",
      "Q Loss:  0.00047004170482978225\n",
      "Policy Loss:  -0.004513620864599943\n",
      "[(0.00026, 0.10577), (0.0, 0.10559), (1.0, 0.10577)]\n",
      "Alpha*: 0.0 tau*: 0.10559 Episode: 45540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.0005920523544773459\n",
      "Q Loss:  0.0008779680356383324\n",
      "Policy Loss:  -0.004549606237560511\n",
      "[(0.00026, 0.10559), (0.0, 0.10541), (1.0, 0.10559)]\n",
      "Alpha*: 0.0 tau*: 0.10541 Episode: 45544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.429142038337886e-05\n",
      "Q Loss:  0.0005840868689119816\n",
      "Policy Loss:  -0.0036792082246392965\n",
      "[(0.00026, 0.10541), (0.0, 0.10523), (1.0, 0.10541)]\n",
      "Alpha*: 0.0 tau*: 0.10523 Episode: 45551 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0005077333189547062\n",
      "Q Loss:  0.0012384902220219374\n",
      "Policy Loss:  0.006129451096057892\n",
      "[(0.00026, 0.10523), (0.0, 0.10505), (1.0, 0.10523)]\n",
      "Alpha*: 0.0 tau*: 0.10505 Episode: 45556 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0003874617977999151\n",
      "Q Loss:  0.0005453454796224833\n",
      "Policy Loss:  -0.002001718617975712\n",
      "[(0.00026, 0.10505), (0.0, 0.10487), (1.0, 0.10505)]\n",
      "Alpha*: 0.0 tau*: 0.10487 Episode: 45560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.8983009457588196\n",
      "Q Loss:  0.030736654996871948\n",
      "Policy Loss:  -1.0505783557891846\n",
      "[(0.00026, 0.10487), (0.0, 0.10469), (1.0, 0.10487)]\n",
      "Alpha*: 0.0 tau*: 0.10469 Episode: 45629 length: 63 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  32.24394226074219\n",
      "Q Loss:  0.06988535076379776\n",
      "Policy Loss:  -9.027608871459961\n",
      "[(0.00026, 0.10469), (0.0, 0.10451), (1.0, 0.10469)]\n",
      "Alpha*: 0.0 tau*: 0.10451 Episode: 45713 length: 77 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.774981061927974e-05\n",
      "Q Loss:  0.023110968992114067\n",
      "Policy Loss:  0.052561573684215546\n",
      "[(0.00026, 0.10451), (0.0, 0.10433), (1.0, 0.10451)]\n",
      "Alpha*: 0.0 tau*: 0.10433 Episode: 45718 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  26596.361328125\n",
      "Q Loss:  24641.8984375\n",
      "Policy Loss:  -6.794619560241699\n",
      "[(0.00026, 0.10433), (0.0, 0.10415), (1.0, 0.10433)]\n",
      "Alpha*: 0.0 tau*: 0.10415 Episode: 45753 length: 34 #teleports:1\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  72.71527099609375\n",
      "Q Loss:  0.08879849314689636\n",
      "Policy Loss:  -17.296785354614258\n",
      "[(0.00026, 0.10415), (0.0, 0.10397), (1.0, 0.10415)]\n",
      "Alpha*: 0.0 tau*: 0.10397 Episode: 45793 length: 34 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0006029593059793115\n",
      "Q Loss:  0.0004213774809613824\n",
      "Policy Loss:  0.015854673460125923\n",
      "[(0.00027, 0.10397), (0.0, 0.10379), (1.0, 0.10397)]\n",
      "Alpha*: 0.0 tau*: 0.10379 Episode: 45797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300429344177246\n",
      "Value Loss:  0.00038948055589571595\n",
      "Q Loss:  3.03771721519297e-05\n",
      "Policy Loss:  -0.0007387732621282339\n",
      "[(0.00027, 0.10379), (0.0, 0.10361), (1.0, 0.10379)]\n",
      "Alpha*: 0.0 tau*: 0.10361 Episode: 45801 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300762176513672\n",
      "Value Loss:  0.00013572353054769337\n",
      "Q Loss:  33.85453796386719\n",
      "Policy Loss:  3.2568092346191406\n",
      "[(0.00027, 0.10361), (0.0, 0.10343), (1.0, 0.10361)]\n",
      "Alpha*: 0.0 tau*: 0.10343 Episode: 45806 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  5.234940181253478e-05\n",
      "Q Loss:  0.0006079970044083893\n",
      "Policy Loss:  0.015576394274830818\n",
      "[(0.00027, 0.10343), (0.0, 0.10325), (1.0, 0.10343)]\n",
      "Alpha*: 0.0 tau*: 0.10325 Episode: 45810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.1850885130115785e-05\n",
      "Q Loss:  50.148258209228516\n",
      "Policy Loss:  4.723254203796387\n",
      "[(0.00028, 0.10325), (0.0, 0.10307), (1.0, 0.10325)]\n",
      "Alpha*: 0.0 tau*: 0.10307 Episode: 45814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00019688399333972484\n",
      "Q Loss:  334.4471740722656\n",
      "Policy Loss:  1.4372186660766602\n",
      "[(0.00028, 0.10307), (0.0, 0.10289), (1.0, 0.10307)]\n",
      "Alpha*: 0.0 tau*: 0.10289 Episode: 45820 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.0004705981118604541\n",
      "Q Loss:  0.009203044697642326\n",
      "Policy Loss:  0.017061680555343628\n",
      "[(0.00028, 0.10289), (0.0, 0.10271), (1.0, 0.10289)]\n",
      "Alpha*: 0.0 tau*: 0.10271 Episode: 45824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  33.7816276550293\n",
      "Q Loss:  100.52542877197266\n",
      "Policy Loss:  -5.623857498168945\n",
      "[(0.00028, 0.10271), (0.0, 0.10253), (1.0, 0.10271)]\n",
      "Alpha*: 0.0 tau*: 0.10253 Episode: 45902 length: 75 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00037297740345820785\n",
      "Q Loss:  0.0006339589017443359\n",
      "Policy Loss:  -0.01057150773704052\n",
      "[(0.00028, 0.10253), (0.0, 0.10235), (1.0, 0.10253)]\n",
      "Alpha*: 0.0 tau*: 0.10235 Episode: 45908 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00019473663996905088\n",
      "Q Loss:  16.449214935302734\n",
      "Policy Loss:  1.6474741697311401\n",
      "[(0.00028, 0.10235), (0.0, 0.10217), (1.0, 0.10235)]\n",
      "Alpha*: 0.0 tau*: 0.10217 Episode: 45913 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.028006315231323242\n",
      "Value Loss:  0.00012212809815537184\n",
      "Q Loss:  0.00013031112030148506\n",
      "Policy Loss:  0.001786338398233056\n",
      "[(0.00028, 0.10217), (0.0, 0.10199), (1.0, 0.10217)]\n",
      "Alpha*: 0.0 tau*: 0.10199 Episode: 45917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301189422607422\n",
      "Value Loss:  0.0006356690428219736\n",
      "Q Loss:  0.0008424171828664839\n",
      "Policy Loss:  -0.0067389169707894325\n",
      "[(0.00028, 0.10199), (0.0, 0.10181), (1.0, 0.10199)]\n",
      "Alpha*: 0.0 tau*: 0.10181 Episode: 45921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  9.598480573913548e-06\n",
      "Q Loss:  0.004092826973646879\n",
      "Policy Loss:  0.023883268237113953\n",
      "[(0.00028, 0.10181), (0.0, 0.10163), (1.0, 0.10181)]\n",
      "Alpha*: 0.0 tau*: 0.10163 Episode: 45926 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012000799179077148\n",
      "Value Loss:  2.1794488930027e-05\n",
      "Q Loss:  0.0001402880297973752\n",
      "Policy Loss:  0.003655107691884041\n",
      "[(0.00028, 0.10163), (0.0, 0.10145), (1.0, 0.10163)]\n",
      "Alpha*: 0.0 tau*: 0.10145 Episode: 45932 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.822725193458609e-05\n",
      "Q Loss:  0.0002878005616366863\n",
      "Policy Loss:  0.006922991015017033\n",
      "[(0.00028, 0.10145), (0.0, 0.10127), (1.0, 0.10145)]\n",
      "Alpha*: 0.0 tau*: 0.10127 Episode: 45937 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  622.0323486328125\n",
      "Q Loss:  0.0007320218719542027\n",
      "Policy Loss:  -143.45680236816406\n",
      "[(0.00028, 0.10127), (0.0, 0.10109), (1.0, 0.10127)]\n",
      "Alpha*: 0.0 tau*: 0.10109 Episode: 45942 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  16949.228515625\n",
      "Q Loss:  15823.095703125\n",
      "Policy Loss:  -47.520938873291016\n",
      "[(0.00028, 0.10109), (0.0, 0.10091), (1.0, 0.10109)]\n",
      "Alpha*: 0.0 tau*: 0.10091 Episode: 46002 length: 54 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.0827480554580688\n",
      "Q Loss:  0.08029576390981674\n",
      "Policy Loss:  -0.815809965133667\n",
      "[(0.00028, 0.10091), (0.0, 0.10073), (1.0, 0.10091)]\n",
      "Alpha*: 0.0 tau*: 0.10073 Episode: 46052 length: 44 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04901123046875\n",
      "Value Loss:  622.0732421875\n",
      "Q Loss:  16.187950134277344\n",
      "Policy Loss:  -136.67919921875\n",
      "[(0.00028, 0.10073), (0.0, 0.10055), (1.0, 0.10073)]\n",
      "Alpha*: 0.0 tau*: 0.10055 Episode: 46057 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  6.418916746042669e-05\n",
      "Q Loss:  0.00037661532405763865\n",
      "Policy Loss:  -0.0002514938823878765\n",
      "[(0.00028, 0.10055), (0.0, 0.10037), (1.0, 0.10055)]\n",
      "Alpha*: 0.0 tau*: 0.10037 Episode: 46061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  5.7962075516115874e-05\n",
      "Q Loss:  0.0003141142369713634\n",
      "Policy Loss:  -0.008966188877820969\n",
      "[(0.00028, 0.10037), (0.0, 0.10019), (1.0, 0.10037)]\n",
      "Alpha*: 0.0 tau*: 0.10019 Episode: 46065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0005872342735528946\n",
      "Q Loss:  0.0006028402131050825\n",
      "Policy Loss:  -0.010283393785357475\n",
      "[(0.00028, 0.10019), (0.0, 0.10001), (1.0, 0.10019)]\n",
      "Alpha*: 0.0 tau*: 0.10001 Episode: 46069 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.073335291352123e-05\n",
      "Q Loss:  0.007253546267747879\n",
      "Policy Loss:  0.25232023000717163\n",
      "[(0.00028, 0.10001), (0.0, 0.09983), (1.0, 0.10001)]\n",
      "Alpha*: 0.0 tau*: 0.09983 Episode: 46074 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  52.68175506591797\n",
      "Q Loss:  157.10244750976562\n",
      "Policy Loss:  -8.12026596069336\n",
      "[(0.00027, 0.09983), (0.0, 0.09965), (1.0, 0.09983)]\n",
      "Alpha*: 0.0 tau*: 0.09965 Episode: 46124 length: 48 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0002914257056545466\n",
      "Q Loss:  0.00013546623813454062\n",
      "Policy Loss:  -0.008413868024945259\n",
      "[(0.00027, 0.09965), (0.0, 0.09947), (1.0, 0.09965)]\n",
      "Alpha*: 0.0 tau*: 0.09947 Episode: 46128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.8157878811471164e-05\n",
      "Q Loss:  0.00021348529844544828\n",
      "Policy Loss:  -0.009352092631161213\n",
      "[(0.00027, 0.09947), (0.0, 0.09929), (1.0, 0.09947)]\n",
      "Alpha*: 0.0 tau*: 0.09929 Episode: 46132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020005226135253906\n",
      "Value Loss:  9.816914098337293e-05\n",
      "Q Loss:  0.0009762491099536419\n",
      "Policy Loss:  -0.0021706800907850266\n",
      "[(0.00027, 0.09929), (0.0, 0.09911), (1.0, 0.09929)]\n",
      "Alpha*: 0.0 tau*: 0.09911 Episode: 46136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015014886856079102\n",
      "Value Loss:  0.6461159586906433\n",
      "Q Loss:  0.11639522761106491\n",
      "Policy Loss:  -2.917616128921509\n",
      "[(0.00027, 0.09911), (0.0, 0.09893), (1.0, 0.09911)]\n",
      "Alpha*: 0.0 tau*: 0.09893 Episode: 46142 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  2.496221895853523e-05\n",
      "Q Loss:  0.0002405188570264727\n",
      "Policy Loss:  0.016990646719932556\n",
      "[(0.00027, 0.09893), (0.0, 0.09875), (1.0, 0.09893)]\n",
      "Alpha*: 0.0 tau*: 0.09875 Episode: 46148 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.03400731086730957\n",
      "Value Loss:  5.456092912936583e-05\n",
      "Q Loss:  0.0003810686757788062\n",
      "Policy Loss:  0.00590002816170454\n",
      "[(0.00026, 0.09875), (0.0, 0.09857), (1.0, 0.09875)]\n",
      "Alpha*: 0.0 tau*: 0.09857 Episode: 46152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.6417441964149475\n",
      "Q Loss:  0.15982995927333832\n",
      "Policy Loss:  -2.837576150894165\n",
      "[(0.00026, 0.09857), (0.0, 0.09839), (1.0, 0.09857)]\n",
      "Alpha*: 0.0 tau*: 0.09839 Episode: 46156 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  88.78915405273438\n",
      "Q Loss:  160.4789276123047\n",
      "Policy Loss:  -16.99376678466797\n",
      "[(0.00026, 0.09839), (0.0, 0.09821), (1.0, 0.09839)]\n",
      "Alpha*: 0.0 tau*: 0.09821 Episode: 46222 length: 56 #teleports:10\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.6328893899917603\n",
      "Q Loss:  0.14955995976924896\n",
      "Policy Loss:  -2.7764017581939697\n",
      "[(0.00026, 0.09821), (0.0, 0.09803), (1.0, 0.09821)]\n",
      "Alpha*: 0.0 tau*: 0.09803 Episode: 46227 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00017916294746100903\n",
      "Q Loss:  0.00031678678351454437\n",
      "Policy Loss:  0.006085899658501148\n",
      "[(0.00026, 0.09803), (0.0, 0.09785), (1.0, 0.09803)]\n",
      "Alpha*: 0.0 tau*: 0.09785 Episode: 46232 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0003005787148140371\n",
      "Q Loss:  0.0005383838433772326\n",
      "Policy Loss:  0.009788278490304947\n",
      "[(0.00026, 0.09785), (0.0, 0.09767), (1.0, 0.09785)]\n",
      "Alpha*: 0.0 tau*: 0.09767 Episode: 46236 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.968802623916417e-05\n",
      "Q Loss:  0.0003160353226121515\n",
      "Policy Loss:  0.004240115638822317\n",
      "[(0.00026, 0.09767), (0.0, 0.09749), (1.0, 0.09767)]\n",
      "Alpha*: 0.0 tau*: 0.09749 Episode: 46241 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03700876235961914\n",
      "Value Loss:  0.00010554113396210596\n",
      "Q Loss:  0.0018611896084621549\n",
      "Policy Loss:  0.028789889067411423\n",
      "[(0.00026, 0.09749), (0.0, 0.09732), (1.0, 0.09749)]\n",
      "Alpha*: 0.0 tau*: 0.09732 Episode: 46245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014635562896728516\n",
      "Value Loss:  1.1308098692097701e-05\n",
      "Q Loss:  0.00029083999106660485\n",
      "Policy Loss:  0.24977752566337585\n",
      "[(0.00026, 0.09732), (0.0, 0.09715), (1.0, 0.09732)]\n",
      "Alpha*: 0.0 tau*: 0.09715 Episode: 46250 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00028183343238197267\n",
      "Q Loss:  0.00019600750238168985\n",
      "Policy Loss:  -0.010510453954339027\n",
      "[(0.00026, 0.09715), (0.0, 0.09698), (1.0, 0.09715)]\n",
      "Alpha*: 0.0 tau*: 0.09698 Episode: 46254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  612.4219970703125\n",
      "Q Loss:  333.4123840332031\n",
      "Policy Loss:  -135.40965270996094\n",
      "[(0.00026, 0.09698), (0.0, 0.09681), (1.0, 0.09698)]\n",
      "Alpha*: 0.0 tau*: 0.09681 Episode: 46259 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  611.0084228515625\n",
      "Q Loss:  1880.0303955078125\n",
      "Policy Loss:  -68.23493957519531\n",
      "[(0.00026, 0.09681), (0.0, 0.09664), (1.0, 0.09681)]\n",
      "Alpha*: 0.0 tau*: 0.09664 Episode: 46263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  2.3925022105686367e-05\n",
      "Q Loss:  0.0005109196063131094\n",
      "Policy Loss:  0.004217267036437988\n",
      "[(0.00027, 0.09664), (0.0, 0.09647), (1.0, 0.09664)]\n",
      "Alpha*: 0.0 tau*: 0.09647 Episode: 46267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.00016278082330245525\n",
      "Q Loss:  0.0007393513806164265\n",
      "Policy Loss:  0.012173940427601337\n",
      "[(0.00027, 0.09647), (0.0, 0.0963), (1.0, 0.09647)]\n",
      "Alpha*: 0.0 tau*: 0.0963 Episode: 46271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001537538191769272\n",
      "Q Loss:  0.0005341109354048967\n",
      "Policy Loss:  0.003830507630482316\n",
      "[(0.00027, 0.0963), (0.0, 0.09613), (1.0, 0.0963)]\n",
      "Alpha*: 0.0 tau*: 0.09613 Episode: 46275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00016317705740220845\n",
      "Q Loss:  0.0023562873248010874\n",
      "Policy Loss:  0.009788223542273045\n",
      "[(0.00027, 0.09613), (0.0, 0.09596), (1.0, 0.09613)]\n",
      "Alpha*: 0.0 tau*: 0.09596 Episode: 46279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00012369816249702126\n",
      "Q Loss:  0.0006305723218247294\n",
      "Policy Loss:  0.25005972385406494\n",
      "[(0.00027, 0.09596), (0.0, 0.09579), (1.0, 0.09596)]\n",
      "Alpha*: 0.0 tau*: 0.09579 Episode: 46283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.1515833139419556\n",
      "Q Loss:  0.24543626606464386\n",
      "Policy Loss:  -3.8854153156280518\n",
      "[(0.00027, 0.09579), (0.0, 0.09562), (1.0, 0.09579)]\n",
      "Alpha*: 0.0 tau*: 0.09562 Episode: 46288 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0002520903944969177\n",
      "Q Loss:  0.0009597551543265581\n",
      "Policy Loss:  0.018722297623753548\n",
      "[(0.00026, 0.09562), (0.0, 0.09545), (1.0, 0.09562)]\n",
      "Alpha*: 0.0 tau*: 0.09545 Episode: 46293 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00013464751827996224\n",
      "Q Loss:  0.0012723124818876386\n",
      "Policy Loss:  0.009080326184630394\n",
      "[(0.00026, 0.09545), (0.0, 0.09528), (1.0, 0.09545)]\n",
      "Alpha*: 0.0 tau*: 0.09528 Episode: 46297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014174461364746094\n",
      "Value Loss:  0.5484300255775452\n",
      "Q Loss:  0.1941671222448349\n",
      "Policy Loss:  -2.2455570697784424\n",
      "[(0.00026, 0.09528), (0.0, 0.09511), (1.0, 0.09528)]\n",
      "Alpha*: 0.0 tau*: 0.09511 Episode: 46302 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  0.0003390350320842117\n",
      "Q Loss:  4.135194467380643e-05\n",
      "Policy Loss:  -0.003112731035798788\n",
      "[(0.00026, 0.09511), (0.0, 0.09494), (1.0, 0.09511)]\n",
      "Alpha*: 0.0 tau*: 0.09494 Episode: 46308 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0005527693429030478\n",
      "Q Loss:  0.004482712130993605\n",
      "Policy Loss:  -0.03278413787484169\n",
      "[(0.00026, 0.09494), (0.0, 0.09477), (1.0, 0.09494)]\n",
      "Alpha*: 0.0 tau*: 0.09477 Episode: 46313 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.6706804672139697e-05\n",
      "Q Loss:  0.0016215217765420675\n",
      "Policy Loss:  0.020100172609090805\n",
      "[(0.00026, 0.09477), (0.0, 0.0946), (1.0, 0.09477)]\n",
      "Alpha*: 0.0 tau*: 0.0946 Episode: 46318 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  7.20032476237975e-05\n",
      "Q Loss:  0.0014214840484783053\n",
      "Policy Loss:  0.00997973419725895\n",
      "[(0.00026, 0.0946), (0.0, 0.09443), (1.0, 0.0946)]\n",
      "Alpha*: 0.0 tau*: 0.09443 Episode: 46322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600764274597168\n",
      "Value Loss:  1.0063508749008179\n",
      "Q Loss:  0.2269388884305954\n",
      "Policy Loss:  -1.3389651775360107\n",
      "[(0.00025, 0.09443), (0.0, 0.09426), (1.0, 0.09443)]\n",
      "Alpha*: 0.0 tau*: 0.09426 Episode: 46326 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  13785.890625\n",
      "Q Loss:  12799.302734375\n",
      "Policy Loss:  -19.75537109375\n",
      "[(0.00025, 0.09426), (0.0, 0.09409), (1.0, 0.09426)]\n",
      "Alpha*: 0.0 tau*: 0.09409 Episode: 46398 length: 66 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.000360928475856781\n",
      "Q Loss:  0.00031544550438411534\n",
      "Policy Loss:  -0.003931280225515366\n",
      "[(0.00026, 0.09409), (0.0, 0.09392), (1.0, 0.09409)]\n",
      "Alpha*: 0.0 tau*: 0.09392 Episode: 46402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.1698506568791345e-05\n",
      "Q Loss:  0.0002458690432831645\n",
      "Policy Loss:  0.001639551599510014\n",
      "[(0.00026, 0.09392), (0.0, 0.09375), (1.0, 0.09392)]\n",
      "Alpha*: 0.0 tau*: 0.09375 Episode: 46406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.551149999722838e-05\n",
      "Q Loss:  0.0003039145958609879\n",
      "Policy Loss:  -0.00270185898989439\n",
      "[(0.00026, 0.09375), (0.0, 0.09358), (1.0, 0.09375)]\n",
      "Alpha*: 0.0 tau*: 0.09358 Episode: 46410 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026006221771240234\n",
      "Value Loss:  9.340450196759775e-05\n",
      "Q Loss:  0.00014877470675855875\n",
      "Policy Loss:  -0.006219477392733097\n",
      "[(0.00026, 0.09358), (0.0, 0.09341), (1.0, 0.09358)]\n",
      "Alpha*: 0.0 tau*: 0.09341 Episode: 46414 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.829132080078125\n",
      "Q Loss:  0.00434952974319458\n",
      "Policy Loss:  -0.5590394735336304\n",
      "[(0.00026, 0.09341), (0.0, 0.09324), (1.0, 0.09341)]\n",
      "Alpha*: 0.0 tau*: 0.09324 Episode: 46486 length: 67 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00022165171685628593\n",
      "Q Loss:  0.0004083229578100145\n",
      "Policy Loss:  -0.0043410067446529865\n",
      "[(0.00026, 0.09324), (0.0, 0.09307), (1.0, 0.09324)]\n",
      "Alpha*: 0.0 tau*: 0.09307 Episode: 46492 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  7.161611847550375e-06\n",
      "Q Loss:  6.981795013416559e-05\n",
      "Policy Loss:  -0.00016035826411098242\n",
      "[(0.00026, 0.09307), (0.0, 0.0929), (1.0, 0.09307)]\n",
      "Alpha*: 0.0 tau*: 0.0929 Episode: 46497 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.8573331292136572e-06\n",
      "Q Loss:  1.1509538126119878e-05\n",
      "Policy Loss:  -0.0002249199606012553\n",
      "[(0.00026, 0.0929), (0.0, 0.09273), (1.0, 0.0929)]\n",
      "Alpha*: 0.0 tau*: 0.09273 Episode: 46501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.532949447631836\n",
      "Q Loss:  0.005832024849951267\n",
      "Policy Loss:  3.9376437664031982\n",
      "[(0.00026, 0.09273), (0.0, 0.09256), (1.0, 0.09273)]\n",
      "Alpha*: 0.0 tau*: 0.09256 Episode: 46513 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  6.660031795036048e-05\n",
      "Q Loss:  0.0006803302094340324\n",
      "Policy Loss:  -0.00544759351760149\n",
      "[(0.00026, 0.09256), (0.0, 0.09239), (1.0, 0.09256)]\n",
      "Alpha*: 0.0 tau*: 0.09239 Episode: 46517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00011044586426578462\n",
      "Q Loss:  0.00017465671407990158\n",
      "Policy Loss:  -0.00517352856695652\n",
      "[(0.00026, 0.09239), (0.0, 0.09222), (1.0, 0.09239)]\n",
      "Alpha*: 0.0 tau*: 0.09222 Episode: 46521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00022182172688189894\n",
      "Q Loss:  0.00012853569933213294\n",
      "Policy Loss:  -0.009601414203643799\n",
      "[(0.00026, 0.09222), (0.0, 0.09205), (1.0, 0.09222)]\n",
      "Alpha*: 0.0 tau*: 0.09205 Episode: 46525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026006698608398438\n",
      "Value Loss:  0.00011045917926821858\n",
      "Q Loss:  0.001541785546578467\n",
      "Policy Loss:  0.2154698371887207\n",
      "[(0.00026, 0.09205), (0.0, 0.09188), (1.0, 0.09205)]\n",
      "Alpha*: 0.0 tau*: 0.09188 Episode: 46530 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  596.4926147460938\n",
      "Q Loss:  2162.24169921875\n",
      "Policy Loss:  -60.04786682128906\n",
      "[(0.00026, 0.09188), (0.0, 0.09171), (1.0, 0.09188)]\n",
      "Alpha*: 0.0 tau*: 0.09171 Episode: 46535 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  595.4617919921875\n",
      "Q Loss:  0.01623615249991417\n",
      "Policy Loss:  -140.43934631347656\n",
      "[(0.00026, 0.09171), (0.0, 0.09154), (1.0, 0.09171)]\n",
      "Alpha*: 0.0 tau*: 0.09154 Episode: 46540 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.03800821304321289\n",
      "Value Loss:  0.0004645732988137752\n",
      "Q Loss:  0.00178136071190238\n",
      "Policy Loss:  0.000147238839417696\n",
      "[(0.00027, 0.09154), (0.0, 0.09137), (1.0, 0.09154)]\n",
      "Alpha*: 0.0 tau*: 0.09137 Episode: 46545 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005546400207094848\n",
      "Q Loss:  9.024418977787718e-05\n",
      "Policy Loss:  0.006263634655624628\n",
      "[(0.00027, 0.09137), (0.0, 0.0912), (1.0, 0.09137)]\n",
      "Alpha*: 0.0 tau*: 0.0912 Episode: 46549 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015506505966186523\n",
      "Value Loss:  56.79104995727539\n",
      "Q Loss:  104.48796081542969\n",
      "Policy Loss:  -11.533385276794434\n",
      "[(0.00027, 0.0912), (0.0, 0.09103), (1.0, 0.0912)]\n",
      "Alpha*: 0.0 tau*: 0.09103 Episode: 46642 length: 84 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.7954878211021423\n",
      "Q Loss:  0.02905518002808094\n",
      "Policy Loss:  -0.7581798434257507\n",
      "[(0.00026, 0.09103), (0.0, 0.09086), (1.0, 0.09103)]\n",
      "Alpha*: 0.0 tau*: 0.09086 Episode: 46727 length: 70 #teleports:15\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  7.726351032033563e-05\n",
      "Q Loss:  0.0014319764450192451\n",
      "Policy Loss:  0.02063625678420067\n",
      "[(0.00026, 0.09086), (0.0, 0.09069), (1.0, 0.09086)]\n",
      "Alpha*: 0.0 tau*: 0.09069 Episode: 46731 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014590740203857422\n",
      "Value Loss:  585.3933715820312\n",
      "Q Loss:  1821.495849609375\n",
      "Policy Loss:  -66.65428924560547\n",
      "[(0.00026, 0.09069), (0.0, 0.09052), (1.0, 0.09069)]\n",
      "Alpha*: 0.0 tau*: 0.09052 Episode: 46736 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  9.086616046261042e-05\n",
      "Q Loss:  19.441898345947266\n",
      "Policy Loss:  1.5381871461868286\n",
      "[(0.00025, 0.09052), (0.0, 0.09035), (1.0, 0.09052)]\n",
      "Alpha*: 0.0 tau*: 0.09035 Episode: 46744 length: 4 #teleports:4\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  7.474477024516091e-05\n",
      "Q Loss:  0.0006717114010825753\n",
      "Policy Loss:  0.23440000414848328\n",
      "[(0.00025, 0.09035), (0.0, 0.09018), (1.0, 0.09035)]\n",
      "Alpha*: 0.0 tau*: 0.09018 Episode: 46748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301189422607422\n",
      "Value Loss:  28.229759216308594\n",
      "Q Loss:  85.67942810058594\n",
      "Policy Loss:  -5.615846633911133\n",
      "[(0.00025, 0.09018), (0.0, 0.09001), (1.0, 0.09018)]\n",
      "Alpha*: 0.0 tau*: 0.09001 Episode: 46837 length: 84 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011004209518432617\n",
      "Value Loss:  72.99356079101562\n",
      "Q Loss:  224.0921630859375\n",
      "Policy Loss:  -12.913013458251953\n",
      "[(0.00025, 0.09001), (0.0, 0.08984), (1.0, 0.09001)]\n",
      "Alpha*: 0.0 tau*: 0.08984 Episode: 46907 length: 64 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00010754851246019825\n",
      "Q Loss:  0.001047686324454844\n",
      "Policy Loss:  0.01726159080862999\n",
      "[(0.00024, 0.08984), (0.0, 0.08967), (1.0, 0.08984)]\n",
      "Alpha*: 0.0 tau*: 0.08967 Episode: 46911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011004924774169922\n",
      "Value Loss:  0.00015873968368396163\n",
      "Q Loss:  0.0004639281833078712\n",
      "Policy Loss:  0.006780687719583511\n",
      "[(0.00024, 0.08967), (0.0, 0.0895), (1.0, 0.08967)]\n",
      "Alpha*: 0.0 tau*: 0.0895 Episode: 46915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  9.500785381533206e-05\n",
      "Q Loss:  0.00014739666949026287\n",
      "Policy Loss:  0.0034118671901524067\n",
      "[(0.00024, 0.0895), (0.0, 0.08933), (1.0, 0.0895)]\n",
      "Alpha*: 0.0 tau*: 0.08933 Episode: 46919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  8.788818377070129e-05\n",
      "Q Loss:  0.0002626702771522105\n",
      "Policy Loss:  0.004986701998859644\n",
      "[(0.00024, 0.08933), (0.0, 0.08916), (1.0, 0.08933)]\n",
      "Alpha*: 0.0 tau*: 0.08916 Episode: 46923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  56.96000671386719\n",
      "Q Loss:  3.852886438369751\n",
      "Policy Loss:  -13.140046119689941\n",
      "[(0.00024, 0.08916), (0.0, 0.08899), (1.0, 0.08916)]\n",
      "Alpha*: 0.0 tau*: 0.08899 Episode: 46967 length: 41 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.033003807067871094\n",
      "Value Loss:  2.7926385402679443\n",
      "Q Loss:  0.12548010051250458\n",
      "Policy Loss:  -0.7367393374443054\n",
      "[(0.00024, 0.08899), (0.0, 0.08882), (1.0, 0.08899)]\n",
      "Alpha*: 0.0 tau*: 0.08882 Episode: 46990 length: 20 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  36278.46484375\n",
      "Q Loss:  33568.9296875\n",
      "Policy Loss:  -11.257769584655762\n",
      "[(0.00023, 0.08882), (0.0, 0.08865), (1.0, 0.08882)]\n",
      "Alpha*: 0.0 tau*: 0.08865 Episode: 47017 length: 25 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.583992600440979\n",
      "Q Loss:  0.06823404133319855\n",
      "Policy Loss:  -3.6798176765441895\n",
      "[(0.00023, 0.08865), (0.0, 0.08848), (1.0, 0.08865)]\n",
      "Alpha*: 0.0 tau*: 0.08848 Episode: 47022 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00018066451593767852\n",
      "Q Loss:  0.0014923328999429941\n",
      "Policy Loss:  0.011080631986260414\n",
      "[(0.00023, 0.08848), (0.0, 0.08831), (1.0, 0.08848)]\n",
      "Alpha*: 0.0 tau*: 0.08831 Episode: 47027 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  1.2009197473526\n",
      "Q Loss:  0.13550354540348053\n",
      "Policy Loss:  -4.027801036834717\n",
      "[(0.00023, 0.08831), (0.0, 0.08814), (1.0, 0.08831)]\n",
      "Alpha*: 0.0 tau*: 0.08814 Episode: 47031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.4003071784973145\n",
      "Q Loss:  0.11798743158578873\n",
      "Policy Loss:  -2.6919333934783936\n",
      "[(0.00023, 0.08814), (0.0, 0.08797), (1.0, 0.08814)]\n",
      "Alpha*: 0.0 tau*: 0.08797 Episode: 47093 length: 58 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  1157.21728515625\n",
      "Q Loss:  3864.38330078125\n",
      "Policy Loss:  -5.651681423187256\n",
      "[(0.00024, 0.08797), (0.0, 0.0878), (1.0, 0.08797)]\n",
      "Alpha*: 0.0 tau*: 0.0878 Episode: 47098 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1870779991149902\n",
      "Q Loss:  0.6698185205459595\n",
      "Policy Loss:  -3.482079029083252\n",
      "[(0.00024, 0.0878), (0.0, 0.08763), (1.0, 0.0878)]\n",
      "Alpha*: 0.0 tau*: 0.08763 Episode: 47104 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.017004966735839844\n",
      "Value Loss:  17814.775390625\n",
      "Q Loss:  16445.400390625\n",
      "Policy Loss:  -18.839111328125\n",
      "[(0.00025, 0.08763), (0.0, 0.08746), (1.0, 0.08763)]\n",
      "Alpha*: 0.0 tau*: 0.08746 Episode: 47160 length: 51 #teleports:5\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018002986907958984\n",
      "Value Loss:  59.44596481323242\n",
      "Q Loss:  0.08639886975288391\n",
      "Policy Loss:  -15.375519752502441\n",
      "[(0.00025, 0.08746), (0.0, 0.08729), (1.0, 0.08746)]\n",
      "Alpha*: 0.0 tau*: 0.08729 Episode: 47203 length: 40 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  5.7521530834492296e-05\n",
      "Q Loss:  0.00032932430622167885\n",
      "Policy Loss:  0.012132769450545311\n",
      "[(0.00025, 0.08729), (0.0, 0.08712), (1.0, 0.08729)]\n",
      "Alpha*: 0.0 tau*: 0.08712 Episode: 47208 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00020913405751343817\n",
      "Q Loss:  0.0014730223920196295\n",
      "Policy Loss:  0.021794848144054413\n",
      "[(0.00025, 0.08712), (0.0, 0.08695), (1.0, 0.08712)]\n",
      "Alpha*: 0.0 tau*: 0.08695 Episode: 47212 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  57.88893127441406\n",
      "Q Loss:  176.55516052246094\n",
      "Policy Loss:  -8.592369079589844\n",
      "[(0.00025, 0.08695), (0.0, 0.08678), (1.0, 0.08695)]\n",
      "Alpha*: 0.0 tau*: 0.08678 Episode: 47259 length: 41 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.850346565246582\n",
      "Q Loss:  0.004411471076309681\n",
      "Policy Loss:  -0.7309953570365906\n",
      "[(0.00025, 0.08678), (0.0, 0.08661), (1.0, 0.08678)]\n",
      "Alpha*: 0.0 tau*: 0.08661 Episode: 47288 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  581.428955078125\n",
      "Q Loss:  1786.511474609375\n",
      "Policy Loss:  -59.59778594970703\n",
      "[(0.00025, 0.08661), (0.0, 0.08644), (1.0, 0.08661)]\n",
      "Alpha*: 0.0 tau*: 0.08644 Episode: 47292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1161.4185791015625\n",
      "Q Loss:  2339.96142578125\n",
      "Policy Loss:  -120.54449462890625\n",
      "[(0.00025, 0.08644), (0.0, 0.08627), (1.0, 0.08644)]\n",
      "Alpha*: 0.0 tau*: 0.08627 Episode: 47296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.267179221846163e-05\n",
      "Q Loss:  0.000337181641953066\n",
      "Policy Loss:  0.003740521613508463\n",
      "[(0.00025, 0.08627), (0.0, 0.0861), (1.0, 0.08627)]\n",
      "Alpha*: 0.0 tau*: 0.0861 Episode: 47300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.8406462913844734e-05\n",
      "Q Loss:  0.0007509033312089741\n",
      "Policy Loss:  0.008307196199893951\n",
      "[(0.00025, 0.0861), (0.0, 0.08593), (1.0, 0.0861)]\n",
      "Alpha*: 0.0 tau*: 0.08593 Episode: 47304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3.365675001987256e-05\n",
      "Q Loss:  5.343216616893187e-05\n",
      "Policy Loss:  -0.0012461012229323387\n",
      "[(0.00025, 0.08593), (0.0, 0.08576), (1.0, 0.08593)]\n",
      "Alpha*: 0.0 tau*: 0.08576 Episode: 47308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00024202362692449242\n",
      "Q Loss:  0.07211009413003922\n",
      "Policy Loss:  0.09824100881814957\n",
      "[(0.00025, 0.08576), (0.0, 0.08559), (1.0, 0.08576)]\n",
      "Alpha*: 0.0 tau*: 0.08559 Episode: 47312 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.3113768100738525\n",
      "Q Loss:  0.13462477922439575\n",
      "Policy Loss:  -0.34239739179611206\n",
      "[(0.00025, 0.08559), (0.0, 0.08542), (1.0, 0.08559)]\n",
      "Alpha*: 0.0 tau*: 0.08542 Episode: 47341 length: 27 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00016293596127070487\n",
      "Q Loss:  0.06923644989728928\n",
      "Policy Loss:  0.09799890965223312\n",
      "[(0.00025, 0.08542), (0.0, 0.08525), (1.0, 0.08542)]\n",
      "Alpha*: 0.0 tau*: 0.08525 Episode: 47345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400920867919922\n",
      "Value Loss:  7.329183426918462e-05\n",
      "Q Loss:  0.06859323382377625\n",
      "Policy Loss:  0.08482436835765839\n",
      "[(0.00025, 0.08525), (0.0, 0.08508), (1.0, 0.08525)]\n",
      "Alpha*: 0.0 tau*: 0.08508 Episode: 47349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  56.65861892700195\n",
      "Q Loss:  2.4214701652526855\n",
      "Policy Loss:  -13.8727445602417\n",
      "[(0.00025, 0.08508), (0.0, 0.08491), (1.0, 0.08508)]\n",
      "Alpha*: 0.0 tau*: 0.08491 Episode: 47394 length: 41 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  7.417076994897798e-05\n",
      "Q Loss:  0.00034529963159002364\n",
      "Policy Loss:  0.00808546133339405\n",
      "[(0.00025, 0.08491), (0.0, 0.08474), (1.0, 0.08491)]\n",
      "Alpha*: 0.0 tau*: 0.08474 Episode: 47398 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  7.934412133181468e-05\n",
      "Q Loss:  0.0004553616454359144\n",
      "Policy Loss:  -0.010638358071446419\n",
      "[(0.00025, 0.08474), (0.0, 0.08457), (1.0, 0.08474)]\n",
      "Alpha*: 0.0 tau*: 0.08457 Episode: 47402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.00016440807667095214\n",
      "Q Loss:  0.08833347260951996\n",
      "Policy Loss:  0.13032382726669312\n",
      "[(0.00025, 0.08457), (0.0, 0.0844), (1.0, 0.08457)]\n",
      "Alpha*: 0.0 tau*: 0.0844 Episode: 47406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  52.792537689208984\n",
      "Q Loss:  93.06394958496094\n",
      "Policy Loss:  -10.884045600891113\n",
      "[(0.00025, 0.0844), (0.0, 0.08423), (1.0, 0.0844)]\n",
      "Alpha*: 0.0 tau*: 0.08423 Episode: 47496 length: 86 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.044010162353515625\n",
      "Value Loss:  0.0006744767306372523\n",
      "Q Loss:  0.003836593823507428\n",
      "Policy Loss:  -0.031115420162677765\n",
      "[(0.00025, 0.08423), (0.0, 0.08406), (1.0, 0.08423)]\n",
      "Alpha*: 0.0 tau*: 0.08406 Episode: 47500 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.3677729233168066e-06\n",
      "Q Loss:  0.005687044933438301\n",
      "Policy Loss:  0.024802692234516144\n",
      "[(0.00025, 0.08406), (0.0, 0.08389), (1.0, 0.08406)]\n",
      "Alpha*: 0.0 tau*: 0.08389 Episode: 47504 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.5950039625167847\n",
      "Q Loss:  0.01741594448685646\n",
      "Policy Loss:  -1.9756615161895752\n",
      "[(0.00025, 0.08389), (0.0, 0.08372), (1.0, 0.08389)]\n",
      "Alpha*: 0.0 tau*: 0.08372 Episode: 47508 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  77.49790954589844\n",
      "Q Loss:  76.98216247558594\n",
      "Policy Loss:  -17.72788429260254\n",
      "[(0.00024, 0.08372), (0.0, 0.08355), (1.0, 0.08372)]\n",
      "Alpha*: 0.0 tau*: 0.08355 Episode: 47603 length: 87 #teleports:8\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  4.55934859928675e-05\n",
      "Q Loss:  0.007287729997187853\n",
      "Policy Loss:  0.03794310986995697\n",
      "[(0.00024, 0.08355), (0.0, 0.08338), (1.0, 0.08355)]\n",
      "Alpha*: 0.0 tau*: 0.08338 Episode: 47607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.633939195424318e-05\n",
      "Q Loss:  0.0010035540908575058\n",
      "Policy Loss:  0.01766141504049301\n",
      "[(0.00024, 0.08338), (0.0, 0.08321), (1.0, 0.08338)]\n",
      "Alpha*: 0.0 tau*: 0.08321 Episode: 47611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.165644764318131e-05\n",
      "Q Loss:  0.0003549470566213131\n",
      "Policy Loss:  0.24577979743480682\n",
      "[(0.00024, 0.08321), (0.0, 0.08304), (1.0, 0.08321)]\n",
      "Alpha*: 0.0 tau*: 0.08304 Episode: 47615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  1.1759945154190063\n",
      "Q Loss:  0.4320169985294342\n",
      "Policy Loss:  -4.711804389953613\n",
      "[(0.00024, 0.08304), (0.0, 0.08287), (1.0, 0.08304)]\n",
      "Alpha*: 0.0 tau*: 0.08287 Episode: 47619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  36.819515228271484\n",
      "Q Loss:  109.14979553222656\n",
      "Policy Loss:  -7.422418117523193\n",
      "[(0.00024, 0.08287), (0.0, 0.0827), (1.0, 0.08287)]\n",
      "Alpha*: 0.0 tau*: 0.0827 Episode: 47757 length: 122 #teleports:16\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.981763489311561e-05\n",
      "Q Loss:  0.0002634894335642457\n",
      "Policy Loss:  0.007321685552597046\n",
      "[(0.00024, 0.0827), (0.0, 0.08253), (1.0, 0.0827)]\n",
      "Alpha*: 0.0 tau*: 0.08253 Episode: 47761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.5888233722071163e-05\n",
      "Q Loss:  0.0006851237267255783\n",
      "Policy Loss:  0.013042178936302662\n",
      "[(0.00024, 0.08253), (0.0, 0.08236), (1.0, 0.08253)]\n",
      "Alpha*: 0.0 tau*: 0.08236 Episode: 47766 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.125287963077426e-05\n",
      "Q Loss:  0.0005197119899094105\n",
      "Policy Loss:  0.0050226859748363495\n",
      "[(0.00023, 0.08236), (0.0, 0.08219), (1.0, 0.08236)]\n",
      "Alpha*: 0.0 tau*: 0.08219 Episode: 47770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.4108459949493408\n",
      "Q Loss:  0.0060278200544416904\n",
      "Policy Loss:  -0.6713732481002808\n",
      "[(0.00023, 0.08219), (0.0, 0.08202), (1.0, 0.08219)]\n",
      "Alpha*: 0.0 tau*: 0.08202 Episode: 47808 length: 35 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  9.84355210675858e-06\n",
      "Q Loss:  1.2150941984145902e-05\n",
      "Policy Loss:  -0.001989726908504963\n",
      "[(0.00023, 0.08202), (0.0, 0.08185), (1.0, 0.08202)]\n",
      "Alpha*: 0.0 tau*: 0.08185 Episode: 47812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019309282302856445\n",
      "Value Loss:  3.117242158623412e-05\n",
      "Q Loss:  0.00018304577679373324\n",
      "Policy Loss:  0.006755481008440256\n",
      "[(0.00023, 0.08185), (0.0, 0.08168), (1.0, 0.08185)]\n",
      "Alpha*: 0.0 tau*: 0.08168 Episode: 47817 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00019610978779383004\n",
      "Q Loss:  0.010372433811426163\n",
      "Policy Loss:  -0.04455031827092171\n",
      "[(0.00023, 0.08168), (0.0, 0.08151), (1.0, 0.08168)]\n",
      "Alpha*: 0.0 tau*: 0.08151 Episode: 47821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700638771057129\n",
      "Value Loss:  0.0003138514584861696\n",
      "Q Loss:  0.013524200767278671\n",
      "Policy Loss:  -0.040319424122571945\n",
      "[(0.00023, 0.08151), (0.0, 0.08134), (1.0, 0.08151)]\n",
      "Alpha*: 0.0 tau*: 0.08134 Episode: 47825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.154306250507943e-05\n",
      "Q Loss:  0.001874161884188652\n",
      "Policy Loss:  -0.006364189554005861\n",
      "[(0.00023, 0.08134), (0.0, 0.08117), (1.0, 0.08134)]\n",
      "Alpha*: 0.0 tau*: 0.08117 Episode: 47830 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  8.248970516433474e-06\n",
      "Q Loss:  0.0011927351588383317\n",
      "Policy Loss:  -0.008607467636466026\n",
      "[(0.00023, 0.08117), (0.0, 0.081), (1.0, 0.08117)]\n",
      "Alpha*: 0.0 tau*: 0.081 Episode: 47834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.259210668853484e-05\n",
      "Q Loss:  0.0008722966304048896\n",
      "Policy Loss:  -0.008113737218081951\n",
      "[(0.00023, 0.081), (0.0, 0.08083), (1.0, 0.081)]\n",
      "Alpha*: 0.0 tau*: 0.08083 Episode: 47839 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  80.8861312866211\n",
      "Q Loss:  7.585351467132568\n",
      "Policy Loss:  -18.774694442749023\n",
      "[(0.00023, 0.08083), (0.0, 0.08066), (1.0, 0.08083)]\n",
      "Alpha*: 0.0 tau*: 0.08066 Episode: 47898 length: 55 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  3.739440679550171\n",
      "Q Loss:  0.09399290382862091\n",
      "Policy Loss:  2.582388401031494\n",
      "[(0.00023, 0.08066), (0.0, 0.08049), (1.0, 0.08066)]\n",
      "Alpha*: 0.0 tau*: 0.08049 Episode: 47913 length: 15 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.625141521799378e-05\n",
      "Q Loss:  0.0005922501441091299\n",
      "Policy Loss:  -0.00951958354562521\n",
      "[(0.00023, 0.08049), (0.0, 0.08032), (1.0, 0.08049)]\n",
      "Alpha*: 0.0 tau*: 0.08032 Episode: 47917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.1753590772277676e-05\n",
      "Q Loss:  0.0001698207634035498\n",
      "Policy Loss:  -0.0016521353973075747\n",
      "[(0.00023, 0.08032), (0.0, 0.08015), (1.0, 0.08032)]\n",
      "Alpha*: 0.0 tau*: 0.08015 Episode: 47921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  90.54421997070312\n",
      "Q Loss:  159.81881713867188\n",
      "Policy Loss:  -17.616209030151367\n",
      "[(0.00022, 0.08015), (0.0, 0.07998), (1.0, 0.08015)]\n",
      "Alpha*: 0.0 tau*: 0.07998 Episode: 47974 length: 49 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012004375457763672\n",
      "Value Loss:  98.67134857177734\n",
      "Q Loss:  315.99169921875\n",
      "Policy Loss:  -13.131287574768066\n",
      "[(0.00022, 0.07998), (0.0, 0.07981), (1.0, 0.07998)]\n",
      "Alpha*: 0.0 tau*: 0.07981 Episode: 48022 length: 45 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  5.775650606665295e-06\n",
      "Q Loss:  0.0002886821166612208\n",
      "Policy Loss:  -0.00395943783223629\n",
      "[(0.00022, 0.07981), (0.0, 0.07964), (1.0, 0.07981)]\n",
      "Alpha*: 0.0 tau*: 0.07964 Episode: 48027 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.3607103028334677e-05\n",
      "Q Loss:  0.00015599615289829671\n",
      "Policy Loss:  0.001281479373574257\n",
      "[(0.00022, 0.07964), (0.0, 0.07947), (1.0, 0.07964)]\n",
      "Alpha*: 0.0 tau*: 0.07947 Episode: 48031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.0538379582576454e-05\n",
      "Q Loss:  6.985298387007788e-05\n",
      "Policy Loss:  0.0030937937553972006\n",
      "[(0.00022, 0.07947), (0.0, 0.0793), (1.0, 0.07947)]\n",
      "Alpha*: 0.0 tau*: 0.0793 Episode: 48035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  8.559029083698988e-06\n",
      "Q Loss:  9.9320532171987e-06\n",
      "Policy Loss:  0.0020787115208804607\n",
      "[(0.00022, 0.0793), (0.0, 0.07913), (1.0, 0.0793)]\n",
      "Alpha*: 0.0 tau*: 0.07913 Episode: 48039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.893730071373284e-06\n",
      "Q Loss:  8.934276411309838e-05\n",
      "Policy Loss:  -0.0031194346956908703\n",
      "[(0.00022, 0.07913), (0.0, 0.07896), (1.0, 0.07913)]\n",
      "Alpha*: 0.0 tau*: 0.07896 Episode: 48043 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013583660125732422\n",
      "Value Loss:  3.198760896339081e-05\n",
      "Q Loss:  0.0032584730070084333\n",
      "Policy Loss:  -0.014104187488555908\n",
      "[(0.00022, 0.07896), (0.0, 0.07879), (1.0, 0.07896)]\n",
      "Alpha*: 0.0 tau*: 0.07879 Episode: 48047 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500937461853027\n",
      "Value Loss:  3.9843675040174276e-05\n",
      "Q Loss:  0.001196265104226768\n",
      "Policy Loss:  0.22941863536834717\n",
      "[(0.00022, 0.07879), (0.0, 0.07862), (1.0, 0.07879)]\n",
      "Alpha*: 0.0 tau*: 0.07862 Episode: 48052 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6350809335708618\n",
      "Q Loss:  0.2994271218776703\n",
      "Policy Loss:  -3.73610520362854\n",
      "[(0.00022, 0.07862), (0.0, 0.07845), (1.0, 0.07862)]\n",
      "Alpha*: 0.0 tau*: 0.07845 Episode: 48057 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.6350168585777283\n",
      "Q Loss:  0.29153141379356384\n",
      "Policy Loss:  -1.3169022798538208\n",
      "[(0.00022, 0.07845), (0.0, 0.07828), (1.0, 0.07845)]\n",
      "Alpha*: 0.0 tau*: 0.07828 Episode: 48061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  199.0702667236328\n",
      "Q Loss:  197.2940673828125\n",
      "Policy Loss:  -41.409420013427734\n",
      "[(0.00022, 0.07828), (0.0, 0.07811), (1.0, 0.07828)]\n",
      "Alpha*: 0.0 tau*: 0.07811 Episode: 48110 length: 44 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  17479.861328125\n",
      "Q Loss:  16243.990234375\n",
      "Policy Loss:  -8.231812477111816\n",
      "[(0.00021, 0.07811), (0.0, 0.07794), (1.0, 0.07811)]\n",
      "Alpha*: 0.0 tau*: 0.07794 Episode: 48165 length: 52 #teleports:3\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00012015474203508347\n",
      "Q Loss:  0.00017979982658289373\n",
      "Policy Loss:  0.007113038096576929\n",
      "[(0.00021, 0.07794), (0.0, 0.07777), (1.0, 0.07794)]\n",
      "Alpha*: 0.0 tau*: 0.07777 Episode: 48169 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  41.51643753051758\n",
      "Q Loss:  18.90906524658203\n",
      "Policy Loss:  -10.997961044311523\n",
      "[(0.00021, 0.07777), (0.0, 0.0776), (1.0, 0.07777)]\n",
      "Alpha*: 0.0 tau*: 0.0776 Episode: 48229 length: 54 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.2445178072084673e-05\n",
      "Q Loss:  2.025878529821057e-05\n",
      "Policy Loss:  -0.00042600775486789644\n",
      "[(0.00021, 0.0776), (0.0, 0.07743), (1.0, 0.0776)]\n",
      "Alpha*: 0.0 tau*: 0.07743 Episode: 48234 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.037008047103881836\n",
      "Value Loss:  14266.162109375\n",
      "Q Loss:  13319.47265625\n",
      "Policy Loss:  -19.355335235595703\n",
      "[(0.00021, 0.07743), (0.0, 0.07726), (1.0, 0.07743)]\n",
      "Alpha*: 0.0 tau*: 0.07726 Episode: 48305 length: 64 #teleports:7\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002500289410818368\n",
      "Q Loss:  0.014635373838245869\n",
      "Policy Loss:  0.03985351324081421\n",
      "[(0.00021, 0.07726), (0.0, 0.07709), (1.0, 0.07726)]\n",
      "Alpha*: 0.0 tau*: 0.07709 Episode: 48309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00011494447971927002\n",
      "Q Loss:  0.00022785777400713414\n",
      "Policy Loss:  -0.010744394734501839\n",
      "[(0.00021, 0.07709), (0.0, 0.07692), (1.0, 0.07709)]\n",
      "Alpha*: 0.0 tau*: 0.07692 Episode: 48314 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001664040028117597\n",
      "Q Loss:  0.00038482469972223043\n",
      "Policy Loss:  -0.010499600321054459\n",
      "[(0.00021, 0.07692), (0.0, 0.07675), (1.0, 0.07692)]\n",
      "Alpha*: 0.0 tau*: 0.07675 Episode: 48318 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  7.511775766033679e-05\n",
      "Q Loss:  0.00010844615462701768\n",
      "Policy Loss:  -0.0013272350188344717\n",
      "[(0.00021, 0.07675), (0.0, 0.07658), (1.0, 0.07675)]\n",
      "Alpha*: 0.0 tau*: 0.07658 Episode: 48322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  9.46598156588152e-05\n",
      "Q Loss:  0.00010173176997341216\n",
      "Policy Loss:  0.004508385434746742\n",
      "[(0.00021, 0.07658), (0.0, 0.07641), (1.0, 0.07658)]\n",
      "Alpha*: 0.0 tau*: 0.07641 Episode: 48326 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00013714181841351092\n",
      "Q Loss:  0.00011248076043557376\n",
      "Policy Loss:  0.004002339206635952\n",
      "[(0.00021, 0.07641), (0.0, 0.07624), (1.0, 0.07641)]\n",
      "Alpha*: 0.0 tau*: 0.07624 Episode: 48330 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00013755192048847675\n",
      "Q Loss:  0.0006545038195326924\n",
      "Policy Loss:  0.23834434151649475\n",
      "[(0.0002, 0.07624), (0.0, 0.07607), (1.0, 0.07624)]\n",
      "Alpha*: 0.0 tau*: 0.07607 Episode: 48334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.5104303359985352\n",
      "Q Loss:  0.11489751189947128\n",
      "Policy Loss:  -1.9839491844177246\n",
      "[(0.0002, 0.07607), (0.0, 0.0759), (1.0, 0.07607)]\n",
      "Alpha*: 0.0 tau*: 0.0759 Episode: 48376 length: 39 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  9.098474401980639e-05\n",
      "Q Loss:  0.00014875097258482128\n",
      "Policy Loss:  -0.0035275749396532774\n",
      "[(0.0002, 0.0759), (0.0, 0.07573), (1.0, 0.0759)]\n",
      "Alpha*: 0.0 tau*: 0.07573 Episode: 48380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01335597038269043\n",
      "Value Loss:  0.0002270955592393875\n",
      "Q Loss:  9.313460759585723e-05\n",
      "Policy Loss:  0.0008073464268818498\n",
      "[(0.0002, 0.07573), (0.0, 0.07556), (1.0, 0.07573)]\n",
      "Alpha*: 0.0 tau*: 0.07556 Episode: 48384 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.6581924557685852\n",
      "Q Loss:  0.09489350765943527\n",
      "Policy Loss:  -2.7399628162384033\n",
      "[(0.0002, 0.07556), (0.0, 0.07539), (1.0, 0.07556)]\n",
      "Alpha*: 0.0 tau*: 0.07539 Episode: 48388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.311521291732788\n",
      "Q Loss:  0.26914432644844055\n",
      "Policy Loss:  -4.4568586349487305\n",
      "[(0.0002, 0.07539), (0.0, 0.07522), (1.0, 0.07539)]\n",
      "Alpha*: 0.0 tau*: 0.07522 Episode: 48393 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.9399020604614634e-06\n",
      "Q Loss:  0.00011439769150456414\n",
      "Policy Loss:  -0.002012350130826235\n",
      "[(0.0002, 0.07522), (0.0, 0.07505), (1.0, 0.07522)]\n",
      "Alpha*: 0.0 tau*: 0.07505 Episode: 48397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1122.1746826171875\n",
      "Q Loss:  3659.26708984375\n",
      "Policy Loss:  9.097268104553223\n",
      "[(0.0002, 0.07505), (0.0, 0.07488), (1.0, 0.07505)]\n",
      "Alpha*: 0.0 tau*: 0.07488 Episode: 48404 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.005990348756313324\n",
      "Q Loss:  0.016150301322340965\n",
      "Policy Loss:  -0.05787377431988716\n",
      "[(0.0002, 0.07488), (0.0, 0.07471), (1.0, 0.07488)]\n",
      "Alpha*: 0.0 tau*: 0.07471 Episode: 48408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  0.0003939117304980755\n",
      "Q Loss:  0.0001692794030532241\n",
      "Policy Loss:  -0.002722432604059577\n",
      "[(0.0002, 0.07471), (0.0, 0.07455), (1.0, 0.07471)]\n",
      "Alpha*: 0.0 tau*: 0.07455 Episode: 48412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00021865707822144032\n",
      "Q Loss:  0.00046665125410072505\n",
      "Policy Loss:  0.016212357208132744\n",
      "[(0.0002, 0.07455), (0.0, 0.07439), (1.0, 0.07455)]\n",
      "Alpha*: 0.0 tau*: 0.07439 Episode: 48416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  43.75476837158203\n",
      "Q Loss:  133.83935546875\n",
      "Policy Loss:  -6.352305889129639\n",
      "[(0.00019, 0.07439), (0.0, 0.07423), (1.0, 0.07439)]\n",
      "Alpha*: 0.0 tau*: 0.07423 Episode: 48474 length: 52 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.4942128658294678\n",
      "Q Loss:  0.060585133731365204\n",
      "Policy Loss:  -0.2604064345359802\n",
      "[(0.00019, 0.07423), (0.0, 0.07407), (1.0, 0.07423)]\n",
      "Alpha*: 0.0 tau*: 0.07407 Episode: 48497 length: 22 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0002082256687572226\n",
      "Q Loss:  0.0008235640125349164\n",
      "Policy Loss:  0.02028752863407135\n",
      "[(0.00019, 0.07407), (0.0, 0.07391), (1.0, 0.07407)]\n",
      "Alpha*: 0.0 tau*: 0.07391 Episode: 48502 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.943441985640675e-05\n",
      "Q Loss:  0.0004269444616511464\n",
      "Policy Loss:  0.009192866273224354\n",
      "[(0.00019, 0.07391), (0.0, 0.07375), (1.0, 0.07391)]\n",
      "Alpha*: 0.0 tau*: 0.07375 Episode: 48506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.6023348507587798e-05\n",
      "Q Loss:  0.00021162569464650005\n",
      "Policy Loss:  0.009502650238573551\n",
      "[(0.00019, 0.07375), (0.0, 0.07359), (1.0, 0.07375)]\n",
      "Alpha*: 0.0 tau*: 0.07359 Episode: 48510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.5064697265625\n",
      "Q Loss:  0.026091471314430237\n",
      "Policy Loss:  -1.4348266124725342\n",
      "[(0.00019, 0.07359), (0.0, 0.07343), (1.0, 0.07359)]\n",
      "Alpha*: 0.0 tau*: 0.07343 Episode: 48549 length: 38 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  0.0006660842918790877\n",
      "Q Loss:  0.00012347142910584807\n",
      "Policy Loss:  0.0009281635284423828\n",
      "[(0.00019, 0.07343), (0.0, 0.07327), (1.0, 0.07343)]\n",
      "Alpha*: 0.0 tau*: 0.07327 Episode: 48553 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.00035010758438147604\n",
      "Q Loss:  0.0007553804898634553\n",
      "Policy Loss:  0.2469388246536255\n",
      "[(0.00019, 0.07327), (0.0, 0.07311), (1.0, 0.07327)]\n",
      "Alpha*: 0.0 tau*: 0.07311 Episode: 48557 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  98.9477310180664\n",
      "Q Loss:  113.63166809082031\n",
      "Policy Loss:  -21.704265594482422\n",
      "[(0.00018, 0.07311), (0.0, 0.07295), (1.0, 0.07311)]\n",
      "Alpha*: 0.0 tau*: 0.07295 Episode: 48627 length: 67 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00017200755246449262\n",
      "Q Loss:  0.0030074073001742363\n",
      "Policy Loss:  -0.002472926629707217\n",
      "[(0.00018, 0.07295), (0.0, 0.07279), (1.0, 0.07295)]\n",
      "Alpha*: 0.0 tau*: 0.07279 Episode: 48632 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.007547036744654179\n",
      "Q Loss:  27.894750595092773\n",
      "Policy Loss:  1.7932748794555664\n",
      "[(0.00018, 0.07279), (0.0, 0.07263), (1.0, 0.07279)]\n",
      "Alpha*: 0.0 tau*: 0.07263 Episode: 48636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  546.1195068359375\n",
      "Q Loss:  1892.32177734375\n",
      "Policy Loss:  -48.23830032348633\n",
      "[(0.00018, 0.07263), (0.0, 0.07247), (1.0, 0.07263)]\n",
      "Alpha*: 0.0 tau*: 0.07247 Episode: 48641 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00010482583456905559\n",
      "Q Loss:  0.0011671764077618718\n",
      "Policy Loss:  0.005751820281147957\n",
      "[(0.00018, 0.07247), (0.0, 0.07231), (1.0, 0.07247)]\n",
      "Alpha*: 0.0 tau*: 0.07231 Episode: 48645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  17564.103515625\n",
      "Q Loss:  16430.353515625\n",
      "Policy Loss:  -21.533447265625\n",
      "[(0.00019, 0.07231), (0.0, 0.07215), (1.0, 0.07231)]\n",
      "Alpha*: 0.0 tau*: 0.07215 Episode: 48702 length: 52 #teleports:5\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  543.32666015625\n",
      "Q Loss:  1601.397216796875\n",
      "Policy Loss:  -66.09049224853516\n",
      "[(0.00019, 0.07215), (0.0, 0.07199), (1.0, 0.07215)]\n",
      "Alpha*: 0.0 tau*: 0.07199 Episode: 48706 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0028379354625940323\n",
      "Q Loss:  0.0017527788877487183\n",
      "Policy Loss:  -0.026865992695093155\n",
      "[(0.00018, 0.07199), (0.0, 0.07183), (1.0, 0.07199)]\n",
      "Alpha*: 0.0 tau*: 0.07183 Episode: 48710 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0024099741131067276\n",
      "Q Loss:  27.758071899414062\n",
      "Policy Loss:  1.8266435861587524\n",
      "[(0.00018, 0.07183), (0.0, 0.07167), (1.0, 0.07183)]\n",
      "Alpha*: 0.0 tau*: 0.07167 Episode: 48715 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  0.0003249727305956185\n",
      "Q Loss:  0.0007406254298985004\n",
      "Policy Loss:  0.011377992108464241\n",
      "[(0.00018, 0.07167), (0.0, 0.07151), (1.0, 0.07167)]\n",
      "Alpha*: 0.0 tau*: 0.07151 Episode: 48719 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.0003761736734304577\n",
      "Q Loss:  8.651442476548254e-05\n",
      "Policy Loss:  0.004551267251372337\n",
      "[(0.00018, 0.07151), (0.0, 0.07135), (1.0, 0.07151)]\n",
      "Alpha*: 0.0 tau*: 0.07135 Episode: 48724 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00029941159300506115\n",
      "Q Loss:  0.00043288571760058403\n",
      "Policy Loss:  0.016397442668676376\n",
      "[(0.00018, 0.07135), (0.0, 0.07119), (1.0, 0.07135)]\n",
      "Alpha*: 0.0 tau*: 0.07119 Episode: 48729 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  33.42188262939453\n",
      "Q Loss:  0.04556557163596153\n",
      "Policy Loss:  -8.831586837768555\n",
      "[(0.00018, 0.07119), (0.0, 0.07103), (1.0, 0.07119)]\n",
      "Alpha*: 0.0 tau*: 0.07103 Episode: 48801 length: 66 #teleports:6\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  27555.984375\n",
      "Q Loss:  25687.927734375\n",
      "Policy Loss:  -12.049715995788574\n",
      "[(0.00018, 0.07103), (0.0, 0.07087), (1.0, 0.07103)]\n",
      "Alpha*: 0.0 tau*: 0.07087 Episode: 48838 length: 33 #teleports:4\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011001110076904297\n",
      "Value Loss:  0.0005035867798142135\n",
      "Q Loss:  0.027542157098650932\n",
      "Policy Loss:  0.07014493644237518\n",
      "[(0.00018, 0.07087), (0.0, 0.07071), (1.0, 0.07087)]\n",
      "Alpha*: 0.0 tau*: 0.07071 Episode: 48842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00025316260871477425\n",
      "Q Loss:  0.034562163054943085\n",
      "Policy Loss:  0.06586402654647827\n",
      "[(0.00018, 0.07071), (0.0, 0.07055), (1.0, 0.07071)]\n",
      "Alpha*: 0.0 tau*: 0.07055 Episode: 48846 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0006440018187277019\n",
      "Q Loss:  0.00512349558994174\n",
      "Policy Loss:  0.012657936662435532\n",
      "[(0.00018, 0.07055), (0.0, 0.07039), (1.0, 0.07055)]\n",
      "Alpha*: 0.0 tau*: 0.07039 Episode: 48850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0003052585234399885\n",
      "Q Loss:  0.0003729902673512697\n",
      "Policy Loss:  -0.00032686989288777113\n",
      "[(0.00018, 0.07039), (0.0, 0.07023), (1.0, 0.07039)]\n",
      "Alpha*: 0.0 tau*: 0.07023 Episode: 48855 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0021233505103737116\n",
      "Q Loss:  0.0031450754031538963\n",
      "Policy Loss:  -0.014706950634717941\n",
      "[(0.00018, 0.07023), (0.0, 0.07007), (1.0, 0.07023)]\n",
      "Alpha*: 0.0 tau*: 0.07007 Episode: 48859 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0015107829822227359\n",
      "Q Loss:  0.0027001884300261736\n",
      "Policy Loss:  -0.016796555370092392\n",
      "[(0.00018, 0.07007), (0.0, 0.06991), (1.0, 0.07007)]\n",
      "Alpha*: 0.0 tau*: 0.06991 Episode: 48864 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0013080945936962962\n",
      "Q Loss:  0.0005603039753623307\n",
      "Policy Loss:  -0.00965113565325737\n",
      "[(0.00018, 0.06991), (0.0, 0.06975), (1.0, 0.06991)]\n",
      "Alpha*: 0.0 tau*: 0.06975 Episode: 48868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0010422243503853679\n",
      "Q Loss:  0.014652755111455917\n",
      "Policy Loss:  -0.05538883060216904\n",
      "[(0.00018, 0.06975), (0.0, 0.06959), (1.0, 0.06975)]\n",
      "Alpha*: 0.0 tau*: 0.06959 Episode: 48875 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0005041608237661421\n",
      "Q Loss:  0.0008841320523060858\n",
      "Policy Loss:  -0.005234883166849613\n",
      "[(0.00018, 0.06959), (0.0, 0.06943), (1.0, 0.06959)]\n",
      "Alpha*: 0.0 tau*: 0.06943 Episode: 48879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0006070914678275585\n",
      "Q Loss:  83.59107971191406\n",
      "Policy Loss:  5.494173049926758\n",
      "[(0.00018, 0.06943), (0.0, 0.06927), (1.0, 0.06943)]\n",
      "Alpha*: 0.0 tau*: 0.06927 Episode: 48884 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.000380422396119684\n",
      "Q Loss:  0.05481484532356262\n",
      "Policy Loss:  -0.10511964559555054\n",
      "[(0.00018, 0.06927), (0.0, 0.06911), (1.0, 0.06927)]\n",
      "Alpha*: 0.0 tau*: 0.06911 Episode: 48888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.004325388465076685\n",
      "Q Loss:  0.004136121831834316\n",
      "Policy Loss:  0.01416641566902399\n",
      "[(0.00018, 0.06911), (0.0, 0.06895), (1.0, 0.06911)]\n",
      "Alpha*: 0.0 tau*: 0.06895 Episode: 48892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  2.5544722080230713\n",
      "Q Loss:  0.1153370663523674\n",
      "Policy Loss:  -0.9274610877037048\n",
      "[(0.00018, 0.06895), (0.0, 0.06879), (1.0, 0.06895)]\n",
      "Alpha*: 0.0 tau*: 0.06879 Episode: 48918 length: 25 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01163172721862793\n",
      "Value Loss:  0.0002574060927145183\n",
      "Q Loss:  0.01730199344456196\n",
      "Policy Loss:  -0.041376493871212006\n",
      "[(0.00018, 0.06879), (0.0, 0.06863), (1.0, 0.06879)]\n",
      "Alpha*: 0.0 tau*: 0.06863 Episode: 48922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00048584851901978254\n",
      "Q Loss:  0.020170778036117554\n",
      "Policy Loss:  -0.05180526524782181\n",
      "[(0.00018, 0.06863), (0.0, 0.06847), (1.0, 0.06863)]\n",
      "Alpha*: 0.0 tau*: 0.06847 Episode: 48926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100847244262695\n",
      "Value Loss:  0.0005572326481342316\n",
      "Q Loss:  0.003197174519300461\n",
      "Policy Loss:  -0.01314761582762003\n",
      "[(0.00018, 0.06847), (0.0, 0.06831), (1.0, 0.06847)]\n",
      "Alpha*: 0.0 tau*: 0.06831 Episode: 48930 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005578994750977\n",
      "Value Loss:  0.01309799961745739\n",
      "Q Loss:  0.014721600338816643\n",
      "Policy Loss:  0.061540596187114716\n",
      "[(0.00018, 0.06831), (0.0, 0.06815), (1.0, 0.06831)]\n",
      "Alpha*: 0.0 tau*: 0.06815 Episode: 48934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  6.204906094353646e-05\n",
      "Q Loss:  0.0074367886409163475\n",
      "Policy Loss:  0.2761225998401642\n",
      "[(0.00018, 0.06815), (0.0, 0.06799), (1.0, 0.06815)]\n",
      "Alpha*: 0.0 tau*: 0.06799 Episode: 48938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  57.5306282043457\n",
      "Q Loss:  66.18228149414062\n",
      "Policy Loss:  -13.059083938598633\n",
      "[(0.00017, 0.06799), (0.0, 0.06783), (1.0, 0.06799)]\n",
      "Alpha*: 0.0 tau*: 0.06783 Episode: 49068 length: 117 #teleports:13\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.7063088417053223\n",
      "Q Loss:  0.149954691529274\n",
      "Policy Loss:  -1.703548789024353\n",
      "[(0.00017, 0.06783), (0.0, 0.06767), (1.0, 0.06783)]\n",
      "Alpha*: 0.0 tau*: 0.06767 Episode: 49103 length: 34 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1112.71826171875\n",
      "Q Loss:  258.84716796875\n",
      "Policy Loss:  -255.34442138671875\n",
      "[(0.00017, 0.06767), (0.0, 0.06751), (1.0, 0.06767)]\n",
      "Alpha*: 0.0 tau*: 0.06751 Episode: 49108 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007844286155886948\n",
      "Q Loss:  0.008908575400710106\n",
      "Policy Loss:  0.0009768586605787277\n",
      "[(0.00017, 0.06751), (0.0, 0.06735), (1.0, 0.06751)]\n",
      "Alpha*: 0.0 tau*: 0.06735 Episode: 49112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.006719185970723629\n",
      "Q Loss:  0.002948105102404952\n",
      "Policy Loss:  -0.04193159565329552\n",
      "[(0.00017, 0.06735), (0.0, 0.06719), (1.0, 0.06735)]\n",
      "Alpha*: 0.0 tau*: 0.06719 Episode: 49116 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.007034966256469488\n",
      "Q Loss:  0.01405822392553091\n",
      "Policy Loss:  -0.037608757615089417\n",
      "[(0.00017, 0.06719), (0.0, 0.06703), (1.0, 0.06719)]\n",
      "Alpha*: 0.0 tau*: 0.06703 Episode: 49120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.005728858057409525\n",
      "Q Loss:  0.003035525791347027\n",
      "Policy Loss:  0.00539235956966877\n",
      "[(0.00017, 0.06703), (0.0, 0.06687), (1.0, 0.06703)]\n",
      "Alpha*: 0.0 tau*: 0.06687 Episode: 49124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04000687599182129\n",
      "Value Loss:  0.0002504060685168952\n",
      "Q Loss:  0.003748709335923195\n",
      "Policy Loss:  0.024062879383563995\n",
      "[(0.00017, 0.06687), (0.0, 0.06671), (1.0, 0.06687)]\n",
      "Alpha*: 0.0 tau*: 0.06671 Episode: 49128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0013912381837144494\n",
      "Q Loss:  0.010669408366084099\n",
      "Policy Loss:  0.023210929706692696\n",
      "[(0.00017, 0.06671), (0.0, 0.06655), (1.0, 0.06671)]\n",
      "Alpha*: 0.0 tau*: 0.06655 Episode: 49133 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.0005662172334268689\n",
      "Q Loss:  0.004318819381296635\n",
      "Policy Loss:  0.01737133041024208\n",
      "[(0.00017, 0.06655), (0.0, 0.06639), (1.0, 0.06655)]\n",
      "Alpha*: 0.0 tau*: 0.06639 Episode: 49137 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.5844193696975708\n",
      "Q Loss:  0.08550998568534851\n",
      "Policy Loss:  -1.2151634693145752\n",
      "[(0.00017, 0.06639), (0.0, 0.06623), (1.0, 0.06639)]\n",
      "Alpha*: 0.0 tau*: 0.06623 Episode: 49167 length: 29 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  11680.8115234375\n",
      "Q Loss:  10864.681640625\n",
      "Policy Loss:  -12.631651878356934\n",
      "[(0.00017, 0.06623), (0.0, 0.06607), (1.0, 0.06623)]\n",
      "Alpha*: 0.0 tau*: 0.06607 Episode: 49254 length: 78 #teleports:9\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.1065542697906494\n",
      "Q Loss:  0.036514200270175934\n",
      "Policy Loss:  -1.2629809379577637\n",
      "[(0.00017, 0.06607), (0.0, 0.06591), (1.0, 0.06607)]\n",
      "Alpha*: 0.0 tau*: 0.06591 Episode: 49301 length: 44 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0003129288670606911\n",
      "Q Loss:  0.06153898313641548\n",
      "Policy Loss:  0.1079881340265274\n",
      "[(0.00017, 0.06591), (0.0, 0.06575), (1.0, 0.06591)]\n",
      "Alpha*: 0.0 tau*: 0.06575 Episode: 49305 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.000307966663967818\n",
      "Q Loss:  0.0005147007177583873\n",
      "Policy Loss:  0.010318238288164139\n",
      "[(0.00017, 0.06575), (0.0, 0.06559), (1.0, 0.06575)]\n",
      "Alpha*: 0.0 tau*: 0.06559 Episode: 49309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.004455397371202707\n",
      "Q Loss:  0.015041660517454147\n",
      "Policy Loss:  0.033225834369659424\n",
      "[(0.00017, 0.06559), (0.0, 0.06543), (1.0, 0.06559)]\n",
      "Alpha*: 0.0 tau*: 0.06543 Episode: 49314 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.004334405995905399\n",
      "Q Loss:  0.00044146092841401696\n",
      "Policy Loss:  0.029398422688245773\n",
      "[(0.00017, 0.06543), (0.0, 0.06527), (1.0, 0.06543)]\n",
      "Alpha*: 0.0 tau*: 0.06527 Episode: 49318 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.003282595193013549\n",
      "Q Loss:  0.005174826830625534\n",
      "Policy Loss:  0.015341343358159065\n",
      "[(0.00017, 0.06527), (0.0, 0.06511), (1.0, 0.06527)]\n",
      "Alpha*: 0.0 tau*: 0.06511 Episode: 49322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005340576171875\n",
      "Value Loss:  61.90993118286133\n",
      "Q Loss:  3.084204912185669\n",
      "Policy Loss:  -15.109782218933105\n",
      "[(0.00017, 0.06511), (0.0, 0.06495), (1.0, 0.06511)]\n",
      "Alpha*: 0.0 tau*: 0.06495 Episode: 49360 length: 36 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0027221804484725\n",
      "Q Loss:  0.0031511769630014896\n",
      "Policy Loss:  0.01261948887258768\n",
      "[(0.00017, 0.06495), (0.0, 0.06479), (1.0, 0.06495)]\n",
      "Alpha*: 0.0 tau*: 0.06479 Episode: 49364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600170135498047\n",
      "Value Loss:  0.0006394754745997488\n",
      "Q Loss:  0.002307303249835968\n",
      "Policy Loss:  -0.009503128938376904\n",
      "[(0.00017, 0.06479), (0.0, 0.06463), (1.0, 0.06479)]\n",
      "Alpha*: 0.0 tau*: 0.06463 Episode: 49368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0008512596832588315\n",
      "Q Loss:  0.0014912267215549946\n",
      "Policy Loss:  -0.02659820392727852\n",
      "[(0.00017, 0.06463), (0.0, 0.06447), (1.0, 0.06463)]\n",
      "Alpha*: 0.0 tau*: 0.06447 Episode: 49372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.819608747959137\n",
      "Q Loss:  0.2851755917072296\n",
      "Policy Loss:  -2.9878013134002686\n",
      "[(0.00017, 0.06447), (0.0, 0.06431), (1.0, 0.06447)]\n",
      "Alpha*: 0.0 tau*: 0.06431 Episode: 49376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.345568895339966\n",
      "Q Loss:  0.17459486424922943\n",
      "Policy Loss:  -1.1411908864974976\n",
      "[(0.00017, 0.06431), (0.0, 0.06415), (1.0, 0.06431)]\n",
      "Alpha*: 0.0 tau*: 0.06415 Episode: 49397 length: 20 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.8162773847579956\n",
      "Q Loss:  0.2791828513145447\n",
      "Policy Loss:  -2.969269275665283\n",
      "[(0.00017, 0.06415), (0.0, 0.06399), (1.0, 0.06415)]\n",
      "Alpha*: 0.0 tau*: 0.06399 Episode: 49402 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0036800203379243612\n",
      "Q Loss:  0.012111940421164036\n",
      "Policy Loss:  -0.02360219694674015\n",
      "[(0.00017, 0.06399), (0.0, 0.06383), (1.0, 0.06399)]\n",
      "Alpha*: 0.0 tau*: 0.06383 Episode: 49407 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.8047356605529785\n",
      "Q Loss:  0.0900159701704979\n",
      "Policy Loss:  -2.949894905090332\n",
      "[(0.00017, 0.06383), (0.0, 0.06367), (1.0, 0.06383)]\n",
      "Alpha*: 0.0 tau*: 0.06367 Episode: 49411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.84309321641922\n",
      "Q Loss:  0.03589225932955742\n",
      "Policy Loss:  -1.828112244606018\n",
      "[(0.00016, 0.06367), (0.0, 0.06351), (1.0, 0.06367)]\n",
      "Alpha*: 0.0 tau*: 0.06351 Episode: 49488 length: 72 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.7755054235458374\n",
      "Q Loss:  0.08924683928489685\n",
      "Policy Loss:  -4.254170894622803\n",
      "[(0.00016, 0.06351), (0.0, 0.06335), (1.0, 0.06351)]\n",
      "Alpha*: 0.0 tau*: 0.06335 Episode: 49495 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0013740893919020891\n",
      "Q Loss:  0.004200095310807228\n",
      "Policy Loss:  -0.009714489802718163\n",
      "[(0.00016, 0.06335), (0.0, 0.06319), (1.0, 0.06335)]\n",
      "Alpha*: 0.0 tau*: 0.06319 Episode: 49499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0012227374827489257\n",
      "Q Loss:  0.0036378970835357904\n",
      "Policy Loss:  -0.02643038146197796\n",
      "[(0.00016, 0.06319), (0.0, 0.06303), (1.0, 0.06319)]\n",
      "Alpha*: 0.0 tau*: 0.06303 Episode: 49503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.002311897464096546\n",
      "Q Loss:  0.004207651596516371\n",
      "Policy Loss:  0.008768226951360703\n",
      "[(0.00016, 0.06303), (0.0, 0.06287), (1.0, 0.06303)]\n",
      "Alpha*: 0.0 tau*: 0.06287 Episode: 49508 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200103759765625\n",
      "Value Loss:  0.0013361787423491478\n",
      "Q Loss:  0.0008570282370783389\n",
      "Policy Loss:  0.014108862727880478\n",
      "[(0.00016, 0.06287), (0.0, 0.06271), (1.0, 0.06287)]\n",
      "Alpha*: 0.0 tau*: 0.06271 Episode: 49513 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.4003398418426514\n",
      "Q Loss:  0.3203223943710327\n",
      "Policy Loss:  -3.990783214569092\n",
      "[(0.00016, 0.06271), (0.0, 0.06255), (1.0, 0.06271)]\n",
      "Alpha*: 0.0 tau*: 0.06255 Episode: 49517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  20196.77734375\n",
      "Q Loss:  18787.0078125\n",
      "Policy Loss:  -8.779712677001953\n",
      "[(0.00016, 0.06255), (0.0, 0.06239), (1.0, 0.06255)]\n",
      "Alpha*: 0.0 tau*: 0.06239 Episode: 49564 length: 45 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03400826454162598\n",
      "Value Loss:  39508.9765625\n",
      "Q Loss:  36801.45703125\n",
      "Policy Loss:  -2.9152071475982666\n",
      "[(0.00016, 0.06239), (0.0, 0.06223), (1.0, 0.06239)]\n",
      "Alpha*: 0.0 tau*: 0.06223 Episode: 49589 length: 23 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03200721740722656\n",
      "Value Loss:  0.0025333231315016747\n",
      "Q Loss:  0.008018866181373596\n",
      "Policy Loss:  0.2806428074836731\n",
      "[(0.00016, 0.06223), (0.0, 0.06207), (1.0, 0.06223)]\n",
      "Alpha*: 0.0 tau*: 0.06207 Episode: 49593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  126.94245910644531\n",
      "Q Loss:  296.60284423828125\n",
      "Policy Loss:  -22.204877853393555\n",
      "[(0.00016, 0.06207), (0.0, 0.06191), (1.0, 0.06207)]\n",
      "Alpha*: 0.0 tau*: 0.06191 Episode: 49651 length: 53 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.004068313166499138\n",
      "Q Loss:  0.002652438823133707\n",
      "Policy Loss:  0.005020769312977791\n",
      "[(0.00016, 0.06191), (0.0, 0.06175), (1.0, 0.06191)]\n",
      "Alpha*: 0.0 tau*: 0.06175 Episode: 49655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6253155469894409\n",
      "Q Loss:  0.05361233651638031\n",
      "Policy Loss:  -2.3732638359069824\n",
      "[(0.00017, 0.06175), (0.0, 0.06159), (1.0, 0.06175)]\n",
      "Alpha*: 0.0 tau*: 0.06159 Episode: 49659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.2895615100860596\n",
      "Q Loss:  4.738028526306152\n",
      "Policy Loss:  -0.6608670949935913\n",
      "[(0.00017, 0.06159), (0.0, 0.06143), (1.0, 0.06159)]\n",
      "Alpha*: 0.0 tau*: 0.06143 Episode: 49708 length: 48 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04701113700866699\n",
      "Value Loss:  1.8212964534759521\n",
      "Q Loss:  0.31250032782554626\n",
      "Policy Loss:  -6.642513275146484\n",
      "[(0.00017, 0.06143), (0.0, 0.06127), (1.0, 0.06143)]\n",
      "Alpha*: 0.0 tau*: 0.06127 Episode: 49712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0007023912621662021\n",
      "Q Loss:  0.0022214034106582403\n",
      "Policy Loss:  -0.010049250908195972\n",
      "[(0.00017, 0.06127), (0.0, 0.06111), (1.0, 0.06127)]\n",
      "Alpha*: 0.0 tau*: 0.06111 Episode: 49716 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1.335216760635376\n",
      "Q Loss:  0.032247915863990784\n",
      "Policy Loss:  -0.8790631890296936\n",
      "[(0.00017, 0.06111), (0.0, 0.06095), (1.0, 0.06111)]\n",
      "Alpha*: 0.0 tau*: 0.06095 Episode: 49758 length: 40 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.0007916073664091527\n",
      "Q Loss:  0.001817881828173995\n",
      "Policy Loss:  -0.018224073573946953\n",
      "[(0.00017, 0.06095), (0.0, 0.06079), (1.0, 0.06095)]\n",
      "Alpha*: 0.0 tau*: 0.06079 Episode: 49762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0005929151084274054\n",
      "Q Loss:  0.001616623834706843\n",
      "Policy Loss:  -0.017339933663606644\n",
      "[(0.00017, 0.06079), (0.0, 0.06063), (1.0, 0.06079)]\n",
      "Alpha*: 0.0 tau*: 0.06063 Episode: 49766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2.5960471630096436\n",
      "Q Loss:  0.10314243286848068\n",
      "Policy Loss:  0.5393297076225281\n",
      "[(0.00017, 0.06063), (0.0, 0.06047), (1.0, 0.06063)]\n",
      "Alpha*: 0.0 tau*: 0.06047 Episode: 49789 length: 21 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.000162511074449867\n",
      "Q Loss:  0.001083853654563427\n",
      "Policy Loss:  0.012020928785204887\n",
      "[(0.00017, 0.06047), (0.0, 0.06031), (1.0, 0.06047)]\n",
      "Alpha*: 0.0 tau*: 0.06031 Episode: 49793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  26.835634231567383\n",
      "Q Loss:  2.5363566875457764\n",
      "Policy Loss:  -7.202460289001465\n",
      "[(0.00017, 0.06031), (0.0, 0.06015), (1.0, 0.06031)]\n",
      "Alpha*: 0.0 tau*: 0.06015 Episode: 49892 length: 90 #teleports:9\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  3.9143858884926885e-05\n",
      "Q Loss:  0.004001979250460863\n",
      "Policy Loss:  0.002746566431596875\n",
      "[(0.00017, 0.06015), (0.0, 0.05999), (1.0, 0.06015)]\n",
      "Alpha*: 0.0 tau*: 0.05999 Episode: 49896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.3177176469980623e-06\n",
      "Q Loss:  0.0001635160151636228\n",
      "Policy Loss:  5.796132609248161e-05\n",
      "[(0.00017, 0.05999), (0.0, 0.05983), (1.0, 0.05999)]\n",
      "Alpha*: 0.0 tau*: 0.05983 Episode: 49900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013287544250488281\n",
      "Value Loss:  0.0020466549322009087\n",
      "Q Loss:  0.0004423419013619423\n",
      "Policy Loss:  -0.004844840615987778\n",
      "[(0.00017, 0.05983), (0.0, 0.05967), (1.0, 0.05983)]\n",
      "Alpha*: 0.0 tau*: 0.05967 Episode: 49904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00038202173891477287\n",
      "Q Loss:  0.0001282195735257119\n",
      "Policy Loss:  -0.004091402515769005\n",
      "[(0.00017, 0.05967), (0.0, 0.05951), (1.0, 0.05967)]\n",
      "Alpha*: 0.0 tau*: 0.05951 Episode: 49908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00016330300422850996\n",
      "Q Loss:  0.00014072773046791553\n",
      "Policy Loss:  -0.006736767943948507\n",
      "[(0.00017, 0.05951), (0.0, 0.05935), (1.0, 0.05951)]\n",
      "Alpha*: 0.0 tau*: 0.05935 Episode: 49912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.98062264919281\n",
      "Q Loss:  0.07741080224514008\n",
      "Policy Loss:  -1.0739538669586182\n",
      "[(0.00017, 0.05935), (0.0, 0.05919), (1.0, 0.05935)]\n",
      "Alpha*: 0.0 tau*: 0.05919 Episode: 49947 length: 34 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0007731137447990477\n",
      "Q Loss:  0.0038874342571944\n",
      "Policy Loss:  -0.004899714142084122\n",
      "[(0.00017, 0.05919), (0.0, 0.05903), (1.0, 0.05919)]\n",
      "Alpha*: 0.0 tau*: 0.05903 Episode: 49952 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.0009696165798231959\n",
      "Q Loss:  0.00018441952124703676\n",
      "Policy Loss:  -0.005444765090942383\n",
      "[(0.00017, 0.05903), (0.0, 0.05887), (1.0, 0.05903)]\n",
      "Alpha*: 0.0 tau*: 0.05887 Episode: 49956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0009529371163807809\n",
      "Q Loss:  0.0026718878652900457\n",
      "Policy Loss:  -0.002915162593126297\n",
      "[(0.00017, 0.05887), (0.0, 0.05871), (1.0, 0.05887)]\n",
      "Alpha*: 0.0 tau*: 0.05871 Episode: 49961 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0019809866789728403\n",
      "Q Loss:  0.0006495996494777501\n",
      "Policy Loss:  -0.016188932582736015\n",
      "[(0.00017, 0.05871), (0.0, 0.05855), (1.0, 0.05871)]\n",
      "Alpha*: 0.0 tau*: 0.05855 Episode: 49965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00021949269284959882\n",
      "Q Loss:  0.0002958147379104048\n",
      "Policy Loss:  0.008322764188051224\n",
      "[(0.00017, 0.05855), (0.0, 0.05839), (1.0, 0.05855)]\n",
      "Alpha*: 0.0 tau*: 0.05839 Episode: 49969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.0002090703055728227\n",
      "Q Loss:  0.0004662986611947417\n",
      "Policy Loss:  0.020970571786165237\n",
      "[(0.00017, 0.05839), (0.0, 0.05823), (1.0, 0.05839)]\n",
      "Alpha*: 0.0 tau*: 0.05823 Episode: 49973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.9670246839523315\n",
      "Q Loss:  0.03480591997504234\n",
      "Policy Loss:  -0.27789998054504395\n",
      "[(0.00016, 0.05823), (0.0, 0.05807), (1.0, 0.05823)]\n",
      "Alpha*: 0.0 tau*: 0.05807 Episode: 50000 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  9.818156104302034e-05\n",
      "Q Loss:  0.0022926153615117073\n",
      "Policy Loss:  0.24565176665782928\n",
      "[(0.00016, 0.05807), (0.0, 0.05791), (1.0, 0.05807)]\n",
      "Alpha*: 0.0 tau*: 0.05791 Episode: 50004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800607681274414\n",
      "Value Loss:  1.5597983598709106\n",
      "Q Loss:  0.6648789644241333\n",
      "Policy Loss:  -6.150024890899658\n",
      "[(0.00016, 0.05791), (0.0, 0.05775), (1.0, 0.05791)]\n",
      "Alpha*: 0.0 tau*: 0.05775 Episode: 50008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  596.132568359375\n",
      "Q Loss:  1801.6038818359375\n",
      "Policy Loss:  16.276203155517578\n",
      "[(0.00016, 0.05775), (0.0, 0.05759), (1.0, 0.05775)]\n",
      "Alpha*: 0.0 tau*: 0.05759 Episode: 50013 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  594.6380004882812\n",
      "Q Loss:  2074.759033203125\n",
      "Policy Loss:  -42.692832946777344\n",
      "[(0.00016, 0.05759), (0.0, 0.05743), (1.0, 0.05759)]\n",
      "Alpha*: 0.0 tau*: 0.05743 Episode: 50017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  2.596464219095651e-05\n",
      "Q Loss:  54.93257141113281\n",
      "Policy Loss:  3.609442710876465\n",
      "[(0.00016, 0.05743), (0.0, 0.05727), (1.0, 0.05743)]\n",
      "Alpha*: 0.0 tau*: 0.05727 Episode: 50021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.6818512449390255e-05\n",
      "Q Loss:  0.0016269683837890625\n",
      "Policy Loss:  -0.02335847169160843\n",
      "[(0.00016, 0.05727), (0.0, 0.05711), (1.0, 0.05727)]\n",
      "Alpha*: 0.0 tau*: 0.05711 Episode: 50025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.010050516575574875\n",
      "Q Loss:  0.001637125271372497\n",
      "Policy Loss:  0.023515816777944565\n",
      "[(0.00016, 0.05711), (0.0, 0.05695), (1.0, 0.05711)]\n",
      "Alpha*: 0.0 tau*: 0.05695 Episode: 50030 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  0.0034427265636622906\n",
      "Q Loss:  0.0004028540279250592\n",
      "Policy Loss:  0.004434551112353802\n",
      "[(0.00016, 0.05695), (0.0, 0.05679), (1.0, 0.05695)]\n",
      "Alpha*: 0.0 tau*: 0.05679 Episode: 50034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  84.71923828125\n",
      "Q Loss:  161.16598510742188\n",
      "Policy Loss:  -16.621265411376953\n",
      "[(0.00016, 0.05679), (0.0, 0.05663), (1.0, 0.05679)]\n",
      "Alpha*: 0.0 tau*: 0.05663 Episode: 50097 length: 56 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  584.7411499023438\n",
      "Q Loss:  0.001339247333817184\n",
      "Policy Loss:  -139.0075225830078\n",
      "[(0.00016, 0.05663), (0.0, 0.05647), (1.0, 0.05663)]\n",
      "Alpha*: 0.0 tau*: 0.05647 Episode: 50101 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00014076492516323924\n",
      "Q Loss:  0.0012498268624767661\n",
      "Policy Loss:  -0.007254852447658777\n",
      "[(0.00015, 0.05647), (0.0, 0.05631), (1.0, 0.05647)]\n",
      "Alpha*: 0.0 tau*: 0.05631 Episode: 50105 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0004453362198546529\n",
      "Q Loss:  0.00011158206325490028\n",
      "Policy Loss:  -0.008832077495753765\n",
      "[(0.00015, 0.05631), (0.0, 0.05615), (1.0, 0.05631)]\n",
      "Alpha*: 0.0 tau*: 0.05615 Episode: 50111 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.790818199282512e-05\n",
      "Q Loss:  0.038873203098773956\n",
      "Policy Loss:  0.11450207233428955\n",
      "[(0.00015, 0.05615), (0.0, 0.05599), (1.0, 0.05615)]\n",
      "Alpha*: 0.0 tau*: 0.05599 Episode: 50115 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00016820359451230615\n",
      "Q Loss:  0.0019404558697715402\n",
      "Policy Loss:  -0.021017152816057205\n",
      "[(0.00015, 0.05599), (0.0, 0.05583), (1.0, 0.05599)]\n",
      "Alpha*: 0.0 tau*: 0.05583 Episode: 50119 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.8788213133811951\n",
      "Q Loss:  0.052058491855859756\n",
      "Policy Loss:  -2.7954800128936768\n",
      "[(0.00015, 0.05583), (0.0, 0.05567), (1.0, 0.05583)]\n",
      "Alpha*: 0.0 tau*: 0.05567 Episode: 50124 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011010408401489258\n",
      "Value Loss:  0.006369174458086491\n",
      "Q Loss:  0.0003942500043194741\n",
      "Policy Loss:  -0.02194431982934475\n",
      "[(0.00015, 0.05567), (0.0, 0.05551), (1.0, 0.05567)]\n",
      "Alpha*: 0.0 tau*: 0.05551 Episode: 50128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  40.46297073364258\n",
      "Q Loss:  133.94224548339844\n",
      "Policy Loss:  -6.991621971130371\n",
      "[(0.00015, 0.05551), (0.0, 0.05535), (1.0, 0.05551)]\n",
      "Alpha*: 0.0 tau*: 0.05535 Episode: 50188 length: 58 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01859903335571289\n",
      "Value Loss:  0.0014823232777416706\n",
      "Q Loss:  0.007131041027605534\n",
      "Policy Loss:  0.22149303555488586\n",
      "[(0.00015, 0.05535), (0.0, 0.05519), (1.0, 0.05535)]\n",
      "Alpha*: 0.0 tau*: 0.05519 Episode: 50192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  3.253124475479126\n",
      "Q Loss:  0.01211942546069622\n",
      "Policy Loss:  0.7562229633331299\n",
      "[(0.00015, 0.05519), (0.0, 0.05503), (1.0, 0.05519)]\n",
      "Alpha*: 0.0 tau*: 0.05503 Episode: 50210 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  0.0007006749510765076\n",
      "Q Loss:  0.0031114215962588787\n",
      "Policy Loss:  0.02946615219116211\n",
      "[(0.00015, 0.05503), (0.0, 0.05487), (1.0, 0.05503)]\n",
      "Alpha*: 0.0 tau*: 0.05487 Episode: 50214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0007919685449451208\n",
      "Q Loss:  0.0017186552286148071\n",
      "Policy Loss:  0.022811785340309143\n",
      "[(0.00015, 0.05487), (0.0, 0.05471), (1.0, 0.05487)]\n",
      "Alpha*: 0.0 tau*: 0.05471 Episode: 50219 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  0.00014447116700466722\n",
      "Q Loss:  0.008598599582910538\n",
      "Policy Loss:  0.030653957277536392\n",
      "[(0.00015, 0.05471), (0.0, 0.05455), (1.0, 0.05471)]\n",
      "Alpha*: 0.0 tau*: 0.05455 Episode: 50223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.4229944944381714\n",
      "Q Loss:  0.22893299162387848\n",
      "Policy Loss:  -1.7509886026382446\n",
      "[(0.00015, 0.05455), (0.0, 0.05439), (1.0, 0.05455)]\n",
      "Alpha*: 0.0 tau*: 0.05439 Episode: 50227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.1095525026321411\n",
      "Q Loss:  3.7072527408599854\n",
      "Policy Loss:  -0.08739989250898361\n",
      "[(0.00015, 0.05439), (0.0, 0.05423), (1.0, 0.05439)]\n",
      "Alpha*: 0.0 tau*: 0.05423 Episode: 50284 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015371322631835938\n",
      "Value Loss:  0.00011521585111040622\n",
      "Q Loss:  0.0015447244513779879\n",
      "Policy Loss:  -0.014968499541282654\n",
      "[(0.00014, 0.05423), (0.0, 0.05407), (1.0, 0.05423)]\n",
      "Alpha*: 0.0 tau*: 0.05407 Episode: 50288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0016806706553325057\n",
      "Q Loss:  0.0018603652715682983\n",
      "Policy Loss:  0.0020661107264459133\n",
      "[(0.00014, 0.05407), (0.0, 0.05391), (1.0, 0.05407)]\n",
      "Alpha*: 0.0 tau*: 0.05391 Episode: 50293 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.158774572715629e-06\n",
      "Q Loss:  0.0014851060695946217\n",
      "Policy Loss:  0.20810145139694214\n",
      "[(0.00014, 0.05391), (0.0, 0.05375), (1.0, 0.05391)]\n",
      "Alpha*: 0.0 tau*: 0.05375 Episode: 50297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.3767539262771606\n",
      "Q Loss:  0.07865714281797409\n",
      "Policy Loss:  -0.6990321278572083\n",
      "[(0.00014, 0.05375), (0.0, 0.05359), (1.0, 0.05375)]\n",
      "Alpha*: 0.0 tau*: 0.05359 Episode: 50340 length: 41 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016509532928466797\n",
      "Value Loss:  0.8542495965957642\n",
      "Q Loss:  0.04753193259239197\n",
      "Policy Loss:  -4.893062114715576\n",
      "[(0.00014, 0.05359), (0.0, 0.05343), (1.0, 0.05359)]\n",
      "Alpha*: 0.0 tau*: 0.05343 Episode: 50345 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.4231550693511963\n",
      "Q Loss:  0.19064085185527802\n",
      "Policy Loss:  -1.9142217636108398\n",
      "[(0.00014, 0.05343), (0.0, 0.05327), (1.0, 0.05343)]\n",
      "Alpha*: 0.0 tau*: 0.05327 Episode: 50349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  4.7479275963269174e-05\n",
      "Q Loss:  0.0017342530190944672\n",
      "Policy Loss:  -0.0009054015390574932\n",
      "[(0.00014, 0.05327), (0.0, 0.05311), (1.0, 0.05327)]\n",
      "Alpha*: 0.0 tau*: 0.05311 Episode: 50353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  111.11747741699219\n",
      "Q Loss:  2.5268359184265137\n",
      "Policy Loss:  -26.29343032836914\n",
      "[(0.00014, 0.05311), (0.0, 0.05295), (1.0, 0.05311)]\n",
      "Alpha*: 0.0 tau*: 0.05295 Episode: 50398 length: 41 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.002660731552168727\n",
      "Q Loss:  0.0006476723938249052\n",
      "Policy Loss:  -0.005559712182730436\n",
      "[(0.00014, 0.05295), (0.0, 0.05279), (1.0, 0.05295)]\n",
      "Alpha*: 0.0 tau*: 0.05279 Episode: 50402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0014734207652509212\n",
      "Q Loss:  0.0009561018669046462\n",
      "Policy Loss:  0.017549507319927216\n",
      "[(0.00014, 0.05279), (0.0, 0.05263), (1.0, 0.05279)]\n",
      "Alpha*: 0.0 tau*: 0.05263 Episode: 50406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1174451112747192\n",
      "Q Loss:  0.021154267713427544\n",
      "Policy Loss:  -1.064342737197876\n",
      "[(0.00014, 0.05263), (0.0, 0.05248), (1.0, 0.05263)]\n",
      "Alpha*: 0.0 tau*: 0.05248 Episode: 50466 length: 57 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014017105102539062\n",
      "Value Loss:  0.00018762139370664954\n",
      "Q Loss:  25.783306121826172\n",
      "Policy Loss:  1.7496858835220337\n",
      "[(0.00013, 0.05248), (0.0, 0.05233), (1.0, 0.05248)]\n",
      "Alpha*: 0.0 tau*: 0.05233 Episode: 50471 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  1.5465177057194524e-05\n",
      "Q Loss:  51.404998779296875\n",
      "Policy Loss:  3.4943227767944336\n",
      "[(0.00013, 0.05233), (0.0, 0.05218), (1.0, 0.05233)]\n",
      "Alpha*: 0.0 tau*: 0.05218 Episode: 50475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  2.7508358471095562e-05\n",
      "Q Loss:  25.47993278503418\n",
      "Policy Loss:  1.7305848598480225\n",
      "[(0.00013, 0.05218), (0.0, 0.05203), (1.0, 0.05218)]\n",
      "Alpha*: 0.0 tau*: 0.05203 Episode: 50479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.005954939406365156\n",
      "Q Loss:  0.006253104656934738\n",
      "Policy Loss:  0.027701105922460556\n",
      "[(0.00013, 0.05203), (0.0, 0.05188), (1.0, 0.05203)]\n",
      "Alpha*: 0.0 tau*: 0.05188 Episode: 50483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0022833344992250204\n",
      "Q Loss:  0.003198613878339529\n",
      "Policy Loss:  -0.0026401113718748093\n",
      "[(0.00013, 0.05188), (0.0, 0.05173), (1.0, 0.05188)]\n",
      "Alpha*: 0.0 tau*: 0.05173 Episode: 50487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  4.028861440019682e-05\n",
      "Q Loss:  0.0004720874421764165\n",
      "Policy Loss:  -0.016832951456308365\n",
      "[(0.00013, 0.05173), (0.0, 0.05158), (1.0, 0.05173)]\n",
      "Alpha*: 0.0 tau*: 0.05158 Episode: 50491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.5891783237457275\n",
      "Q Loss:  0.00778301153331995\n",
      "Policy Loss:  -0.5653773546218872\n",
      "[(0.00013, 0.05158), (0.0, 0.05143), (1.0, 0.05158)]\n",
      "Alpha*: 0.0 tau*: 0.05143 Episode: 50528 length: 36 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.000313326483592391\n",
      "Q Loss:  0.00040237489156425\n",
      "Policy Loss:  -0.017130551859736443\n",
      "[(0.00013, 0.05143), (0.0, 0.05128), (1.0, 0.05143)]\n",
      "Alpha*: 0.0 tau*: 0.05128 Episode: 50532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.2608714314410463e-05\n",
      "Q Loss:  0.001444535213522613\n",
      "Policy Loss:  -0.018499862402677536\n",
      "[(0.00013, 0.05128), (0.0, 0.05113), (1.0, 0.05128)]\n",
      "Alpha*: 0.0 tau*: 0.05113 Episode: 50536 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  3.237123746657744e-05\n",
      "Q Loss:  0.3746911883354187\n",
      "Policy Loss:  -0.01662602834403515\n",
      "[(0.00013, 0.05113), (0.0, 0.05098), (1.0, 0.05113)]\n",
      "Alpha*: 0.0 tau*: 0.05098 Episode: 50540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801130294799805\n",
      "Value Loss:  0.41854679584503174\n",
      "Q Loss:  0.05730671435594559\n",
      "Policy Loss:  -2.14789080619812\n",
      "[(0.00013, 0.05098), (0.0, 0.05083), (1.0, 0.05098)]\n",
      "Alpha*: 0.0 tau*: 0.05083 Episode: 50545 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.0159299373626709\n",
      "Value Loss:  1.4859397411346436\n",
      "Q Loss:  0.06278842687606812\n",
      "Policy Loss:  -1.2643364667892456\n",
      "[(0.00012, 0.05083), (0.0, 0.05068), (1.0, 0.05083)]\n",
      "Alpha*: 0.0 tau*: 0.05068 Episode: 50593 length: 46 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0400087833404541\n",
      "Value Loss:  557.8698120117188\n",
      "Q Loss:  0.0034389884676784277\n",
      "Policy Loss:  -135.81761169433594\n",
      "[(0.00012, 0.05068), (0.0, 0.05053), (1.0, 0.05068)]\n",
      "Alpha*: 0.0 tau*: 0.05053 Episode: 50597 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.0016988108400255442\n",
      "Q Loss:  0.0004622997948899865\n",
      "Policy Loss:  -0.021844414994120598\n",
      "[(0.00012, 0.05053), (0.0, 0.05038), (1.0, 0.05053)]\n",
      "Alpha*: 0.0 tau*: 0.05038 Episode: 50601 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  80.4072494506836\n",
      "Q Loss:  155.4806365966797\n",
      "Policy Loss:  -15.967998504638672\n",
      "[(0.00012, 0.05038), (0.0, 0.05023), (1.0, 0.05038)]\n",
      "Alpha*: 0.0 tau*: 0.05023 Episode: 50660 length: 56 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.644875586265698e-05\n",
      "Q Loss:  0.00010686760651879013\n",
      "Policy Loss:  0.20870569348335266\n",
      "[(0.00012, 0.05023), (0.0, 0.05008), (1.0, 0.05023)]\n",
      "Alpha*: 0.0 tau*: 0.05008 Episode: 50664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.817291498184204\n",
      "Q Loss:  0.02575027197599411\n",
      "Policy Loss:  -0.6323864459991455\n",
      "[(0.00012, 0.05008), (0.0, 0.04993), (1.0, 0.05008)]\n",
      "Alpha*: 0.0 tau*: 0.04993 Episode: 50696 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.9989554857602343e-05\n",
      "Q Loss:  0.0003587064566090703\n",
      "Policy Loss:  0.0061641838401556015\n",
      "[(0.00012, 0.04993), (0.0, 0.04978), (1.0, 0.04993)]\n",
      "Alpha*: 0.0 tau*: 0.04978 Episode: 50700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  3.0489729397231713e-05\n",
      "Q Loss:  0.0004753022803924978\n",
      "Policy Loss:  0.005910123232752085\n",
      "[(0.00012, 0.04978), (0.0, 0.04963), (1.0, 0.04978)]\n",
      "Alpha*: 0.0 tau*: 0.04963 Episode: 50704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016018390655517578\n",
      "Value Loss:  2.1127367290318944e-05\n",
      "Q Loss:  0.0004088938294444233\n",
      "Policy Loss:  -0.003230370581150055\n",
      "[(0.00012, 0.04963), (0.0, 0.04948), (1.0, 0.04963)]\n",
      "Alpha*: 0.0 tau*: 0.04948 Episode: 50708 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.4432426691055298\n",
      "Q Loss:  0.14319412410259247\n",
      "Policy Loss:  -2.058675765991211\n",
      "[(0.00012, 0.04948), (0.0, 0.04933), (1.0, 0.04948)]\n",
      "Alpha*: 0.0 tau*: 0.04933 Episode: 50712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2.464137077331543\n",
      "Q Loss:  0.04249289259314537\n",
      "Policy Loss:  -0.2114560455083847\n",
      "[(0.00012, 0.04933), (0.0, 0.04918), (1.0, 0.04933)]\n",
      "Alpha*: 0.0 tau*: 0.04918 Episode: 50736 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.00017809141718316823\n",
      "Q Loss:  0.00017940171528607607\n",
      "Policy Loss:  0.005130627192556858\n",
      "[(0.00012, 0.04918), (0.0, 0.04903), (1.0, 0.04918)]\n",
      "Alpha*: 0.0 tau*: 0.04903 Episode: 50740 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  17184.056640625\n",
      "Q Loss:  15937.65625\n",
      "Policy Loss:  -17.23073387145996\n",
      "[(0.00012, 0.04903), (0.0, 0.04888), (1.0, 0.04903)]\n",
      "Alpha*: 0.0 tau*: 0.04888 Episode: 50795 length: 53 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0001140554086305201\n",
      "Q Loss:  0.0008478241506963968\n",
      "Policy Loss:  0.019321918487548828\n",
      "[(0.00012, 0.04888), (0.0, 0.04873), (1.0, 0.04888)]\n",
      "Alpha*: 0.0 tau*: 0.04873 Episode: 50799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  8.104086737148464e-05\n",
      "Q Loss:  0.00027771969325840473\n",
      "Policy Loss:  -0.010144295170903206\n",
      "[(0.00012, 0.04873), (0.0, 0.04858), (1.0, 0.04873)]\n",
      "Alpha*: 0.0 tau*: 0.04858 Episode: 50803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  8.903606067178771e-05\n",
      "Q Loss:  0.008392272517085075\n",
      "Policy Loss:  0.027477853000164032\n",
      "[(0.00012, 0.04858), (0.0, 0.04843), (1.0, 0.04858)]\n",
      "Alpha*: 0.0 tau*: 0.04843 Episode: 50807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.0543278455734253\n",
      "Q Loss:  1.660300374031067\n",
      "Policy Loss:  -0.632260799407959\n",
      "[(0.00012, 0.04843), (0.0, 0.04828), (1.0, 0.04843)]\n",
      "Alpha*: 0.0 tau*: 0.04828 Episode: 50867 length: 57 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  6.381604180205613e-05\n",
      "Q Loss:  0.00013923125516157597\n",
      "Policy Loss:  -0.005240209400653839\n",
      "[(0.00012, 0.04828), (0.0, 0.04813), (1.0, 0.04828)]\n",
      "Alpha*: 0.0 tau*: 0.04813 Episode: 50872 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.198355650762096e-05\n",
      "Q Loss:  0.007988517172634602\n",
      "Policy Loss:  0.030602198094129562\n",
      "[(0.00012, 0.04813), (0.0, 0.04798), (1.0, 0.04813)]\n",
      "Alpha*: 0.0 tau*: 0.04798 Episode: 50876 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.324402885278687e-06\n",
      "Q Loss:  0.004033103119581938\n",
      "Policy Loss:  0.0346955768764019\n",
      "[(0.00011, 0.04798), (0.0, 0.04783), (1.0, 0.04798)]\n",
      "Alpha*: 0.0 tau*: 0.04783 Episode: 50881 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  2.242405025754124e-05\n",
      "Q Loss:  0.0027118483558297157\n",
      "Policy Loss:  0.01877901516854763\n",
      "[(0.00011, 0.04783), (0.0, 0.04768), (1.0, 0.04783)]\n",
      "Alpha*: 0.0 tau*: 0.04768 Episode: 50885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00011390475265216082\n",
      "Q Loss:  0.0007709104102104902\n",
      "Policy Loss:  -0.012929700314998627\n",
      "[(0.00011, 0.04768), (0.0, 0.04753), (1.0, 0.04768)]\n",
      "Alpha*: 0.0 tau*: 0.04753 Episode: 50889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.5517848775489256e-05\n",
      "Q Loss:  0.0017663667676970363\n",
      "Policy Loss:  0.20648330450057983\n",
      "[(0.00011, 0.04753), (0.0, 0.04738), (1.0, 0.04753)]\n",
      "Alpha*: 0.0 tau*: 0.04738 Episode: 50893 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  54.3167724609375\n",
      "Q Loss:  32.3704833984375\n",
      "Policy Loss:  -11.54609489440918\n",
      "[(0.00011, 0.04738), (0.0, 0.04723), (1.0, 0.04738)]\n",
      "Alpha*: 0.0 tau*: 0.04723 Episode: 50938 length: 42 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00012667247210629284\n",
      "Q Loss:  9.412772487848997e-05\n",
      "Policy Loss:  -0.0013287159381434321\n",
      "[(0.00011, 0.04723), (0.0, 0.04708), (1.0, 0.04723)]\n",
      "Alpha*: 0.0 tau*: 0.04708 Episode: 50942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.484725185553543e-06\n",
      "Q Loss:  0.00010104489047080278\n",
      "Policy Loss:  0.0002277588937431574\n",
      "[(0.00011, 0.04708), (0.0, 0.04693), (1.0, 0.04708)]\n",
      "Alpha*: 0.0 tau*: 0.04693 Episode: 50947 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  7.493371958844364e-05\n",
      "Q Loss:  0.00010906058014370501\n",
      "Policy Loss:  -0.002506411634385586\n",
      "[(0.00011, 0.04693), (0.0, 0.04678), (1.0, 0.04693)]\n",
      "Alpha*: 0.0 tau*: 0.04678 Episode: 50951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.772689524339512e-05\n",
      "Q Loss:  0.0024905751924961805\n",
      "Policy Loss:  0.20562341809272766\n",
      "[(0.00011, 0.04678), (0.0, 0.04663), (1.0, 0.04678)]\n",
      "Alpha*: 0.0 tau*: 0.04663 Episode: 50956 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  2.0223844051361084\n",
      "Q Loss:  0.08779846131801605\n",
      "Policy Loss:  -0.8820608258247375\n",
      "[(0.00011, 0.04663), (0.0, 0.04648), (1.0, 0.04663)]\n",
      "Alpha*: 0.0 tau*: 0.04648 Episode: 50984 length: 27 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010000944137573242\n",
      "Value Loss:  3.409933560760692e-05\n",
      "Q Loss:  0.000603146618232131\n",
      "Policy Loss:  -0.003640740644186735\n",
      "[(0.00011, 0.04648), (0.0, 0.04633), (1.0, 0.04648)]\n",
      "Alpha*: 0.0 tau*: 0.04633 Episode: 50988 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  9.817714499149588e-07\n",
      "Q Loss:  0.00043676767381839454\n",
      "Policy Loss:  -0.004785850644111633\n",
      "[(0.00011, 0.04633), (0.0, 0.04618), (1.0, 0.04633)]\n",
      "Alpha*: 0.0 tau*: 0.04618 Episode: 50992 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  9.48964589042589e-06\n",
      "Q Loss:  0.0004301372682675719\n",
      "Policy Loss:  -0.003984998911619186\n",
      "[(0.00011, 0.04618), (0.0, 0.04603), (1.0, 0.04618)]\n",
      "Alpha*: 0.0 tau*: 0.04603 Episode: 50996 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  1.3377060895436443e-05\n",
      "Q Loss:  0.00019630236783996224\n",
      "Policy Loss:  -0.0024184691719710827\n",
      "[(0.00011, 0.04603), (0.0, 0.04588), (1.0, 0.04603)]\n",
      "Alpha*: 0.0 tau*: 0.04588 Episode: 51000 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00013205944560468197\n",
      "Q Loss:  0.005572805646806955\n",
      "Policy Loss:  0.02894136682152748\n",
      "[(0.00011, 0.04588), (0.0, 0.04573), (1.0, 0.04588)]\n",
      "Alpha*: 0.0 tau*: 0.04573 Episode: 51004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  9.194757876684889e-05\n",
      "Q Loss:  0.003191629657521844\n",
      "Policy Loss:  0.21945181488990784\n",
      "[(0.00011, 0.04573), (0.0, 0.04558), (1.0, 0.04573)]\n",
      "Alpha*: 0.0 tau*: 0.04558 Episode: 51008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300572395324707\n",
      "Value Loss:  1.1364505290985107\n",
      "Q Loss:  0.23794779181480408\n",
      "Policy Loss:  -4.519553184509277\n",
      "[(0.00011, 0.04558), (0.0, 0.04543), (1.0, 0.04558)]\n",
      "Alpha*: 0.0 tau*: 0.04543 Episode: 51012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.4072377681732178\n",
      "Q Loss:  0.0647723451256752\n",
      "Policy Loss:  -1.188118577003479\n",
      "[(0.00011, 0.04543), (0.0, 0.04528), (1.0, 0.04543)]\n",
      "Alpha*: 0.0 tau*: 0.04528 Episode: 51050 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.883441917831078e-05\n",
      "Q Loss:  0.00014723751519341022\n",
      "Policy Loss:  0.005245697684586048\n",
      "[(0.0001, 0.04528), (0.0, 0.04513), (1.0, 0.04528)]\n",
      "Alpha*: 0.0 tau*: 0.04513 Episode: 51054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.5615676045417786\n",
      "Q Loss:  0.10681065171957016\n",
      "Policy Loss:  -2.627009153366089\n",
      "[(0.0001, 0.04513), (0.0, 0.04498), (1.0, 0.04513)]\n",
      "Alpha*: 0.0 tau*: 0.04498 Episode: 51058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.1835243701934814\n",
      "Q Loss:  0.048775121569633484\n",
      "Policy Loss:  -1.5336416959762573\n",
      "[(0.0001, 0.04498), (0.0, 0.04483), (1.0, 0.04498)]\n",
      "Alpha*: 0.0 tau*: 0.04483 Episode: 51109 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  9.784159192349762e-05\n",
      "Q Loss:  0.011069431900978088\n",
      "Policy Loss:  0.2785956561565399\n",
      "[(0.0001, 0.04483), (0.0, 0.04468), (1.0, 0.04483)]\n",
      "Alpha*: 0.0 tau*: 0.04468 Episode: 51113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  150.09034729003906\n",
      "Q Loss:  325.798583984375\n",
      "Policy Loss:  -21.269765853881836\n",
      "[(0.0001, 0.04468), (0.0, 0.04453), (1.0, 0.04468)]\n",
      "Alpha*: 0.0 tau*: 0.04453 Episode: 51159 length: 45 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  22142.650390625\n",
      "Q Loss:  20563.0625\n",
      "Policy Loss:  -8.249617576599121\n",
      "[(0.0001, 0.04453), (0.0, 0.04438), (1.0, 0.04453)]\n",
      "Alpha*: 0.0 tau*: 0.04438 Episode: 51204 length: 41 #teleports:4\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.061636924743652344\n",
      "Value Loss:  0.00011345275561325252\n",
      "Q Loss:  0.004391110967844725\n",
      "Policy Loss:  0.02670820988714695\n",
      "[(0.0001, 0.04438), (0.0, 0.04423), (1.0, 0.04438)]\n",
      "Alpha*: 0.0 tau*: 0.04423 Episode: 51208 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  102.81465148925781\n",
      "Q Loss:  246.80494689941406\n",
      "Policy Loss:  -17.19569206237793\n",
      "[(0.0001, 0.04423), (0.0, 0.04408), (1.0, 0.04423)]\n",
      "Alpha*: 0.0 tau*: 0.04408 Episode: 51276 length: 66 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.1581210603471845e-05\n",
      "Q Loss:  9.143334318650886e-05\n",
      "Policy Loss:  0.0015348999295383692\n",
      "[(0.0001, 0.04408), (0.0, 0.04393), (1.0, 0.04408)]\n",
      "Alpha*: 0.0 tau*: 0.04393 Episode: 51280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011585235595703125\n",
      "Value Loss:  3.3735846045601647e-06\n",
      "Q Loss:  0.008725672960281372\n",
      "Policy Loss:  0.05104464292526245\n",
      "[(0.0001, 0.04393), (0.0, 0.04378), (1.0, 0.04393)]\n",
      "Alpha*: 0.0 tau*: 0.04378 Episode: 51284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.500296876765788e-06\n",
      "Q Loss:  23.01656150817871\n",
      "Policy Loss:  1.903632640838623\n",
      "[(0.0001, 0.04378), (0.0, 0.04363), (1.0, 0.04378)]\n",
      "Alpha*: 0.0 tau*: 0.04363 Episode: 51289 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.5552623271942139\n",
      "Q Loss:  0.12846186757087708\n",
      "Policy Loss:  -2.5623626708984375\n",
      "[(0.0001, 0.04363), (0.0, 0.04348), (1.0, 0.04363)]\n",
      "Alpha*: 0.0 tau*: 0.04348 Episode: 51294 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.4568885564804077\n",
      "Q Loss:  2.199176549911499\n",
      "Policy Loss:  -1.1459275484085083\n",
      "[(0.0001, 0.04348), (0.0, 0.04333), (1.0, 0.04348)]\n",
      "Alpha*: 0.0 tau*: 0.04333 Episode: 51338 length: 43 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  0.00011299455218249932\n",
      "Q Loss:  0.0008833538158796728\n",
      "Policy Loss:  0.011798464693129063\n",
      "[(0.0001, 0.04333), (0.0, 0.04318), (1.0, 0.04333)]\n",
      "Alpha*: 0.0 tau*: 0.04318 Episode: 51342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.00020234609837643802\n",
      "Q Loss:  0.0001344334305031225\n",
      "Policy Loss:  -0.002908180234953761\n",
      "[(0.0001, 0.04318), (0.0, 0.04303), (1.0, 0.04318)]\n",
      "Alpha*: 0.0 tau*: 0.04303 Episode: 51349 length: 4 #teleports:3\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  1.096352219581604\n",
      "Q Loss:  0.21967187523841858\n",
      "Policy Loss:  -2.347388744354248\n",
      "[(0.0001, 0.04303), (0.0, 0.04288), (1.0, 0.04303)]\n",
      "Alpha*: 0.0 tau*: 0.04288 Episode: 51353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.8387364149093628\n",
      "Q Loss:  0.06603962928056717\n",
      "Policy Loss:  -1.252241611480713\n",
      "[(0.0001, 0.04288), (0.0, 0.04273), (1.0, 0.04288)]\n",
      "Alpha*: 0.0 tau*: 0.04273 Episode: 51389 length: 33 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.036760623828741e-06\n",
      "Q Loss:  0.0003618919581640512\n",
      "Policy Loss:  0.007411430589854717\n",
      "[(0.0001, 0.04273), (0.0, 0.04258), (1.0, 0.04273)]\n",
      "Alpha*: 0.0 tau*: 0.04258 Episode: 51393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.7531394152902067e-05\n",
      "Q Loss:  0.000338820245815441\n",
      "Policy Loss:  0.007892842404544353\n",
      "[(0.0001, 0.04258), (0.0, 0.04243), (1.0, 0.04258)]\n",
      "Alpha*: 0.0 tau*: 0.04243 Episode: 51397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.7064245184883475e-05\n",
      "Q Loss:  1.7897655197884887e-05\n",
      "Policy Loss:  -0.0005649130325764418\n",
      "[(0.0001, 0.04243), (0.0, 0.04228), (1.0, 0.04243)]\n",
      "Alpha*: 0.0 tau*: 0.04228 Episode: 51401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009612560272216797\n",
      "Value Loss:  3.183711214660434e-06\n",
      "Q Loss:  0.0005998684791848063\n",
      "Policy Loss:  -0.01338603999465704\n",
      "[(0.0001, 0.04228), (0.0, 0.04213), (1.0, 0.04228)]\n",
      "Alpha*: 0.0 tau*: 0.04213 Episode: 51405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  29248.7421875\n",
      "Q Loss:  27148.798828125\n",
      "Policy Loss:  -12.546762466430664\n",
      "[(0.0001, 0.04213), (0.0, 0.04198), (1.0, 0.04213)]\n",
      "Alpha*: 0.0 tau*: 0.04198 Episode: 51437 length: 31 #teleports:1\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  1.2126346291552181e-06\n",
      "Q Loss:  0.0002383548126090318\n",
      "Policy Loss:  -0.008253928273916245\n",
      "[(0.0001, 0.04198), (0.0, 0.04183), (1.0, 0.04198)]\n",
      "Alpha*: 0.0 tau*: 0.04183 Episode: 51441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.3514630836652941e-06\n",
      "Q Loss:  0.0006791765918023884\n",
      "Policy Loss:  0.22283409535884857\n",
      "[(0.0001, 0.04183), (0.0, 0.04168), (1.0, 0.04183)]\n",
      "Alpha*: 0.0 tau*: 0.04168 Episode: 51445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.9856835007667542\n",
      "Q Loss:  0.03556806966662407\n",
      "Policy Loss:  -1.2604948282241821\n",
      "[(0.0001, 0.04168), (0.0, 0.04153), (1.0, 0.04168)]\n",
      "Alpha*: 0.0 tau*: 0.04153 Episode: 51509 length: 62 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  7.415890286210924e-05\n",
      "Q Loss:  0.00045283528743311763\n",
      "Policy Loss:  0.0029376004822552204\n",
      "[(0.0001, 0.04153), (0.0, 0.04138), (1.0, 0.04153)]\n",
      "Alpha*: 0.0 tau*: 0.04138 Episode: 51513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011000633239746094\n",
      "Value Loss:  2.716006201808341e-05\n",
      "Q Loss:  0.00012078748841304332\n",
      "Policy Loss:  -0.006355601362884045\n",
      "[(0.0001, 0.04138), (0.0, 0.04123), (1.0, 0.04138)]\n",
      "Alpha*: 0.0 tau*: 0.04123 Episode: 51517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  3.461412779870443e-05\n",
      "Q Loss:  0.00014303573698271066\n",
      "Policy Loss:  -0.005745012313127518\n",
      "[(0.0001, 0.04123), (0.0, 0.04108), (1.0, 0.04123)]\n",
      "Alpha*: 0.0 tau*: 0.04108 Episode: 51521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.1319625627947971e-05\n",
      "Q Loss:  0.00046172557631507516\n",
      "Policy Loss:  -0.008337162435054779\n",
      "[(0.0001, 0.04108), (0.0, 0.04093), (1.0, 0.04108)]\n",
      "Alpha*: 0.0 tau*: 0.04093 Episode: 51525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  109.81800079345703\n",
      "Q Loss:  128.6520538330078\n",
      "Policy Loss:  -22.48434829711914\n",
      "[(0.0001, 0.04093), (0.0, 0.04078), (1.0, 0.04093)]\n",
      "Alpha*: 0.0 tau*: 0.04078 Episode: 51595 length: 65 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  9.857276381808333e-06\n",
      "Q Loss:  0.00015800073742866516\n",
      "Policy Loss:  0.006078471429646015\n",
      "[(0.0001, 0.04078), (0.0, 0.04063), (1.0, 0.04078)]\n",
      "Alpha*: 0.0 tau*: 0.04063 Episode: 51599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  2.920814495155355e-06\n",
      "Q Loss:  4.463105869945139e-05\n",
      "Policy Loss:  0.002214842475950718\n",
      "[(0.0001, 0.04063), (0.0, 0.04048), (1.0, 0.04063)]\n",
      "Alpha*: 0.0 tau*: 0.04048 Episode: 51603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  3.5646404285216704e-05\n",
      "Q Loss:  0.00010762916645035148\n",
      "Policy Loss:  -0.0005076370434835553\n",
      "[(0.0001, 0.04048), (0.0, 0.04033), (1.0, 0.04048)]\n",
      "Alpha*: 0.0 tau*: 0.04033 Episode: 51607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  5.803838575957343e-06\n",
      "Q Loss:  2.8240796382306144e-05\n",
      "Policy Loss:  0.0004367097862996161\n",
      "[(0.0001, 0.04033), (0.0, 0.04018), (1.0, 0.04033)]\n",
      "Alpha*: 0.0 tau*: 0.04018 Episode: 51611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  8.381950465263799e-06\n",
      "Q Loss:  0.0002600281441118568\n",
      "Policy Loss:  -0.0060997214168310165\n",
      "[(0.0001, 0.04018), (0.0, 0.04003), (1.0, 0.04018)]\n",
      "Alpha*: 0.0 tau*: 0.04003 Episode: 51615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.5370417833328247\n",
      "Q Loss:  0.13387200236320496\n",
      "Policy Loss:  -1.3859539031982422\n",
      "[(0.0001, 0.04003), (0.0, 0.03988), (1.0, 0.04003)]\n",
      "Alpha*: 0.0 tau*: 0.03988 Episode: 51619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  49.051918029785156\n",
      "Q Loss:  143.22061157226562\n",
      "Policy Loss:  -6.461232662200928\n",
      "[(0.0001, 0.03988), (0.0, 0.03973), (1.0, 0.03988)]\n",
      "Alpha*: 0.0 tau*: 0.03973 Episode: 51669 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.2290751934051514\n",
      "Q Loss:  0.023453988134860992\n",
      "Policy Loss:  -1.2345672845840454\n",
      "[(0.0001, 0.03973), (0.0, 0.03958), (1.0, 0.03973)]\n",
      "Alpha*: 0.0 tau*: 0.03958 Episode: 51717 length: 46 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.006487870356068e-05\n",
      "Q Loss:  6.303111877059564e-05\n",
      "Policy Loss:  -0.0009840530110523105\n",
      "[(0.0001, 0.03958), (0.0, 0.03943), (1.0, 0.03958)]\n",
      "Alpha*: 0.0 tau*: 0.03943 Episode: 51721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.5337923169136047\n",
      "Q Loss:  0.09028310328722\n",
      "Policy Loss:  -2.4498186111450195\n",
      "[(0.0001, 0.03943), (0.0, 0.03928), (1.0, 0.03943)]\n",
      "Alpha*: 0.0 tau*: 0.03928 Episode: 51726 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  115.23963165283203\n",
      "Q Loss:  28.456878662109375\n",
      "Policy Loss:  -26.957460403442383\n",
      "[(0.0001, 0.03928), (0.0, 0.03913), (1.0, 0.03928)]\n",
      "Alpha*: 0.0 tau*: 0.03913 Episode: 51768 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  10574.546875\n",
      "Q Loss:  9863.966796875\n",
      "Policy Loss:  -15.702128410339355\n",
      "[(0.0001, 0.03913), (0.0, 0.03898), (1.0, 0.03913)]\n",
      "Alpha*: 0.0 tau*: 0.03898 Episode: 51856 length: 86 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.4352248146897182e-05\n",
      "Q Loss:  3.067242505494505e-05\n",
      "Policy Loss:  0.0039657894521951675\n",
      "[(0.0001, 0.03898), (0.0, 0.03883), (1.0, 0.03898)]\n",
      "Alpha*: 0.0 tau*: 0.03883 Episode: 51860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.5294302105903625\n",
      "Q Loss:  0.07928042113780975\n",
      "Policy Loss:  -2.4163482189178467\n",
      "[(0.0001, 0.03883), (0.0, 0.03868), (1.0, 0.03883)]\n",
      "Alpha*: 0.0 tau*: 0.03868 Episode: 51864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.8342886567115784\n",
      "Q Loss:  1.3637272119522095\n",
      "Policy Loss:  -0.7953857779502869\n",
      "[(0.0001, 0.03868), (0.0, 0.03853), (1.0, 0.03868)]\n",
      "Alpha*: 0.0 tau*: 0.03853 Episode: 51937 length: 68 #teleports:5\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  28.012083053588867\n",
      "Q Loss:  6.936834812164307\n",
      "Policy Loss:  -7.025444507598877\n",
      "[(0.0001, 0.03853), (0.0, 0.03838), (1.0, 0.03853)]\n",
      "Alpha*: 0.0 tau*: 0.03838 Episode: 52118 length: 174 #teleports:7\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010016441345214844\n",
      "Value Loss:  8.627135684946552e-06\n",
      "Q Loss:  5.275542935123667e-05\n",
      "Policy Loss:  0.0034297588281333447\n",
      "[(0.0001, 0.03838), (0.0, 0.03823), (1.0, 0.03838)]\n",
      "Alpha*: 0.0 tau*: 0.03823 Episode: 52122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  41.31059646606445\n",
      "Q Loss:  21.676382064819336\n",
      "Policy Loss:  -10.156909942626953\n",
      "[(0.0001, 0.03823), (0.0, 0.03808), (1.0, 0.03823)]\n",
      "Alpha*: 0.0 tau*: 0.03808 Episode: 52184 length: 60 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.5292740727090859e-06\n",
      "Q Loss:  3.1498464522883296e-05\n",
      "Policy Loss:  0.0007098774658516049\n",
      "[(0.0001, 0.03808), (0.0, 0.03793), (1.0, 0.03808)]\n",
      "Alpha*: 0.0 tau*: 0.03793 Episode: 52188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.607396552572027e-05\n",
      "Q Loss:  0.00011077487579314038\n",
      "Policy Loss:  0.0017238556174561381\n",
      "[(0.0001, 0.03793), (0.0, 0.03778), (1.0, 0.03793)]\n",
      "Alpha*: 0.0 tau*: 0.03778 Episode: 52192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.733004268724471e-05\n",
      "Q Loss:  0.0004202096024528146\n",
      "Policy Loss:  0.009581098333001137\n",
      "[(0.0001, 0.03778), (0.0, 0.03763), (1.0, 0.03778)]\n",
      "Alpha*: 0.0 tau*: 0.03763 Episode: 52196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.6908519268035889\n",
      "Q Loss:  0.0002921156119555235\n",
      "Policy Loss:  -0.5034552216529846\n",
      "[(0.0001, 0.03763), (0.0, 0.03748), (1.0, 0.03763)]\n",
      "Alpha*: 0.0 tau*: 0.03748 Episode: 52227 length: 30 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011069536209106445\n",
      "Value Loss:  90410.6171875\n",
      "Q Loss:  83783.4609375\n",
      "Policy Loss:  -10.519701957702637\n",
      "[(0.00011, 0.03748), (0.0, 0.03733), (1.0, 0.03748)]\n",
      "Alpha*: 0.0 tau*: 0.03733 Episode: 52237 length: 10 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  2.7072038650512695\n",
      "Q Loss:  0.1301533728837967\n",
      "Policy Loss:  -0.047854870557785034\n",
      "[(0.00011, 0.03733), (0.0, 0.03718), (1.0, 0.03733)]\n",
      "Alpha*: 0.0 tau*: 0.03718 Episode: 52259 length: 20 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00028490228578448296\n",
      "Q Loss:  8.756565512157977e-05\n",
      "Policy Loss:  -0.002761100884526968\n",
      "[(0.00011, 0.03718), (0.0, 0.03703), (1.0, 0.03718)]\n",
      "Alpha*: 0.0 tau*: 0.03703 Episode: 52263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0006070684758014977\n",
      "Q Loss:  0.00028045225189998746\n",
      "Policy Loss:  -0.010001245886087418\n",
      "[(0.00011, 0.03703), (0.0, 0.03688), (1.0, 0.03703)]\n",
      "Alpha*: 0.0 tau*: 0.03688 Episode: 52268 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.000523545197211206\n",
      "Q Loss:  8.752573921810836e-05\n",
      "Policy Loss:  -0.0014910514000803232\n",
      "[(0.00011, 0.03688), (0.0, 0.03673), (1.0, 0.03688)]\n",
      "Alpha*: 0.0 tau*: 0.03673 Episode: 52272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.00900125503540039\n",
      "Value Loss:  0.0003576413728296757\n",
      "Q Loss:  8.462585537927225e-05\n",
      "Policy Loss:  0.0028132107108831406\n",
      "[(0.00011, 0.03673), (0.0, 0.03658), (1.0, 0.03673)]\n",
      "Alpha*: 0.0 tau*: 0.03658 Episode: 52278 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.009564876556396484\n",
      "Value Loss:  2.1340114471968263e-05\n",
      "Q Loss:  0.0004012029094155878\n",
      "Policy Loss:  0.012775696814060211\n",
      "[(0.00011, 0.03658), (0.0, 0.03643), (1.0, 0.03658)]\n",
      "Alpha*: 0.0 tau*: 0.03643 Episode: 52283 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.00016373192192986608\n",
      "Q Loss:  0.00021588621893897653\n",
      "Policy Loss:  0.00830015167593956\n",
      "[(0.00011, 0.03643), (0.0, 0.03628), (1.0, 0.03643)]\n",
      "Alpha*: 0.0 tau*: 0.03628 Episode: 52287 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  15562.3349609375\n",
      "Q Loss:  14397.81640625\n",
      "Policy Loss:  -16.75031280517578\n",
      "[(0.00012, 0.03628), (0.0, 0.03613), (1.0, 0.03628)]\n",
      "Alpha*: 0.0 tau*: 0.03613 Episode: 52351 length: 58 #teleports:6\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  118.19403076171875\n",
      "Q Loss:  159.8387908935547\n",
      "Policy Loss:  -22.186132431030273\n",
      "[(0.00012, 0.03613), (0.0, 0.03598), (1.0, 0.03613)]\n",
      "Alpha*: 0.0 tau*: 0.03598 Episode: 52422 length: 68 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00015735909983050078\n",
      "Q Loss:  0.0005045593716204166\n",
      "Policy Loss:  0.012671997770667076\n",
      "[(0.00012, 0.03598), (0.0, 0.03583), (1.0, 0.03598)]\n",
      "Alpha*: 0.0 tau*: 0.03583 Episode: 52426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.960392005974427e-05\n",
      "Q Loss:  0.02153300866484642\n",
      "Policy Loss:  0.07832968980073929\n",
      "[(0.00012, 0.03583), (0.0, 0.03568), (1.0, 0.03583)]\n",
      "Alpha*: 0.0 tau*: 0.03568 Episode: 52431 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.892059587291442e-05\n",
      "Q Loss:  0.03262193873524666\n",
      "Policy Loss:  0.0982259139418602\n",
      "[(0.00012, 0.03568), (0.0, 0.03553), (1.0, 0.03568)]\n",
      "Alpha*: 0.0 tau*: 0.03553 Episode: 52435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.8628078103065491\n",
      "Q Loss:  0.028774378821253777\n",
      "Policy Loss:  -1.1754056215286255\n",
      "[(0.00012, 0.03553), (0.0, 0.03538), (1.0, 0.03553)]\n",
      "Alpha*: 0.0 tau*: 0.03538 Episode: 52492 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.00016651191981509328\n",
      "Q Loss:  0.0002655894495546818\n",
      "Policy Loss:  0.009462649002671242\n",
      "[(0.00012, 0.03538), (0.0, 0.03523), (1.0, 0.03538)]\n",
      "Alpha*: 0.0 tau*: 0.03523 Episode: 52496 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  3.553596258163452\n",
      "Q Loss:  0.02357332780957222\n",
      "Policy Loss:  2.4093542098999023\n",
      "[(0.00012, 0.03523), (0.0, 0.03508), (1.0, 0.03523)]\n",
      "Alpha*: 0.0 tau*: 0.03508 Episode: 52508 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.00020469677110668272\n",
      "Q Loss:  6.50219080853276e-05\n",
      "Policy Loss:  0.003090354846790433\n",
      "[(0.00012, 0.03508), (0.0, 0.03493), (1.0, 0.03508)]\n",
      "Alpha*: 0.0 tau*: 0.03493 Episode: 52513 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  2.776782989501953\n",
      "Q Loss:  0.07495959848165512\n",
      "Policy Loss:  0.24443581700325012\n",
      "[(0.00012, 0.03493), (0.0, 0.03478), (1.0, 0.03493)]\n",
      "Alpha*: 0.0 tau*: 0.03478 Episode: 52529 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.00019628697191365063\n",
      "Q Loss:  3.2653959351591766e-05\n",
      "Policy Loss:  0.005282798316329718\n",
      "[(0.00012, 0.03478), (0.0, 0.03463), (1.0, 0.03478)]\n",
      "Alpha*: 0.0 tau*: 0.03463 Episode: 52533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00046272025792859495\n",
      "Q Loss:  0.0006455695838667452\n",
      "Policy Loss:  -0.015211096033453941\n",
      "[(0.00011, 0.03463), (0.0, 0.03448), (1.0, 0.03463)]\n",
      "Alpha*: 0.0 tau*: 0.03448 Episode: 52537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.0005673171253874898\n",
      "Q Loss:  0.0009393251384608448\n",
      "Policy Loss:  -0.010522015392780304\n",
      "[(0.00011, 0.03448), (0.0, 0.03433), (1.0, 0.03448)]\n",
      "Alpha*: 0.0 tau*: 0.03433 Episode: 52541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00044883362716063857\n",
      "Q Loss:  0.024713627994060516\n",
      "Policy Loss:  0.2558722496032715\n",
      "[(0.00011, 0.03433), (0.0, 0.03418), (1.0, 0.03433)]\n",
      "Alpha*: 0.0 tau*: 0.03418 Episode: 52545 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  1.1429932117462158\n",
      "Q Loss:  0.07873469591140747\n",
      "Policy Loss:  -2.119563102722168\n",
      "[(0.00011, 0.03418), (0.0, 0.03403), (1.0, 0.03418)]\n",
      "Alpha*: 0.0 tau*: 0.03403 Episode: 52592 length: 46 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  20442.275390625\n",
      "Q Loss:  18873.466796875\n",
      "Policy Loss:  -22.53253173828125\n",
      "[(0.00011, 0.03403), (0.0, 0.03388), (1.0, 0.03403)]\n",
      "Alpha*: 0.0 tau*: 0.03388 Episode: 52639 length: 44 #teleports:3\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0002240173052996397\n",
      "Q Loss:  0.0009005318861454725\n",
      "Policy Loss:  0.022271322086453438\n",
      "[(0.00011, 0.03388), (0.0, 0.03373), (1.0, 0.03388)]\n",
      "Alpha*: 0.0 tau*: 0.03373 Episode: 52643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0001474016607971862\n",
      "Q Loss:  0.022281983867287636\n",
      "Policy Loss:  0.2839500308036804\n",
      "[(0.00011, 0.03373), (0.0, 0.03358), (1.0, 0.03373)]\n",
      "Alpha*: 0.0 tau*: 0.03358 Episode: 52647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  12107.4677734375\n",
      "Q Loss:  11171.986328125\n",
      "Policy Loss:  -7.082974433898926\n",
      "[(0.00011, 0.03358), (0.0, 0.03343), (1.0, 0.03358)]\n",
      "Alpha*: 0.0 tau*: 0.03343 Episode: 52722 length: 74 #teleports:1\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0003418081905692816\n",
      "Q Loss:  0.002174590714275837\n",
      "Policy Loss:  0.026824507862329483\n",
      "[(0.00011, 0.03343), (0.0, 0.03328), (1.0, 0.03343)]\n",
      "Alpha*: 0.0 tau*: 0.03328 Episode: 52726 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.0331668853759766\n",
      "Q Loss:  1.9502254724502563\n",
      "Policy Loss:  -1.7645759582519531\n",
      "[(0.00011, 0.03328), (0.0, 0.03313), (1.0, 0.03328)]\n",
      "Alpha*: 0.0 tau*: 0.03313 Episode: 52776 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011828494461951777\n",
      "Q Loss:  0.03204071894288063\n",
      "Policy Loss:  0.09553308039903641\n",
      "[(0.00011, 0.03313), (0.0, 0.03298), (1.0, 0.03313)]\n",
      "Alpha*: 0.0 tau*: 0.03298 Episode: 52780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010020971298217773\n",
      "Value Loss:  0.0003532839473336935\n",
      "Q Loss:  0.0013248842442408204\n",
      "Policy Loss:  0.007829736918210983\n",
      "[(0.00011, 0.03298), (0.0, 0.03283), (1.0, 0.03298)]\n",
      "Alpha*: 0.0 tau*: 0.03283 Episode: 52784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00010529196879360825\n",
      "Q Loss:  0.00039141805609688163\n",
      "Policy Loss:  0.0030317488126456738\n",
      "[(0.00011, 0.03283), (0.0, 0.03268), (1.0, 0.03283)]\n",
      "Alpha*: 0.0 tau*: 0.03268 Episode: 52788 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.203770352731226e-06\n",
      "Q Loss:  1.1521828128024936e-05\n",
      "Policy Loss:  0.0028558834455907345\n",
      "[(0.00011, 0.03268), (0.0, 0.03253), (1.0, 0.03268)]\n",
      "Alpha*: 0.0 tau*: 0.03253 Episode: 52792 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.1977403119090013e-05\n",
      "Q Loss:  0.0003929358208552003\n",
      "Policy Loss:  0.006310456432402134\n",
      "[(0.00011, 0.03253), (0.0, 0.03238), (1.0, 0.03253)]\n",
      "Alpha*: 0.0 tau*: 0.03238 Episode: 52796 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1200450658798218\n",
      "Q Loss:  1.1457301378250122\n",
      "Policy Loss:  -5.15618371963501\n",
      "[(0.00011, 0.03238), (0.0, 0.03223), (1.0, 0.03238)]\n",
      "Alpha*: 0.0 tau*: 0.03223 Episode: 52800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.2100718021392822\n",
      "Q Loss:  2.1528830528259277\n",
      "Policy Loss:  -2.15763783454895\n",
      "[(0.00011, 0.03223), (0.0, 0.03208), (1.0, 0.03223)]\n",
      "Alpha*: 0.0 tau*: 0.03208 Episode: 52850 length: 46 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012908458709716797\n",
      "Value Loss:  0.00016555287584196776\n",
      "Q Loss:  0.004003991838544607\n",
      "Policy Loss:  0.03437081351876259\n",
      "[(0.00011, 0.03208), (0.0, 0.03193), (1.0, 0.03208)]\n",
      "Alpha*: 0.0 tau*: 0.03193 Episode: 52854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00037941502523608506\n",
      "Q Loss:  0.0012018505949527025\n",
      "Policy Loss:  0.011524707078933716\n",
      "[(0.00011, 0.03193), (0.0, 0.03178), (1.0, 0.03193)]\n",
      "Alpha*: 0.0 tau*: 0.03178 Episode: 52858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.039008140563964844\n",
      "Value Loss:  0.00044977752259001136\n",
      "Q Loss:  0.00062568299472332\n",
      "Policy Loss:  -0.006402087397873402\n",
      "[(0.00012, 0.03178), (0.0, 0.03163), (1.0, 0.03178)]\n",
      "Alpha*: 0.0 tau*: 0.03163 Episode: 52862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.527474447968416e-05\n",
      "Q Loss:  0.6789788603782654\n",
      "Policy Loss:  0.04114219918847084\n",
      "[(0.00012, 0.03163), (0.0, 0.03148), (1.0, 0.03163)]\n",
      "Alpha*: 0.0 tau*: 0.03148 Episode: 52866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  60.73423385620117\n",
      "Q Loss:  5.723362922668457\n",
      "Policy Loss:  -13.375007629394531\n",
      "[(0.00012, 0.03148), (0.0, 0.03133), (1.0, 0.03148)]\n",
      "Alpha*: 0.0 tau*: 0.03133 Episode: 52916 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.744674515677616e-05\n",
      "Q Loss:  0.0018542222678661346\n",
      "Policy Loss:  -0.009547825902700424\n",
      "[(0.00012, 0.03133), (0.0, 0.03118), (1.0, 0.03133)]\n",
      "Alpha*: 0.0 tau*: 0.03118 Episode: 52920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.533518611220643e-05\n",
      "Q Loss:  0.003466953057795763\n",
      "Policy Loss:  -0.0033386265859007835\n",
      "[(0.00012, 0.03118), (0.0, 0.03103), (1.0, 0.03118)]\n",
      "Alpha*: 0.0 tau*: 0.03103 Episode: 52924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001607894897461\n",
      "Value Loss:  1.8938874291052343e-06\n",
      "Q Loss:  0.002509351121261716\n",
      "Policy Loss:  -0.00821071956306696\n",
      "[(0.00012, 0.03103), (0.0, 0.03088), (1.0, 0.03103)]\n",
      "Alpha*: 0.0 tau*: 0.03088 Episode: 52928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.2388041019439697\n",
      "Q Loss:  0.2871764302253723\n",
      "Policy Loss:  -5.846071243286133\n",
      "[(0.00012, 0.03088), (0.0, 0.03073), (1.0, 0.03088)]\n",
      "Alpha*: 0.0 tau*: 0.03073 Episode: 52932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.201890468597412\n",
      "Q Loss:  0.2303190976381302\n",
      "Policy Loss:  -8.200678825378418\n",
      "[(0.00012, 0.03073), (0.0, 0.03058), (1.0, 0.03073)]\n",
      "Alpha*: 0.0 tau*: 0.03058 Episode: 52937 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00013090540596749634\n",
      "Q Loss:  0.1378093957901001\n",
      "Policy Loss:  0.14510759711265564\n",
      "[(0.00013, 0.03058), (0.0, 0.03043), (1.0, 0.03058)]\n",
      "Alpha*: 0.0 tau*: 0.03043 Episode: 52941 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.071408987045288\n",
      "Q Loss:  0.48028770089149475\n",
      "Policy Loss:  -2.128980875015259\n",
      "[(0.00013, 0.03043), (0.0, 0.03028), (1.0, 0.03043)]\n",
      "Alpha*: 0.0 tau*: 0.03028 Episode: 52945 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.9675676822662354\n",
      "Q Loss:  0.5659106373786926\n",
      "Policy Loss:  -6.696561336517334\n",
      "[(0.00013, 0.03028), (0.0, 0.03013), (1.0, 0.03028)]\n",
      "Alpha*: 0.0 tau*: 0.03013 Episode: 52951 length: 4 #teleports:2\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  159.33139038085938\n",
      "Q Loss:  502.6877136230469\n",
      "Policy Loss:  -16.67402458190918\n",
      "[(0.00013, 0.03013), (0.0, 0.02998), (1.0, 0.03013)]\n",
      "Alpha*: 0.0 tau*: 0.02998 Episode: 52990 length: 38 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0011510343756526709\n",
      "Q Loss:  0.0011212736135348678\n",
      "Policy Loss:  0.026370475068688393\n",
      "[(0.00013, 0.02998), (0.0, 0.02983), (1.0, 0.02998)]\n",
      "Alpha*: 0.0 tau*: 0.02983 Episode: 52995 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0003014724643435329\n",
      "Q Loss:  0.36413779854774475\n",
      "Policy Loss:  0.5923183560371399\n",
      "[(0.00013, 0.02983), (0.0, 0.02968), (1.0, 0.02983)]\n",
      "Alpha*: 0.0 tau*: 0.02968 Episode: 52999 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.6963748931884766\n",
      "Q Loss:  0.09084734320640564\n",
      "Policy Loss:  -1.3885533809661865\n",
      "[(0.00013, 0.02968), (0.0, 0.02953), (1.0, 0.02968)]\n",
      "Alpha*: 0.0 tau*: 0.02953 Episode: 53088 length: 87 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  24817.572265625\n",
      "Q Loss:  22863.013671875\n",
      "Policy Loss:  -12.093755722045898\n",
      "[(0.00013, 0.02953), (0.0, 0.02938), (1.0, 0.02953)]\n",
      "Alpha*: 0.0 tau*: 0.02938 Episode: 53127 length: 36 #teleports:3\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011001110076904297\n",
      "Value Loss:  0.0008913006167858839\n",
      "Q Loss:  23.56015396118164\n",
      "Policy Loss:  1.6811237335205078\n",
      "[(0.00013, 0.02938), (0.0, 0.02923), (1.0, 0.02938)]\n",
      "Alpha*: 0.0 tau*: 0.02923 Episode: 53131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0006185945821925998\n",
      "Q Loss:  0.0008249516831710935\n",
      "Policy Loss:  -0.004493926651775837\n",
      "[(0.00013, 0.02923), (0.0, 0.02908), (1.0, 0.02923)]\n",
      "Alpha*: 0.0 tau*: 0.02908 Episode: 53135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005069722537882626\n",
      "Q Loss:  0.0002676366420928389\n",
      "Policy Loss:  -0.011950483545660973\n",
      "[(0.00013, 0.02908), (0.0, 0.02893), (1.0, 0.02908)]\n",
      "Alpha*: 0.0 tau*: 0.02893 Episode: 53139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1.5794743299484253\n",
      "Q Loss:  0.015215255320072174\n",
      "Policy Loss:  -1.0780720710754395\n",
      "[(0.00013, 0.02893), (0.0, 0.02878), (1.0, 0.02893)]\n",
      "Alpha*: 0.0 tau*: 0.02878 Episode: 53174 length: 34 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013627767562866211\n",
      "Value Loss:  1.9290997982025146\n",
      "Q Loss:  0.1221374049782753\n",
      "Policy Loss:  -0.5799954533576965\n",
      "[(0.00013, 0.02878), (0.0, 0.02863), (1.0, 0.02878)]\n",
      "Alpha*: 0.0 tau*: 0.02863 Episode: 53203 length: 28 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.3609235286712646\n",
      "Q Loss:  2.494762659072876\n",
      "Policy Loss:  -0.3582172095775604\n",
      "[(0.00013, 0.02863), (0.0, 0.02849), (1.0, 0.02863)]\n",
      "Alpha*: 0.0 tau*: 0.02849 Episode: 53242 length: 38 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.0007778079016134143\n",
      "Q Loss:  46.07511901855469\n",
      "Policy Loss:  3.2927374839782715\n",
      "[(0.00013, 0.02849), (0.0, 0.02835), (1.0, 0.02849)]\n",
      "Alpha*: 0.0 tau*: 0.02835 Episode: 53246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00036452891072258353\n",
      "Q Loss:  22.937911987304688\n",
      "Policy Loss:  1.6298205852508545\n",
      "[(0.00013, 0.02835), (0.0, 0.02821), (1.0, 0.02835)]\n",
      "Alpha*: 0.0 tau*: 0.02821 Episode: 53251 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  8.762141078477725e-05\n",
      "Q Loss:  0.15243977308273315\n",
      "Policy Loss:  0.20179235935211182\n",
      "[(0.00013, 0.02821), (0.0, 0.02807), (1.0, 0.02821)]\n",
      "Alpha*: 0.0 tau*: 0.02807 Episode: 53256 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.737899068160914e-06\n",
      "Q Loss:  0.11904407292604446\n",
      "Policy Loss:  0.16179244220256805\n",
      "[(0.00013, 0.02807), (0.0, 0.02793), (1.0, 0.02807)]\n",
      "Alpha*: 0.0 tau*: 0.02793 Episode: 53260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  8.451627218164504e-05\n",
      "Q Loss:  0.0013040140038356185\n",
      "Policy Loss:  -0.008273577317595482\n",
      "[(0.00013, 0.02793), (0.0, 0.02779), (1.0, 0.02793)]\n",
      "Alpha*: 0.0 tau*: 0.02779 Episode: 53264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0001287864870391786\n",
      "Q Loss:  0.01498633436858654\n",
      "Policy Loss:  0.028656678274273872\n",
      "[(0.00013, 0.02779), (0.0, 0.02765), (1.0, 0.02779)]\n",
      "Alpha*: 0.0 tau*: 0.02765 Episode: 53268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.00023895491904113442\n",
      "Q Loss:  0.02549460157752037\n",
      "Policy Loss:  0.05163591355085373\n",
      "[(0.00013, 0.02765), (0.0, 0.02751), (1.0, 0.02765)]\n",
      "Alpha*: 0.0 tau*: 0.02751 Episode: 53272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0001437603059457615\n",
      "Q Loss:  0.013211295008659363\n",
      "Policy Loss:  0.2674713730812073\n",
      "[(0.00013, 0.02751), (0.0, 0.02737), (1.0, 0.02751)]\n",
      "Alpha*: 0.0 tau*: 0.02737 Episode: 53276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01003265380859375\n",
      "Value Loss:  0.9357970952987671\n",
      "Q Loss:  0.06924218684434891\n",
      "Policy Loss:  -1.6957060098648071\n",
      "[(0.00012, 0.02737), (0.0, 0.02723), (1.0, 0.02737)]\n",
      "Alpha*: 0.0 tau*: 0.02723 Episode: 53353 length: 74 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.025005340576171875\n",
      "Value Loss:  1.0508909326745197e-05\n",
      "Q Loss:  0.5432043671607971\n",
      "Policy Loss:  -0.014249149709939957\n",
      "[(0.00012, 0.02723), (0.0, 0.02709), (1.0, 0.02723)]\n",
      "Alpha*: 0.0 tau*: 0.02709 Episode: 53357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.7773739099502563\n",
      "Q Loss:  0.38340282440185547\n",
      "Policy Loss:  -1.8604918718338013\n",
      "[(0.00012, 0.02709), (0.0, 0.02695), (1.0, 0.02709)]\n",
      "Alpha*: 0.0 tau*: 0.02695 Episode: 53361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1554927825927734\n",
      "Q Loss:  0.35953596234321594\n",
      "Policy Loss:  -5.349560260772705\n",
      "[(0.00012, 0.02695), (0.0, 0.02681), (1.0, 0.02695)]\n",
      "Alpha*: 0.0 tau*: 0.02681 Episode: 53365 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012590885162353516\n",
      "Value Loss:  26497.09765625\n",
      "Q Loss:  24759.455078125\n",
      "Policy Loss:  -47.19002151489258\n",
      "[(0.00012, 0.02681), (0.0, 0.02667), (1.0, 0.02681)]\n",
      "Alpha*: 0.0 tau*: 0.02667 Episode: 53401 length: 34 #teleports:2\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1563.2420654296875\n",
      "Q Loss:  443.01654052734375\n",
      "Policy Loss:  -293.60455322265625\n",
      "[(0.00012, 0.02667), (0.0, 0.02653), (1.0, 0.02667)]\n",
      "Alpha*: 0.0 tau*: 0.02653 Episode: 53405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  781.02587890625\n",
      "Q Loss:  418.9672546386719\n",
      "Policy Loss:  -152.8609161376953\n",
      "[(0.00012, 0.02653), (0.0, 0.02639), (1.0, 0.02653)]\n",
      "Alpha*: 0.0 tau*: 0.02639 Episode: 53409 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  19381.3984375\n",
      "Q Loss:  17861.16796875\n",
      "Policy Loss:  -8.557145118713379\n",
      "[(0.00012, 0.02639), (0.0, 0.02625), (1.0, 0.02639)]\n",
      "Alpha*: 0.0 tau*: 0.02625 Episode: 53458 length: 46 #teleports:3\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.05801248550415039\n",
      "Value Loss:  3.0800561944488436e-05\n",
      "Q Loss:  0.0024970732629299164\n",
      "Policy Loss:  0.006914885714650154\n",
      "[(0.00012, 0.02625), (0.0, 0.02611), (1.0, 0.02625)]\n",
      "Alpha*: 0.0 tau*: 0.02611 Episode: 53462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.0905865565291606e-05\n",
      "Q Loss:  0.0013716570101678371\n",
      "Policy Loss:  -0.006130848079919815\n",
      "[(0.00012, 0.02611), (0.0, 0.02597), (1.0, 0.02611)]\n",
      "Alpha*: 0.0 tau*: 0.02597 Episode: 53466 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.048011064529418945\n",
      "Value Loss:  35907.24609375\n",
      "Q Loss:  33605.23828125\n",
      "Policy Loss:  -31.425024032592773\n",
      "[(0.00013, 0.02597), (0.0, 0.02583), (1.0, 0.02597)]\n",
      "Alpha*: 0.0 tau*: 0.02583 Episode: 53491 length: 25 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002193906984757632\n",
      "Q Loss:  0.0017976828385144472\n",
      "Policy Loss:  -0.02353207767009735\n",
      "[(0.00013, 0.02583), (0.0, 0.02569), (1.0, 0.02583)]\n",
      "Alpha*: 0.0 tau*: 0.02569 Episode: 53495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.4781436622142792\n",
      "Q Loss:  0.32289743423461914\n",
      "Policy Loss:  -1.760879635810852\n",
      "[(0.00013, 0.02569), (0.0, 0.02555), (1.0, 0.02569)]\n",
      "Alpha*: 0.0 tau*: 0.02555 Episode: 53499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.4722302556037903\n",
      "Q Loss:  0.34799402952194214\n",
      "Policy Loss:  -0.7311114072799683\n",
      "[(0.00013, 0.02555), (0.0, 0.02541), (1.0, 0.02555)]\n",
      "Alpha*: 0.0 tau*: 0.02541 Episode: 53503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  133.82774353027344\n",
      "Q Loss:  420.691162109375\n",
      "Policy Loss:  -17.32308006286621\n",
      "[(0.00013, 0.02541), (0.0, 0.02527), (1.0, 0.02541)]\n",
      "Alpha*: 0.0 tau*: 0.02527 Episode: 53552 length: 48 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001913348096422851\n",
      "Q Loss:  0.0009335772483609617\n",
      "Policy Loss:  -0.010408378206193447\n",
      "[(0.00013, 0.02527), (0.0, 0.02513), (1.0, 0.02527)]\n",
      "Alpha*: 0.0 tau*: 0.02513 Episode: 53557 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.4509522318840027\n",
      "Q Loss:  0.018162546679377556\n",
      "Policy Loss:  -1.9432373046875\n",
      "[(0.00013, 0.02513), (0.0, 0.02499), (1.0, 0.02513)]\n",
      "Alpha*: 0.0 tau*: 0.02499 Episode: 53561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010610818862915039\n",
      "Value Loss:  0.8385642766952515\n",
      "Q Loss:  2.703822135925293\n",
      "Policy Loss:  -0.5572589635848999\n",
      "[(0.00013, 0.02499), (0.0, 0.02485), (1.0, 0.02499)]\n",
      "Alpha*: 0.0 tau*: 0.02485 Episode: 53637 length: 75 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  6.80223893141374e-05\n",
      "Q Loss:  0.0014441590756177902\n",
      "Policy Loss:  -0.017252985388040543\n",
      "[(0.00013, 0.02485), (0.0, 0.02471), (1.0, 0.02485)]\n",
      "Alpha*: 0.0 tau*: 0.02471 Episode: 53641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  7.513973832828924e-05\n",
      "Q Loss:  0.0018801469122990966\n",
      "Policy Loss:  0.008972186595201492\n",
      "[(0.00013, 0.02471), (0.0, 0.02457), (1.0, 0.02471)]\n",
      "Alpha*: 0.0 tau*: 0.02457 Episode: 53645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300572395324707\n",
      "Value Loss:  1.2723273038864136\n",
      "Q Loss:  0.07039297372102737\n",
      "Policy Loss:  -0.915527880191803\n",
      "[(0.00013, 0.02457), (0.0, 0.02443), (1.0, 0.02457)]\n",
      "Alpha*: 0.0 tau*: 0.02443 Episode: 53692 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015587568283081055\n",
      "Value Loss:  0.00019398504809942096\n",
      "Q Loss:  0.0012884882744401693\n",
      "Policy Loss:  0.0022188248112797737\n",
      "[(0.00013, 0.02443), (0.0, 0.02429), (1.0, 0.02443)]\n",
      "Alpha*: 0.0 tau*: 0.02429 Episode: 53696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  9.368477913085371e-05\n",
      "Q Loss:  0.0012333022896200418\n",
      "Policy Loss:  0.00689571350812912\n",
      "[(0.00013, 0.02429), (0.0, 0.02415), (1.0, 0.02429)]\n",
      "Alpha*: 0.0 tau*: 0.02415 Episode: 53700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0008521811687387526\n",
      "Q Loss:  0.0021474577952176332\n",
      "Policy Loss:  -0.011605605483055115\n",
      "[(0.00013, 0.02415), (0.0, 0.02401), (1.0, 0.02415)]\n",
      "Alpha*: 0.0 tau*: 0.02401 Episode: 53704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.0107650756835938\n",
      "Q Loss:  0.012917985208332539\n",
      "Policy Loss:  -0.5156756043434143\n",
      "[(0.00013, 0.02401), (0.0, 0.02387), (1.0, 0.02401)]\n",
      "Alpha*: 0.0 tau*: 0.02387 Episode: 53733 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  814.5567626953125\n",
      "Q Loss:  2414.948974609375\n",
      "Policy Loss:  -72.56803894042969\n",
      "[(0.00012, 0.02387), (0.0, 0.02373), (1.0, 0.02387)]\n",
      "Alpha*: 0.0 tau*: 0.02373 Episode: 53737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.875164348864928e-05\n",
      "Q Loss:  0.0009328013984486461\n",
      "Policy Loss:  -0.01090562716126442\n",
      "[(0.00012, 0.02373), (0.0, 0.02359), (1.0, 0.02373)]\n",
      "Alpha*: 0.0 tau*: 0.02359 Episode: 53741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800583839416504\n",
      "Value Loss:  0.0001426881499355659\n",
      "Q Loss:  0.0018971911631524563\n",
      "Policy Loss:  0.01920279487967491\n",
      "[(0.00012, 0.02359), (0.0, 0.02345), (1.0, 0.02359)]\n",
      "Alpha*: 0.0 tau*: 0.02345 Episode: 53745 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  0.00017680255405139178\n",
      "Q Loss:  0.0012607361422851682\n",
      "Policy Loss:  0.21875110268592834\n",
      "[(0.00012, 0.02345), (0.0, 0.02331), (1.0, 0.02345)]\n",
      "Alpha*: 0.0 tau*: 0.02331 Episode: 53750 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  3.4741075069177896e-05\n",
      "Q Loss:  0.0017566197784617543\n",
      "Policy Loss:  0.02189260721206665\n",
      "[(0.00012, 0.02331), (0.0, 0.02317), (1.0, 0.02331)]\n",
      "Alpha*: 0.0 tau*: 0.02317 Episode: 53754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.8617563910083845e-05\n",
      "Q Loss:  0.0024808146990835667\n",
      "Policy Loss:  0.02817070111632347\n",
      "[(0.00012, 0.02317), (0.0, 0.02303), (1.0, 0.02317)]\n",
      "Alpha*: 0.0 tau*: 0.02303 Episode: 53758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.0839263015659526e-05\n",
      "Q Loss:  0.0028543276712298393\n",
      "Policy Loss:  0.1965639889240265\n",
      "[(0.00012, 0.02303), (0.0, 0.02289), (1.0, 0.02303)]\n",
      "Alpha*: 0.0 tau*: 0.02289 Episode: 53762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.9782493114471436\n",
      "Q Loss:  0.007029721513390541\n",
      "Policy Loss:  -0.8015840649604797\n",
      "[(0.00012, 0.02289), (0.0, 0.02275), (1.0, 0.02289)]\n",
      "Alpha*: 0.0 tau*: 0.02275 Episode: 53822 length: 59 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00036351755261421204\n",
      "Q Loss:  0.008897161111235619\n",
      "Policy Loss:  -0.025020994246006012\n",
      "[(0.00012, 0.02275), (0.0, 0.02261), (1.0, 0.02275)]\n",
      "Alpha*: 0.0 tau*: 0.02261 Episode: 53826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  4.69206934212707e-05\n",
      "Q Loss:  0.001022462034597993\n",
      "Policy Loss:  0.02151823788881302\n",
      "[(0.00012, 0.02261), (0.0, 0.02247), (1.0, 0.02261)]\n",
      "Alpha*: 0.0 tau*: 0.02247 Episode: 53830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  1.9134249687194824\n",
      "Q Loss:  0.010644677095115185\n",
      "Policy Loss:  -0.7081438899040222\n",
      "[(0.00011, 0.02247), (0.0, 0.02233), (1.0, 0.02247)]\n",
      "Alpha*: 0.0 tau*: 0.02233 Episode: 53860 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.440981451305561e-06\n",
      "Q Loss:  0.0018103793263435364\n",
      "Policy Loss:  0.002770524937659502\n",
      "[(0.00011, 0.02233), (0.0, 0.02219), (1.0, 0.02233)]\n",
      "Alpha*: 0.0 tau*: 0.02219 Episode: 53864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.059623850276694e-05\n",
      "Q Loss:  0.00015067811182234436\n",
      "Policy Loss:  0.002064955420792103\n",
      "[(0.00011, 0.02219), (0.0, 0.02205), (1.0, 0.02219)]\n",
      "Alpha*: 0.0 tau*: 0.02205 Episode: 53868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0003017914423253387\n",
      "Q Loss:  0.0021818114910274744\n",
      "Policy Loss:  -0.026945967227220535\n",
      "[(0.00011, 0.02205), (0.0, 0.02191), (1.0, 0.02205)]\n",
      "Alpha*: 0.0 tau*: 0.02191 Episode: 53873 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.553596590994857e-05\n",
      "Q Loss:  0.0017262804321944714\n",
      "Policy Loss:  0.0007340358570218086\n",
      "[(0.00011, 0.02191), (0.0, 0.02177), (1.0, 0.02191)]\n",
      "Alpha*: 0.0 tau*: 0.02177 Episode: 53877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013287782669067383\n",
      "Value Loss:  1.527390668343287e-05\n",
      "Q Loss:  0.0007914754678495228\n",
      "Policy Loss:  0.0034652752801775932\n",
      "[(0.00011, 0.02177), (0.0, 0.02163), (1.0, 0.02177)]\n",
      "Alpha*: 0.0 tau*: 0.02163 Episode: 53881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.7830221652984619\n",
      "Q Loss:  1.5744863748550415\n",
      "Policy Loss:  -0.5154488682746887\n",
      "[(0.00011, 0.02163), (0.0, 0.02149), (1.0, 0.02163)]\n",
      "Alpha*: 0.0 tau*: 0.02149 Episode: 53954 length: 72 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.024672189727425575\n",
      "Q Loss:  27.46390151977539\n",
      "Policy Loss:  1.8445911407470703\n",
      "[(0.00011, 0.02149), (0.0, 0.02135), (1.0, 0.02149)]\n",
      "Alpha*: 0.0 tau*: 0.02135 Episode: 53958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  46829.703125\n",
      "Q Loss:  43005.22265625\n",
      "Policy Loss:  -7.663119316101074\n",
      "[(0.00011, 0.02135), (0.0, 0.02121), (1.0, 0.02135)]\n",
      "Alpha*: 0.0 tau*: 0.02121 Episode: 53977 length: 19 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03900861740112305\n",
      "Value Loss:  0.00028830202063545585\n",
      "Q Loss:  0.00057898712111637\n",
      "Policy Loss:  0.005018786992877722\n",
      "[(0.00011, 0.02121), (0.0, 0.02107), (1.0, 0.02121)]\n",
      "Alpha*: 0.0 tau*: 0.02107 Episode: 53981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0004762129101436585\n",
      "Q Loss:  0.0010650192853063345\n",
      "Policy Loss:  0.20194953680038452\n",
      "[(0.00011, 0.02107), (0.0, 0.02093), (1.0, 0.02107)]\n",
      "Alpha*: 0.0 tau*: 0.02093 Episode: 53985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01392054557800293\n",
      "Value Loss:  24017.322265625\n",
      "Q Loss:  22007.32421875\n",
      "Policy Loss:  -11.154446601867676\n",
      "[(0.00011, 0.02093), (0.0, 0.02079), (1.0, 0.02093)]\n",
      "Alpha*: 0.0 tau*: 0.02079 Episode: 54022 length: 37 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  1.0377511978149414\n",
      "Q Loss:  0.07633931189775467\n",
      "Policy Loss:  -3.564516305923462\n",
      "[(0.00011, 0.02079), (0.0, 0.02065), (1.0, 0.02079)]\n",
      "Alpha*: 0.0 tau*: 0.02065 Episode: 54026 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.9383333325386047\n",
      "Q Loss:  1.9521105289459229\n",
      "Policy Loss:  -0.2995465099811554\n",
      "[(0.00011, 0.02065), (0.0, 0.02051), (1.0, 0.02065)]\n",
      "Alpha*: 0.0 tau*: 0.02051 Episode: 54082 length: 54 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  6.175471935421228e-05\n",
      "Q Loss:  0.000346450338838622\n",
      "Policy Loss:  0.0038560612592846155\n",
      "[(0.00011, 0.02051), (0.0, 0.02037), (1.0, 0.02051)]\n",
      "Alpha*: 0.0 tau*: 0.02037 Episode: 54086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.193642785641714e-06\n",
      "Q Loss:  0.0003768311580643058\n",
      "Policy Loss:  0.011868545785546303\n",
      "[(0.00011, 0.02037), (0.0, 0.02023), (1.0, 0.02037)]\n",
      "Alpha*: 0.0 tau*: 0.02023 Episode: 54090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  5.697528104064986e-05\n",
      "Q Loss:  0.0009039966389536858\n",
      "Policy Loss:  0.22796788811683655\n",
      "[(0.00011, 0.02023), (0.0, 0.02009), (1.0, 0.02023)]\n",
      "Alpha*: 0.0 tau*: 0.02009 Episode: 54094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  76.12733459472656\n",
      "Q Loss:  41.81706619262695\n",
      "Policy Loss:  -14.780056953430176\n",
      "[(0.00011, 0.02009), (0.0, 0.01995), (1.0, 0.02009)]\n",
      "Alpha*: 0.0 tau*: 0.01995 Episode: 54143 length: 46 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.000535829458385706\n",
      "Q Loss:  0.001222897437401116\n",
      "Policy Loss:  0.005806012079119682\n",
      "[(0.00011, 0.01995), (0.0, 0.01981), (1.0, 0.01995)]\n",
      "Alpha*: 0.0 tau*: 0.01981 Episode: 54147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002889216411858797\n",
      "Q Loss:  0.0010800384916365147\n",
      "Policy Loss:  0.010134371928870678\n",
      "[(0.00011, 0.01981), (0.0, 0.01967), (1.0, 0.01981)]\n",
      "Alpha*: 0.0 tau*: 0.01967 Episode: 54151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.0028252601623535\n",
      "Q Loss:  0.038564443588256836\n",
      "Policy Loss:  -0.8249397873878479\n",
      "[(0.00011, 0.01967), (0.0, 0.01953), (1.0, 0.01967)]\n",
      "Alpha*: 0.0 tau*: 0.01953 Episode: 54205 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.57078218460083\n",
      "Q Loss:  0.17496328055858612\n",
      "Policy Loss:  -0.6817262768745422\n",
      "[(0.00011, 0.01953), (0.0, 0.01939), (1.0, 0.01953)]\n",
      "Alpha*: 0.0 tau*: 0.01939 Episode: 54226 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200103759765625\n",
      "Value Loss:  4.184857243672013e-05\n",
      "Q Loss:  0.00013444482465274632\n",
      "Policy Loss:  0.005677857901901007\n",
      "[(0.00011, 0.01939), (0.0, 0.01925), (1.0, 0.01939)]\n",
      "Alpha*: 0.0 tau*: 0.01925 Episode: 54230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.9063747206237167e-05\n",
      "Q Loss:  5.66224662179593e-05\n",
      "Policy Loss:  0.0009417939581908286\n",
      "[(0.00011, 0.01925), (0.0, 0.01911), (1.0, 0.01925)]\n",
      "Alpha*: 0.0 tau*: 0.01911 Episode: 54234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.2265176337677985e-05\n",
      "Q Loss:  9.878650598693639e-05\n",
      "Policy Loss:  -0.008596798405051231\n",
      "[(0.00011, 0.01911), (0.0, 0.01897), (1.0, 0.01911)]\n",
      "Alpha*: 0.0 tau*: 0.01897 Episode: 54238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  71.7490005493164\n",
      "Q Loss:  202.4491729736328\n",
      "Policy Loss:  -10.085177421569824\n",
      "[(0.00011, 0.01897), (0.0, 0.01883), (1.0, 0.01897)]\n",
      "Alpha*: 0.0 tau*: 0.01883 Episode: 54292 length: 50 #teleports:4\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.5941525101661682\n",
      "Q Loss:  0.26333215832710266\n",
      "Policy Loss:  -1.2833502292633057\n",
      "[(0.00011, 0.01883), (0.0, 0.01869), (1.0, 0.01883)]\n",
      "Alpha*: 0.0 tau*: 0.01869 Episode: 54296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  1.3016561269760132\n",
      "Q Loss:  0.03663073852658272\n",
      "Policy Loss:  -1.440097689628601\n",
      "[(0.00011, 0.01869), (0.0, 0.01855), (1.0, 0.01869)]\n",
      "Alpha*: 0.0 tau*: 0.01855 Episode: 54340 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012992620468139648\n",
      "Value Loss:  888.0697021484375\n",
      "Q Loss:  2540.80419921875\n",
      "Policy Loss:  -85.72409057617188\n",
      "[(0.00011, 0.01855), (0.0, 0.01841), (1.0, 0.01855)]\n",
      "Alpha*: 0.0 tau*: 0.01841 Episode: 54344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.002668843837454915\n",
      "Q Loss:  0.0028927603270858526\n",
      "Policy Loss:  0.032066989690065384\n",
      "[(0.00011, 0.01841), (0.0, 0.01827), (1.0, 0.01841)]\n",
      "Alpha*: 0.0 tau*: 0.01827 Episode: 54348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00030658062314614654\n",
      "Q Loss:  0.0004778584698215127\n",
      "Policy Loss:  -0.014085555449128151\n",
      "[(0.0001, 0.01827), (0.0, 0.01813), (1.0, 0.01827)]\n",
      "Alpha*: 0.0 tau*: 0.01813 Episode: 54352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0002277857856824994\n",
      "Q Loss:  0.00027175890863873065\n",
      "Policy Loss:  -0.0079677514731884\n",
      "[(0.0001, 0.01813), (0.0, 0.01799), (1.0, 0.01813)]\n",
      "Alpha*: 0.0 tau*: 0.01799 Episode: 54356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  7.755924889352173e-05\n",
      "Q Loss:  0.0004646955640055239\n",
      "Policy Loss:  -0.00989573821425438\n",
      "[(0.0001, 0.01799), (0.0, 0.01785), (1.0, 0.01799)]\n",
      "Alpha*: 0.0 tau*: 0.01785 Episode: 54360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  59.06899642944336\n",
      "Q Loss:  3.4367778301239014\n",
      "Policy Loss:  -12.035265922546387\n",
      "[(0.0001, 0.01785), (0.0, 0.01771), (1.0, 0.01785)]\n",
      "Alpha*: 0.0 tau*: 0.01771 Episode: 54423 length: 61 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  0.00025679118698462844\n",
      "Q Loss:  0.0005579277640208602\n",
      "Policy Loss:  0.006798524875193834\n",
      "[(0.0001, 0.01771), (0.0, 0.01757), (1.0, 0.01771)]\n",
      "Alpha*: 0.0 tau*: 0.01757 Episode: 54427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400136947631836\n",
      "Value Loss:  0.00037460654857568443\n",
      "Q Loss:  0.0005018789088353515\n",
      "Policy Loss:  -0.0011771488934755325\n",
      "[(0.0001, 0.01757), (0.0, 0.01743), (1.0, 0.01757)]\n",
      "Alpha*: 0.0 tau*: 0.01743 Episode: 54431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300501823425293\n",
      "Value Loss:  0.0002653656993061304\n",
      "Q Loss:  0.0047354670241475105\n",
      "Policy Loss:  0.2609727382659912\n",
      "[(0.0001, 0.01743), (0.0, 0.01729), (1.0, 0.01743)]\n",
      "Alpha*: 0.0 tau*: 0.01729 Episode: 54435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.2615299224853516\n",
      "Q Loss:  0.09163762629032135\n",
      "Policy Loss:  -0.9913790822029114\n",
      "[(0.0001, 0.01729), (0.0, 0.01715), (1.0, 0.01729)]\n",
      "Alpha*: 0.0 tau*: 0.01715 Episode: 54460 length: 25 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0007473101723007858\n",
      "Q Loss:  0.0005853220354765654\n",
      "Policy Loss:  0.002353167627006769\n",
      "[(0.0001, 0.01715), (0.0, 0.01701), (1.0, 0.01715)]\n",
      "Alpha*: 0.0 tau*: 0.01701 Episode: 54464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00025902222841978073\n",
      "Q Loss:  0.0005410155863501132\n",
      "Policy Loss:  0.011397769674658775\n",
      "[(9e-05, 0.01701), (0.0, 0.01687), (1.0, 0.01701)]\n",
      "Alpha*: 0.0 tau*: 0.01687 Episode: 54468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  1.4718289375305176\n",
      "Q Loss:  0.06727757304906845\n",
      "Policy Loss:  -1.6140484809875488\n",
      "[(9e-05, 0.01687), (0.0, 0.01673), (1.0, 0.01687)]\n",
      "Alpha*: 0.0 tau*: 0.01673 Episode: 54511 length: 40 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00033008254831656814\n",
      "Q Loss:  0.0031405924819409847\n",
      "Policy Loss:  0.017296738922595978\n",
      "[(9e-05, 0.01673), (0.0, 0.01659), (1.0, 0.01673)]\n",
      "Alpha*: 0.0 tau*: 0.01659 Episode: 54515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0005405049305409193\n",
      "Q Loss:  0.0001632097555557266\n",
      "Policy Loss:  0.006052304990589619\n",
      "[(9e-05, 0.01659), (0.0, 0.01645), (1.0, 0.01659)]\n",
      "Alpha*: 0.0 tau*: 0.01645 Episode: 54519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04118180274963379\n",
      "Value Loss:  0.00017086727893911302\n",
      "Q Loss:  0.0014756876043975353\n",
      "Policy Loss:  0.009494759142398834\n",
      "[(9e-05, 0.01645), (0.0, 0.01631), (1.0, 0.01645)]\n",
      "Alpha*: 0.0 tau*: 0.01631 Episode: 54523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00017003467655740678\n",
      "Q Loss:  0.00037682949914596975\n",
      "Policy Loss:  0.007609953638166189\n",
      "[(9e-05, 0.01631), (0.0, 0.01617), (1.0, 0.01631)]\n",
      "Alpha*: 0.0 tau*: 0.01617 Episode: 54527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00014120611012913287\n",
      "Q Loss:  0.0017983511788770556\n",
      "Policy Loss:  0.2463243007659912\n",
      "[(9e-05, 0.01617), (0.0, 0.01603), (1.0, 0.01617)]\n",
      "Alpha*: 0.0 tau*: 0.01603 Episode: 54531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.360473871231079\n",
      "Q Loss:  0.04083552584052086\n",
      "Policy Loss:  -1.519113540649414\n",
      "[(9e-05, 0.01603), (0.0, 0.01589), (1.0, 0.01603)]\n",
      "Alpha*: 0.0 tau*: 0.01589 Episode: 54571 length: 39 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.0989354096818715e-05\n",
      "Q Loss:  0.0003707603318616748\n",
      "Policy Loss:  -0.011889955028891563\n",
      "[(9e-05, 0.01589), (0.0, 0.01575), (1.0, 0.01589)]\n",
      "Alpha*: 0.0 tau*: 0.01575 Episode: 54575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.02444594935514e-05\n",
      "Q Loss:  0.0001179936807602644\n",
      "Policy Loss:  -0.006728306412696838\n",
      "[(9e-05, 0.01575), (0.0, 0.01561), (1.0, 0.01575)]\n",
      "Alpha*: 0.0 tau*: 0.01561 Episode: 54579 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  4.3156724132131785e-05\n",
      "Q Loss:  0.0006220168434083462\n",
      "Policy Loss:  -0.014139970764517784\n",
      "[(9e-05, 0.01561), (0.0, 0.01547), (1.0, 0.01561)]\n",
      "Alpha*: 0.0 tau*: 0.01547 Episode: 54583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013597488403320312\n",
      "Value Loss:  0.0002696671290323138\n",
      "Q Loss:  0.0006861456786282361\n",
      "Policy Loss:  -0.010324148461222649\n",
      "[(9e-05, 0.01547), (0.0, 0.01533), (1.0, 0.01547)]\n",
      "Alpha*: 0.0 tau*: 0.01533 Episode: 54587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.00014782114885747433\n",
      "Q Loss:  0.00030163160408847034\n",
      "Policy Loss:  -0.002845419105142355\n",
      "[(9e-05, 0.01533), (0.0, 0.01519), (1.0, 0.01533)]\n",
      "Alpha*: 0.0 tau*: 0.01519 Episode: 54591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  4.8195979616139084e-05\n",
      "Q Loss:  3.919279697583988e-05\n",
      "Policy Loss:  0.0017743516946211457\n",
      "[(9e-05, 0.01519), (0.0, 0.01505), (1.0, 0.01519)]\n",
      "Alpha*: 0.0 tau*: 0.01505 Episode: 54595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.8126579523086548\n",
      "Q Loss:  3.8905556201934814\n",
      "Policy Loss:  -0.16334237158298492\n",
      "[(8e-05, 0.01505), (0.0, 0.01491), (1.0, 0.01505)]\n",
      "Alpha*: 0.0 tau*: 0.01491 Episode: 54652 length: 54 #teleports:3\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.00012124448403483257\n",
      "Q Loss:  0.0001311260712100193\n",
      "Policy Loss:  -0.00361731112934649\n",
      "[(8e-05, 0.01491), (0.0, 0.01477), (1.0, 0.01491)]\n",
      "Alpha*: 0.0 tau*: 0.01477 Episode: 54656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013005495071411133\n",
      "Value Loss:  0.0001133787227445282\n",
      "Q Loss:  7.420220754283946e-06\n",
      "Policy Loss:  0.007049488835036755\n",
      "[(8e-05, 0.01477), (0.0, 0.01463), (1.0, 0.01477)]\n",
      "Alpha*: 0.0 tau*: 0.01463 Episode: 54660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.5791404247283936\n",
      "Q Loss:  3.2947843074798584\n",
      "Policy Loss:  -0.7070907950401306\n",
      "[(8e-05, 0.01463), (0.0, 0.01449), (1.0, 0.01463)]\n",
      "Alpha*: 0.0 tau*: 0.01449 Episode: 54693 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.00018547951185610145\n",
      "Q Loss:  0.0007361234747804701\n",
      "Policy Loss:  0.017185194417834282\n",
      "[(8e-05, 0.01449), (0.0, 0.01435), (1.0, 0.01449)]\n",
      "Alpha*: 0.0 tau*: 0.01435 Episode: 54698 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.912142276763916\n",
      "Q Loss:  0.02165946364402771\n",
      "Policy Loss:  -1.3819156885147095\n",
      "[(8e-05, 0.01435), (0.0, 0.01421), (1.0, 0.01435)]\n",
      "Alpha*: 0.0 tau*: 0.01421 Episode: 54724 length: 24 #teleports:2\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001355834974674508\n",
      "Q Loss:  0.00012731626338791102\n",
      "Policy Loss:  0.0006319435779005289\n",
      "[(8e-05, 0.01421), (0.0, 0.01407), (1.0, 0.01421)]\n",
      "Alpha*: 0.0 tau*: 0.01407 Episode: 54728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.767722487449646\n",
      "Q Loss:  0.74756920337677\n",
      "Policy Loss:  -4.249449253082275\n",
      "[(8e-05, 0.01407), (0.0, 0.01393), (1.0, 0.01407)]\n",
      "Alpha*: 0.0 tau*: 0.01393 Episode: 54733 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  3.82120706490241e-05\n",
      "Q Loss:  0.004128748085349798\n",
      "Policy Loss:  0.25614917278289795\n",
      "[(8e-05, 0.01393), (0.0, 0.01379), (1.0, 0.01393)]\n",
      "Alpha*: 0.0 tau*: 0.01379 Episode: 54737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.3281307220458984\n",
      "Q Loss:  0.4311434030532837\n",
      "Policy Loss:  -8.590963363647461\n",
      "[(8e-05, 0.01379), (0.0, 0.01365), (1.0, 0.01379)]\n",
      "Alpha*: 0.0 tau*: 0.01365 Episode: 54741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.8539897203445435\n",
      "Q Loss:  0.21515345573425293\n",
      "Policy Loss:  -1.9769140481948853\n",
      "[(8e-05, 0.01365), (0.0, 0.01351), (1.0, 0.01365)]\n",
      "Alpha*: 0.0 tau*: 0.01351 Episode: 54778 length: 36 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.7494056224822998\n",
      "Q Loss:  0.24606657028198242\n",
      "Policy Loss:  -2.5250279903411865\n",
      "[(8e-05, 0.01351), (0.0, 0.01337), (1.0, 0.01351)]\n",
      "Alpha*: 0.0 tau*: 0.01337 Episode: 54782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  71.11741638183594\n",
      "Q Loss:  0.04565888270735741\n",
      "Policy Loss:  -14.838138580322266\n",
      "[(8e-05, 0.01337), (0.0, 0.01323), (1.0, 0.01337)]\n",
      "Alpha*: 0.0 tau*: 0.01323 Episode: 54832 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.0005988950142636895\n",
      "Q Loss:  52.237525939941406\n",
      "Policy Loss:  3.5367226600646973\n",
      "[(8e-05, 0.01323), (0.0, 0.01309), (1.0, 0.01323)]\n",
      "Alpha*: 0.0 tau*: 0.01309 Episode: 54837 length: 4 #teleports:1\n",
      "Time for bound evaluation:  0.048011064529418945\n",
      "Value Loss:  0.9370211958885193\n",
      "Q Loss:  0.005388796795159578\n",
      "Policy Loss:  -0.6991934776306152\n",
      "[(8e-05, 0.01309), (0.0, 0.01295), (1.0, 0.01309)]\n",
      "Alpha*: 0.0 tau*: 0.01295 Episode: 54884 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  875.2727661132812\n",
      "Q Loss:  25.758403778076172\n",
      "Policy Loss:  -161.46275329589844\n",
      "[(8e-05, 0.01295), (0.0, 0.01281), (1.0, 0.01295)]\n",
      "Alpha*: 0.0 tau*: 0.01281 Episode: 54888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  5.3565581765724346e-05\n",
      "Q Loss:  0.0022110778372734785\n",
      "Policy Loss:  0.015288632363080978\n",
      "[(8e-05, 0.01281), (0.0, 0.01267), (1.0, 0.01281)]\n",
      "Alpha*: 0.0 tau*: 0.01267 Episode: 54892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00020058342488482594\n",
      "Q Loss:  4.836310836253688e-05\n",
      "Policy Loss:  0.0034938761964440346\n",
      "[(8e-05, 0.01267), (0.0, 0.01253), (1.0, 0.01267)]\n",
      "Alpha*: 0.0 tau*: 0.01253 Episode: 54896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.927918791770935\n",
      "Q Loss:  0.11618874967098236\n",
      "Policy Loss:  -2.2434840202331543\n",
      "[(8e-05, 0.01253), (0.0, 0.01239), (1.0, 0.01253)]\n",
      "Alpha*: 0.0 tau*: 0.01239 Episode: 54932 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.9667205810546875\n",
      "Q Loss:  0.041405703872442245\n",
      "Policy Loss:  -1.6044563055038452\n",
      "[(8e-05, 0.01239), (0.0, 0.01225), (1.0, 0.01239)]\n",
      "Alpha*: 0.0 tau*: 0.01225 Episode: 54959 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.062757448584307e-05\n",
      "Q Loss:  0.0003178470942657441\n",
      "Policy Loss:  -0.009283453226089478\n",
      "[(8e-05, 0.01225), (0.0, 0.01211), (1.0, 0.01225)]\n",
      "Alpha*: 0.0 tau*: 0.01211 Episode: 54963 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  6.312673940556124e-05\n",
      "Q Loss:  0.0003614920424297452\n",
      "Policy Loss:  0.2494991421699524\n",
      "[(8e-05, 0.01211), (0.0, 0.01197), (1.0, 0.01211)]\n",
      "Alpha*: 0.0 tau*: 0.01197 Episode: 54967 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.7072949409484863\n",
      "Q Loss:  0.344521701335907\n",
      "Policy Loss:  -8.197929382324219\n",
      "[(8e-05, 0.01197), (0.0, 0.01183), (1.0, 0.01197)]\n",
      "Alpha*: 0.0 tau*: 0.01183 Episode: 54971 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300880432128906\n",
      "Value Loss:  1.1644344329833984\n",
      "Q Loss:  0.03612379729747772\n",
      "Policy Loss:  -1.3006576299667358\n",
      "[(8e-05, 0.01183), (0.0, 0.01169), (1.0, 0.01183)]\n",
      "Alpha*: 0.0 tau*: 0.01169 Episode: 55017 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  1.026720643043518\n",
      "Q Loss:  0.03199145942926407\n",
      "Policy Loss:  -1.4129960536956787\n",
      "[(8e-05, 0.01169), (0.0, 0.01155), (1.0, 0.01169)]\n",
      "Alpha*: 0.0 tau*: 0.01155 Episode: 55072 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0001465960667701438\n",
      "Q Loss:  0.000612764386460185\n",
      "Policy Loss:  0.012288139201700687\n",
      "[(8e-05, 0.01155), (0.0, 0.01141), (1.0, 0.01155)]\n",
      "Alpha*: 0.0 tau*: 0.01141 Episode: 55076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  3.2457139695907244e-06\n",
      "Q Loss:  0.00045185390627011657\n",
      "Policy Loss:  -0.012898610904812813\n",
      "[(8e-05, 0.01141), (0.0, 0.01127), (1.0, 0.01141)]\n",
      "Alpha*: 0.0 tau*: 0.01127 Episode: 55080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.0609069906640798e-05\n",
      "Q Loss:  0.0002787541307043284\n",
      "Policy Loss:  -0.008474260568618774\n",
      "[(8e-05, 0.01127), (0.0, 0.01113), (1.0, 0.01127)]\n",
      "Alpha*: 0.0 tau*: 0.01113 Episode: 55084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.208227496998006e-07\n",
      "Q Loss:  0.00012701217201538384\n",
      "Policy Loss:  -0.004582986235618591\n",
      "[(8e-05, 0.01113), (0.0, 0.01099), (1.0, 0.01113)]\n",
      "Alpha*: 0.0 tau*: 0.01099 Episode: 55088 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.933993710030336e-05\n",
      "Q Loss:  0.0011943565914407372\n",
      "Policy Loss:  -0.020286958664655685\n",
      "[(8e-05, 0.01099), (0.0, 0.01085), (1.0, 0.01099)]\n",
      "Alpha*: 0.0 tau*: 0.01085 Episode: 55092 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  8.027938747545704e-06\n",
      "Q Loss:  0.0008092002826742828\n",
      "Policy Loss:  -0.011895712465047836\n",
      "[(8e-05, 0.01085), (0.0, 0.01071), (1.0, 0.01085)]\n",
      "Alpha*: 0.0 tau*: 0.01071 Episode: 55096 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016001462936401367\n",
      "Value Loss:  0.8999840021133423\n",
      "Q Loss:  0.03524748980998993\n",
      "Policy Loss:  -0.8162831664085388\n",
      "[(9e-05, 0.01071), (0.0, 0.01057), (1.0, 0.01071)]\n",
      "Alpha*: 0.0 tau*: 0.01057 Episode: 55156 length: 59 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011483430862426758\n",
      "Value Loss:  0.00012432754738256335\n",
      "Q Loss:  0.00045554136158898473\n",
      "Policy Loss:  -0.0002495014341548085\n",
      "[(9e-05, 0.01057), (0.0, 0.01043), (1.0, 0.01057)]\n",
      "Alpha*: 0.0 tau*: 0.01043 Episode: 55160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.5837117795599625e-05\n",
      "Q Loss:  0.0002582590386737138\n",
      "Policy Loss:  -0.006758841685950756\n",
      "[(9e-05, 0.01043), (0.0, 0.01029), (1.0, 0.01043)]\n",
      "Alpha*: 0.0 tau*: 0.01029 Episode: 55164 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.7353637304040603e-05\n",
      "Q Loss:  0.0002684035571292043\n",
      "Policy Loss:  -0.0008309516124427319\n",
      "[(9e-05, 0.01029), (0.0, 0.01015), (1.0, 0.01029)]\n",
      "Alpha*: 0.0 tau*: 0.01015 Episode: 55168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.563859224319458\n",
      "Q Loss:  0.33266767859458923\n",
      "Policy Loss:  -2.098754644393921\n",
      "[(8e-05, 0.01015), (0.0, 0.01001), (1.0, 0.01015)]\n",
      "Alpha*: 0.0 tau*: 0.01001 Episode: 55172 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010998964309692383\n",
      "Value Loss:  2.9809226989746094\n",
      "Q Loss:  0.13709913194179535\n",
      "Policy Loss:  1.0606753826141357\n",
      "[(8e-05, 0.01001), (0.0, 0.00987), (1.0, 0.01001)]\n",
      "Alpha*: 0.0 tau*: 0.00987 Episode: 55190 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.1164034605026245\n",
      "Q Loss:  0.05179648846387863\n",
      "Policy Loss:  -2.4842710494995117\n",
      "[(8e-05, 0.00987), (0.0, 0.00973), (1.0, 0.00987)]\n",
      "Alpha*: 0.0 tau*: 0.00973 Episode: 55194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.6766828298568726\n",
      "Q Loss:  0.08025271445512772\n",
      "Policy Loss:  -1.280816912651062\n",
      "[(8e-05, 0.00973), (0.0, 0.00959), (1.0, 0.00973)]\n",
      "Alpha*: 0.0 tau*: 0.00959 Episode: 55235 length: 40 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0013139924267306924\n",
      "Q Loss:  47.44904327392578\n",
      "Policy Loss:  3.365513563156128\n",
      "[(8e-05, 0.00959), (0.0, 0.00945), (1.0, 0.00959)]\n",
      "Alpha*: 0.0 tau*: 0.00945 Episode: 55239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0006978834280744195\n",
      "Q Loss:  0.0002647017245180905\n",
      "Policy Loss:  0.006553173065185547\n",
      "[(8e-05, 0.00945), (0.0, 0.00931), (1.0, 0.00945)]\n",
      "Alpha*: 0.0 tau*: 0.00931 Episode: 55243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.8054233553120866e-05\n",
      "Q Loss:  0.0002297818282386288\n",
      "Policy Loss:  0.005693119019269943\n",
      "[(8e-05, 0.00931), (0.0, 0.00917), (1.0, 0.00931)]\n",
      "Alpha*: 0.0 tau*: 0.00917 Episode: 55247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.0070444345474243\n",
      "Q Loss:  0.007298384793102741\n",
      "Policy Loss:  -0.6905450224876404\n",
      "[(8e-05, 0.00917), (0.0, 0.00903), (1.0, 0.00917)]\n",
      "Alpha*: 0.0 tau*: 0.00903 Episode: 55299 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.723324179649353\n",
      "Q Loss:  0.10229479521512985\n",
      "Policy Loss:  -1.272991418838501\n",
      "[(8e-05, 0.00903), (0.0, 0.00889), (1.0, 0.00903)]\n",
      "Alpha*: 0.0 tau*: 0.00889 Episode: 55339 length: 39 #teleports:1\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  193.9170379638672\n",
      "Q Loss:  450.5928649902344\n",
      "Policy Loss:  -28.03432273864746\n",
      "[(8e-05, 0.00889), (0.0, 0.00875), (1.0, 0.00889)]\n",
      "Alpha*: 0.0 tau*: 0.00875 Episode: 55392 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.7750018034566892e-06\n",
      "Q Loss:  0.00029113522032275796\n",
      "Policy Loss:  -0.01238077413290739\n",
      "[(8e-05, 0.00875), (0.0, 0.00861), (1.0, 0.00875)]\n",
      "Alpha*: 0.0 tau*: 0.00861 Episode: 55396 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.0955511243082583e-05\n",
      "Q Loss:  2.6040417651529424e-05\n",
      "Policy Loss:  -0.002685416489839554\n",
      "[(8e-05, 0.00861), (0.0, 0.00847), (1.0, 0.00861)]\n",
      "Alpha*: 0.0 tau*: 0.00847 Episode: 55400 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.562686081044376e-05\n",
      "Q Loss:  0.018337305635213852\n",
      "Policy Loss:  0.05245991796255112\n",
      "[(8e-05, 0.00847), (0.0, 0.00833), (1.0, 0.00847)]\n",
      "Alpha*: 0.0 tau*: 0.00833 Episode: 55404 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.106715510308277e-05\n",
      "Q Loss:  0.00036617895239032805\n",
      "Policy Loss:  -0.012592924758791924\n",
      "[(8e-05, 0.00833), (0.0, 0.00819), (1.0, 0.00833)]\n",
      "Alpha*: 0.0 tau*: 0.00819 Episode: 55408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  9.145415788225364e-06\n",
      "Q Loss:  0.00011550445924513042\n",
      "Policy Loss:  -0.0007473682635463774\n",
      "[(7e-05, 0.00819), (0.0, 0.00805), (1.0, 0.00819)]\n",
      "Alpha*: 0.0 tau*: 0.00805 Episode: 55412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0131683349609375\n",
      "Value Loss:  1.4066778021515347e-05\n",
      "Q Loss:  0.005171057768166065\n",
      "Policy Loss:  0.25205016136169434\n",
      "[(7e-05, 0.00805), (0.0, 0.00791), (1.0, 0.00805)]\n",
      "Alpha*: 0.0 tau*: 0.00791 Episode: 55416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.25540828704834\n",
      "Q Loss:  0.012226946651935577\n",
      "Policy Loss:  -0.5713778138160706\n",
      "[(7e-05, 0.00791), (0.0, 0.00778), (1.0, 0.00791)]\n",
      "Alpha*: 0.0 tau*: 0.00778 Episode: 55440 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000832567922770977\n",
      "Q Loss:  0.0018649864941835403\n",
      "Policy Loss:  -0.016271322965621948\n",
      "[(7e-05, 0.00778), (0.0, 0.00765), (1.0, 0.00778)]\n",
      "Alpha*: 0.0 tau*: 0.00765 Episode: 55444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.2121177860535681e-05\n",
      "Q Loss:  0.002071419730782509\n",
      "Policy Loss:  0.012245088815689087\n",
      "[(7e-05, 0.00765), (0.0, 0.00752), (1.0, 0.00765)]\n",
      "Alpha*: 0.0 tau*: 0.00752 Episode: 55448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.123926257510902e-06\n",
      "Q Loss:  0.0014766580425202847\n",
      "Policy Loss:  0.24065417051315308\n",
      "[(7e-05, 0.00752), (0.0, 0.00739), (1.0, 0.00752)]\n",
      "Alpha*: 0.0 tau*: 0.00739 Episode: 55452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  56.6165885925293\n",
      "Q Loss:  34.73197555541992\n",
      "Policy Loss:  -10.858098983764648\n",
      "[(7e-05, 0.00739), (0.0, 0.00726), (1.0, 0.00739)]\n",
      "Alpha*: 0.0 tau*: 0.00726 Episode: 55513 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  847.4110107421875\n",
      "Q Loss:  2468.41259765625\n",
      "Policy Loss:  -83.21347045898438\n",
      "[(7e-05, 0.00726), (0.0, 0.00713), (1.0, 0.00726)]\n",
      "Alpha*: 0.0 tau*: 0.00713 Episode: 55517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011005401611328125\n",
      "Value Loss:  0.00010672335338313133\n",
      "Q Loss:  0.0004177567025180906\n",
      "Policy Loss:  0.005732506979256868\n",
      "[(7e-05, 0.00713), (0.0, 0.007), (1.0, 0.00713)]\n",
      "Alpha*: 0.0 tau*: 0.007 Episode: 55521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011005878448486328\n",
      "Value Loss:  101.50100708007812\n",
      "Q Loss:  319.7619323730469\n",
      "Policy Loss:  -13.853544235229492\n",
      "[(7e-05, 0.007), (0.0, 0.00687), (1.0, 0.007)]\n",
      "Alpha*: 0.0 tau*: 0.00687 Episode: 55588 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  7.623970304848626e-05\n",
      "Q Loss:  0.0032047920394688845\n",
      "Policy Loss:  -0.016466550529003143\n",
      "[(6e-05, 0.00687), (0.0, 0.00674), (1.0, 0.00687)]\n",
      "Alpha*: 0.0 tau*: 0.00674 Episode: 55592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.160872776992619e-05\n",
      "Q Loss:  0.0002966013562399894\n",
      "Policy Loss:  0.0073194969445466995\n",
      "[(6e-05, 0.00674), (0.0, 0.00661), (1.0, 0.00674)]\n",
      "Alpha*: 0.0 tau*: 0.00661 Episode: 55596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01398921012878418\n",
      "Value Loss:  0.5905872583389282\n",
      "Q Loss:  0.04641040787100792\n",
      "Policy Loss:  -2.441634178161621\n",
      "[(6e-05, 0.00661), (0.0, 0.00648), (1.0, 0.00661)]\n",
      "Alpha*: 0.0 tau*: 0.00648 Episode: 55600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020873546600341797\n",
      "Value Loss:  1.3813190460205078\n",
      "Q Loss:  2.1441309452056885\n",
      "Policy Loss:  -1.0412449836730957\n",
      "[(6e-05, 0.00648), (0.0, 0.00635), (1.0, 0.00648)]\n",
      "Alpha*: 0.0 tau*: 0.00635 Episode: 55645 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  1.4798429012298584\n",
      "Q Loss:  6.571347236633301\n",
      "Policy Loss:  0.5332592129707336\n",
      "[(6e-05, 0.00635), (0.0, 0.00622), (1.0, 0.00635)]\n",
      "Alpha*: 0.0 tau*: 0.00622 Episode: 55687 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.09811377216829e-06\n",
      "Q Loss:  0.00014598967391066253\n",
      "Policy Loss:  -0.005790356080979109\n",
      "[(6e-05, 0.00622), (0.0, 0.00609), (1.0, 0.00622)]\n",
      "Alpha*: 0.0 tau*: 0.00609 Episode: 55691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.5935868620872498\n",
      "Q Loss:  0.23188383877277374\n",
      "Policy Loss:  -2.4470088481903076\n",
      "[(6e-05, 0.00609), (0.0, 0.00596), (1.0, 0.00609)]\n",
      "Alpha*: 0.0 tau*: 0.00596 Episode: 55695 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  128.7569122314453\n",
      "Q Loss:  219.0592041015625\n",
      "Policy Loss:  -21.386411666870117\n",
      "[(6e-05, 0.00596), (0.0, 0.00583), (1.0, 0.00596)]\n",
      "Alpha*: 0.0 tau*: 0.00583 Episode: 55747 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015006303787231445\n",
      "Value Loss:  6.203346129041165e-05\n",
      "Q Loss:  0.00010447368549648672\n",
      "Policy Loss:  0.003935590852051973\n",
      "[(6e-05, 0.00583), (0.0, 0.0057), (1.0, 0.00583)]\n",
      "Alpha*: 0.0 tau*: 0.0057 Episode: 55751 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300762176513672\n",
      "Value Loss:  1.2037829037581105e-05\n",
      "Q Loss:  0.00024389883037656546\n",
      "Policy Loss:  -0.0007795628625899553\n",
      "[(6e-05, 0.0057), (0.0, 0.00557), (1.0, 0.0057)]\n",
      "Alpha*: 0.0 tau*: 0.00557 Episode: 55755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  44416.19921875\n",
      "Q Loss:  40703.85546875\n",
      "Policy Loss:  -16.490131378173828\n",
      "[(5e-05, 0.00557), (0.0, 0.00544), (1.0, 0.00557)]\n",
      "Alpha*: 0.0 tau*: 0.00544 Episode: 55776 length: 20 #teleports:1\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1664.71044921875\n",
      "Q Loss:  5272.1826171875\n",
      "Policy Loss:  -4.49146842956543\n",
      "[(5e-05, 0.00544), (0.0, 0.00531), (1.0, 0.00544)]\n",
      "Alpha*: 0.0 tau*: 0.00531 Episode: 55780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0006596808088943362\n",
      "Q Loss:  0.000821105029899627\n",
      "Policy Loss:  0.014169164001941681\n",
      "[(5e-05, 0.00531), (0.0, 0.00518), (1.0, 0.00531)]\n",
      "Alpha*: 0.0 tau*: 0.00518 Episode: 55784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00015492874081246555\n",
      "Q Loss:  5.5513672123197466e-05\n",
      "Policy Loss:  -0.002803896786645055\n",
      "[(5e-05, 0.00518), (0.0, 0.00505), (1.0, 0.00518)]\n",
      "Alpha*: 0.0 tau*: 0.00505 Episode: 55788 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.3277924060821533\n",
      "Q Loss:  0.03681999072432518\n",
      "Policy Loss:  -1.4213039875030518\n",
      "[(5e-05, 0.00505), (0.0, 0.00492), (1.0, 0.00505)]\n",
      "Alpha*: 0.0 tau*: 0.00492 Episode: 55831 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.664330819854513e-05\n",
      "Q Loss:  5.906135629629716e-05\n",
      "Policy Loss:  -0.003619049908593297\n",
      "[(5e-05, 0.00492), (0.0, 0.00479), (1.0, 0.00492)]\n",
      "Alpha*: 0.0 tau*: 0.00479 Episode: 55835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.659229827870149e-06\n",
      "Q Loss:  0.00038966917782090604\n",
      "Policy Loss:  0.0019025264773517847\n",
      "[(5e-05, 0.00479), (0.0, 0.00466), (1.0, 0.00479)]\n",
      "Alpha*: 0.0 tau*: 0.00466 Episode: 55839 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.243118405342102\n",
      "Q Loss:  0.27257469296455383\n",
      "Policy Loss:  -4.1328959465026855\n",
      "[(5e-05, 0.00466), (0.0, 0.00453), (1.0, 0.00466)]\n",
      "Alpha*: 0.0 tau*: 0.00453 Episode: 55843 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.6163238883018494\n",
      "Q Loss:  0.20934702455997467\n",
      "Policy Loss:  -2.5760107040405273\n",
      "[(5e-05, 0.00453), (0.0, 0.0044), (1.0, 0.00453)]\n",
      "Alpha*: 0.0 tau*: 0.0044 Episode: 55847 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200697898864746\n",
      "Value Loss:  0.6071300506591797\n",
      "Q Loss:  0.20107510685920715\n",
      "Policy Loss:  -2.562598466873169\n",
      "[(5e-05, 0.0044), (0.0, 0.00427), (1.0, 0.0044)]\n",
      "Alpha*: 0.0 tau*: 0.00427 Episode: 55851 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.4352571964263916\n",
      "Q Loss:  0.17446258664131165\n",
      "Policy Loss:  0.8193436861038208\n",
      "[(5e-05, 0.00427), (0.0, 0.00414), (1.0, 0.00427)]\n",
      "Alpha*: 0.0 tau*: 0.00414 Episode: 55867 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  9.166745439870283e-05\n",
      "Q Loss:  0.0006504959310404956\n",
      "Policy Loss:  0.00561131164431572\n",
      "[(4e-05, 0.00414), (0.0, 0.00401), (1.0, 0.00414)]\n",
      "Alpha*: 0.0 tau*: 0.00401 Episode: 55871 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  6.098726225900464e-05\n",
      "Q Loss:  7.335570262512192e-05\n",
      "Policy Loss:  -0.001300484873354435\n",
      "[(4e-05, 0.00401), (0.0, 0.00388), (1.0, 0.00401)]\n",
      "Alpha*: 0.0 tau*: 0.00388 Episode: 55875 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.0555388927459717\n",
      "Q Loss:  0.047730833292007446\n",
      "Policy Loss:  -0.9329736828804016\n",
      "[(4e-05, 0.00388), (0.0, 0.00375), (1.0, 0.00388)]\n",
      "Alpha*: 0.0 tau*: 0.00375 Episode: 55923 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011049985885620117\n",
      "Value Loss:  2.0257678031921387\n",
      "Q Loss:  0.014177805744111538\n",
      "Policy Loss:  -0.6599025130271912\n",
      "[(4e-05, 0.00375), (0.0, 0.00362), (1.0, 0.00375)]\n",
      "Alpha*: 0.0 tau*: 0.00362 Episode: 55948 length: 25 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001491559814894572\n",
      "Q Loss:  0.0002495184016879648\n",
      "Policy Loss:  0.005745439790189266\n",
      "[(4e-05, 0.00362), (0.0, 0.00349), (1.0, 0.00362)]\n",
      "Alpha*: 0.0 tau*: 0.00349 Episode: 55952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.5908164978027344\n",
      "Q Loss:  0.1517428755760193\n",
      "Policy Loss:  -2.5502333641052246\n",
      "[(4e-05, 0.00349), (0.0, 0.00336), (1.0, 0.00349)]\n",
      "Alpha*: 0.0 tau*: 0.00336 Episode: 55956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.5906078219413757\n",
      "Q Loss:  0.14492420852184296\n",
      "Policy Loss:  -1.3836379051208496\n",
      "[(4e-05, 0.00336), (0.0, 0.00323), (1.0, 0.00336)]\n",
      "Alpha*: 0.0 tau*: 0.00323 Episode: 55960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1352497339248657\n",
      "Q Loss:  0.06557775288820267\n",
      "Policy Loss:  -2.1083922386169434\n",
      "[(4e-05, 0.00323), (0.0, 0.0031), (1.0, 0.00323)]\n",
      "Alpha*: 0.0 tau*: 0.0031 Episode: 56021 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  2.419329757685773e-05\n",
      "Q Loss:  0.000295078702038154\n",
      "Policy Loss:  0.005689601879566908\n",
      "[(3e-05, 0.0031), (0.0, 0.00297), (1.0, 0.0031)]\n",
      "Alpha*: 0.0 tau*: 0.00297 Episode: 56025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.041010379791259766\n",
      "Value Loss:  0.5785223245620728\n",
      "Q Loss:  0.12051916122436523\n",
      "Policy Loss:  -1.4142457246780396\n",
      "[(3e-05, 0.00297), (0.0, 0.00284), (1.0, 0.00297)]\n",
      "Alpha*: 0.0 tau*: 0.00284 Episode: 56029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.9274499416351318\n",
      "Q Loss:  0.06540173292160034\n",
      "Policy Loss:  -1.4314770698547363\n",
      "[(3e-05, 0.00284), (0.0, 0.00271), (1.0, 0.00284)]\n",
      "Alpha*: 0.0 tau*: 0.00271 Episode: 56059 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1681.3858642578125\n",
      "Q Loss:  443.83294677734375\n",
      "Policy Loss:  -317.68255615234375\n",
      "[(3e-05, 0.00271), (0.0, 0.00258), (1.0, 0.00271)]\n",
      "Alpha*: 0.0 tau*: 0.00258 Episode: 56063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.10201791964937e-05\n",
      "Q Loss:  0.00027320539811626077\n",
      "Policy Loss:  0.011187340132892132\n",
      "[(3e-05, 0.00258), (0.0, 0.00245), (1.0, 0.00258)]\n",
      "Alpha*: 0.0 tau*: 0.00245 Episode: 56067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.590775668271817e-05\n",
      "Q Loss:  0.0006171931163407862\n",
      "Policy Loss:  0.23864442110061646\n",
      "[(3e-05, 0.00245), (0.0, 0.00232), (1.0, 0.00245)]\n",
      "Alpha*: 0.0 tau*: 0.00232 Episode: 56071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.2480047941207886\n",
      "Q Loss:  0.024440566077828407\n",
      "Policy Loss:  -1.0906089544296265\n",
      "[(3e-05, 0.00232), (0.0, 0.00219), (1.0, 0.00232)]\n",
      "Alpha*: 0.0 tau*: 0.00219 Episode: 56114 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.5570898056030273\n",
      "Q Loss:  0.10220746695995331\n",
      "Policy Loss:  -2.557882785797119\n",
      "[(3e-05, 0.00219), (0.0, 0.00206), (1.0, 0.00219)]\n",
      "Alpha*: 0.0 tau*: 0.00206 Episode: 56118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1692025661468506\n",
      "Q Loss:  0.060745805501937866\n",
      "Policy Loss:  -1.0967334508895874\n",
      "[(3e-05, 0.00206), (0.0, 0.00193), (1.0, 0.00206)]\n",
      "Alpha*: 0.0 tau*: 0.00193 Episode: 56164 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  822.4802856445312\n",
      "Q Loss:  0.028563877567648888\n",
      "Policy Loss:  -164.67945861816406\n",
      "[(3e-05, 0.00193), (0.0, 0.0018), (1.0, 0.00193)]\n",
      "Alpha*: 0.0 tau*: 0.0018 Episode: 56168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.0544023098191246e-05\n",
      "Q Loss:  0.002762715332210064\n",
      "Policy Loss:  -0.015295859426259995\n",
      "[(3e-05, 0.0018), (0.0, 0.00167), (1.0, 0.0018)]\n",
      "Alpha*: 0.0 tau*: 0.00167 Episode: 56172 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00019660897669382393\n",
      "Q Loss:  0.00013957597548142076\n",
      "Policy Loss:  -1.0942574590444565e-05\n",
      "[(3e-05, 0.00167), (0.0, 0.00154), (1.0, 0.00167)]\n",
      "Alpha*: 0.0 tau*: 0.00154 Episode: 56176 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.536690827691928e-05\n",
      "Q Loss:  0.0016971478471532464\n",
      "Policy Loss:  0.016014613211154938\n",
      "[(3e-05, 0.00154), (0.0, 0.00141), (1.0, 0.00154)]\n",
      "Alpha*: 0.0 tau*: 0.00141 Episode: 56180 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  1.19381844997406\n",
      "Q Loss:  0.03124264068901539\n",
      "Policy Loss:  -1.1529994010925293\n",
      "[(3e-05, 0.00141), (0.0, 0.00128), (1.0, 0.00141)]\n",
      "Alpha*: 0.0 tau*: 0.00128 Episode: 56227 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.0083007257198915e-05\n",
      "Q Loss:  0.001059535425156355\n",
      "Policy Loss:  0.003897028276696801\n",
      "[(3e-05, 0.00128), (0.0, 0.00115), (1.0, 0.00128)]\n",
      "Alpha*: 0.0 tau*: 0.00115 Episode: 56231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  2.446593999862671\n",
      "Q Loss:  0.05059751868247986\n",
      "Policy Loss:  -0.5647189617156982\n",
      "[(3e-05, 0.00115), (0.0, 0.00102), (1.0, 0.00115)]\n",
      "Alpha*: 0.0 tau*: 0.00102 Episode: 56253 length: 22 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  6.639735602220753e-06\n",
      "Q Loss:  0.0005379037465900183\n",
      "Policy Loss:  0.008220789954066277\n",
      "[(3e-05, 0.00102), (0.0, 0.00089), (1.0, 0.00102)]\n",
      "Alpha*: 0.0 tau*: 0.00089 Episode: 56257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.6404948584968224e-05\n",
      "Q Loss:  0.0011444042902439833\n",
      "Policy Loss:  0.007342679426074028\n",
      "[(3e-05, 0.00089), (0.0, 0.00076), (1.0, 0.00089)]\n",
      "Alpha*: 0.0 tau*: 0.00076 Episode: 56261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04501056671142578\n",
      "Value Loss:  2.8923606872558594\n",
      "Q Loss:  0.1821160912513733\n",
      "Policy Loss:  0.3132045865058899\n",
      "[(3e-05, 0.00076), (0.0, 0.00063), (1.0, 0.00076)]\n",
      "Alpha*: 0.0 tau*: 0.00063 Episode: 56281 length: 20 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.317432492622174e-05\n",
      "Q Loss:  0.012199743650853634\n",
      "Policy Loss:  0.03289172798395157\n",
      "[(3e-05, 0.00063), (0.0, 0.0005), (1.0, 0.00063)]\n",
      "Alpha*: 0.0 tau*: 0.0005 Episode: 56285 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00010616588406264782\n",
      "Q Loss:  0.0002744297089520842\n",
      "Policy Loss:  -0.007439023349434137\n",
      "[(3e-05, 0.0005), (0.0, 0.00037), (1.0, 0.0005)]\n",
      "Alpha*: 0.0 tau*: 0.00037 Episode: 56289 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.5950221419334412\n",
      "Q Loss:  0.10022205859422684\n",
      "Policy Loss:  -2.6824615001678467\n",
      "[(3e-05, 0.00037), (0.0, 0.00024), (1.0, 0.00037)]\n",
      "Alpha*: 0.0 tau*: 0.00024 Episode: 56293 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.5975017547607422\n",
      "Q Loss:  0.10012666136026382\n",
      "Policy Loss:  -2.655892848968506\n",
      "[(2e-05, 0.00024), (0.0, 0.00011), (1.0, 0.00024)]\n",
      "Alpha*: 0.0 tau*: 0.00011 Episode: 56297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  5.7498516980558634e-05\n",
      "Q Loss:  0.001914206426590681\n",
      "Policy Loss:  0.020472504198551178\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56301 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.0141403436136898e-05\n",
      "Q Loss:  0.00348385120742023\n",
      "Policy Loss:  0.2636968493461609\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56305 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.7575840950012207\n",
      "Q Loss:  0.097383514046669\n",
      "Policy Loss:  -1.8677293062210083\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56339 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  6.0852995375171304e-05\n",
      "Q Loss:  0.0005635321722365916\n",
      "Policy Loss:  0.006555924192070961\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56343 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  235.45706176757812\n",
      "Q Loss:  756.7450561523438\n",
      "Policy Loss:  -23.11297607421875\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56370 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.8091664211824536e-05\n",
      "Q Loss:  0.0006867837510071695\n",
      "Policy Loss:  0.0003561144694685936\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56374 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04501032829284668\n",
      "Value Loss:  4.935957804264035e-06\n",
      "Q Loss:  0.0004010604170616716\n",
      "Policy Loss:  -0.00342450849711895\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56378 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  6.042596396582667e-06\n",
      "Q Loss:  0.0008107458124868572\n",
      "Policy Loss:  1.0662770364433527e-05\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56382 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.183517249766737e-05\n",
      "Q Loss:  0.0003527056542225182\n",
      "Policy Loss:  0.24885234236717224\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  13142.90625\n",
      "Q Loss:  12196.44921875\n",
      "Policy Loss:  -44.10380172729492\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56455 length: 69 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.4357086406089365e-05\n",
      "Q Loss:  0.00038713926915079355\n",
      "Policy Loss:  0.0004441654891707003\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012016057968139648\n",
      "Value Loss:  7.99238114268519e-06\n",
      "Q Loss:  0.0002131052897311747\n",
      "Policy Loss:  0.004941287450492382\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.56518137070816e-05\n",
      "Q Loss:  0.00016001610492821783\n",
      "Policy Loss:  0.0050354888662695885\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.5888372659683228\n",
      "Q Loss:  0.17736144363880157\n",
      "Policy Loss:  -2.403502941131592\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56509 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05701279640197754\n",
      "Value Loss:  1.554254412651062\n",
      "Q Loss:  0.09050916135311127\n",
      "Policy Loss:  -1.7813814878463745\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56547 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.052011728286743164\n",
      "Value Loss:  1.94931635633111e-06\n",
      "Q Loss:  0.00018762802937999368\n",
      "Policy Loss:  0.24684427678585052\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.2954096794128418\n",
      "Q Loss:  0.26984646916389465\n",
      "Policy Loss:  -7.381444454193115\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  4.5324610255192965e-05\n",
      "Q Loss:  0.00011086622544098645\n",
      "Policy Loss:  2.014869824051857e-05\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.381701728561893e-05\n",
      "Q Loss:  6.548357487190515e-05\n",
      "Policy Loss:  0.0006989934481680393\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56563 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.5408091864374e-06\n",
      "Q Loss:  4.185988291283138e-05\n",
      "Policy Loss:  0.005778108723461628\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56567 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011004209518432617\n",
      "Value Loss:  1.2854942083358765\n",
      "Q Loss:  0.0599982850253582\n",
      "Policy Loss:  -1.600761890411377\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56615 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1575.0634765625\n",
      "Q Loss:  2736.75048828125\n",
      "Policy Loss:  -158.61207580566406\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.855562292505056e-05\n",
      "Q Loss:  0.000569745956454426\n",
      "Policy Loss:  0.011215412057936192\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56623 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00015603096107952297\n",
      "Q Loss:  0.001614264096133411\n",
      "Policy Loss:  0.027916844934225082\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56627 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.7436693926574662e-05\n",
      "Q Loss:  0.0015460432041436434\n",
      "Policy Loss:  0.020996686071157455\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56631 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0003402997681405395\n",
      "Q Loss:  0.0003404468880034983\n",
      "Policy Loss:  0.002575585385784507\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005102157592773\n",
      "Value Loss:  8.89433067641221e-05\n",
      "Q Loss:  0.0005092360079288483\n",
      "Policy Loss:  0.005470591131597757\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.609753194832592e-07\n",
      "Q Loss:  0.0006838464178144932\n",
      "Policy Loss:  0.016921382397413254\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6138480305671692\n",
      "Q Loss:  0.14554916322231293\n",
      "Policy Loss:  -1.3207706212997437\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.4010635614395142\n",
      "Q Loss:  0.1219438910484314\n",
      "Policy Loss:  -1.574377417564392\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56686 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.674397784285247e-05\n",
      "Q Loss:  0.002087103668600321\n",
      "Policy Loss:  0.004279083572328091\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008261992479674518\n",
      "Q Loss:  0.0016524405218660831\n",
      "Policy Loss:  -0.02234683930873871\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.1238211189711365e-10\n",
      "Q Loss:  0.0009674710454419255\n",
      "Policy Loss:  0.016555212438106537\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56698 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.4198906421661377\n",
      "Q Loss:  0.05917167291045189\n",
      "Policy Loss:  -1.6364591121673584\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56740 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  761.5567016601562\n",
      "Q Loss:  2286.835693359375\n",
      "Policy Loss:  -77.6620864868164\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56744 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.018368806806393e-05\n",
      "Q Loss:  0.001397611340507865\n",
      "Policy Loss:  0.0042211138643324375\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.997948366915807e-05\n",
      "Q Loss:  0.000789994781371206\n",
      "Policy Loss:  0.00783858448266983\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56752 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00013051812129560858\n",
      "Q Loss:  0.0006139496108517051\n",
      "Policy Loss:  0.006314288824796677\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56756 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00010180853132624179\n",
      "Q Loss:  0.00030592127586714923\n",
      "Policy Loss:  0.003623188938945532\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56760 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.545049548847601e-05\n",
      "Q Loss:  0.00028033240232616663\n",
      "Policy Loss:  -0.006083065643906593\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  7.77458626544103e-06\n",
      "Q Loss:  0.00010475121962372214\n",
      "Policy Loss:  -0.004854302387684584\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.4717546036990825e-05\n",
      "Q Loss:  0.0001252268993994221\n",
      "Policy Loss:  -0.008365750312805176\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026004314422607422\n",
      "Value Loss:  5.402793613029644e-05\n",
      "Q Loss:  0.00034035195130854845\n",
      "Policy Loss:  -0.010972803458571434\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003795623779297\n",
      "Value Loss:  92.17347717285156\n",
      "Q Loss:  0.1400413066148758\n",
      "Policy Loss:  -19.955053329467773\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56809 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.2525882084446494e-05\n",
      "Q Loss:  0.0004754307447001338\n",
      "Policy Loss:  -0.0032712011598050594\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56813 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.813546497141942e-05\n",
      "Q Loss:  0.0003532631671987474\n",
      "Policy Loss:  -0.00679893558844924\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56817 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.6034356355667114\n",
      "Q Loss:  0.08742014318704605\n",
      "Policy Loss:  -2.5774145126342773\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.6005516648292542\n",
      "Q Loss:  0.1777634173631668\n",
      "Policy Loss:  -2.3049097061157227\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.9624034762382507\n",
      "Q Loss:  0.04617363587021828\n",
      "Policy Loss:  -1.6625468730926514\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56892 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.0832847692654468e-05\n",
      "Q Loss:  0.0002564736641943455\n",
      "Policy Loss:  0.24071982502937317\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01820659637451172\n",
      "Value Loss:  73.33487701416016\n",
      "Q Loss:  3.2096054553985596\n",
      "Policy Loss:  -15.391162872314453\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56937 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.7458181381225586\n",
      "Q Loss:  0.317028671503067\n",
      "Policy Loss:  -4.612060546875\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56941 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026006460189819336\n",
      "Value Loss:  1.1344472169876099\n",
      "Q Loss:  0.012583601288497448\n",
      "Policy Loss:  -1.0656551122665405\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56988 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.395471013500355e-06\n",
      "Q Loss:  6.427672633435577e-05\n",
      "Policy Loss:  -0.005317737348377705\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56992 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012795686721801758\n",
      "Value Loss:  0.00012824792065657675\n",
      "Q Loss:  0.0037648119032382965\n",
      "Policy Loss:  0.02525434084236622\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 56996 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.5437714457511902\n",
      "Q Loss:  0.06773396581411362\n",
      "Policy Loss:  -2.1716580390930176\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57000 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.9606008529663086\n",
      "Q Loss:  4.238224983215332\n",
      "Policy Loss:  -0.25626757740974426\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57031 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  9.915508417179808e-05\n",
      "Q Loss:  0.0031167182605713606\n",
      "Policy Loss:  0.24799522757530212\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.739323616027832\n",
      "Q Loss:  0.0952940285205841\n",
      "Policy Loss:  4.954881191253662\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57047 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.7031443348969333e-06\n",
      "Q Loss:  0.002736087189987302\n",
      "Policy Loss:  -0.007802398409694433\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57051 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011506080627441406\n",
      "Value Loss:  2.5966390239773318e-05\n",
      "Q Loss:  0.0005034967325627804\n",
      "Policy Loss:  0.010805729776620865\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57055 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  8.516982052242383e-05\n",
      "Q Loss:  0.0016014052089303732\n",
      "Policy Loss:  0.005138107109814882\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.529485821723938\n",
      "Q Loss:  0.5741416215896606\n",
      "Policy Loss:  -2.1420328617095947\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.109774112701416\n",
      "Q Loss:  0.3157651424407959\n",
      "Policy Loss:  -6.251018047332764\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.1716349124908447\n",
      "Q Loss:  0.04872238636016846\n",
      "Policy Loss:  -0.8899421095848083\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57114 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.0670444794413925e-07\n",
      "Q Loss:  0.0009789038449525833\n",
      "Policy Loss:  0.0015361316036432981\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.396643191739713e-07\n",
      "Q Loss:  2.021888576564379e-05\n",
      "Policy Loss:  -0.008772613480687141\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.737358368511195e-07\n",
      "Q Loss:  0.0002744985686149448\n",
      "Policy Loss:  -0.007625431753695011\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.8920169370394433e-07\n",
      "Q Loss:  0.00017743778880685568\n",
      "Policy Loss:  0.004514447413384914\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04600930213928223\n",
      "Value Loss:  1.2043906281178351e-05\n",
      "Q Loss:  0.00018183732754550874\n",
      "Policy Loss:  0.0027510833460837603\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57134 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.1103997975587845e-06\n",
      "Q Loss:  5.313816654961556e-05\n",
      "Policy Loss:  0.0004656488308683038\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57138 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  8.784409146755934e-05\n",
      "Q Loss:  0.01763155125081539\n",
      "Policy Loss:  0.04678119719028473\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57142 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.4453001320362091\n",
      "Q Loss:  0.04106494039297104\n",
      "Policy Loss:  -1.696892261505127\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.3115501403808594\n",
      "Q Loss:  0.2502278685569763\n",
      "Policy Loss:  -2.3278229236602783\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  23018.7109375\n",
      "Q Loss:  21294.029296875\n",
      "Policy Loss:  -14.001509666442871\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57189 length: 39 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00012657737534027547\n",
      "Q Loss:  0.00026352694840170443\n",
      "Policy Loss:  -0.0015924170147627592\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014880895614624023\n",
      "Value Loss:  100.0522232055664\n",
      "Q Loss:  4.295406341552734\n",
      "Policy Loss:  -19.72882080078125\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57223 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.7795336842536926\n",
      "Q Loss:  0.22528076171875\n",
      "Policy Loss:  -4.069217681884766\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.8705308437347412\n",
      "Q Loss:  0.05498943477869034\n",
      "Policy Loss:  -0.17782607674598694\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57259 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  741.6538696289062\n",
      "Q Loss:  0.002281436463817954\n",
      "Policy Loss:  -156.81224060058594\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.965576903894544e-05\n",
      "Q Loss:  0.00016733788652345538\n",
      "Policy Loss:  -0.011336113326251507\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012589454650878906\n",
      "Value Loss:  1.5178111791610718\n",
      "Q Loss:  0.004036076832562685\n",
      "Policy Loss:  -0.292023628950119\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57305 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.623664138605818e-05\n",
      "Q Loss:  0.0001607445883564651\n",
      "Policy Loss:  -0.004043444991111755\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00016875304572749883\n",
      "Q Loss:  0.009055474773049355\n",
      "Policy Loss:  0.21332263946533203\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57313 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.35880380868911743\n",
      "Q Loss:  0.17185096442699432\n",
      "Policy Loss:  -2.5088069438934326\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57317 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.5601558685302734\n",
      "Q Loss:  0.05846890062093735\n",
      "Policy Loss:  -0.49454498291015625\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57356 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03800845146179199\n",
      "Value Loss:  7.317075505852699e-05\n",
      "Q Loss:  31.835712432861328\n",
      "Policy Loss:  1.9359301328659058\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  2.055568984360434e-05\n",
      "Q Loss:  0.0014010514132678509\n",
      "Policy Loss:  -0.014075223356485367\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0001779338053893298\n",
      "Q Loss:  0.0006054560653865337\n",
      "Policy Loss:  -0.0068991221487522125\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100372314453125\n",
      "Value Loss:  0.000241618967265822\n",
      "Q Loss:  0.0002035551588051021\n",
      "Policy Loss:  -0.009627044200897217\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017618894577026367\n",
      "Value Loss:  85.50674438476562\n",
      "Q Loss:  20.378053665161133\n",
      "Policy Loss:  -18.469600677490234\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57442 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  49680.015625\n",
      "Q Loss:  45614.8359375\n",
      "Policy Loss:  -1.5027443170547485\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57460 length: 18 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.4167658921214752e-05\n",
      "Q Loss:  0.001410192926414311\n",
      "Policy Loss:  -0.01614796742796898\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.3185842767124996e-05\n",
      "Q Loss:  0.0006752345361746848\n",
      "Policy Loss:  -0.0034202532842755318\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.891171970986761e-05\n",
      "Q Loss:  0.00013781280722469091\n",
      "Policy Loss:  0.0034066038206219673\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57472 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.5723061561584473\n",
      "Q Loss:  0.0847746953368187\n",
      "Policy Loss:  -0.3003140687942505\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57496 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  56.784820556640625\n",
      "Q Loss:  6.864718914031982\n",
      "Policy Loss:  -10.902151107788086\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57551 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.0003321878903079778\n",
      "Q Loss:  0.00038718595169484615\n",
      "Policy Loss:  -0.00046686106361448765\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  7.755792466923594e-05\n",
      "Q Loss:  0.0001948520221048966\n",
      "Policy Loss:  0.001923350733704865\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.780147910118103\n",
      "Q Loss:  0.03510032221674919\n",
      "Policy Loss:  -0.9088501334190369\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57594 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.8102525472640991\n",
      "Q Loss:  0.16598698496818542\n",
      "Policy Loss:  -3.7848634719848633\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  1.5061724185943604\n",
      "Q Loss:  0.015329107642173767\n",
      "Policy Loss:  -0.7150331139564514\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57637 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0004452656430657953\n",
      "Q Loss:  31.336475372314453\n",
      "Policy Loss:  1.9411275386810303\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.00014069957251194865\n",
      "Q Loss:  0.0001647033786866814\n",
      "Policy Loss:  0.0120865348726511\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08001828193664551\n",
      "Value Loss:  6.285343260969967e-05\n",
      "Q Loss:  7.997958164196461e-05\n",
      "Policy Loss:  -0.007108651101589203\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031006813049316406\n",
      "Value Loss:  4.281594738131389e-05\n",
      "Q Loss:  0.001164266257546842\n",
      "Policy Loss:  0.18723386526107788\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200103759765625\n",
      "Value Loss:  2.146784782409668\n",
      "Q Loss:  0.12586301565170288\n",
      "Policy Loss:  -1.173640489578247\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57684 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.0001778303849278018\n",
      "Q Loss:  0.0006225868128240108\n",
      "Policy Loss:  0.011967996135354042\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57688 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.433218389749527\n",
      "Q Loss:  0.08463142812252045\n",
      "Policy Loss:  -2.3033103942871094\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800583839416504\n",
      "Value Loss:  0.9163094162940979\n",
      "Q Loss:  0.012741193175315857\n",
      "Policy Loss:  -0.7048415541648865\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57755 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  9.45288484217599e-05\n",
      "Q Loss:  0.0003273045876994729\n",
      "Policy Loss:  0.006993598770350218\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.390078589087352e-05\n",
      "Q Loss:  7.152027683332562e-05\n",
      "Policy Loss:  -0.003760660532861948\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 57763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  50.5460205078125\n",
      "Q Loss:  0.02900899574160576\n",
      "Policy Loss:  -11.16246223449707\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57827 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  2.370046240685042e-05\n",
      "Q Loss:  6.0448463045759127e-05\n",
      "Policy Loss:  -0.0033878227695822716\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57831 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.728521212702617e-05\n",
      "Q Loss:  0.00013911013957113028\n",
      "Policy Loss:  0.004143548663705587\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.8947539329528809\n",
      "Q Loss:  0.156780406832695\n",
      "Policy Loss:  -3.823408842086792\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57839 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01734447479248047\n",
      "Value Loss:  1.3847627639770508\n",
      "Q Loss:  0.06732317805290222\n",
      "Policy Loss:  -1.0428611040115356\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57883 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  1.3152319192886353\n",
      "Q Loss:  0.0016787940403446555\n",
      "Policy Loss:  -0.4113789498806\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57924 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.00015220209024846554\n",
      "Q Loss:  30.228883743286133\n",
      "Policy Loss:  1.903810739517212\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002618853759486228\n",
      "Q Loss:  0.0012702459935098886\n",
      "Policy Loss:  0.009125838056206703\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.0227904567727819e-05\n",
      "Q Loss:  0.3265889286994934\n",
      "Policy Loss:  0.015103403478860855\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.3415220975875854\n",
      "Q Loss:  0.24198733270168304\n",
      "Policy Loss:  -4.039206504821777\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.3480708599090576\n",
      "Q Loss:  0.046321071684360504\n",
      "Policy Loss:  -0.31733253598213196\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57966 length: 26 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  5.4209685913519934e-05\n",
      "Q Loss:  3.4013464755844325e-05\n",
      "Policy Loss:  0.0009664918761700392\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  5.1439914386719465e-05\n",
      "Q Loss:  0.019434887915849686\n",
      "Policy Loss:  0.05388801544904709\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  7.140645902836695e-05\n",
      "Q Loss:  0.0007024626829661429\n",
      "Policy Loss:  0.010954992845654488\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.058012962341308594\n",
      "Value Loss:  9.810541814658791e-05\n",
      "Q Loss:  0.00011269332753727213\n",
      "Policy Loss:  0.005030251108109951\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.4220747649669647\n",
      "Q Loss:  0.07205066829919815\n",
      "Policy Loss:  -1.5829901695251465\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 57986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.419085144996643\n",
      "Q Loss:  0.0560154914855957\n",
      "Policy Loss:  -1.1682727336883545\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58033 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  797.0202026367188\n",
      "Q Loss:  2433.217041015625\n",
      "Policy Loss:  -70.11073303222656\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00026097011868841946\n",
      "Q Loss:  0.0005515094962902367\n",
      "Policy Loss:  0.005234632641077042\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  1.2694768905639648\n",
      "Q Loss:  0.00749555928632617\n",
      "Policy Loss:  -0.54395991563797\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58086 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  792.0911865234375\n",
      "Q Loss:  0.002052252646535635\n",
      "Policy Loss:  -161.736572265625\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100847244262695\n",
      "Value Loss:  3.434105383348651e-05\n",
      "Q Loss:  0.0008354289457201958\n",
      "Policy Loss:  -0.016039419919252396\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  5.3961357480147853e-05\n",
      "Q Loss:  0.0006116894073784351\n",
      "Policy Loss:  -0.012211967259645462\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58098 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1.9774253368377686\n",
      "Q Loss:  0.09120018780231476\n",
      "Policy Loss:  -0.9981957077980042\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58131 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.952670471742749e-05\n",
      "Q Loss:  0.000143584911711514\n",
      "Policy Loss:  -0.005957628600299358\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011507987976074219\n",
      "Value Loss:  2.00819993019104\n",
      "Q Loss:  0.03370752930641174\n",
      "Policy Loss:  -0.3924029767513275\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58165 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1554.4827880859375\n",
      "Q Loss:  5122.3017578125\n",
      "Policy Loss:  7.617790222167969\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58169 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  5.456515646073967e-05\n",
      "Q Loss:  0.03848898038268089\n",
      "Policy Loss:  -0.08324585855007172\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58173 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00018181103223469108\n",
      "Q Loss:  0.0002764088858384639\n",
      "Policy Loss:  -0.007174178026616573\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58177 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  8.923532004700974e-05\n",
      "Q Loss:  0.00022538958000950515\n",
      "Policy Loss:  0.0007661243434995413\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.43007341027259827\n",
      "Q Loss:  0.02425219491124153\n",
      "Policy Loss:  -1.990188479423523\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  68.71256256103516\n",
      "Q Loss:  2.6463639736175537\n",
      "Policy Loss:  -14.420741081237793\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58230 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.048011064529418945\n",
      "Value Loss:  8.001008245628327e-05\n",
      "Q Loss:  0.0003189269045833498\n",
      "Policy Loss:  0.008118696510791779\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00015844232984818518\n",
      "Q Loss:  5.7664983614813536e-05\n",
      "Policy Loss:  0.006893903482705355\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  2.6984484975400846e-06\n",
      "Q Loss:  0.044961050152778625\n",
      "Policy Loss:  0.10346563160419464\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  1.5582633068333962e-06\n",
      "Q Loss:  0.04140849411487579\n",
      "Policy Loss:  0.09408637881278992\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.5446765928572859e-06\n",
      "Q Loss:  4.273208469385281e-05\n",
      "Policy Loss:  0.0006032275850884616\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.4268406377814244e-06\n",
      "Q Loss:  0.013972478918731213\n",
      "Policy Loss:  0.041578613221645355\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.535262942314148\n",
      "Q Loss:  0.030161788687109947\n",
      "Policy Loss:  -0.9919840693473816\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58295 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  737.7833251953125\n",
      "Q Loss:  0.017663979902863503\n",
      "Policy Loss:  -155.87921142578125\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011577129364013672\n",
      "Value Loss:  0.0002255067229270935\n",
      "Q Loss:  0.002339644357562065\n",
      "Policy Loss:  0.018561316654086113\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58303 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  732.0491943359375\n",
      "Q Loss:  353.55938720703125\n",
      "Policy Loss:  -146.06605529785156\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58307 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.5195149899227545e-05\n",
      "Q Loss:  0.007633632980287075\n",
      "Policy Loss:  0.03276073932647705\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58311 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00033752358285710216\n",
      "Q Loss:  0.0025336272083222866\n",
      "Policy Loss:  0.011235661804676056\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58315 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.3227379642776214e-05\n",
      "Q Loss:  0.006129118613898754\n",
      "Policy Loss:  0.23010239005088806\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  22393.263671875\n",
      "Q Loss:  20569.8671875\n",
      "Policy Loss:  -7.633397102355957\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58359 length: 40 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.2430741662683431e-06\n",
      "Q Loss:  0.0036578266881406307\n",
      "Policy Loss:  0.022305455058813095\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016508817672729492\n",
      "Value Loss:  1.5511122910538688e-05\n",
      "Q Loss:  0.000466745812445879\n",
      "Policy Loss:  0.003170320298522711\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.322636414144654e-06\n",
      "Q Loss:  0.0011663734912872314\n",
      "Policy Loss:  0.20943579077720642\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013767242431640625\n",
      "Value Loss:  1.3481602668762207\n",
      "Q Loss:  0.2801222801208496\n",
      "Policy Loss:  -2.1503424644470215\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.8827252984046936\n",
      "Q Loss:  0.271352082490921\n",
      "Policy Loss:  -4.370401859283447\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  7.941038347780704e-05\n",
      "Q Loss:  0.000684943690430373\n",
      "Policy Loss:  0.009092096239328384\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.8331484794616699\n",
      "Q Loss:  0.2543075680732727\n",
      "Policy Loss:  -0.7725906372070312\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.8011333346366882\n",
      "Q Loss:  0.24144935607910156\n",
      "Policy Loss:  -2.526839017868042\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  70.03292846679688\n",
      "Q Loss:  0.07847170531749725\n",
      "Policy Loss:  -15.495926856994629\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58433 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015624284744262695\n",
      "Value Loss:  0.0006634843302890658\n",
      "Q Loss:  0.0036911005154252052\n",
      "Policy Loss:  -0.037612780928611755\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58437 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.040009260177612305\n",
      "Value Loss:  0.0003860533470287919\n",
      "Q Loss:  0.004162417259067297\n",
      "Policy Loss:  -0.016964474692940712\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00022939957852941006\n",
      "Q Loss:  0.006915058940649033\n",
      "Policy Loss:  -0.034864090383052826\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.32839950919151306\n",
      "Q Loss:  0.1705845594406128\n",
      "Policy Loss:  -1.6024123430252075\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.5958738327026367\n",
      "Q Loss:  0.008962511084973812\n",
      "Policy Loss:  -0.5688573718070984\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58489 length: 40 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  3.8010493881301954e-05\n",
      "Q Loss:  0.009251464158296585\n",
      "Policy Loss:  -0.05209636688232422\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.6046103239059448\n",
      "Q Loss:  0.461335688829422\n",
      "Policy Loss:  -4.42113733291626\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  68.28179931640625\n",
      "Q Loss:  238.59974670410156\n",
      "Policy Loss:  -8.660283088684082\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58540 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  103.75778198242188\n",
      "Q Loss:  211.90631103515625\n",
      "Policy Loss:  -15.521112442016602\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58596 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0004308606730774045\n",
      "Q Loss:  0.00047306829947046936\n",
      "Policy Loss:  -0.009514388628304005\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  8.642439206596464e-05\n",
      "Q Loss:  7.746918709017336e-05\n",
      "Policy Loss:  -0.005031357053667307\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58604 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015000581741333008\n",
      "Value Loss:  5.579312801361084\n",
      "Q Loss:  0.0366106741130352\n",
      "Policy Loss:  8.935731887817383\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58616 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.299799861153588e-05\n",
      "Q Loss:  0.00010904253576882184\n",
      "Policy Loss:  -0.004140911623835564\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  71667.5546875\n",
      "Q Loss:  65732.890625\n",
      "Policy Loss:  -14.65188980102539\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58645 length: 25 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00017273487173952162\n",
      "Q Loss:  0.0014342773938551545\n",
      "Policy Loss:  -0.008115587756037712\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.0005620130687020719\n",
      "Q Loss:  0.0005960268899798393\n",
      "Policy Loss:  0.004055493511259556\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.031667726347223e-05\n",
      "Q Loss:  0.002406186191365123\n",
      "Policy Loss:  0.01812702603638172\n",
      "[(2e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 2e-05 tau*: 0.00011 Episode: 58657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.5883735418319702\n",
      "Q Loss:  0.0551186203956604\n",
      "Policy Loss:  -2.591728687286377\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  69.67276763916016\n",
      "Q Loss:  210.2066650390625\n",
      "Policy Loss:  -9.085798263549805\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58705 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00015823269495740533\n",
      "Q Loss:  0.00546049140393734\n",
      "Policy Loss:  -0.01856786012649536\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58709 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5.8684345276560634e-05\n",
      "Q Loss:  0.0007602350087836385\n",
      "Policy Loss:  0.004240917507559061\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58713 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  8.761131903156638e-05\n",
      "Q Loss:  0.0007141180103644729\n",
      "Policy Loss:  0.01373684499412775\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.2972782254219055\n",
      "Q Loss:  0.029650859534740448\n",
      "Policy Loss:  -1.4782781600952148\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.1167402267456055\n",
      "Q Loss:  0.024977074936032295\n",
      "Policy Loss:  -0.5053917169570923\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58779 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.00042495466186665\n",
      "Q Loss:  0.00030292067094706\n",
      "Policy Loss:  0.009347505867481232\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  5.294397830963135\n",
      "Q Loss:  0.06638821959495544\n",
      "Policy Loss:  5.5729827880859375\n",
      "[(3e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 3e-05 tau*: 0.00011 Episode: 58795 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0002879082167055458\n",
      "Q Loss:  0.0006079412414692342\n",
      "Policy Loss:  0.007499443367123604\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.8418162401067093e-05\n",
      "Q Loss:  0.00030716430046595633\n",
      "Policy Loss:  -0.001120860455557704\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.304604903561994e-05\n",
      "Q Loss:  0.013190959580242634\n",
      "Policy Loss:  0.03352317214012146\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  0.6536664962768555\n",
      "Q Loss:  0.049834027886390686\n",
      "Policy Loss:  -2.3479220867156982\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58811 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.6582494974136353\n",
      "Q Loss:  0.02583228424191475\n",
      "Policy Loss:  -0.6535377502441406\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58850 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002881774853449315\n",
      "Q Loss:  0.0011522346176207066\n",
      "Policy Loss:  -0.019009532406926155\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.4277478456497192\n",
      "Q Loss:  0.040069907903671265\n",
      "Policy Loss:  -0.9553975462913513\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58901 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015593290328979492\n",
      "Value Loss:  6.12174189882353e-05\n",
      "Q Loss:  0.000796926615294069\n",
      "Policy Loss:  -0.0021598946768790483\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0004118083161301911\n",
      "Q Loss:  0.006344978231936693\n",
      "Policy Loss:  0.015725336968898773\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  2.6428433557157405e-05\n",
      "Q Loss:  0.0006962751504033804\n",
      "Policy Loss:  0.1795596480369568\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58913 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  4.975319862365723\n",
      "Q Loss:  0.07032183557748795\n",
      "Policy Loss:  3.37414813041687\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58925 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.2593532018363476e-05\n",
      "Q Loss:  0.0002019122039200738\n",
      "Policy Loss:  0.006446421146392822\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58929 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  38857.22265625\n",
      "Q Loss:  35904.4453125\n",
      "Policy Loss:  -15.958209037780762\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58952 length: 23 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  9.280211816076189e-05\n",
      "Q Loss:  0.0004569619195535779\n",
      "Policy Loss:  0.0018851945642381907\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011543035507202148\n",
      "Value Loss:  9.954836968972813e-06\n",
      "Q Loss:  7.257152174133807e-05\n",
      "Policy Loss:  0.004637099802494049\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026006221771240234\n",
      "Value Loss:  1.8848001956939697\n",
      "Q Loss:  0.06196200102567673\n",
      "Policy Loss:  -0.6034905314445496\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 58992 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  19332.599609375\n",
      "Q Loss:  17675.69140625\n",
      "Policy Loss:  -8.417513847351074\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 59038 length: 46 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.43551069498062134\n",
      "Q Loss:  0.43848174810409546\n",
      "Policy Loss:  -1.6721574068069458\n",
      "[(4e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 4e-05 tau*: 0.00011 Episode: 59042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  29837.1015625\n",
      "Q Loss:  27118.19921875\n",
      "Policy Loss:  -47.934913635253906\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59072 length: 30 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.032007455825805664\n",
      "Value Loss:  0.0004927268601022661\n",
      "Q Loss:  2.983854392368812e-05\n",
      "Policy Loss:  0.0067943911999464035\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00022159088985063136\n",
      "Q Loss:  0.0012095615966245532\n",
      "Policy Loss:  0.013265730813145638\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.288884909125045e-05\n",
      "Q Loss:  0.000323087238939479\n",
      "Policy Loss:  0.01319194957613945\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.5894574921258027e-06\n",
      "Q Loss:  0.00044257211266085505\n",
      "Policy Loss:  0.01276581734418869\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59088 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04200935363769531\n",
      "Value Loss:  6.197120092110708e-05\n",
      "Q Loss:  0.003920210525393486\n",
      "Policy Loss:  0.025044364854693413\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59092 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00012054732360411435\n",
      "Q Loss:  0.0012057661078870296\n",
      "Policy Loss:  0.020720526576042175\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59096 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.147195664292667e-05\n",
      "Q Loss:  0.00039329170249402523\n",
      "Policy Loss:  0.01080247387290001\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59100 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.2854993343353271\n",
      "Q Loss:  0.08062805980443954\n",
      "Policy Loss:  -1.6920579671859741\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59154 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.1020270651206374e-05\n",
      "Q Loss:  0.0060129850171506405\n",
      "Policy Loss:  0.20507770776748657\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.7287870645523071\n",
      "Q Loss:  0.06235864758491516\n",
      "Policy Loss:  -0.8380581736564636\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59191 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00018743974214885384\n",
      "Q Loss:  4.997999712941237e-05\n",
      "Policy Loss:  -0.0032952120527625084\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  7.399250171147287e-05\n",
      "Q Loss:  0.001134222955442965\n",
      "Policy Loss:  -0.0093842763453722\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  4.749858379364014\n",
      "Q Loss:  0.0654238685965538\n",
      "Policy Loss:  4.791985034942627\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59210 length: 11 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  18811.146484375\n",
      "Q Loss:  17112.48828125\n",
      "Policy Loss:  -10.698810577392578\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59257 length: 47 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0003527345252223313\n",
      "Q Loss:  0.0017695565475150943\n",
      "Policy Loss:  0.00011434894986450672\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00013925119128543884\n",
      "Q Loss:  0.0007968740537762642\n",
      "Policy Loss:  -0.006646681576967239\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00030978641007095575\n",
      "Q Loss:  0.05290943756699562\n",
      "Policy Loss:  0.0713014304637909\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00016951633733697236\n",
      "Q Loss:  0.05069953203201294\n",
      "Policy Loss:  0.07084061205387115\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  5.331382271833718e-05\n",
      "Q Loss:  0.09803611040115356\n",
      "Policy Loss:  0.34269002079963684\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.6463714838027954\n",
      "Q Loss:  0.06788196414709091\n",
      "Policy Loss:  -2.27354097366333\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59316 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.256218910217285\n",
      "Q Loss:  0.05417899787425995\n",
      "Policy Loss:  -1.1366780996322632\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59341 length: 25 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1840.979736328125\n",
      "Q Loss:  482.76904296875\n",
      "Policy Loss:  -310.9257507324219\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00036919958074577153\n",
      "Q Loss:  0.01367294043302536\n",
      "Policy Loss:  0.06077662855386734\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02665257453918457\n",
      "Value Loss:  0.0010300690773874521\n",
      "Q Loss:  0.007684959098696709\n",
      "Policy Loss:  0.025702808052301407\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002571065560914576\n",
      "Q Loss:  7.898980402387679e-05\n",
      "Policy Loss:  -0.003449107054620981\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.9682655334472656\n",
      "Q Loss:  0.06328961253166199\n",
      "Policy Loss:  -1.9081735610961914\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59423 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.033814430236816406\n",
      "Value Loss:  9.327141742687672e-05\n",
      "Q Loss:  0.03696674108505249\n",
      "Policy Loss:  0.05088598281145096\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.525681576225907e-05\n",
      "Q Loss:  160.08474731445312\n",
      "Policy Loss:  8.728958129882812\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00011660471500363201\n",
      "Q Loss:  0.0019454013090580702\n",
      "Policy Loss:  -0.02604351006448269\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.1520299267431255e-05\n",
      "Q Loss:  0.0070781707763671875\n",
      "Policy Loss:  -0.044136542826890945\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.000111914130684454\n",
      "Q Loss:  0.005447652190923691\n",
      "Policy Loss:  -0.04120562598109245\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0019637143705040216\n",
      "Q Loss:  0.002644845750182867\n",
      "Policy Loss:  -0.03069925308227539\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500819206237793\n",
      "Value Loss:  0.00028922181809321046\n",
      "Q Loss:  0.001641501672565937\n",
      "Policy Loss:  -0.023992562666535378\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.8826844692230225\n",
      "Q Loss:  0.2517067492008209\n",
      "Policy Loss:  -0.12558774650096893\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59469 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.088841438293457\n",
      "Q Loss:  0.0198349691927433\n",
      "Policy Loss:  -1.167564034461975\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59511 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1805.0389404296875\n",
      "Q Loss:  6009.13623046875\n",
      "Policy Loss:  12.775028228759766\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002599742147140205\n",
      "Q Loss:  0.00012170505215181038\n",
      "Policy Loss:  -0.0023367307148873806\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00041198096005246043\n",
      "Q Loss:  0.0007484538946300745\n",
      "Policy Loss:  0.009367411024868488\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00034132052678614855\n",
      "Q Loss:  0.0009421864524483681\n",
      "Policy Loss:  0.0027176905423402786\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.7933786511421204\n",
      "Q Loss:  0.13112089037895203\n",
      "Policy Loss:  -3.2027435302734375\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.5882658958435059\n",
      "Q Loss:  0.46070361137390137\n",
      "Policy Loss:  -5.261299133300781\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.5684024095535278\n",
      "Q Loss:  0.3313114643096924\n",
      "Policy Loss:  -5.142275333404541\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004040182975586504\n",
      "Q Loss:  0.0008776347967796028\n",
      "Policy Loss:  -0.0012859846465289593\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.5847769975662231\n",
      "Q Loss:  0.006210363004356623\n",
      "Policy Loss:  -0.7601925134658813\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59570 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0003742277040146291\n",
      "Q Loss:  0.0017642161110416055\n",
      "Policy Loss:  0.02395760640501976\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59574 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.7296818494796753\n",
      "Q Loss:  0.10411319136619568\n",
      "Policy Loss:  -2.794461488723755\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59578 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400897026062012\n",
      "Value Loss:  2.868147134780884\n",
      "Q Loss:  0.37098217010498047\n",
      "Policy Loss:  -8.525222778320312\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.0588676929473877\n",
      "Q Loss:  0.07897219806909561\n",
      "Policy Loss:  -1.3170785903930664\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59632 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000609584734775126\n",
      "Q Loss:  0.0026789316907525063\n",
      "Policy Loss:  0.0319429449737072\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00044657106627710164\n",
      "Q Loss:  0.004534386098384857\n",
      "Policy Loss:  0.2922702133655548\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 59640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.29827880859375\n",
      "Q Loss:  0.03594576194882393\n",
      "Policy Loss:  -0.8082107901573181\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59678 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.9744210243225098\n",
      "Q Loss:  0.08978467434644699\n",
      "Policy Loss:  0.8949289321899414\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59698 length: 20 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.4423973560333252\n",
      "Q Loss:  0.15485593676567078\n",
      "Policy Loss:  -1.6260615587234497\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59746 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014608383178710938\n",
      "Value Loss:  0.00019678610260598361\n",
      "Q Loss:  0.005873026791960001\n",
      "Policy Loss:  0.27029478549957275\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.0103753805160522\n",
      "Q Loss:  0.0256356131285429\n",
      "Policy Loss:  -0.8099746108055115\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59800 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013583660125732422\n",
      "Value Loss:  1.6263349056243896\n",
      "Q Loss:  0.04190407320857048\n",
      "Policy Loss:  -1.1760382652282715\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 59834 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1605716943740845\n",
      "Q Loss:  0.04232809692621231\n",
      "Policy Loss:  -3.1957273483276367\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.6414861679077148\n",
      "Q Loss:  1.8974121809005737\n",
      "Policy Loss:  -0.5536906719207764\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59921 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00010862151248147711\n",
      "Q Loss:  0.0024212750140577555\n",
      "Policy Loss:  0.01285996101796627\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59925 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.0535725778026972e-05\n",
      "Q Loss:  0.0018553005065768957\n",
      "Policy Loss:  0.0007816839497536421\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59929 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  82.85675811767578\n",
      "Q Loss:  259.1543884277344\n",
      "Policy Loss:  -9.974627494812012\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59971 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.7373702576151118e-05\n",
      "Q Loss:  0.0023992243222892284\n",
      "Policy Loss:  0.008762305602431297\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59975 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.3413532946724445e-05\n",
      "Q Loss:  0.0010321541922166944\n",
      "Policy Loss:  -0.0030577806755900383\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59979 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.3998411052161828e-05\n",
      "Q Loss:  0.001607260899618268\n",
      "Policy Loss:  -0.02166438102722168\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59983 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00020476282224990427\n",
      "Q Loss:  0.0003736807848326862\n",
      "Policy Loss:  0.005305520258843899\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59987 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.550188422203064\n",
      "Q Loss:  0.33755871653556824\n",
      "Policy Loss:  -2.1899852752685547\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59991 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.091518521308899\n",
      "Q Loss:  0.3370063602924347\n",
      "Policy Loss:  -0.9123440384864807\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 59995 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  99.28197479248047\n",
      "Q Loss:  46.301998138427734\n",
      "Policy Loss:  -19.372215270996094\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60030 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  65922.25\n",
      "Q Loss:  59958.16796875\n",
      "Policy Loss:  -59.047237396240234\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60057 length: 27 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  862.149169921875\n",
      "Q Loss:  1.609278678894043\n",
      "Policy Loss:  -171.11822509765625\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0007325878832489252\n",
      "Q Loss:  0.00039325410034507513\n",
      "Policy Loss:  -0.0110861137509346\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00041400158079341054\n",
      "Q Loss:  7.051052671158686e-05\n",
      "Policy Loss:  0.0065946318209171295\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60069 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  7.021053897915408e-05\n",
      "Q Loss:  0.002918487647548318\n",
      "Policy Loss:  0.02785089612007141\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60073 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.5071840286254883\n",
      "Q Loss:  0.2760462462902069\n",
      "Policy Loss:  -0.7883642315864563\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60077 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.3353025913238525\n",
      "Q Loss:  0.008991733193397522\n",
      "Policy Loss:  -0.7207590341567993\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60117 length: 40 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  32756.70703125\n",
      "Q Loss:  29739.95703125\n",
      "Policy Loss:  -12.697885513305664\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60144 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  3.2460069633089006e-05\n",
      "Q Loss:  40.035552978515625\n",
      "Policy Loss:  2.1773324012756348\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005952175124548376\n",
      "Q Loss:  0.005006260704249144\n",
      "Policy Loss:  0.02624506689608097\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04601025581359863\n",
      "Value Loss:  1.818102478981018\n",
      "Q Loss:  4.5709099769592285\n",
      "Policy Loss:  0.179972305893898\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60188 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.935367906000465e-05\n",
      "Q Loss:  39.8414306640625\n",
      "Policy Loss:  2.211545467376709\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.6789046640042216e-05\n",
      "Q Loss:  0.0018511023372411728\n",
      "Policy Loss:  -0.00019382406026124954\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00023472060274798423\n",
      "Q Loss:  0.0016171569004654884\n",
      "Policy Loss:  0.00014592823572456837\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00014260539319366217\n",
      "Q Loss:  0.002017857041209936\n",
      "Policy Loss:  0.22233456373214722\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.5212029218673706\n",
      "Q Loss:  0.037134867161512375\n",
      "Policy Loss:  -1.2769297361373901\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60243 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.947061142956954e-07\n",
      "Q Loss:  0.0015610966365784407\n",
      "Policy Loss:  -0.008141239173710346\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.516142740205396e-05\n",
      "Q Loss:  0.0008346945978701115\n",
      "Policy Loss:  -0.012179361656308174\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.3108454115572385e-05\n",
      "Q Loss:  0.0011566668981686234\n",
      "Policy Loss:  0.20753169059753418\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.0294150114059448\n",
      "Q Loss:  0.21735987067222595\n",
      "Policy Loss:  -5.961405277252197\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 60259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.528442144393921\n",
      "Q Loss:  0.17826828360557556\n",
      "Policy Loss:  -4.09171199798584\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.9864670038223267\n",
      "Q Loss:  0.04176079109311104\n",
      "Policy Loss:  -0.8794756531715393\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60292 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.0011980041163042188\n",
      "Q Loss:  0.0067871506325900555\n",
      "Policy Loss:  -0.044363364577293396\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00046932679833844304\n",
      "Q Loss:  0.001352741033770144\n",
      "Policy Loss:  0.20649923384189606\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.4003007411956787\n",
      "Q Loss:  0.10913807898759842\n",
      "Policy Loss:  -0.4316955506801605\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60329 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.205282211303711\n",
      "Q Loss:  0.17769016325473785\n",
      "Policy Loss:  1.1899359226226807\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60349 length: 20 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1908.7176513671875\n",
      "Q Loss:  475.8297119140625\n",
      "Policy Loss:  -323.685302734375\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0009070326923392713\n",
      "Q Loss:  0.023607974871993065\n",
      "Policy Loss:  0.006035221740603447\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.4541551470756531\n",
      "Q Loss:  0.031646016985177994\n",
      "Policy Loss:  -2.1749908924102783\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.9059884548187256\n",
      "Q Loss:  0.034498393535614014\n",
      "Policy Loss:  -0.605036199092865\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60391 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00036241201451048255\n",
      "Q Loss:  0.0005682907649315894\n",
      "Policy Loss:  -0.008542429655790329\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60395 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00011946492304559797\n",
      "Q Loss:  0.004818934015929699\n",
      "Policy Loss:  0.18647944927215576\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60399 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.3379008769989014\n",
      "Q Loss:  0.25474023818969727\n",
      "Policy Loss:  -2.4330458641052246\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60403 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012606620788574219\n",
      "Value Loss:  1.3103150129318237\n",
      "Q Loss:  0.4717509150505066\n",
      "Policy Loss:  -2.3443095684051514\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60407 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  153.7757110595703\n",
      "Q Loss:  240.58509826660156\n",
      "Policy Loss:  -23.082612991333008\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60456 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  132.02613830566406\n",
      "Q Loss:  0.04339807108044624\n",
      "Policy Loss:  -25.533964157104492\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60513 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0009414491360075772\n",
      "Q Loss:  0.0030239238403737545\n",
      "Policy Loss:  0.00265095685608685\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.895056554232724e-05\n",
      "Q Loss:  0.008745650760829449\n",
      "Policy Loss:  0.2484012246131897\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  122.74883270263672\n",
      "Q Loss:  219.50900268554688\n",
      "Policy Loss:  -17.673442840576172\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60582 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.7511494755744934\n",
      "Q Loss:  0.20655500888824463\n",
      "Policy Loss:  -0.810731053352356\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.6668529510498047\n",
      "Q Loss:  0.02529035694897175\n",
      "Policy Loss:  -0.741759717464447\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60624 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.0744956731796265\n",
      "Q Loss:  0.03718637302517891\n",
      "Policy Loss:  -2.145263433456421\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  63.642765045166016\n",
      "Q Loss:  202.67295837402344\n",
      "Policy Loss:  -5.917522430419922\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60687 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.66662701102905e-05\n",
      "Q Loss:  0.0002464797580614686\n",
      "Policy Loss:  0.0012772113550454378\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.6919358968734741\n",
      "Q Loss:  0.004872208461165428\n",
      "Policy Loss:  -0.2949528098106384\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60727 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014593124389648438\n",
      "Value Loss:  0.00011539031402207911\n",
      "Q Loss:  0.0009456452098675072\n",
      "Policy Loss:  0.0005999684799462557\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60731 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.3140096366405487\n",
      "Q Loss:  0.011237064376473427\n",
      "Policy Loss:  -1.576389193534851\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60735 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  17306.8828125\n",
      "Q Loss:  15614.828125\n",
      "Policy Loss:  -9.880776405334473\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60786 length: 51 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  3.186179310432635e-05\n",
      "Q Loss:  0.00027300789952278137\n",
      "Policy Loss:  0.007901053875684738\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500795364379883\n",
      "Value Loss:  6.145540282886941e-06\n",
      "Q Loss:  0.0018748234724625945\n",
      "Policy Loss:  0.17894572019577026\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  1.5797241926193237\n",
      "Q Loss:  0.01919177547097206\n",
      "Policy Loss:  -0.50888991355896\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60835 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.4111757278442383\n",
      "Q Loss:  0.04033375158905983\n",
      "Policy Loss:  1.5319844484329224\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60854 length: 19 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002437652146909386\n",
      "Q Loss:  84.16120910644531\n",
      "Policy Loss:  4.472611427307129\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.078446338302456e-05\n",
      "Q Loss:  41.746707916259766\n",
      "Policy Loss:  2.2074954509735107\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.731715206522495e-05\n",
      "Q Loss:  5.765154492110014e-05\n",
      "Policy Loss:  0.0012064609909430146\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  152.49139404296875\n",
      "Q Loss:  36.03564453125\n",
      "Policy Loss:  -28.43184471130371\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60915 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01734137535095215\n",
      "Value Loss:  926.5345458984375\n",
      "Q Loss:  2934.734619140625\n",
      "Policy Loss:  -83.20210266113281\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  4.90392403662554e-06\n",
      "Q Loss:  0.004316187463700771\n",
      "Policy Loss:  -0.02985464408993721\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.314257264719345e-05\n",
      "Q Loss:  0.002945543499663472\n",
      "Policy Loss:  -0.004999615252017975\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.034008026123046875\n",
      "Value Loss:  9.145913645625114e-05\n",
      "Q Loss:  0.0009586521191522479\n",
      "Policy Loss:  0.16969990730285645\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 60931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.316230773925781\n",
      "Q Loss:  0.08226523548364639\n",
      "Policy Loss:  4.310688018798828\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60946 length: 15 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  1.3916957868786994e-05\n",
      "Q Loss:  0.0004129762528464198\n",
      "Policy Loss:  0.015298953279852867\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.017126568418462e-06\n",
      "Q Loss:  0.0005987269105389714\n",
      "Policy Loss:  0.0025200936943292618\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.2209867388010025e-06\n",
      "Q Loss:  0.0012659698259085417\n",
      "Policy Loss:  0.0008854296756908298\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  9.432629894945421e-07\n",
      "Q Loss:  0.0009730017627589405\n",
      "Policy Loss:  0.008997549302875996\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.261428719270043e-05\n",
      "Q Loss:  0.0003126666124444455\n",
      "Policy Loss:  0.005923835560679436\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  6.26532273599878e-05\n",
      "Q Loss:  0.000903938664123416\n",
      "Policy Loss:  0.01272338442504406\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.1064311265945435\n",
      "Q Loss:  0.14714288711547852\n",
      "Policy Loss:  -3.7886874675750732\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 60974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.316239595413208\n",
      "Q Loss:  3.3382699489593506\n",
      "Policy Loss:  -0.24406442046165466\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61021 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.6764135580160655e-05\n",
      "Q Loss:  0.0018174690194427967\n",
      "Policy Loss:  0.011271857656538486\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.981776404136326e-05\n",
      "Q Loss:  0.001628538011573255\n",
      "Policy Loss:  0.005643648561090231\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.949446439743042\n",
      "Q Loss:  0.022997207939624786\n",
      "Policy Loss:  0.5661728978157043\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61050 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  37803.22265625\n",
      "Q Loss:  34281.27734375\n",
      "Policy Loss:  -47.06630325317383\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61097 length: 47 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  916.05517578125\n",
      "Q Loss:  2878.35107421875\n",
      "Policy Loss:  -83.1673583984375\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61101 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.1062991436338052e-05\n",
      "Q Loss:  0.0007185101858340204\n",
      "Policy Loss:  0.009954050183296204\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61105 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.3765634298324585\n",
      "Q Loss:  0.03142682462930679\n",
      "Policy Loss:  -1.9634877443313599\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1.5066735744476318\n",
      "Q Loss:  0.10224079340696335\n",
      "Policy Loss:  -4.701064109802246\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.731026291847229\n",
      "Q Loss:  0.0029363890644162893\n",
      "Policy Loss:  -0.42628538608551025\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61147 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  1.2846070528030396\n",
      "Q Loss:  10.192032814025879\n",
      "Policy Loss:  1.0072181224822998\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61193 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.2492250204086304\n",
      "Q Loss:  9.036299705505371\n",
      "Policy Loss:  0.8809121251106262\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61245 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.9388269720366225e-05\n",
      "Q Loss:  0.0005037632072344422\n",
      "Policy Loss:  -0.010262967087328434\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.0329353244742379e-05\n",
      "Q Loss:  8.521693962393329e-05\n",
      "Policy Loss:  0.18197253346443176\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  114.36965942382812\n",
      "Q Loss:  0.048572152853012085\n",
      "Policy Loss:  -21.498476028442383\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61286 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  118.05021667480469\n",
      "Q Loss:  370.2841491699219\n",
      "Policy Loss:  -9.480549812316895\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61318 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.2362756729125977\n",
      "Q Loss:  0.07203344255685806\n",
      "Policy Loss:  -0.2428329735994339\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61345 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  3.630930223152973e-05\n",
      "Q Loss:  0.0006442732992582023\n",
      "Policy Loss:  -0.0009125109063461423\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.000328460504533723\n",
      "Q Loss:  0.001133620971813798\n",
      "Policy Loss:  -0.0209477748721838\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  5.901736949454062e-05\n",
      "Q Loss:  0.0008721314370632172\n",
      "Policy Loss:  0.0018451116047799587\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049010276794433594\n",
      "Value Loss:  4.578335938276723e-05\n",
      "Q Loss:  0.0008514919318258762\n",
      "Policy Loss:  0.01438775472342968\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  8.169138163793832e-05\n",
      "Q Loss:  6.910663796588778e-05\n",
      "Policy Loss:  0.00031863083131611347\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61365 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3.4537268220447004e-05\n",
      "Q Loss:  0.00046152446884661913\n",
      "Policy Loss:  0.01080973818898201\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61369 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.7791004211176187e-05\n",
      "Q Loss:  0.0002873926714528352\n",
      "Policy Loss:  0.001681023626588285\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61373 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  7.988014112925157e-05\n",
      "Q Loss:  0.00021287640265654773\n",
      "Policy Loss:  0.0006852383958175778\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.7720511555671692\n",
      "Q Loss:  1.928637146949768\n",
      "Policy Loss:  -0.570396900177002\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61459 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.4902943298220634e-05\n",
      "Q Loss:  4.259338675183244e-05\n",
      "Policy Loss:  -0.002007204107940197\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  4.206657104077749e-05\n",
      "Q Loss:  9.696141933090985e-05\n",
      "Policy Loss:  -0.00033168791560456157\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05201125144958496\n",
      "Value Loss:  0.8617092967033386\n",
      "Q Loss:  0.014128495007753372\n",
      "Policy Loss:  -2.714285373687744\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.8574199676513672\n",
      "Q Loss:  0.2725534439086914\n",
      "Policy Loss:  -2.4614365100860596\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  2.3270890712738037\n",
      "Q Loss:  0.04416866973042488\n",
      "Policy Loss:  -0.34890156984329224\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 61500 length: 25 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0004155909118708223\n",
      "Q Loss:  38.57722091674805\n",
      "Policy Loss:  2.166187286376953\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61504 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0002510051126591861\n",
      "Q Loss:  76.68194580078125\n",
      "Policy Loss:  4.27519416809082\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61508 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.44461498875171e-05\n",
      "Q Loss:  0.001808138913474977\n",
      "Policy Loss:  -0.0026158196851611137\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61512 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.8324669478461146e-05\n",
      "Q Loss:  0.0008538990514352918\n",
      "Policy Loss:  -0.012145673856139183\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61516 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.4116099178791046\n",
      "Q Loss:  0.010308456607162952\n",
      "Policy Loss:  -1.9327895641326904\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61520 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.1550469398498535\n",
      "Q Loss:  0.03891126438975334\n",
      "Policy Loss:  -0.4475456774234772\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61548 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.052011728286743164\n",
      "Value Loss:  0.00019263973808847368\n",
      "Q Loss:  0.0011724040377885103\n",
      "Policy Loss:  0.0005666017532348633\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005889892578125\n",
      "Value Loss:  7.697501132497564e-06\n",
      "Q Loss:  0.0011615590192377567\n",
      "Policy Loss:  -0.012601702474057674\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.675218224292621e-05\n",
      "Q Loss:  0.0014534861547872424\n",
      "Policy Loss:  0.004818923771381378\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.4060688018798828\n",
      "Q Loss:  0.20170146226882935\n",
      "Policy Loss:  -1.9648499488830566\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  46.1902961730957\n",
      "Q Loss:  145.12908935546875\n",
      "Policy Loss:  -5.735363483428955\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61646 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.0182965929270722e-05\n",
      "Q Loss:  0.00034473990672267973\n",
      "Policy Loss:  -0.010087158530950546\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  2.112106631102506e-05\n",
      "Q Loss:  0.00023676145065110177\n",
      "Policy Loss:  -0.007916811853647232\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61654 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.7959591746330261\n",
      "Q Loss:  0.1911824643611908\n",
      "Policy Loss:  -3.0501179695129395\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 61658 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05501246452331543\n",
      "Value Loss:  140.18650817871094\n",
      "Q Loss:  215.99942016601562\n",
      "Policy Loss:  -22.833024978637695\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61738 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  929.1856079101562\n",
      "Q Loss:  35.812599182128906\n",
      "Policy Loss:  -166.1256103515625\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.565012568491511e-05\n",
      "Q Loss:  0.007197028025984764\n",
      "Policy Loss:  -0.028671015053987503\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61746 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.4797188669035677e-05\n",
      "Q Loss:  0.0005545939784497023\n",
      "Policy Loss:  -0.0025581640657037497\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.4760872545593884e-05\n",
      "Q Loss:  0.00020568122272379696\n",
      "Policy Loss:  -0.004964100196957588\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  5.906045771553181e-05\n",
      "Q Loss:  0.0007229947368614376\n",
      "Policy Loss:  -0.005072356201708317\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000640869140625\n",
      "Value Loss:  0.7411251068115234\n",
      "Q Loss:  0.16442391276359558\n",
      "Policy Loss:  -1.3193196058273315\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.1164147853851318\n",
      "Q Loss:  0.08868671953678131\n",
      "Policy Loss:  -1.2045375108718872\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61824 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0004894960438832641\n",
      "Q Loss:  34.758121490478516\n",
      "Policy Loss:  2.0448975563049316\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00013003834465052933\n",
      "Q Loss:  0.00039854689384810627\n",
      "Policy Loss:  0.010069082491099834\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.8884538551210426e-05\n",
      "Q Loss:  0.0003408884513191879\n",
      "Policy Loss:  -0.008337181061506271\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.440586442593485e-05\n",
      "Q Loss:  0.0023415391333401203\n",
      "Policy Loss:  -0.0026809799019247293\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006004333496094\n",
      "Value Loss:  4.18708186771255e-05\n",
      "Q Loss:  0.0021420323755592108\n",
      "Policy Loss:  -0.02496923878788948\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 61844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.9603819251060486\n",
      "Q Loss:  0.028132056817412376\n",
      "Policy Loss:  -1.2267776727676392\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 61918 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  5.029850959777832\n",
      "Q Loss:  0.01706768572330475\n",
      "Policy Loss:  4.246359348297119\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 61930 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.041203975677490234\n",
      "Value Loss:  61026.2265625\n",
      "Q Loss:  55071.265625\n",
      "Policy Loss:  -49.32408905029297\n",
      "[(5e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 5e-05 tau*: 0.00011 Episode: 61959 length: 29 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00019602848624344915\n",
      "Q Loss:  0.0005536457756534219\n",
      "Policy Loss:  -0.011291281320154667\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61963 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00021284770627971739\n",
      "Q Loss:  0.0008231745450757444\n",
      "Policy Loss:  -0.01789640262722969\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61967 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014560222625732422\n",
      "Value Loss:  0.00025985122192651033\n",
      "Q Loss:  0.00061571947298944\n",
      "Policy Loss:  -0.01597980037331581\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61971 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001209109032060951\n",
      "Q Loss:  0.00028380402363836765\n",
      "Policy Loss:  -0.00661351578310132\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 61975 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  1.206452488899231\n",
      "Q Loss:  2.6458241939544678\n",
      "Policy Loss:  -0.34056979417800903\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62026 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  5.805880209663883e-05\n",
      "Q Loss:  5.079147013020702e-05\n",
      "Policy Loss:  0.001668992335908115\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62030 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00010926239338004962\n",
      "Q Loss:  0.0001279814459849149\n",
      "Policy Loss:  0.0022461283951997757\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  2.471018075942993\n",
      "Q Loss:  0.031148044392466545\n",
      "Policy Loss:  0.1762363761663437\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62058 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.4378362894058228\n",
      "Q Loss:  0.016233719885349274\n",
      "Policy Loss:  -0.7319325804710388\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62099 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00017996221140492707\n",
      "Q Loss:  0.0010038979817181826\n",
      "Policy Loss:  0.013304008170962334\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01160120964050293\n",
      "Value Loss:  1.9893552234862e-05\n",
      "Q Loss:  0.35204073786735535\n",
      "Policy Loss:  0.00814583245664835\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.0925567150115967\n",
      "Q Loss:  0.005259529687464237\n",
      "Policy Loss:  -0.30899327993392944\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62133 length: 26 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04500913619995117\n",
      "Value Loss:  3.6975293159484863\n",
      "Q Loss:  0.07349536567926407\n",
      "Policy Loss:  1.7242470979690552\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62149 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.480363612761721e-05\n",
      "Q Loss:  3.197056139470078e-05\n",
      "Policy Loss:  -4.948483547195792e-05\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62153 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.1854043006896973\n",
      "Q Loss:  0.0029061695095151663\n",
      "Policy Loss:  -0.2425604611635208\n",
      "[(6e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 6e-05 tau*: 0.00011 Episode: 62177 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1950.734619140625\n",
      "Q Loss:  530.1254272460938\n",
      "Policy Loss:  -324.30401611328125\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002267311792820692\n",
      "Q Loss:  0.0005539521225728095\n",
      "Policy Loss:  0.012521511875092983\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002851434692274779\n",
      "Q Loss:  0.000536107225343585\n",
      "Policy Loss:  0.009216592647135258\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00013176239735912532\n",
      "Q Loss:  0.0006485588965006173\n",
      "Policy Loss:  0.016370851546525955\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1155558824539185\n",
      "Q Loss:  0.21455609798431396\n",
      "Policy Loss:  -4.576852321624756\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.688400149345398\n",
      "Q Loss:  0.3284109830856323\n",
      "Policy Loss:  -5.151678562164307\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  122.82963562011719\n",
      "Q Loss:  32.9349365234375\n",
      "Policy Loss:  -22.434179306030273\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62264 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  3.5009589195251465\n",
      "Q Loss:  0.10630494356155396\n",
      "Policy Loss:  1.5089892148971558\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62280 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01155233383178711\n",
      "Value Loss:  0.0002575044345576316\n",
      "Q Loss:  0.09188000857830048\n",
      "Policy Loss:  0.16391828656196594\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015987544611562043\n",
      "Q Loss:  0.08873462677001953\n",
      "Policy Loss:  0.14681878685951233\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.5585625767707825\n",
      "Q Loss:  0.2584976255893707\n",
      "Policy Loss:  -1.9677319526672363\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.235010862350464\n",
      "Q Loss:  0.14998070895671844\n",
      "Policy Loss:  -0.6143178343772888\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62320 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  951.6909790039062\n",
      "Q Loss:  0.03697667270898819\n",
      "Policy Loss:  -176.87486267089844\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005861750105395913\n",
      "Q Loss:  35.63256072998047\n",
      "Policy Loss:  2.0970559120178223\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002605984336696565\n",
      "Q Loss:  35.50016784667969\n",
      "Policy Loss:  2.068197250366211\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000534231192432344\n",
      "Q Loss:  0.0014304996002465487\n",
      "Policy Loss:  0.012777834199368954\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.9712193608283997\n",
      "Q Loss:  0.007817219011485577\n",
      "Policy Loss:  -0.7813817858695984\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62389 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  0.00017057987861335278\n",
      "Q Loss:  0.0015718983486294746\n",
      "Policy Loss:  0.001655718544498086\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.946259650751017e-05\n",
      "Q Loss:  0.00029917460051365197\n",
      "Policy Loss:  -0.012657582759857178\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001607894897461\n",
      "Value Loss:  0.563309371471405\n",
      "Q Loss:  0.08947732299566269\n",
      "Policy Loss:  -2.5477302074432373\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.523564338684082\n",
      "Q Loss:  3.263855457305908\n",
      "Policy Loss:  -1.0627923011779785\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62445 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.044010162353515625\n",
      "Value Loss:  0.5598235130310059\n",
      "Q Loss:  0.08759264647960663\n",
      "Policy Loss:  -2.5358047485351562\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  99.5176010131836\n",
      "Q Loss:  327.07049560546875\n",
      "Policy Loss:  -8.318706512451172\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62487 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  928.929443359375\n",
      "Q Loss:  3568.858154296875\n",
      "Policy Loss:  -61.134796142578125\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021005868911743164\n",
      "Value Loss:  0.0004763167235068977\n",
      "Q Loss:  0.07942606508731842\n",
      "Policy Loss:  -0.10127303004264832\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00039746687980368733\n",
      "Q Loss:  0.00039568834472447634\n",
      "Policy Loss:  -0.009213292971253395\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.001358682056888938\n",
      "Q Loss:  0.0021775478962808847\n",
      "Policy Loss:  0.02735018916428089\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  14009.216796875\n",
      "Q Loss:  12597.7333984375\n",
      "Policy Loss:  -7.154937267303467\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62566 length: 63 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005884834681637585\n",
      "Q Loss:  0.11010423302650452\n",
      "Policy Loss:  -0.1218816488981247\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62570 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.032007694244384766\n",
      "Value Loss:  0.0005156384431757033\n",
      "Q Loss:  0.0004129449662286788\n",
      "Policy Loss:  0.01299002580344677\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62574 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00019186009012628347\n",
      "Q Loss:  0.00020394547027535737\n",
      "Policy Loss:  -0.00047560129314661026\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62578 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.5367193222045898\n",
      "Q Loss:  0.20874150097370148\n",
      "Policy Loss:  -2.335981607437134\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  4.025079250335693\n",
      "Q Loss:  0.06354852020740509\n",
      "Policy Loss:  2.8670434951782227\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62595 length: 13 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  5.747369505115785e-05\n",
      "Q Loss:  0.0010343927424401045\n",
      "Policy Loss:  0.003082134760916233\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00018876491230912507\n",
      "Q Loss:  0.001597144640982151\n",
      "Policy Loss:  -0.021663889288902283\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  2.7531988620758057\n",
      "Q Loss:  0.049935683608055115\n",
      "Policy Loss:  -0.3479778468608856\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62625 length: 22 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0004203515127301216\n",
      "Q Loss:  0.0008672814583405852\n",
      "Policy Loss:  0.00031429738737642765\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.516784595878562e-05\n",
      "Q Loss:  0.0014157339464873075\n",
      "Policy Loss:  0.013682404533028603\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00015295120829250664\n",
      "Q Loss:  0.0010384302586317062\n",
      "Policy Loss:  0.002009583404287696\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.5695874094963074\n",
      "Q Loss:  0.1831168681383133\n",
      "Policy Loss:  -2.5511510372161865\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  179.9415740966797\n",
      "Q Loss:  43.80068588256836\n",
      "Policy Loss:  -33.65453338623047\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62682 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014753341674804688\n",
      "Value Loss:  915.3226928710938\n",
      "Q Loss:  446.98895263671875\n",
      "Policy Loss:  -163.25970458984375\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.001816843287087977\n",
      "Q Loss:  37.24424362182617\n",
      "Policy Loss:  2.124390125274658\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.0014828845160081983\n",
      "Q Loss:  0.0012328873854130507\n",
      "Policy Loss:  -0.005403658375144005\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.3436390161514282\n",
      "Q Loss:  4.190467357635498\n",
      "Policy Loss:  0.0427776500582695\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62730 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00010271376231685281\n",
      "Q Loss:  0.0008439018274657428\n",
      "Policy Loss:  0.011158300563693047\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62734 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  5.871806206414476e-05\n",
      "Q Loss:  0.002475831424817443\n",
      "Policy Loss:  -0.011112505570054054\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002328062109882012\n",
      "Q Loss:  0.00230054697021842\n",
      "Policy Loss:  -0.006252788472920656\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0010849505197256804\n",
      "Q Loss:  0.0015344686107710004\n",
      "Policy Loss:  0.25209271907806396\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62746 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.8261526823043823\n",
      "Q Loss:  0.07603976875543594\n",
      "Policy Loss:  -0.7867689728736877\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62772 length: 26 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.002737157279625535\n",
      "Q Loss:  0.0006650564610026777\n",
      "Policy Loss:  -0.0016222200356423855\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012978315353393555\n",
      "Value Loss:  0.00021755149646196514\n",
      "Q Loss:  0.0008143068989738822\n",
      "Policy Loss:  0.0043999068439006805\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0004669469781219959\n",
      "Q Loss:  0.0014517944073304534\n",
      "Policy Loss:  0.004274528473615646\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004531860351562\n",
      "Value Loss:  0.0007761073065921664\n",
      "Q Loss:  0.0039054027292877436\n",
      "Policy Loss:  0.018893884494900703\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62788 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.6412402987480164\n",
      "Q Loss:  0.07536006718873978\n",
      "Policy Loss:  -2.6713786125183105\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62792 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.6427173018455505\n",
      "Q Loss:  0.19966135919094086\n",
      "Policy Loss:  -3.7384567260742188\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 62796 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2789714336395264\n",
      "Q Loss:  0.4008680284023285\n",
      "Policy Loss:  -2.2819483280181885\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.8865219354629517\n",
      "Q Loss:  0.32943299412727356\n",
      "Policy Loss:  -4.788180828094482\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62804 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04360795021057129\n",
      "Value Loss:  2.551420211791992\n",
      "Q Loss:  0.1577323079109192\n",
      "Policy Loss:  -0.7822265625\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62834 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0013472780119627714\n",
      "Q Loss:  0.0041402424685657024\n",
      "Policy Loss:  -0.029090099036693573\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0001781026367098093\n",
      "Q Loss:  0.002169427927583456\n",
      "Policy Loss:  0.012657161802053452\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0026339474134147167\n",
      "Q Loss:  0.0029644975438714027\n",
      "Policy Loss:  0.042540863156318665\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62846 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003557205200195\n",
      "Value Loss:  3.0793075561523438\n",
      "Q Loss:  0.05919608846306801\n",
      "Policy Loss:  0.9350813627243042\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62865 length: 19 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.5328521728515625\n",
      "Q Loss:  0.16862992942333221\n",
      "Policy Loss:  -3.518435478210449\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  0.5213947892189026\n",
      "Q Loss:  0.1624029129743576\n",
      "Policy Loss:  -2.253152847290039\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  73.92095184326172\n",
      "Q Loss:  6.4438676834106445\n",
      "Policy Loss:  -13.781878471374512\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62922 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04300999641418457\n",
      "Value Loss:  59.58503723144531\n",
      "Q Loss:  199.60415649414062\n",
      "Policy Loss:  -6.330743312835693\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 62983 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  11428.0888671875\n",
      "Q Loss:  10473.376953125\n",
      "Policy Loss:  -15.292902946472168\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63061 length: 78 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  4.8820955271366984e-05\n",
      "Q Loss:  0.0004430057597346604\n",
      "Policy Loss:  0.004614135250449181\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0023704476188868284\n",
      "Q Loss:  0.004353593103587627\n",
      "Policy Loss:  -0.03287450969219208\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63069 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.9399283528327942\n",
      "Q Loss:  0.5547035932540894\n",
      "Policy Loss:  -5.7543044090271\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63073 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600574493408203\n",
      "Value Loss:  5.332472801208496\n",
      "Q Loss:  0.08028050512075424\n",
      "Policy Loss:  6.249980449676514\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63084 length: 11 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.025005817413330078\n",
      "Value Loss:  2.162917137145996\n",
      "Q Loss:  0.04093040153384209\n",
      "Policy Loss:  -0.7706685066223145\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63112 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.038740214833524e-05\n",
      "Q Loss:  0.0037064130883663893\n",
      "Policy Loss:  0.021568698808550835\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63116 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00014308030949905515\n",
      "Q Loss:  0.00038081625825725496\n",
      "Policy Loss:  0.008545638993382454\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00030229039839468896\n",
      "Q Loss:  0.0003716520732268691\n",
      "Policy Loss:  0.011543553322553635\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  0.00023470970336347818\n",
      "Q Loss:  0.012130431830883026\n",
      "Policy Loss:  0.056422118097543716\n",
      "[(7e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 7e-05 tau*: 0.00011 Episode: 63128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  117.50630187988281\n",
      "Q Loss:  5.21782112121582\n",
      "Policy Loss:  -21.256446838378906\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63159 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  896.5067749023438\n",
      "Q Loss:  3021.86474609375\n",
      "Policy Loss:  -78.96437072753906\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0019444676581770182\n",
      "Q Loss:  0.00036151715903542936\n",
      "Policy Loss:  0.006091705989092588\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63167 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  61.697906494140625\n",
      "Q Loss:  203.59347534179688\n",
      "Policy Loss:  -7.304654121398926\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63226 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00014872806787025183\n",
      "Q Loss:  0.0008515649242326617\n",
      "Policy Loss:  -0.01689661666750908\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.2882588129723445e-05\n",
      "Q Loss:  0.004205652512609959\n",
      "Policy Loss:  -0.023043416440486908\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00011315233132336289\n",
      "Q Loss:  0.02974710427224636\n",
      "Policy Loss:  0.07958842813968658\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04994368553161621\n",
      "Value Loss:  0.9525664448738098\n",
      "Q Loss:  0.08157365769147873\n",
      "Policy Loss:  -3.32450008392334\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  60.08346939086914\n",
      "Q Loss:  197.7728729248047\n",
      "Policy Loss:  -7.834999084472656\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63302 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  15520.10546875\n",
      "Q Loss:  13936.4111328125\n",
      "Policy Loss:  -9.002163887023926\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63359 length: 57 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0004288179334253073\n",
      "Q Loss:  0.004240903537720442\n",
      "Policy Loss:  0.006925211288034916\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003306793805677444\n",
      "Q Loss:  0.0033468115143477917\n",
      "Policy Loss:  0.01150289922952652\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0024839481338858604\n",
      "Q Loss:  0.003790258662775159\n",
      "Policy Loss:  0.00633994210511446\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.0001454252196708694\n",
      "Q Loss:  0.0032491832971572876\n",
      "Policy Loss:  0.0032147178426384926\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701113700866699\n",
      "Value Loss:  64.42549896240234\n",
      "Q Loss:  241.8716583251953\n",
      "Policy Loss:  -9.056321144104004\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63431 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  9.746610885486007e-05\n",
      "Q Loss:  0.004519693553447723\n",
      "Policy Loss:  0.014063803479075432\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00017564384324941784\n",
      "Q Loss:  0.0001707218325464055\n",
      "Policy Loss:  -0.001704546739347279\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.014681577682495\n",
      "Q Loss:  0.08492894470691681\n",
      "Policy Loss:  -0.4770428240299225\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63467 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0023531075567007065\n",
      "Q Loss:  0.002895901445299387\n",
      "Policy Loss:  0.03583911806344986\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.000581404019612819\n",
      "Q Loss:  0.0005309346597641706\n",
      "Policy Loss:  0.00649610348045826\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.518815255025402e-05\n",
      "Q Loss:  0.01910034939646721\n",
      "Policy Loss:  1.0534655302762985e-05\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  1.458358645439148\n",
      "Q Loss:  0.07202872633934021\n",
      "Policy Loss:  -2.860180616378784\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  1.7233127355575562\n",
      "Q Loss:  0.11660515516996384\n",
      "Policy Loss:  -1.3096445798873901\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63520 length: 37 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.001094215433113277\n",
      "Q Loss:  78.98190307617188\n",
      "Policy Loss:  4.355874061584473\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63524 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  891.9573974609375\n",
      "Q Loss:  502.3163146972656\n",
      "Policy Loss:  -139.861083984375\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0008730360423214734\n",
      "Q Loss:  39.08759307861328\n",
      "Policy Loss:  2.1667494773864746\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.002546035684645176\n",
      "Q Loss:  0.0014105322770774364\n",
      "Policy Loss:  -0.02572781778872013\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63536 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00016333030362147838\n",
      "Q Loss:  0.015156997367739677\n",
      "Policy Loss:  -0.008447895757853985\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  130.3900146484375\n",
      "Q Loss:  329.6825866699219\n",
      "Policy Loss:  -18.369953155517578\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63622 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00023993224021978676\n",
      "Q Loss:  0.0003542845952324569\n",
      "Policy Loss:  -0.0007383325137197971\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  27648.578125\n",
      "Q Loss:  24824.12109375\n",
      "Policy Loss:  -12.847745895385742\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63658 length: 32 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0004421072662808001\n",
      "Q Loss:  0.0003025950281880796\n",
      "Policy Loss:  0.007302556652575731\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  3.6715886380989105e-05\n",
      "Q Loss:  0.000308635295368731\n",
      "Policy Loss:  -0.002926528686657548\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63666 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004966735839844\n",
      "Value Loss:  0.4640013575553894\n",
      "Q Loss:  0.22786758840084076\n",
      "Policy Loss:  -2.0655927658081055\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63670 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00012137665908085182\n",
      "Q Loss:  0.009541749954223633\n",
      "Policy Loss:  0.2537999749183655\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.609753966331482\n",
      "Q Loss:  0.004866268020123243\n",
      "Policy Loss:  -0.47186049818992615\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63707 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  1.1939020623685792e-05\n",
      "Q Loss:  0.002917943987995386\n",
      "Policy Loss:  0.008515940979123116\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63711 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.4709105491638184\n",
      "Q Loss:  0.002363976091146469\n",
      "Policy Loss:  -0.42507708072662354\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63747 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  897.9092407226562\n",
      "Q Loss:  3441.75634765625\n",
      "Policy Loss:  -68.78582763671875\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63751 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.002140784403309226\n",
      "Q Loss:  0.006593880709260702\n",
      "Policy Loss:  -0.03024560958147049\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.039008140563964844\n",
      "Value Loss:  0.0002507294702809304\n",
      "Q Loss:  0.0041866968385875225\n",
      "Policy Loss:  -0.005756155587732792\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.0012192053254693747\n",
      "Q Loss:  0.0007719561690464616\n",
      "Policy Loss:  0.015529632568359375\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.4828335642814636\n",
      "Q Loss:  0.023112080991268158\n",
      "Policy Loss:  -2.10539174079895\n",
      "[(8e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 8e-05 tau*: 0.00011 Episode: 63767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  58933.9453125\n",
      "Q Loss:  52896.9296875\n",
      "Policy Loss:  -19.228099822998047\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63782 length: 15 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.3613407611846924\n",
      "Q Loss:  0.11201649159193039\n",
      "Policy Loss:  -2.124830722808838\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63846 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00027848713216371834\n",
      "Q Loss:  8.682940097060055e-05\n",
      "Policy Loss:  0.0025738796684890985\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.053011178970336914\n",
      "Value Loss:  0.00016685770242474973\n",
      "Q Loss:  0.011715376749634743\n",
      "Policy Loss:  0.031465642154216766\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.3197083473205566\n",
      "Q Loss:  0.0065774209797382355\n",
      "Policy Loss:  -0.8587935566902161\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63896 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012645721435546875\n",
      "Value Loss:  178.04705810546875\n",
      "Q Loss:  668.163818359375\n",
      "Policy Loss:  -10.586688995361328\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63938 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.825350202328991e-05\n",
      "Q Loss:  0.003328860504552722\n",
      "Policy Loss:  0.02814093977212906\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.8219411373138428\n",
      "Q Loss:  0.004827371798455715\n",
      "Policy Loss:  -0.5929354429244995\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 63971 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  30647.43359375\n",
      "Q Loss:  27372.59375\n",
      "Policy Loss:  -52.84224319458008\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64000 length: 29 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.726745151448995e-05\n",
      "Q Loss:  0.013092550449073315\n",
      "Policy Loss:  0.05325029045343399\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0014288376551121473\n",
      "Q Loss:  0.000788239180110395\n",
      "Policy Loss:  0.008660122752189636\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.4867849788279273e-05\n",
      "Q Loss:  0.008365826681256294\n",
      "Policy Loss:  -0.005853232927620411\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002883056877180934\n",
      "Q Loss:  0.0036709820851683617\n",
      "Policy Loss:  0.23080036044120789\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.6945853233337402\n",
      "Q Loss:  0.3082694113254547\n",
      "Policy Loss:  -3.15183687210083\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  69.1993179321289\n",
      "Q Loss:  225.73789978027344\n",
      "Policy Loss:  -8.781010627746582\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64077 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005159907741472125\n",
      "Q Loss:  0.0010781552409753203\n",
      "Policy Loss:  0.01779456064105034\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64081 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.554364800453186\n",
      "Q Loss:  0.0242450051009655\n",
      "Policy Loss:  -2.147531747817993\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64085 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  27456.55078125\n",
      "Q Loss:  24582.078125\n",
      "Policy Loss:  -13.943408966064453\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64117 length: 32 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0002727425016928464\n",
      "Q Loss:  0.00015749259910080582\n",
      "Policy Loss:  -0.0016469855327159166\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.000240018343902193\n",
      "Q Loss:  0.00037031021201983094\n",
      "Policy Loss:  -0.00798471923917532\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.231572529533878e-05\n",
      "Q Loss:  0.00033689860720187426\n",
      "Policy Loss:  0.23406502604484558\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  169.92037963867188\n",
      "Q Loss:  7.205387115478516\n",
      "Policy Loss:  -28.82391357421875\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64153 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04200935363769531\n",
      "Value Loss:  0.0003750596661120653\n",
      "Q Loss:  0.00041765213245525956\n",
      "Policy Loss:  -0.012921980582177639\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64157 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  9.088802471524104e-05\n",
      "Q Loss:  0.002170053543522954\n",
      "Policy Loss:  0.2212172895669937\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64161 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.5086913108825684\n",
      "Q Loss:  0.08376414328813553\n",
      "Policy Loss:  2.2207603454589844\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64177 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.1095958948135376\n",
      "Q Loss:  0.30644863843917847\n",
      "Policy Loss:  -1.3322460651397705\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.6645667552947998\n",
      "Q Loss:  0.575885534286499\n",
      "Policy Loss:  -3.1180214881896973\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2.6863704988500103e-05\n",
      "Q Loss:  0.003165031783282757\n",
      "Policy Loss:  0.018909942358732224\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01506352424621582\n",
      "Value Loss:  2.8911020755767822\n",
      "Q Loss:  0.06627223640680313\n",
      "Policy Loss:  0.471181184053421\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64210 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0009762009722180665\n",
      "Q Loss:  0.0007124191615730524\n",
      "Policy Loss:  -0.0030032393988221884\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600811958312988\n",
      "Value Loss:  0.0003256445925217122\n",
      "Q Loss:  0.00035135934012942016\n",
      "Policy Loss:  0.0061956364661455154\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64218 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  7.567270949948579e-05\n",
      "Q Loss:  0.0007242144783958793\n",
      "Policy Loss:  0.0033046624157577753\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64222 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.571351943624904e-06\n",
      "Q Loss:  0.0004709602799266577\n",
      "Policy Loss:  0.003224009647965431\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64226 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04600787162780762\n",
      "Value Loss:  1.8402737623546273e-05\n",
      "Q Loss:  0.00021067014313302934\n",
      "Policy Loss:  -0.009124496020376682\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013606786727905273\n",
      "Value Loss:  1.0278321504592896\n",
      "Q Loss:  0.09316086024045944\n",
      "Policy Loss:  -3.558699131011963\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.803756833076477\n",
      "Q Loss:  0.07555326819419861\n",
      "Policy Loss:  -1.5070489645004272\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64268 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  26646.68359375\n",
      "Q Loss:  23701.6171875\n",
      "Policy Loss:  -29.149133682250977\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64301 length: 33 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1045.6097412109375\n",
      "Q Loss:  3366.54248046875\n",
      "Policy Loss:  -87.87332153320312\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64305 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0012110619572922587\n",
      "Q Loss:  0.002188090467825532\n",
      "Policy Loss:  -0.01350488793104887\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0005507846362888813\n",
      "Q Loss:  0.0003346487646922469\n",
      "Policy Loss:  -0.0013550689909607172\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64313 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  101.55712127685547\n",
      "Q Loss:  0.04801689088344574\n",
      "Policy Loss:  -18.837343215942383\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64355 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.141316134744557e-06\n",
      "Q Loss:  0.0007693041115999222\n",
      "Policy Loss:  0.005964246578514576\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.0005576766561716795\n",
      "Q Loss:  0.002096732845529914\n",
      "Policy Loss:  -0.001296306261792779\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004127502441406\n",
      "Value Loss:  0.0003072326653636992\n",
      "Q Loss:  0.0001431177370250225\n",
      "Policy Loss:  -0.00047004129737615585\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.457880979520269e-05\n",
      "Q Loss:  0.0012010427890345454\n",
      "Policy Loss:  0.22688373923301697\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.437767505645752\n",
      "Q Loss:  0.25651121139526367\n",
      "Policy Loss:  -6.134334087371826\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01238560676574707\n",
      "Value Loss:  2.19500732421875\n",
      "Q Loss:  0.0010743357706815004\n",
      "Policy Loss:  -0.00717531330883503\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64399 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00045226819929666817\n",
      "Q Loss:  0.0002477059024386108\n",
      "Policy Loss:  -0.010479191318154335\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64403 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.9300637328997254e-05\n",
      "Q Loss:  5.6216391385532916e-05\n",
      "Policy Loss:  -0.002213952597230673\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64407 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  1.2628412150661461e-05\n",
      "Q Loss:  0.36712586879730225\n",
      "Policy Loss:  0.009430846199393272\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  2.011061429977417\n",
      "Q Loss:  0.10580270737409592\n",
      "Policy Loss:  -0.8721820116043091\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64442 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  3.8598591345362365e-06\n",
      "Q Loss:  0.0016437940066680312\n",
      "Policy Loss:  0.019860200583934784\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08463430404663086\n",
      "Value Loss:  75.60796356201172\n",
      "Q Loss:  0.09162620455026627\n",
      "Policy Loss:  -14.669384956359863\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64503 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  4.32307767868042\n",
      "Q Loss:  0.12746213376522064\n",
      "Policy Loss:  4.39849328994751\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64517 length: 14 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00022976938635110855\n",
      "Q Loss:  0.00012697686906903982\n",
      "Policy Loss:  0.0023875050246715546\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.4676404893398285\n",
      "Q Loss:  0.18925464153289795\n",
      "Policy Loss:  -2.1393165588378906\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.0119588375091553\n",
      "Q Loss:  0.018111785873770714\n",
      "Policy Loss:  -0.6396536827087402\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64554 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  7.973289757501334e-05\n",
      "Q Loss:  0.00024694972671568394\n",
      "Policy Loss:  0.007142800837755203\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64558 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.35945941414684e-05\n",
      "Q Loss:  0.00017841167573351413\n",
      "Policy Loss:  0.21978600323200226\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64562 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  89.46238708496094\n",
      "Q Loss:  323.33282470703125\n",
      "Policy Loss:  -10.280379295349121\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64610 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900506019592285\n",
      "Value Loss:  1.5094959962880239e-05\n",
      "Q Loss:  0.014052949845790863\n",
      "Policy Loss:  0.2583346962928772\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.9342403411865234\n",
      "Q Loss:  0.02505568601191044\n",
      "Policy Loss:  0.10195397585630417\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64633 length: 19 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00020290569227654487\n",
      "Q Loss:  129.2897186279297\n",
      "Policy Loss:  6.791684150695801\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0005058436072431505\n",
      "Q Loss:  42.75416946411133\n",
      "Policy Loss:  2.2426180839538574\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  7.786832429701462e-05\n",
      "Q Loss:  0.00030447353492490947\n",
      "Policy Loss:  -0.000874062767252326\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.1372041626600549e-05\n",
      "Q Loss:  0.010523571632802486\n",
      "Policy Loss:  0.026234768331050873\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015273094177246094\n",
      "Value Loss:  1.0577750205993652\n",
      "Q Loss:  0.16668546199798584\n",
      "Policy Loss:  -4.260533332824707\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  93.4366226196289\n",
      "Q Loss:  292.057861328125\n",
      "Policy Loss:  -8.97152328491211\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64699 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.052011966705322266\n",
      "Value Loss:  0.0007674263324588537\n",
      "Q Loss:  122.66950988769531\n",
      "Policy Loss:  6.600503444671631\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64703 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00012678778148256242\n",
      "Q Loss:  0.005536440759897232\n",
      "Policy Loss:  0.024329286068677902\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64707 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.495894194813445e-05\n",
      "Q Loss:  0.000905539549421519\n",
      "Policy Loss:  -0.020279042422771454\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64711 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.151606743922457e-05\n",
      "Q Loss:  0.0005176600534468889\n",
      "Policy Loss:  0.00047362223267555237\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011998891830444336\n",
      "Value Loss:  1.690475583076477\n",
      "Q Loss:  0.09780093282461166\n",
      "Policy Loss:  -1.6490691900253296\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64751 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00011028863809769973\n",
      "Q Loss:  0.0028108591213822365\n",
      "Policy Loss:  0.020550590008497238\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.992719136178493e-05\n",
      "Q Loss:  0.00048036774387583137\n",
      "Policy Loss:  0.004125315696001053\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.7036756111774594e-05\n",
      "Q Loss:  0.0018329051090404391\n",
      "Policy Loss:  0.00479048490524292\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00013999662769492716\n",
      "Q Loss:  37.139678955078125\n",
      "Policy Loss:  2.0941500663757324\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00011569880007300526\n",
      "Q Loss:  0.0006353629287332296\n",
      "Policy Loss:  -0.02218875288963318\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.09102034568786621\n",
      "Value Loss:  0.00011205805640202016\n",
      "Q Loss:  0.0017591171199455857\n",
      "Policy Loss:  -0.02820173278450966\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.0003548709792084992\n",
      "Q Loss:  0.0013557825004681945\n",
      "Policy Loss:  -0.016851358115673065\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64779 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00015206962416414171\n",
      "Q Loss:  0.0038811303675174713\n",
      "Policy Loss:  -0.026268109679222107\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100918769836426\n",
      "Value Loss:  6.391383067239076e-05\n",
      "Q Loss:  0.0033354652114212513\n",
      "Policy Loss:  0.2017309069633484\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004541397094727\n",
      "Value Loss:  2.8246119022369385\n",
      "Q Loss:  0.15168394148349762\n",
      "Policy Loss:  -0.9272871613502502\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64810 length: 23 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.0854177474975586\n",
      "Q Loss:  0.2199481874704361\n",
      "Policy Loss:  -4.4718475341796875\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.5381576418876648\n",
      "Q Loss:  0.10441172122955322\n",
      "Policy Loss:  -2.521012783050537\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.592930316925049\n",
      "Q Loss:  0.043390870094299316\n",
      "Policy Loss:  0.05283514782786369\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64839 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.00011904220446012914\n",
      "Q Loss:  0.002767652040347457\n",
      "Policy Loss:  -0.022481709718704224\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64843 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.5273473858833313\n",
      "Q Loss:  0.10247673094272614\n",
      "Policy Loss:  -1.442723274230957\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64847 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  218592.796875\n",
      "Q Loss:  195557.90625\n",
      "Policy Loss:  177.1680145263672\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64851 length: 4 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002838075743056834\n",
      "Q Loss:  0.002477979054674506\n",
      "Policy Loss:  0.018207045271992683\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64855 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.040007829666137695\n",
      "Value Loss:  0.00042082680738531053\n",
      "Q Loss:  0.0011804967653006315\n",
      "Policy Loss:  -0.0037984466180205345\n",
      "[(9e-05, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 9e-05 tau*: 0.00011 Episode: 64859 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0004954079631716013\n",
      "Q Loss:  0.0024604008067399263\n",
      "Policy Loss:  -0.021472282707691193\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64863 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.000441897806013003\n",
      "Q Loss:  0.0007686088792979717\n",
      "Policy Loss:  0.008695949800312519\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64867 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.216360330581665\n",
      "Q Loss:  0.032864268869161606\n",
      "Policy Loss:  -1.2575510740280151\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64912 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.0944089889526367\n",
      "Q Loss:  0.09692712128162384\n",
      "Policy Loss:  -1.6125315427780151\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64964 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0023535829968750477\n",
      "Q Loss:  0.0007148572476580739\n",
      "Policy Loss:  -0.005555645562708378\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64968 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  8.69018113007769e-05\n",
      "Q Loss:  0.0007073830347508192\n",
      "Policy Loss:  0.023196760565042496\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64972 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00016385229537263513\n",
      "Q Loss:  0.0008717048913240433\n",
      "Policy Loss:  0.01682819426059723\n",
      "[(0.0001, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0001 tau*: 0.00011 Episode: 64976 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  291.9945068359375\n",
      "Q Loss:  525.0818481445312\n",
      "Policy Loss:  -34.07359313964844\n",
      "[(0.00011, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00011 tau*: 0.00011 Episode: 65010 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0400090217590332\n",
      "Value Loss:  0.0008097501704469323\n",
      "Q Loss:  0.002007480477914214\n",
      "Policy Loss:  0.018383510410785675\n",
      "[(0.00011, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00011 tau*: 0.00011 Episode: 65014 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.3851501941680908\n",
      "Q Loss:  0.3092442750930786\n",
      "Policy Loss:  -3.6921956539154053\n",
      "[(0.00011, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00011 tau*: 0.00011 Episode: 65018 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  2.7735605239868164\n",
      "Q Loss:  0.8018671870231628\n",
      "Policy Loss:  -11.5501708984375\n",
      "[(0.00011, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00011 tau*: 0.00011 Episode: 65022 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  125.03968048095703\n",
      "Q Loss:  6.707328796386719\n",
      "Policy Loss:  -19.776491165161133\n",
      "[(0.00011, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00011 tau*: 0.00011 Episode: 65063 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.02680019661784172\n",
      "Q Loss:  0.006771102547645569\n",
      "Policy Loss:  0.048482492566108704\n",
      "[(0.00012, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00012 tau*: 0.00011 Episode: 65067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.002057451056316495\n",
      "Q Loss:  0.0008275695145130157\n",
      "Policy Loss:  -0.00986292865127325\n",
      "[(0.00012, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00012 tau*: 0.00011 Episode: 65071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.4338914155960083\n",
      "Q Loss:  0.02253892458975315\n",
      "Policy Loss:  -0.7698243260383606\n",
      "[(0.00012, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00012 tau*: 0.00011 Episode: 65105 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00010659773397492245\n",
      "Q Loss:  0.014189709909260273\n",
      "Policy Loss:  0.06589040905237198\n",
      "[(0.00012, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00012 tau*: 0.00011 Episode: 65109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.6309227347373962\n",
      "Q Loss:  0.187249556183815\n",
      "Policy Loss:  -2.4402523040771484\n",
      "[(0.00012, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00012 tau*: 0.00011 Episode: 65113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301213264465332\n",
      "Value Loss:  192.87710571289062\n",
      "Q Loss:  305.11370849609375\n",
      "Policy Loss:  -26.459304809570312\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 65194 length: 81 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0005612346576526761\n",
      "Q Loss:  0.007168435025960207\n",
      "Policy Loss:  0.030322667211294174\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 65198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.2188119888305664\n",
      "Q Loss:  0.12988726794719696\n",
      "Policy Loss:  -3.71035099029541\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 65202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.7017741203308105\n",
      "Q Loss:  0.10323713719844818\n",
      "Policy Loss:  -1.410326361656189\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 65236 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.7621850967407227\n",
      "Q Loss:  0.30893847346305847\n",
      "Policy Loss:  -3.5430917739868164\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 65240 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.7062296867370605\n",
      "Q Loss:  0.30408138036727905\n",
      "Policy Loss:  -6.024192810058594\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0009773452766239643\n",
      "Q Loss:  0.006291352678090334\n",
      "Policy Loss:  0.0422637015581131\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65248 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  40970.046875\n",
      "Q Loss:  36343.66796875\n",
      "Policy Loss:  -20.24382209777832\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65269 length: 21 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0016271640779450536\n",
      "Q Loss:  0.0010078147752210498\n",
      "Policy Loss:  0.0016389320371672511\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.5805736780166626\n",
      "Q Loss:  0.04372866451740265\n",
      "Policy Loss:  -0.8571878671646118\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65311 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  1333.494384765625\n",
      "Q Loss:  34.34968185424805\n",
      "Policy Loss:  -200.46397399902344\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65315 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.02713967114686966\n",
      "Q Loss:  0.019753895699977875\n",
      "Policy Loss:  -0.008685093373060226\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0011643812758848071\n",
      "Q Loss:  0.0006929534720256925\n",
      "Policy Loss:  -0.010306880809366703\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65323 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.1830625534057617\n",
      "Q Loss:  2.4036028385162354\n",
      "Policy Loss:  -0.6748406291007996\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65382 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0014963799621909857\n",
      "Q Loss:  0.003429549979045987\n",
      "Policy Loss:  0.02109701558947563\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005348248523660004\n",
      "Q Loss:  0.00022032653214409947\n",
      "Policy Loss:  -0.004420847166329622\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 65390 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0004055740137118846\n",
      "Q Loss:  0.0006935707642696798\n",
      "Policy Loss:  0.01333015225827694\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65394 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  432.7961120605469\n",
      "Q Loss:  186.356201171875\n",
      "Policy Loss:  -64.16148376464844\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65444 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.239781141281128\n",
      "Q Loss:  0.052561406046152115\n",
      "Policy Loss:  -1.0593715906143188\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65495 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006412743241526186\n",
      "Q Loss:  0.008340719155967236\n",
      "Policy Loss:  0.2358187437057495\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.2405335903167725\n",
      "Q Loss:  0.012511425651609898\n",
      "Policy Loss:  -0.4064607322216034\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65525 length: 26 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0023625334724783897\n",
      "Q Loss:  0.0009811590425670147\n",
      "Policy Loss:  0.0012551243416965008\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0010764449834823608\n",
      "Q Loss:  0.0006799825350753963\n",
      "Policy Loss:  -0.02298123389482498\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.43194788694381714\n",
      "Q Loss:  0.2701093852519989\n",
      "Policy Loss:  -1.8304979801177979\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.4318396747112274\n",
      "Q Loss:  0.008867465890944004\n",
      "Policy Loss:  -1.8645024299621582\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.2300258874893188\n",
      "Q Loss:  2.7587733268737793\n",
      "Policy Loss:  -0.6265000700950623\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65591 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.010614117607474327\n",
      "Q Loss:  0.00790392141789198\n",
      "Policy Loss:  -0.03503856807947159\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.002156064612790942\n",
      "Q Loss:  0.002579053631052375\n",
      "Policy Loss:  -0.02593350037932396\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600811958312988\n",
      "Value Loss:  188.5548553466797\n",
      "Q Loss:  4.854301929473877\n",
      "Policy Loss:  -28.14053726196289\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65628 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  0.0014033741317689419\n",
      "Q Loss:  0.004864213988184929\n",
      "Policy Loss:  -0.01625777781009674\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0004816005239263177\n",
      "Q Loss:  0.00017610432405490428\n",
      "Policy Loss:  0.005639970302581787\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001585820718901232\n",
      "Q Loss:  0.0005022801924496889\n",
      "Policy Loss:  0.01735679805278778\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.8704699277877808\n",
      "Q Loss:  0.020139381289482117\n",
      "Policy Loss:  -2.7588322162628174\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  1.2696824073791504\n",
      "Q Loss:  0.06172647699713707\n",
      "Policy Loss:  -1.1629735231399536\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65695 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.8589139580726624\n",
      "Q Loss:  0.2518885135650635\n",
      "Policy Loss:  -2.7167463302612305\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65699 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  71.96192932128906\n",
      "Q Loss:  0.029568195343017578\n",
      "Policy Loss:  -12.148487091064453\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65775 length: 76 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.9862512999679893e-05\n",
      "Q Loss:  0.0007765500340610743\n",
      "Policy Loss:  -0.01416286826133728\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65779 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0018856276292353868\n",
      "Q Loss:  0.0021257486660033464\n",
      "Policy Loss:  0.008785305544734001\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 65783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0022808939684182405\n",
      "Q Loss:  0.0002941541315522045\n",
      "Policy Loss:  -0.010109691880643368\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00027095689438283443\n",
      "Q Loss:  0.001325647346675396\n",
      "Policy Loss:  0.19019629061222076\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.59602952003479\n",
      "Q Loss:  0.006014687474817038\n",
      "Policy Loss:  -0.8650832176208496\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65829 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0011962540447711945\n",
      "Q Loss:  0.0022762229200452566\n",
      "Policy Loss:  -0.016698583960533142\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400090217590332\n",
      "Value Loss:  0.0038427512627094984\n",
      "Q Loss:  0.002174593973904848\n",
      "Policy Loss:  -0.020158888772130013\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0485537052154541\n",
      "Value Loss:  258.4548645019531\n",
      "Q Loss:  404.1138000488281\n",
      "Policy Loss:  -28.98270606994629\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65879 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0014956273371353745\n",
      "Q Loss:  0.0007278670091181993\n",
      "Policy Loss:  0.0060417200438678265\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00031635165214538574\n",
      "Q Loss:  0.0020148465409874916\n",
      "Policy Loss:  0.0269581638276577\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65887 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.7661269491072744e-05\n",
      "Q Loss:  0.005099757574498653\n",
      "Policy Loss:  0.038070134818553925\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65891 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0002480055554769933\n",
      "Q Loss:  0.000596196623519063\n",
      "Policy Loss:  0.21044543385505676\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65895 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.3919084072113037\n",
      "Q Loss:  0.040750790387392044\n",
      "Policy Loss:  -0.1672385185956955\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65921 length: 26 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.7696155309677124\n",
      "Q Loss:  0.01101777795702219\n",
      "Policy Loss:  -1.0542157888412476\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65957 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0016176315257325768\n",
      "Q Loss:  0.0003295115602668375\n",
      "Policy Loss:  0.0032995936926454306\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.41488680243492126\n",
      "Q Loss:  0.20150694251060486\n",
      "Policy Loss:  -1.9719457626342773\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 65965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  166.3854217529297\n",
      "Q Loss:  349.5545654296875\n",
      "Policy Loss:  -21.49703025817871\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66030 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.9606678485870361\n",
      "Q Loss:  0.0029142010025680065\n",
      "Policy Loss:  -0.318630576133728\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66058 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0003635119937825948\n",
      "Q Loss:  0.003894332330673933\n",
      "Policy Loss:  -0.02096870169043541\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011000394821166992\n",
      "Value Loss:  0.43307632207870483\n",
      "Q Loss:  0.18666744232177734\n",
      "Policy Loss:  -2.0845425128936768\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.6498714685440063\n",
      "Q Loss:  0.012601645663380623\n",
      "Policy Loss:  -0.8961955904960632\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66102 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0002754069573711604\n",
      "Q Loss:  33.934539794921875\n",
      "Policy Loss:  1.986274242401123\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66106 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.9739329218282364e-05\n",
      "Q Loss:  0.0030899327248334885\n",
      "Policy Loss:  -0.03259776532649994\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66110 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  4.404080755193718e-06\n",
      "Q Loss:  0.0073657408356666565\n",
      "Policy Loss:  -0.016720900312066078\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  0.0005330623826012015\n",
      "Q Loss:  0.00026515015633776784\n",
      "Policy Loss:  0.006534267216920853\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.4577116072177887\n",
      "Q Loss:  0.15346652269363403\n",
      "Policy Loss:  -2.2337820529937744\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.4578404426574707\n",
      "Q Loss:  0.1456318348646164\n",
      "Policy Loss:  -2.2975893020629883\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100539207458496\n",
      "Value Loss:  3.4308084195799893e-06\n",
      "Q Loss:  0.0013491538120433688\n",
      "Policy Loss:  -0.026804562658071518\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.3581798076629639\n",
      "Q Loss:  0.03426254540681839\n",
      "Policy Loss:  -1.1795827150344849\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66176 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  1.193686216538481e-07\n",
      "Q Loss:  0.0011182829039171338\n",
      "Policy Loss:  0.011231792159378529\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66180 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.279312972561456e-06\n",
      "Q Loss:  0.0011115031084045768\n",
      "Policy Loss:  0.010730409994721413\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0005942608113400638\n",
      "Q Loss:  0.0004736084374599159\n",
      "Policy Loss:  0.006895989179611206\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.9018334746360779\n",
      "Q Loss:  0.179997980594635\n",
      "Policy Loss:  -2.0402379035949707\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.1463595628738403\n",
      "Q Loss:  0.016280585899949074\n",
      "Policy Loss:  -0.7489106059074402\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66242 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.6358029319671914e-05\n",
      "Q Loss:  0.0015188197139650583\n",
      "Policy Loss:  0.1979874223470688\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900885581970215\n",
      "Value Loss:  1.315918207168579\n",
      "Q Loss:  0.6345442533493042\n",
      "Policy Loss:  -7.377182960510254\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014611244201660156\n",
      "Value Loss:  0.8558124899864197\n",
      "Q Loss:  0.1701986938714981\n",
      "Policy Loss:  -3.6957828998565674\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.322077989578247\n",
      "Q Loss:  0.03390876576304436\n",
      "Policy Loss:  -1.1581722497940063\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66302 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  22028.1171875\n",
      "Q Loss:  19455.970703125\n",
      "Policy Loss:  -15.951973915100098\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66341 length: 39 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  126.09319305419922\n",
      "Q Loss:  0.010497480630874634\n",
      "Policy Loss:  -20.012081146240234\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66384 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.2615385055541992\n",
      "Q Loss:  0.07715126872062683\n",
      "Policy Loss:  -1.3636531829833984\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66441 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  193.0943145751953\n",
      "Q Loss:  276.4341125488281\n",
      "Policy Loss:  -25.884323120117188\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66525 length: 84 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0310060977935791\n",
      "Value Loss:  0.7635397911071777\n",
      "Q Loss:  0.15022139251232147\n",
      "Policy Loss:  -3.4906833171844482\n",
      "[(0.00013, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00013 tau*: 0.00011 Episode: 66529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.1326606273651123\n",
      "Q Loss:  0.03207364305853844\n",
      "Policy Loss:  -0.6420960426330566\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66582 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  8.920696018321905e-06\n",
      "Q Loss:  0.000411446497309953\n",
      "Policy Loss:  -0.0009424779564142227\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  3.3549458980560303\n",
      "Q Loss:  0.07564815878868103\n",
      "Policy Loss:  1.344165325164795\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66604 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.887273123837076e-05\n",
      "Q Loss:  0.00020891291205771267\n",
      "Policy Loss:  -0.005496370606124401\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66608 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.709084118483588e-05\n",
      "Q Loss:  0.07650347054004669\n",
      "Policy Loss:  0.35419586300849915\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66612 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.5702834129333496\n",
      "Q Loss:  0.05843595042824745\n",
      "Policy Loss:  -1.2960718870162964\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66656 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03900885581970215\n",
      "Value Loss:  1.1184828281402588\n",
      "Q Loss:  0.3362114429473877\n",
      "Policy Loss:  -5.5899529457092285\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  105.66249084472656\n",
      "Q Loss:  326.8021545410156\n",
      "Policy Loss:  -10.166996955871582\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66712 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.00012967127258889377\n",
      "Q Loss:  0.00014684494817629457\n",
      "Policy Loss:  -0.0004832174745388329\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 66716 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.7244365215301514\n",
      "Q Loss:  0.1892584264278412\n",
      "Policy Loss:  -2.500307083129883\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  2.535498970246408e-05\n",
      "Q Loss:  0.02933531068265438\n",
      "Policy Loss:  0.06487791985273361\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.251847349223681e-05\n",
      "Q Loss:  0.0552213117480278\n",
      "Policy Loss:  0.0978405773639679\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  5.755443635280244e-05\n",
      "Q Loss:  0.022235041484236717\n",
      "Policy Loss:  0.039855971932411194\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66732 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  1.0160942077636719\n",
      "Q Loss:  0.0763508677482605\n",
      "Policy Loss:  -2.6755497455596924\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  45156.15234375\n",
      "Q Loss:  39848.7265625\n",
      "Policy Loss:  -19.960668563842773\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66755 length: 19 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04554176330566406\n",
      "Value Loss:  8.19162669358775e-05\n",
      "Q Loss:  0.0007548852590844035\n",
      "Policy Loss:  -0.007143345661461353\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.082252765627345e-05\n",
      "Q Loss:  0.00642983615398407\n",
      "Policy Loss:  0.016901416704058647\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.050830841064453\n",
      "Q Loss:  0.0048822364769876\n",
      "Policy Loss:  -0.16465026140213013\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 66793 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  2.7381076506571844e-05\n",
      "Q Loss:  0.0003513001720421016\n",
      "Policy Loss:  -0.008969034999608994\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.1223149299621582\n",
      "Q Loss:  2.4129638671875\n",
      "Policy Loss:  -0.10100261121988297\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66853 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.988716581370682e-05\n",
      "Q Loss:  0.00281443540006876\n",
      "Policy Loss:  0.012576652690768242\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66857 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.163695899071172e-05\n",
      "Q Loss:  0.005243238992989063\n",
      "Policy Loss:  0.019038517028093338\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66861 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.4144330836861627e-06\n",
      "Q Loss:  0.0014064711285755038\n",
      "Policy Loss:  0.0050683896988630295\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66865 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  2.06287186301779e-05\n",
      "Q Loss:  0.0001556005736347288\n",
      "Policy Loss:  0.004652699455618858\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600550651550293\n",
      "Value Loss:  0.9449054598808289\n",
      "Q Loss:  0.031124798581004143\n",
      "Policy Loss:  -1.9462894201278687\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  92.17090606689453\n",
      "Q Loss:  333.5928649902344\n",
      "Policy Loss:  -9.362424850463867\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66935 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  1414.8284912109375\n",
      "Q Loss:  4353.1044921875\n",
      "Policy Loss:  -104.43748474121094\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.990120452130213e-05\n",
      "Q Loss:  0.0007305319304578006\n",
      "Policy Loss:  0.014155181124806404\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.30179738998413086\n",
      "Q Loss:  0.17745181918144226\n",
      "Policy Loss:  -1.5373936891555786\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.4833096265792847\n",
      "Q Loss:  3.2061498165130615\n",
      "Policy Loss:  0.1468176245689392\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66989 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  5.090353806735948e-05\n",
      "Q Loss:  0.00020014455367345363\n",
      "Policy Loss:  0.0031020177993923426\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.136497177067213e-07\n",
      "Q Loss:  0.0018282399978488684\n",
      "Policy Loss:  -0.017730344086885452\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 66997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05601310729980469\n",
      "Value Loss:  1.2774182558059692\n",
      "Q Loss:  5.560523509979248\n",
      "Policy Loss:  0.5009130835533142\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67045 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  101.95731353759766\n",
      "Q Loss:  370.48968505859375\n",
      "Policy Loss:  -5.5353217124938965\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67101 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.9734680652618408\n",
      "Q Loss:  0.02547367289662361\n",
      "Policy Loss:  -0.5982186794281006\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67135 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  4.374719355837442e-05\n",
      "Q Loss:  0.002798293950036168\n",
      "Policy Loss:  -0.024945484474301338\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.223251613031607e-05\n",
      "Q Loss:  0.2983850836753845\n",
      "Policy Loss:  -0.024347804486751556\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2367844581604004\n",
      "Q Loss:  0.027929142117500305\n",
      "Policy Loss:  -0.6167367100715637\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67195 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.3841250620316714e-05\n",
      "Q Loss:  6.478934665210545e-05\n",
      "Policy Loss:  -0.0036165923811495304\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  20373.548828125\n",
      "Q Loss:  17988.796875\n",
      "Policy Loss:  -15.457441329956055\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67241 length: 42 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04100847244262695\n",
      "Value Loss:  1408.9295654296875\n",
      "Q Loss:  0.004322026390582323\n",
      "Policy Loss:  -215.98922729492188\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00015183413052000105\n",
      "Q Loss:  0.013325504027307034\n",
      "Policy Loss:  -0.03930012136697769\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015631675720214844\n",
      "Value Loss:  1.787378278095275e-05\n",
      "Q Loss:  5.831141606904566e-05\n",
      "Policy Loss:  0.0017095132498070598\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.32785673183389e-05\n",
      "Q Loss:  7.295456452993676e-05\n",
      "Policy Loss:  0.0017058650264516473\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017005443572998047\n",
      "Value Loss:  0.00011508275929372758\n",
      "Q Loss:  6.397701508831233e-05\n",
      "Policy Loss:  0.004786060191690922\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00012260014773346484\n",
      "Q Loss:  8.687243825988844e-05\n",
      "Policy Loss:  0.006112758535891771\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.34086301922798157\n",
      "Q Loss:  0.1932971030473709\n",
      "Policy Loss:  -1.5041940212249756\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.9580366015434265\n",
      "Q Loss:  0.027746405452489853\n",
      "Policy Loss:  -0.6802639961242676\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67336 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0310056209564209\n",
      "Value Loss:  2.914853572845459\n",
      "Q Loss:  0.10610166937112808\n",
      "Policy Loss:  0.8440025448799133\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67358 length: 22 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  3.3608521334826946e-05\n",
      "Q Loss:  0.00014253835252020508\n",
      "Policy Loss:  0.005005856044590473\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67362 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.7053165435791016\n",
      "Q Loss:  0.17753617465496063\n",
      "Policy Loss:  -2.8439674377441406\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 67366 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012514352798461914\n",
      "Value Loss:  3.5438685417175293\n",
      "Q Loss:  0.0963452085852623\n",
      "Policy Loss:  1.9360734224319458\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67384 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.35646694898605347\n",
      "Q Loss:  0.023499729111790657\n",
      "Policy Loss:  -1.891767978668213\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  236.870849609375\n",
      "Q Loss:  855.370361328125\n",
      "Policy Loss:  -16.71659278869629\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67412 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.3640372157096863\n",
      "Q Loss:  0.03363470360636711\n",
      "Policy Loss:  -1.7990669012069702\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.6819325685501099\n",
      "Q Loss:  11.450395584106445\n",
      "Policy Loss:  1.7922616004943848\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67451 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01461029052734375\n",
      "Value Loss:  6.373575160978362e-05\n",
      "Q Loss:  5.488691385835409e-05\n",
      "Policy Loss:  0.0032856687903404236\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.498315997305326e-06\n",
      "Q Loss:  0.0060789454728364944\n",
      "Policy Loss:  0.031079616397619247\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.3836016058921814\n",
      "Q Loss:  0.15267139673233032\n",
      "Policy Loss:  -1.8135095834732056\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.035099029541016\n",
      "Q Loss:  0.0030560907907783985\n",
      "Policy Loss:  2.23856782913208\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67477 length: 14 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.779503872967325e-05\n",
      "Q Loss:  0.00010249933984596282\n",
      "Policy Loss:  0.002066343557089567\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  5.918218812439591e-05\n",
      "Q Loss:  0.0004924471722915769\n",
      "Policy Loss:  0.00037166435504332185\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.6434694771305658e-05\n",
      "Q Loss:  0.0005346297402866185\n",
      "Policy Loss:  0.004990637302398682\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  9.778866115084384e-06\n",
      "Q Loss:  0.0007892585126683116\n",
      "Policy Loss:  0.01091429777443409\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.8564467430114746\n",
      "Q Loss:  0.1807824820280075\n",
      "Policy Loss:  -3.7597646713256836\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.2876040935516357\n",
      "Q Loss:  0.18270991742610931\n",
      "Policy Loss:  -4.245236873626709\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.8443606495857239\n",
      "Q Loss:  0.23787666857242584\n",
      "Policy Loss:  -3.6041345596313477\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.8215490579605103\n",
      "Q Loss:  0.16762036085128784\n",
      "Policy Loss:  -3.5088446140289307\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67509 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.7913237810134888\n",
      "Q Loss:  0.473160982131958\n",
      "Policy Loss:  -3.31402587890625\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  158.7333526611328\n",
      "Q Loss:  534.7164306640625\n",
      "Policy Loss:  -15.93327808380127\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67584 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00046209138236008584\n",
      "Q Loss:  0.0029116563964635134\n",
      "Policy Loss:  0.0046630725264549255\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00024380467948503792\n",
      "Q Loss:  0.0009353890200145543\n",
      "Policy Loss:  0.010513374581933022\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0006396766984835267\n",
      "Q Loss:  0.00031355710234493017\n",
      "Policy Loss:  0.013264061883091927\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04656219482421875\n",
      "Value Loss:  120.62894439697266\n",
      "Q Loss:  365.97064208984375\n",
      "Policy Loss:  -7.755181312561035\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67643 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  8.647270442452282e-05\n",
      "Q Loss:  0.006329407449811697\n",
      "Policy Loss:  0.04398009926080704\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.8024802557192743e-06\n",
      "Q Loss:  0.016440825536847115\n",
      "Policy Loss:  0.2575533390045166\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67651 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.085536003112793\n",
      "Q Loss:  0.0660528838634491\n",
      "Policy Loss:  -0.25346726179122925\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67683 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014005184173583984\n",
      "Value Loss:  0.00042086991015821695\n",
      "Q Loss:  100.85099792480469\n",
      "Policy Loss:  6.007762908935547\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1396.6268310546875\n",
      "Q Loss:  807.3729248046875\n",
      "Policy Loss:  -195.21841430664062\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.001995211699977517\n",
      "Q Loss:  0.0013520875945687294\n",
      "Policy Loss:  -0.020944718271493912\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67695 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0005649508093483746\n",
      "Q Loss:  0.0025209803134202957\n",
      "Policy Loss:  -0.02487259730696678\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67699 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.29313284158706665\n",
      "Q Loss:  0.10176046937704086\n",
      "Policy Loss:  -1.6551772356033325\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67703 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.28788986802101135\n",
      "Q Loss:  0.1076323539018631\n",
      "Policy Loss:  -0.6392970085144043\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67707 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.5656300783157349\n",
      "Q Loss:  0.1943099945783615\n",
      "Policy Loss:  -1.0595545768737793\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67711 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005796432495117\n",
      "Value Loss:  0.27517515420913696\n",
      "Q Loss:  0.09092957526445389\n",
      "Policy Loss:  -1.6099376678466797\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  1.730447769165039\n",
      "Q Loss:  0.0053200796246528625\n",
      "Policy Loss:  -0.2560123801231384\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67752 length: 37 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  53569.65234375\n",
      "Q Loss:  47418.125\n",
      "Policy Loss:  0.9337940216064453\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67768 length: 16 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0002395686460658908\n",
      "Q Loss:  0.0009089283412322402\n",
      "Policy Loss:  0.006772337947040796\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.25919434428215027\n",
      "Q Loss:  0.04674942046403885\n",
      "Policy Loss:  -1.7387615442276\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.824280023574829\n",
      "Q Loss:  7.542200565338135\n",
      "Policy Loss:  1.1758995056152344\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67812 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003407399053685367\n",
      "Q Loss:  0.0008360269130207598\n",
      "Policy Loss:  -0.009663168340921402\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  9.664063691161573e-05\n",
      "Q Loss:  0.002018147148191929\n",
      "Policy Loss:  -0.024478163570165634\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67820 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011993169784545898\n",
      "Value Loss:  5.058956230641343e-05\n",
      "Q Loss:  0.0010502792429178953\n",
      "Policy Loss:  -0.01613171026110649\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  3.028251012437977e-05\n",
      "Q Loss:  0.001484238775447011\n",
      "Policy Loss:  -0.024897973984479904\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  6.003498856443912e-05\n",
      "Q Loss:  0.001244157087057829\n",
      "Policy Loss:  0.1346992403268814\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  102.98086547851562\n",
      "Q Loss:  314.89666748046875\n",
      "Policy Loss:  -8.530957221984863\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67888 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  1426.244140625\n",
      "Q Loss:  789.6189575195312\n",
      "Policy Loss:  -207.2209014892578\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1425.641845703125\n",
      "Q Loss:  5208.76220703125\n",
      "Policy Loss:  -94.10430908203125\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0004039007762912661\n",
      "Q Loss:  0.0006711063906550407\n",
      "Policy Loss:  -0.0029894025065004826\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.749872088432312\n",
      "Q Loss:  0.03957993537187576\n",
      "Policy Loss:  -0.6317628622055054\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67941 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002959295525215566\n",
      "Q Loss:  75.04470825195312\n",
      "Policy Loss:  4.262428283691406\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67945 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004634857177734\n",
      "Value Loss:  0.00029377476312220097\n",
      "Q Loss:  37.86051559448242\n",
      "Policy Loss:  2.1465373039245605\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67949 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.2352466001175344e-05\n",
      "Q Loss:  0.0006450057262554765\n",
      "Policy Loss:  0.004387472756206989\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67953 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  0.00012210787099320441\n",
      "Q Loss:  0.003337577683851123\n",
      "Policy Loss:  0.027332019060850143\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  6.98035437380895e-05\n",
      "Q Loss:  0.0027028319891542196\n",
      "Policy Loss:  0.03179114684462547\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.2658299505710602\n",
      "Q Loss:  0.031890954822301865\n",
      "Policy Loss:  -1.6111712455749512\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 67965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.4318008422851562\n",
      "Q Loss:  0.01281561329960823\n",
      "Policy Loss:  -0.5839709639549255\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 68012 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  5.918193437537411e-06\n",
      "Q Loss:  0.001520104007795453\n",
      "Policy Loss:  -0.01777172088623047\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047829627990722656\n",
      "Value Loss:  0.00016164054977707565\n",
      "Q Loss:  0.001894449582323432\n",
      "Policy Loss:  0.02562331035733223\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.5962517636580742e-06\n",
      "Q Loss:  0.0039473632350564\n",
      "Policy Loss:  0.039268024265766144\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68024 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.7721277698874474e-05\n",
      "Q Loss:  0.002957290504127741\n",
      "Policy Loss:  0.029379814863204956\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68028 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00017181085422635078\n",
      "Q Loss:  0.0026979586109519005\n",
      "Policy Loss:  0.01547190360724926\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68032 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.868248000391759e-05\n",
      "Q Loss:  0.0036301715299487114\n",
      "Policy Loss:  0.03283284977078438\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68036 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  9.271644216823915e-07\n",
      "Q Loss:  0.001355320680886507\n",
      "Policy Loss:  0.014921804890036583\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68040 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.27023932337760925\n",
      "Q Loss:  0.10545606911182404\n",
      "Policy Loss:  -0.8383901119232178\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68044 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.8044923543930054\n",
      "Q Loss:  0.005820087157189846\n",
      "Policy Loss:  -0.36303427815437317\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68080 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.527295434148982e-05\n",
      "Q Loss:  0.00017589365597814322\n",
      "Policy Loss:  0.1628536432981491\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.448951244354248\n",
      "Q Loss:  3.4742140769958496\n",
      "Policy Loss:  -0.021457241848111153\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68131 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00014621559239458293\n",
      "Q Loss:  2.6782410714076832e-05\n",
      "Policy Loss:  -0.003771283430978656\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.5216306564980187e-05\n",
      "Q Loss:  2.9626731702592224e-05\n",
      "Policy Loss:  -0.006256795488297939\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.6003955602645874\n",
      "Q Loss:  3.9873170852661133\n",
      "Policy Loss:  0.22510407865047455\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68180 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1391.6448974609375\n",
      "Q Loss:  40.698150634765625\n",
      "Policy Loss:  -203.58834838867188\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5.341277756087948e-06\n",
      "Q Loss:  0.0003776737139560282\n",
      "Policy Loss:  -0.005180526524782181\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  9.371575288241729e-05\n",
      "Q Loss:  0.0004914058954454958\n",
      "Policy Loss:  0.1569579541683197\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 68192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  19348.365234375\n",
      "Q Loss:  17100.84765625\n",
      "Policy Loss:  -102.23750305175781\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68238 length: 46 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.024008512496948242\n",
      "Value Loss:  1.0695631317503285e-05\n",
      "Q Loss:  0.00012099511513952166\n",
      "Policy Loss:  -0.003226981731131673\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.032758235931396484\n",
      "Value Loss:  6.384374501067214e-06\n",
      "Q Loss:  0.001281071687117219\n",
      "Policy Loss:  -0.010657574981451035\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  2.0277795556467026e-05\n",
      "Q Loss:  0.0006560726324096322\n",
      "Policy Loss:  -0.008680232800543308\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.6014003853779286e-05\n",
      "Q Loss:  0.001376545988023281\n",
      "Policy Loss:  0.15110160410404205\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  71417.15625\n",
      "Q Loss:  62760.15234375\n",
      "Policy Loss:  10.292436599731445\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68266 length: 12 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.670543810585514e-05\n",
      "Q Loss:  0.00023706948559265584\n",
      "Policy Loss:  -0.0007689588237553835\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  4.310412623453885e-05\n",
      "Q Loss:  0.0004068647394888103\n",
      "Policy Loss:  0.004672862123697996\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68274 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  6.743287485733163e-06\n",
      "Q Loss:  0.00011052519403165206\n",
      "Policy Loss:  0.003966696560382843\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68278 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  25149.267578125\n",
      "Q Loss:  22062.287109375\n",
      "Policy Loss:  -17.974584579467773\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68312 length: 34 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.9909964799880981\n",
      "Q Loss:  0.04913710802793503\n",
      "Policy Loss:  -0.5037297606468201\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68345 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9.33705669012852e-05\n",
      "Q Loss:  0.000455100933322683\n",
      "Policy Loss:  0.011251808144152164\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0290069580078125\n",
      "Value Loss:  7.723845556029119e-06\n",
      "Q Loss:  0.0004023096989840269\n",
      "Policy Loss:  0.009962163865566254\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9.297383257944603e-06\n",
      "Q Loss:  0.00023529044119641185\n",
      "Policy Loss:  0.004667226690798998\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  4.249850462656468e-06\n",
      "Q Loss:  9.217998012900352e-05\n",
      "Policy Loss:  0.0044756680727005005\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  5.4660440582665615e-06\n",
      "Q Loss:  0.00012820969277527183\n",
      "Policy Loss:  -0.00461211334913969\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68365 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.422044872218976e-06\n",
      "Q Loss:  0.00015080103185027838\n",
      "Policy Loss:  -0.0014620309229940176\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68369 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02900528907775879\n",
      "Value Loss:  1.104988694190979\n",
      "Q Loss:  0.07520080357789993\n",
      "Policy Loss:  -1.3183468580245972\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68430 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  41682.4375\n",
      "Q Loss:  36419.27734375\n",
      "Policy Loss:  -45.61235809326172\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68471 length: 41 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.06601452827453613\n",
      "Value Loss:  0.008049754425883293\n",
      "Q Loss:  40.60010528564453\n",
      "Policy Loss:  2.2260284423828125\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03130149841308594\n",
      "Value Loss:  3.063190160901286e-05\n",
      "Q Loss:  0.00013855387805961072\n",
      "Policy Loss:  0.006135796196758747\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.2602750909281895e-05\n",
      "Q Loss:  9.867033804766834e-05\n",
      "Policy Loss:  0.003913150168955326\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.4026266038417816\n",
      "Q Loss:  0.41907358169555664\n",
      "Policy Loss:  -2.973301410675049\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  179.5577850341797\n",
      "Q Loss:  381.8895568847656\n",
      "Policy Loss:  -19.29735565185547\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68556 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0001137472499976866\n",
      "Q Loss:  0.0033468101173639297\n",
      "Policy Loss:  0.02096925675868988\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  4.18892886955291e-05\n",
      "Q Loss:  0.0053802416659891605\n",
      "Policy Loss:  0.02651807852089405\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.8358919620513916\n",
      "Q Loss:  0.018895700573921204\n",
      "Policy Loss:  -0.5810045003890991\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68596 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.4065029621124268\n",
      "Q Loss:  0.053825244307518005\n",
      "Policy Loss:  -1.062025785446167\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68640 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1567.44189453125\n",
      "Q Loss:  855.5770874023438\n",
      "Policy Loss:  -217.0227813720703\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  1567.9654541015625\n",
      "Q Loss:  0.0006758603849448264\n",
      "Policy Loss:  -227.7393341064453\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.004857773892581463\n",
      "Q Loss:  125.58346557617188\n",
      "Policy Loss:  6.718194484710693\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1562.3265380859375\n",
      "Q Loss:  5844.47509765625\n",
      "Policy Loss:  -74.938232421875\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1556.521240234375\n",
      "Q Loss:  5784.9296875\n",
      "Policy Loss:  -85.45279693603516\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0008830716251395643\n",
      "Q Loss:  0.015448874793946743\n",
      "Policy Loss:  -0.06439664959907532\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00020646581833716482\n",
      "Q Loss:  0.0005306368693709373\n",
      "Policy Loss:  0.015184544026851654\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.002107418142259121\n",
      "Q Loss:  0.035002127289772034\n",
      "Policy Loss:  0.04473350942134857\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0030835173092782497\n",
      "Q Loss:  0.06813741475343704\n",
      "Policy Loss:  0.12486156821250916\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  1.0475051403045654\n",
      "Q Loss:  0.1105538159608841\n",
      "Policy Loss:  -2.022491693496704\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68758 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.0700993597274646e-05\n",
      "Q Loss:  0.0001727510243654251\n",
      "Policy Loss:  0.002996633993461728\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.7059220883529633e-05\n",
      "Q Loss:  4.000664921477437e-05\n",
      "Policy Loss:  0.0026479829102754593\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  8.971601346274838e-06\n",
      "Q Loss:  2.6282858016202226e-05\n",
      "Policy Loss:  0.003149196272715926\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.266028190613724e-05\n",
      "Q Loss:  0.004734732210636139\n",
      "Policy Loss:  0.030675269663333893\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  207.95236206054688\n",
      "Q Loss:  330.1743469238281\n",
      "Policy Loss:  -26.246662139892578\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68832 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  144.15455627441406\n",
      "Q Loss:  455.1570129394531\n",
      "Policy Loss:  -9.455731391906738\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 68874 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.46157127618789673\n",
      "Q Loss:  0.23191721737384796\n",
      "Policy Loss:  -1.1895583868026733\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68878 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  71.77021026611328\n",
      "Q Loss:  2.241365432739258\n",
      "Policy Loss:  -11.24221420288086\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 68962 length: 84 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.05857517197728157\n",
      "Q Loss:  140.12721252441406\n",
      "Policy Loss:  7.063232421875\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.004331677220761776\n",
      "Q Loss:  0.005668045021593571\n",
      "Policy Loss:  0.01837492734193802\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00313733727671206\n",
      "Q Loss:  0.003183468012139201\n",
      "Policy Loss:  0.01720939576625824\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 68974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013000249862670898\n",
      "Value Loss:  4.887391332886182e-05\n",
      "Q Loss:  0.0008271901169791818\n",
      "Policy Loss:  -0.019179241731762886\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.781887764693238e-05\n",
      "Q Loss:  0.0010883052600547671\n",
      "Policy Loss:  -0.022086169570684433\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0004610838077496737\n",
      "Q Loss:  0.0008225141791626811\n",
      "Policy Loss:  -0.010481167584657669\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 68986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00010714949894463643\n",
      "Q Loss:  0.0017484157579019666\n",
      "Policy Loss:  0.006742116063833237\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 68990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.9281668663024902\n",
      "Q Loss:  0.22205957770347595\n",
      "Policy Loss:  -3.757046937942505\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 68994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.5759979486465454\n",
      "Q Loss:  21.926774978637695\n",
      "Policy Loss:  2.687081813812256\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 69028 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.9142727255821228\n",
      "Q Loss:  0.12377072125673294\n",
      "Policy Loss:  -3.7425479888916016\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69032 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.9007748961448669\n",
      "Q Loss:  0.19369706511497498\n",
      "Policy Loss:  -3.531776189804077\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69036 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04200887680053711\n",
      "Value Loss:  1.314192295074463\n",
      "Q Loss:  0.22900933027267456\n",
      "Policy Loss:  -3.893901824951172\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69040 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  97.260498046875\n",
      "Q Loss:  310.50006103515625\n",
      "Policy Loss:  -10.653817176818848\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69101 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.18238051274966e-06\n",
      "Q Loss:  0.0007548779249191284\n",
      "Policy Loss:  -0.012555629014968872\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69105 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0006382061983458698\n",
      "Q Loss:  6.788796599721536e-05\n",
      "Policy Loss:  0.002976549556478858\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  111.83360290527344\n",
      "Q Loss:  425.5373840332031\n",
      "Policy Loss:  -8.326519966125488\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69162 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1465.34912109375\n",
      "Q Loss:  140.93511962890625\n",
      "Policy Loss:  -185.87924194335938\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1461.3209228515625\n",
      "Q Loss:  5471.7001953125\n",
      "Policy Loss:  -81.14061737060547\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69170 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01506948471069336\n",
      "Value Loss:  0.02921561896800995\n",
      "Q Loss:  0.021803125739097595\n",
      "Policy Loss:  -0.07778075337409973\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69174 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.0071092587895691395\n",
      "Q Loss:  44.841793060302734\n",
      "Policy Loss:  2.319981098175049\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.003852148074656725\n",
      "Q Loss:  0.004372907802462578\n",
      "Policy Loss:  -0.023755455389618874\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0004521360096987337\n",
      "Q Loss:  0.00047717365669086576\n",
      "Policy Loss:  -0.003901928896084428\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0004601808323059231\n",
      "Q Loss:  0.0005058033857494593\n",
      "Policy Loss:  0.010209349915385246\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.014467325992882252\n",
      "Q Loss:  0.01928005740046501\n",
      "Policy Loss:  0.16361169517040253\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  3.269005298614502\n",
      "Q Loss:  0.11605299264192581\n",
      "Policy Loss:  1.7839114665985107\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69215 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.3499332666397095\n",
      "Q Loss:  0.06437336653470993\n",
      "Policy Loss:  -0.9002068638801575\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69264 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.3416380286216736\n",
      "Q Loss:  0.10308751463890076\n",
      "Policy Loss:  -1.710269570350647\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.008894873782992363\n",
      "Q Loss:  0.2416609674692154\n",
      "Policy Loss:  0.04207699000835419\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  18052.845703125\n",
      "Q Loss:  16483.99609375\n",
      "Policy Loss:  -34.58392333984375\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69320 length: 48 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.002135579939931631\n",
      "Q Loss:  0.0020377852488309145\n",
      "Policy Loss:  0.022025419399142265\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.001292179455049336\n",
      "Q Loss:  0.013410218991339207\n",
      "Policy Loss:  0.060999367386102676\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.671703040599823\n",
      "Q Loss:  0.19099879264831543\n",
      "Policy Loss:  -2.7070302963256836\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.586966633796692\n",
      "Q Loss:  0.06147729232907295\n",
      "Policy Loss:  -0.652054488658905\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69373 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  112.55876922607422\n",
      "Q Loss:  353.111572265625\n",
      "Policy Loss:  -8.343284606933594\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69424 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  0.06727984547615051\n",
      "Q Loss:  0.08292367309331894\n",
      "Policy Loss:  0.13799530267715454\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.003633504267781973\n",
      "Q Loss:  0.009796218946576118\n",
      "Policy Loss:  -0.06152501329779625\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.002070761751383543\n",
      "Q Loss:  0.005369296297430992\n",
      "Policy Loss:  -0.015079787001013756\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  300.02374267578125\n",
      "Q Loss:  82.4897689819336\n",
      "Policy Loss:  -43.63237762451172\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69474 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.07274694740772247\n",
      "Q Loss:  44.847373962402344\n",
      "Policy Loss:  2.254843235015869\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04200911521911621\n",
      "Value Loss:  0.0014538951218128204\n",
      "Q Loss:  0.0030603650957345963\n",
      "Policy Loss:  -0.042158808559179306\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  4.4703840103466064e-05\n",
      "Q Loss:  0.0002634855336509645\n",
      "Policy Loss:  -0.004239216912537813\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.673961341381073\n",
      "Q Loss:  0.1919986754655838\n",
      "Policy Loss:  -3.1871063709259033\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012333393096923828\n",
      "Value Loss:  2.313096046447754\n",
      "Q Loss:  0.10559961199760437\n",
      "Policy Loss:  0.1119757667183876\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69518 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04400968551635742\n",
      "Value Loss:  0.002426033141091466\n",
      "Q Loss:  0.0008018586086109281\n",
      "Policy Loss:  0.014682810753583908\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0006039207219146192\n",
      "Q Loss:  0.0010952844750136137\n",
      "Policy Loss:  0.017375702038407326\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.037483215332031\n",
      "Q Loss:  0.08137436211109161\n",
      "Policy Loss:  3.433208465576172\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69542 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  132.92388916015625\n",
      "Q Loss:  3.938737630844116\n",
      "Policy Loss:  -19.861284255981445\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69585 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0001057110057445243\n",
      "Q Loss:  0.00017893631593324244\n",
      "Policy Loss:  -0.012164806947112083\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  0.696712851524353\n",
      "Q Loss:  0.13312529027462006\n",
      "Policy Loss:  -3.1525394916534424\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.4713351726531982\n",
      "Q Loss:  0.08197646588087082\n",
      "Policy Loss:  -0.5593606233596802\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69620 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.1048333644866943\n",
      "Q Loss:  0.04220694676041603\n",
      "Policy Loss:  -0.7216101884841919\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69651 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2820.65087890625\n",
      "Q Loss:  736.5078735351562\n",
      "Policy Loss:  -411.3134460449219\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.029278500005602837\n",
      "Q Loss:  0.1044185683131218\n",
      "Policy Loss:  -0.1416037380695343\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0012936481507495046\n",
      "Q Loss:  0.0008950495976023376\n",
      "Policy Loss:  0.017462577670812607\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00011786568211391568\n",
      "Q Loss:  0.013929921202361584\n",
      "Policy Loss:  0.03605125844478607\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00012791134940925986\n",
      "Q Loss:  0.002139773452654481\n",
      "Policy Loss:  0.17641596496105194\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  40796.6796875\n",
      "Q Loss:  35685.953125\n",
      "Policy Loss:  -19.606292724609375\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69692 length: 21 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.391629656514851e-06\n",
      "Q Loss:  0.0021119369193911552\n",
      "Policy Loss:  0.006769918836653233\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.2262320518493652\n",
      "Q Loss:  0.03747301176190376\n",
      "Policy Loss:  -0.5985720753669739\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69746 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.011196140199899673\n",
      "Q Loss:  45.74446487426758\n",
      "Policy Loss:  2.292654514312744\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.001953553408384323\n",
      "Q Loss:  91.85521697998047\n",
      "Policy Loss:  4.73563814163208\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0019103121012449265\n",
      "Q Loss:  0.013470252975821495\n",
      "Policy Loss:  0.07527288049459457\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 69758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0009910023072734475\n",
      "Q Loss:  0.022585291415452957\n",
      "Policy Loss:  0.07609602063894272\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0014227530919015408\n",
      "Q Loss:  0.00033417908707633615\n",
      "Policy Loss:  0.001657147891819477\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04600834846496582\n",
      "Value Loss:  0.0003953937557525933\n",
      "Q Loss:  0.0013447435339912772\n",
      "Policy Loss:  -0.01717584952712059\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  172.0345001220703\n",
      "Q Loss:  0.08412725478410721\n",
      "Policy Loss:  -26.665451049804688\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69803 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0032166203018277884\n",
      "Q Loss:  0.027719242498278618\n",
      "Policy Loss:  0.10217645764350891\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 69807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0052235615439713\n",
      "Q Loss:  0.005636516492813826\n",
      "Policy Loss:  -0.040108371526002884\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69811 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.002335098572075367\n",
      "Q Loss:  0.001715577789582312\n",
      "Policy Loss:  -0.02755422703921795\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69815 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00015139501192606986\n",
      "Q Loss:  0.0009702799143269658\n",
      "Policy Loss:  0.012088281102478504\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69819 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.000200182810658589\n",
      "Q Loss:  0.005824326537549496\n",
      "Policy Loss:  0.21350440382957458\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69823 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  103.44609069824219\n",
      "Q Loss:  6.667008399963379\n",
      "Policy Loss:  -15.332013130187988\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69878 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  0.008451376110315323\n",
      "Q Loss:  0.0037167039699852467\n",
      "Policy Loss:  0.03693719953298569\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69882 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.143141894834116e-05\n",
      "Q Loss:  0.002999392570927739\n",
      "Policy Loss:  -0.023822791874408722\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69886 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  8.109529153443873e-05\n",
      "Q Loss:  0.0006289149168878794\n",
      "Policy Loss:  0.006456454284489155\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69890 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.9688023328781128\n",
      "Q Loss:  0.0504755936563015\n",
      "Policy Loss:  -1.5047478675842285\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69962 length: 72 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.00016066848183982074\n",
      "Q Loss:  0.000550300523173064\n",
      "Policy Loss:  -0.004153583198785782\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.09902286529541016\n",
      "Value Loss:  0.00021675750031135976\n",
      "Q Loss:  0.002546583069488406\n",
      "Policy Loss:  -0.003712652949616313\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900861740112305\n",
      "Value Loss:  7.318890857277438e-05\n",
      "Q Loss:  0.0012511929962784052\n",
      "Policy Loss:  -0.004317090846598148\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  35649.296875\n",
      "Q Loss:  31059.58203125\n",
      "Policy Loss:  -21.746599197387695\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 69998 length: 24 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00015058889403007925\n",
      "Q Loss:  0.003971199505031109\n",
      "Policy Loss:  0.193280428647995\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.765345573425293\n",
      "Q Loss:  0.05551515892148018\n",
      "Policy Loss:  0.11530508100986481\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70023 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0023099896498024464\n",
      "Q Loss:  0.0006687422865070403\n",
      "Policy Loss:  -0.005626915954053402\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70027 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005548152257688344\n",
      "Q Loss:  0.00039350028964690864\n",
      "Policy Loss:  0.003972513601183891\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  8.448000880889595e-05\n",
      "Q Loss:  0.00043900019954890013\n",
      "Policy Loss:  0.005001728422939777\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0004209867911413312\n",
      "Q Loss:  0.006919886451214552\n",
      "Policy Loss:  -0.039180438965559006\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0001564527628943324\n",
      "Q Loss:  0.002971233334392309\n",
      "Policy Loss:  -0.016285967081785202\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70043 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0012334244092926383\n",
      "Q Loss:  0.0003936075954698026\n",
      "Policy Loss:  -0.014253932982683182\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70047 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.663769115926698e-05\n",
      "Q Loss:  0.0003865625476464629\n",
      "Policy Loss:  0.006329098716378212\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70051 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04201054573059082\n",
      "Value Loss:  4.3948108213953674e-05\n",
      "Q Loss:  6.148811371531337e-05\n",
      "Policy Loss:  0.0029689064249396324\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 70055 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.18937530007679e-05\n",
      "Q Loss:  0.002886607078835368\n",
      "Policy Loss:  0.23567381501197815\n",
      "[(0.00014, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00014 tau*: 0.00011 Episode: 70059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  87.48300170898438\n",
      "Q Loss:  337.4457092285156\n",
      "Policy Loss:  -8.682633399963379\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70126 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.0455608367919922\n",
      "Q Loss:  0.0610831156373024\n",
      "Policy Loss:  -1.1789515018463135\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70180 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.005784354172646999\n",
      "Q Loss:  0.001278440933674574\n",
      "Policy Loss:  0.018835999071598053\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005319595336914\n",
      "Value Loss:  0.0007220933330245316\n",
      "Q Loss:  0.0010586031712591648\n",
      "Policy Loss:  0.005011998116970062\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490107536315918\n",
      "Value Loss:  0.0006223957752808928\n",
      "Q Loss:  0.0003156305756419897\n",
      "Policy Loss:  0.007863840088248253\n",
      "[(0.00015, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00015 tau*: 0.00011 Episode: 70192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  5.921380579820834e-05\n",
      "Q Loss:  0.002867056056857109\n",
      "Policy Loss:  0.22820055484771729\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.36721932888031\n",
      "Q Loss:  0.05222631245851517\n",
      "Policy Loss:  -1.5986247062683105\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70240 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0027355884667485952\n",
      "Q Loss:  0.0032920995727181435\n",
      "Policy Loss:  0.020291289314627647\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00044387017260305583\n",
      "Q Loss:  0.000809520366601646\n",
      "Policy Loss:  5.099852569401264e-05\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70248 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.3940411806106567\n",
      "Q Loss:  0.058814629912376404\n",
      "Policy Loss:  -1.373858094215393\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70291 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0011936163064092398\n",
      "Q Loss:  0.0021846410818398\n",
      "Policy Loss:  0.0007881550118327141\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70295 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0015607556561008096\n",
      "Q Loss:  0.001274595968425274\n",
      "Policy Loss:  -0.003769638016819954\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.596339225769043\n",
      "Q Loss:  0.11254344135522842\n",
      "Policy Loss:  -2.6529648303985596\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70303 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006242752075195\n",
      "Value Loss:  1.9772965908050537\n",
      "Q Loss:  0.062176451086997986\n",
      "Policy Loss:  -1.3806500434875488\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 70332 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  3.1303508281707764\n",
      "Q Loss:  0.030462687835097313\n",
      "Policy Loss:  0.5527088642120361\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70348 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0010795313864946365\n",
      "Q Loss:  0.0007270729402080178\n",
      "Policy Loss:  0.006134173832833767\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0012510953238233924\n",
      "Q Loss:  0.0003260403755120933\n",
      "Policy Loss:  0.007675768807530403\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002573120582383126\n",
      "Q Loss:  0.0010080363135784864\n",
      "Policy Loss:  0.009316465817391872\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012246131896972656\n",
      "Value Loss:  0.0010495109017938375\n",
      "Q Loss:  0.0018123211339116096\n",
      "Policy Loss:  0.03254600614309311\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.0794273614883423\n",
      "Q Loss:  0.026751216500997543\n",
      "Policy Loss:  -1.3153495788574219\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70414 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1463.530517578125\n",
      "Q Loss:  4955.7138671875\n",
      "Policy Loss:  -68.48712158203125\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70418 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.001349523663520813\n",
      "Q Loss:  0.002266271272674203\n",
      "Policy Loss:  0.020202036947011948\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 70422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  1457.774658203125\n",
      "Q Loss:  5602.888671875\n",
      "Policy Loss:  -79.6590347290039\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013975858688354492\n",
      "Value Loss:  0.001582652679644525\n",
      "Q Loss:  0.00214782590046525\n",
      "Policy Loss:  -0.020661626011133194\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0005599168362095952\n",
      "Q Loss:  0.0005044987774454057\n",
      "Policy Loss:  -0.009080834686756134\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00028177243075333536\n",
      "Q Loss:  7.282231672434136e-05\n",
      "Policy Loss:  -0.00499514676630497\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.3562400341033936\n",
      "Q Loss:  0.20496205985546112\n",
      "Policy Loss:  -4.688622951507568\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  186.6167449951172\n",
      "Q Loss:  16.884326934814453\n",
      "Policy Loss:  -25.542726516723633\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70473 length: 31 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04001045227050781\n",
      "Value Loss:  1.105614423751831\n",
      "Q Loss:  0.050568968057632446\n",
      "Policy Loss:  -1.6827507019042969\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70526 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  194.66598510742188\n",
      "Q Loss:  116.26382446289062\n",
      "Policy Loss:  -26.542930603027344\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70585 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  37163.91796875\n",
      "Q Loss:  32450.1640625\n",
      "Policy Loss:  -10.399755477905273\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70608 length: 23 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.9792957305908203\n",
      "Q Loss:  0.06744707375764847\n",
      "Policy Loss:  -1.4800359010696411\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70665 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.6821257472038269\n",
      "Q Loss:  0.23151394724845886\n",
      "Policy Loss:  -2.711275339126587\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.042975902557373\n",
      "Q Loss:  0.3595616817474365\n",
      "Policy Loss:  -4.519709587097168\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 70673 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.1160564422607422\n",
      "Q Loss:  0.007500763982534409\n",
      "Policy Loss:  -0.9235044717788696\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 70716 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  2876.3662109375\n",
      "Q Loss:  5442.6162109375\n",
      "Policy Loss:  -186.88247680664062\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 70720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.000906959583517164\n",
      "Q Loss:  44.01999282836914\n",
      "Policy Loss:  2.29473876953125\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0004319841682445258\n",
      "Q Loss:  0.0004284731112420559\n",
      "Policy Loss:  -0.006747726816684008\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00025581472436897457\n",
      "Q Loss:  0.0002523466246202588\n",
      "Policy Loss:  0.005350642837584019\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70732 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00034804720780812204\n",
      "Q Loss:  0.0007271237554959953\n",
      "Policy Loss:  0.01452688593417406\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05401253700256348\n",
      "Value Loss:  0.00011502718552947044\n",
      "Q Loss:  0.0004679368867073208\n",
      "Policy Loss:  0.006216427776962519\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70740 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  0.00023037692881189287\n",
      "Q Loss:  0.011302751488983631\n",
      "Policy Loss:  0.06216702610254288\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70744 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015946626663208008\n",
      "Value Loss:  0.00012593570863828063\n",
      "Q Loss:  0.009219641797244549\n",
      "Policy Loss:  0.05308707803487778\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 70748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.2264564037323\n",
      "Q Loss:  0.21341130137443542\n",
      "Policy Loss:  -1.2429975271224976\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 70778 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  2.2088115656515583e-05\n",
      "Q Loss:  90.8629379272461\n",
      "Policy Loss:  5.096067428588867\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 70782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  0.00035171647323295474\n",
      "Q Loss:  0.0007017353782430291\n",
      "Policy Loss:  -0.014149264432489872\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.2071692943572998\n",
      "Q Loss:  0.05369795113801956\n",
      "Policy Loss:  -3.3454349040985107\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.6171231269836426\n",
      "Q Loss:  0.010213564150035381\n",
      "Policy Loss:  -1.2260090112686157\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70824 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.4845077859936282e-05\n",
      "Q Loss:  0.0003233292663935572\n",
      "Policy Loss:  -0.0019492810824885964\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  9.712609426060226e-06\n",
      "Q Loss:  0.00027102939202450216\n",
      "Policy Loss:  0.006859315559267998\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0004060632491018623\n",
      "Q Loss:  9.948563092621043e-05\n",
      "Policy Loss:  -0.0038177240639925003\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004375457763672\n",
      "Value Loss:  0.00026238756254315376\n",
      "Q Loss:  0.00021403591381385922\n",
      "Policy Loss:  -0.0023740807082504034\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  113.49016571044922\n",
      "Q Loss:  363.48980712890625\n",
      "Policy Loss:  -10.837246894836426\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 70890 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  6.37314296909608e-05\n",
      "Q Loss:  0.0004945794935338199\n",
      "Policy Loss:  0.008577406406402588\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70894 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04859161376953125\n",
      "Value Loss:  0.00016478699399158359\n",
      "Q Loss:  0.00012490749941207469\n",
      "Policy Loss:  0.0051182946190238\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70898 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00018696569895837456\n",
      "Q Loss:  0.0011516407830640674\n",
      "Policy Loss:  -0.0048493072390556335\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.850477580475854e-06\n",
      "Q Loss:  2.9715725759160705e-05\n",
      "Policy Loss:  -0.007567463908344507\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0014608876081183553\n",
      "Q Loss:  0.0007003318751230836\n",
      "Policy Loss:  0.014512826688587666\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.215998508996563e-05\n",
      "Q Loss:  4.3017385905841365e-05\n",
      "Policy Loss:  -0.0035387107636779547\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  128.24111938476562\n",
      "Q Loss:  0.03773660585284233\n",
      "Policy Loss:  -20.069238662719727\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70958 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1397.5804443359375\n",
      "Q Loss:  44.418678283691406\n",
      "Policy Loss:  -203.7689666748047\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013596057891845703\n",
      "Value Loss:  1393.975341796875\n",
      "Q Loss:  722.6624755859375\n",
      "Policy Loss:  -203.2021942138672\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00021525745978578925\n",
      "Q Loss:  0.00016492183203808963\n",
      "Policy Loss:  -0.011299708858132362\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.195212073274888e-05\n",
      "Q Loss:  1.1753610124287661e-05\n",
      "Policy Loss:  -0.0004973436589352787\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 70974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.244097413495183e-05\n",
      "Q Loss:  2.6636891561793163e-05\n",
      "Policy Loss:  0.001689665368758142\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  3.8699686228937935e-06\n",
      "Q Loss:  9.513158147456124e-05\n",
      "Policy Loss:  0.005852736532688141\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.523807441117242e-05\n",
      "Q Loss:  0.00011594276293180883\n",
      "Policy Loss:  0.004213021136820316\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00028012547409161925\n",
      "Q Loss:  8.20474888314493e-05\n",
      "Policy Loss:  0.0006516696885228157\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00018396573432255536\n",
      "Q Loss:  0.00027818139642477036\n",
      "Policy Loss:  0.00045940722338855267\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  5.625341600534739e-06\n",
      "Q Loss:  0.00016644189599901438\n",
      "Policy Loss:  0.007005743682384491\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 70998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.1390068531036377\n",
      "Q Loss:  0.7147727012634277\n",
      "Policy Loss:  -0.7180615663528442\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2.635222153912764e-05\n",
      "Q Loss:  0.003942740149796009\n",
      "Policy Loss:  0.021791279315948486\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71006 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.5575554966926575\n",
      "Q Loss:  0.33761775493621826\n",
      "Policy Loss:  -1.9798305034637451\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71010 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  4.087701381649822e-05\n",
      "Q Loss:  0.0038960957899689674\n",
      "Policy Loss:  0.020209550857543945\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71014 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.5416358709335327\n",
      "Q Loss:  0.2995394170284271\n",
      "Policy Loss:  -0.9511591196060181\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71018 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.284273624420166\n",
      "Q Loss:  0.11644713580608368\n",
      "Policy Loss:  -1.0062464475631714\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71053 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00011645605263765901\n",
      "Q Loss:  139.60629272460938\n",
      "Policy Loss:  7.080439567565918\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  9.423139272257686e-05\n",
      "Q Loss:  0.009669004939496517\n",
      "Policy Loss:  -0.04981793463230133\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00015054266259539872\n",
      "Q Loss:  0.003919428214430809\n",
      "Policy Loss:  -0.029538283124566078\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  8.100792183540761e-05\n",
      "Q Loss:  0.0018132217228412628\n",
      "Policy Loss:  -0.01827242784202099\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71069 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.2126703950343654e-05\n",
      "Q Loss:  0.0026950102765113115\n",
      "Policy Loss:  -0.01618996448814869\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71073 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.000819713925011456\n",
      "Q Loss:  0.0007239431724883616\n",
      "Policy Loss:  -0.007505491375923157\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71077 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.9566420316696167\n",
      "Q Loss:  0.21308816969394684\n",
      "Policy Loss:  -3.5757248401641846\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71081 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.8677242994308472\n",
      "Q Loss:  0.007062465418130159\n",
      "Policy Loss:  -0.6467293500900269\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71144 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00017406482947990298\n",
      "Q Loss:  0.019112737849354744\n",
      "Policy Loss:  -0.07163412868976593\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.9068190455436707\n",
      "Q Loss:  0.12278468906879425\n",
      "Policy Loss:  -3.7952377796173096\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.3254486322402954\n",
      "Q Loss:  0.23880231380462646\n",
      "Policy Loss:  -3.7297024726867676\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71156 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.133639097213745\n",
      "Q Loss:  0.018506957218050957\n",
      "Policy Loss:  0.7063510417938232\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71174 length: 18 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00035280792508274317\n",
      "Q Loss:  134.08348083496094\n",
      "Policy Loss:  6.918747901916504\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0003832164511550218\n",
      "Q Loss:  0.00941840186715126\n",
      "Policy Loss:  0.0090874545276165\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.5659968741820194e-05\n",
      "Q Loss:  0.005963838193565607\n",
      "Policy Loss:  -0.03749542683362961\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.2775510185747407e-05\n",
      "Q Loss:  0.012341366149485111\n",
      "Policy Loss:  0.1604195535182953\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.7657697796821594\n",
      "Q Loss:  0.23788070678710938\n",
      "Policy Loss:  -1.4110991954803467\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  1.6803463697433472\n",
      "Q Loss:  0.005630889441817999\n",
      "Policy Loss:  -0.42074891924858093\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71228 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  86104.9375\n",
      "Q Loss:  75155.21875\n",
      "Policy Loss:  -57.104732513427734\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71258 length: 30 #teleports:0\n",
      "Got not null reward 3005.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00015768858429510146\n",
      "Q Loss:  42.7227783203125\n",
      "Policy Loss:  2.2508890628814697\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71262 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  7.319640280911699e-05\n",
      "Q Loss:  0.0023413244634866714\n",
      "Policy Loss:  -0.026263564825057983\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71266 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015204668045043945\n",
      "Value Loss:  4.6730448957532644e-05\n",
      "Q Loss:  0.0048086149618029594\n",
      "Policy Loss:  -0.033743105828762054\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.9974051713943481\n",
      "Q Loss:  0.1564655750989914\n",
      "Policy Loss:  -0.7792378664016724\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71302 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00028169917641207576\n",
      "Q Loss:  0.002612202661111951\n",
      "Policy Loss:  0.006736411713063717\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71306 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  0.0001916073524625972\n",
      "Q Loss:  0.0033017497044056654\n",
      "Policy Loss:  -0.02274179458618164\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71310 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.0001347275247098878\n",
      "Q Loss:  0.003416898660361767\n",
      "Policy Loss:  -0.02579805999994278\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71314 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00012807616440113634\n",
      "Q Loss:  4.196027293801308e-05\n",
      "Policy Loss:  -0.0008826095145195723\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71318 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  5.979089473839849e-05\n",
      "Q Loss:  8.222860924433917e-05\n",
      "Policy Loss:  0.006499343551695347\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0001828162930905819\n",
      "Q Loss:  0.0015569967217743397\n",
      "Policy Loss:  0.016919605433940887\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71326 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00018549116794019938\n",
      "Q Loss:  0.0011128917103633285\n",
      "Policy Loss:  0.0037392054218798876\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71330 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001203536987305\n",
      "Value Loss:  0.00018082107999362051\n",
      "Q Loss:  0.000908177113160491\n",
      "Policy Loss:  0.004731115885078907\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001377634471282363\n",
      "Q Loss:  0.0007266720058396459\n",
      "Policy Loss:  -0.0029158121906220913\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71338 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00019166812126059085\n",
      "Q Loss:  0.0017797760665416718\n",
      "Policy Loss:  0.012631796300411224\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300975799560547\n",
      "Value Loss:  0.00018117738363798708\n",
      "Q Loss:  0.0001179735190817155\n",
      "Policy Loss:  -0.0036600648891180754\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71346 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014045953750610352\n",
      "Value Loss:  9.362851415062323e-06\n",
      "Q Loss:  0.0010716685792431235\n",
      "Policy Loss:  -0.013023467734456062\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71350 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0199887752532959\n",
      "Value Loss:  1.1896941661834717\n",
      "Q Loss:  0.07403495162725449\n",
      "Policy Loss:  -1.5705130100250244\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71412 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00029144922154955566\n",
      "Q Loss:  0.0030649788677692413\n",
      "Policy Loss:  -0.0005712818820029497\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400992393493652\n",
      "Value Loss:  7.896640454418957e-05\n",
      "Q Loss:  0.0013955328613519669\n",
      "Policy Loss:  -0.013657691888511181\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.371133283915697e-06\n",
      "Q Loss:  0.0011812668526545167\n",
      "Policy Loss:  -0.009703914634883404\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900315284729004\n",
      "Value Loss:  110.62322235107422\n",
      "Q Loss:  61.7492790222168\n",
      "Policy Loss:  -16.05058479309082\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71477 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00016541199875064194\n",
      "Q Loss:  0.00010912903962889686\n",
      "Policy Loss:  -0.00537142576649785\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.34116899967193604\n",
      "Q Loss:  0.0694630816578865\n",
      "Policy Loss:  -2.0170671939849854\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.5036359400255606e-05\n",
      "Q Loss:  0.06229361891746521\n",
      "Policy Loss:  0.13158655166625977\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.6783680319786072\n",
      "Q Loss:  0.15197403728961945\n",
      "Policy Loss:  -3.1582796573638916\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.6688382625579834\n",
      "Q Loss:  0.14630043506622314\n",
      "Policy Loss:  -3.172856569290161\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.056666410993785e-05\n",
      "Q Loss:  0.0038310785312205553\n",
      "Policy Loss:  0.02672731876373291\n",
      "[(0.00019, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00019 tau*: 0.00011 Episode: 71501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.923516098642722e-05\n",
      "Q Loss:  0.006533331237733364\n",
      "Policy Loss:  0.20564915239810944\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.351646900177002\n",
      "Q Loss:  0.04335653781890869\n",
      "Policy Loss:  -1.149624228477478\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71557 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.3077714145183563\n",
      "Q Loss:  0.06845150142908096\n",
      "Policy Loss:  -1.8890928030014038\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.9047508239746094\n",
      "Q Loss:  0.183195561170578\n",
      "Policy Loss:  -6.105751991271973\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71565 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.727360486984253\n",
      "Q Loss:  0.11124923080205917\n",
      "Policy Loss:  -1.0501620769500732\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71606 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1457.5367431640625\n",
      "Q Loss:  4891.9609375\n",
      "Policy Loss:  -90.4591064453125\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 71610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.00014113198267295957\n",
      "Q Loss:  0.0027086969930678606\n",
      "Policy Loss:  0.014420045539736748\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003770947805605829\n",
      "Q Loss:  0.0012453708332031965\n",
      "Policy Loss:  0.012439580634236336\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002991562068928033\n",
      "Q Loss:  0.003459825413301587\n",
      "Policy Loss:  0.18080353736877441\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.9838104248046875\n",
      "Q Loss:  0.0232254508882761\n",
      "Policy Loss:  -1.069422960281372\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71696 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  5.347416299628094e-05\n",
      "Q Loss:  0.0011582758743315935\n",
      "Policy Loss:  -0.016179252415895462\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.352172714381595e-06\n",
      "Q Loss:  5.883658741367981e-05\n",
      "Policy Loss:  -0.0061666714027523994\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004531860351562\n",
      "Value Loss:  3.6440775147639215e-05\n",
      "Q Loss:  0.003159455955028534\n",
      "Policy Loss:  0.16657786071300507\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71708 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.4871046245098114\n",
      "Q Loss:  0.32135438919067383\n",
      "Policy Loss:  -4.132981300354004\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  1.2201671600341797\n",
      "Q Loss:  5.716130256652832\n",
      "Policy Loss:  0.2926548421382904\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71769 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.869254891877063e-06\n",
      "Q Loss:  0.0029662358574569225\n",
      "Policy Loss:  0.16610002517700195\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.050778865814209\n",
      "Q Loss:  0.023529110476374626\n",
      "Policy Loss:  0.8381403684616089\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71795 length: 22 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1437.2728271484375\n",
      "Q Loss:  0.004273244645446539\n",
      "Policy Loss:  -218.03121948242188\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00020053653861396015\n",
      "Q Loss:  0.001707924879156053\n",
      "Policy Loss:  -0.01442002784460783\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.107972437050194e-05\n",
      "Q Loss:  0.00040278019150719047\n",
      "Policy Loss:  -0.00073579465970397\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0004318089922890067\n",
      "Q Loss:  0.0005423242109827697\n",
      "Policy Loss:  -0.008133988827466965\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71811 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.6013291315175593e-06\n",
      "Q Loss:  0.0005202239262871444\n",
      "Policy Loss:  -0.0003815353265963495\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71815 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900861740112305\n",
      "Value Loss:  0.0005627863574773073\n",
      "Q Loss:  0.00014581218420062214\n",
      "Policy Loss:  -0.005142086651176214\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71819 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033757686614990234\n",
      "Value Loss:  3.744066816580016e-06\n",
      "Q Loss:  3.7085024814587086e-05\n",
      "Policy Loss:  0.0070913126692175865\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71823 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.2625080570578575e-05\n",
      "Q Loss:  8.039010572247207e-05\n",
      "Policy Loss:  0.005768831819295883\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 71827 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000640869140625\n",
      "Value Loss:  1.1252011063334066e-05\n",
      "Q Loss:  0.006375037133693695\n",
      "Policy Loss:  0.025452714413404465\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 71831 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.1732899110938888e-05\n",
      "Q Loss:  0.006634381599724293\n",
      "Policy Loss:  0.023142609745264053\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 71835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  2.7791191314463504e-05\n",
      "Q Loss:  0.01791566237807274\n",
      "Policy Loss:  0.06855788826942444\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 71839 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  66672.171875\n",
      "Q Loss:  57720.65234375\n",
      "Policy Loss:  -124.22409057617188\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71852 length: 13 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.8727003335952759\n",
      "Q Loss:  0.011392542161047459\n",
      "Policy Loss:  -0.2640032470226288\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71888 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  5.6315649999305606e-05\n",
      "Q Loss:  0.006997957359999418\n",
      "Policy Loss:  0.0343908965587616\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.5132128596305847\n",
      "Q Loss:  0.11494453251361847\n",
      "Policy Loss:  -2.5101888179779053\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  7.24678102415055e-05\n",
      "Q Loss:  0.0019399053417146206\n",
      "Policy Loss:  0.013118719682097435\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019005298614501953\n",
      "Value Loss:  1.4054272174835205\n",
      "Q Loss:  0.02651854231953621\n",
      "Policy Loss:  -0.6402238011360168\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 71948 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.6966189327358734e-06\n",
      "Q Loss:  0.0009707733988761902\n",
      "Policy Loss:  0.012175396084785461\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  5.797749508928973e-06\n",
      "Q Loss:  0.0015581885818392038\n",
      "Policy Loss:  0.015422669239342213\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.5729612641735002e-05\n",
      "Q Loss:  0.21205396950244904\n",
      "Policy Loss:  0.018372144550085068\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 71960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.5093940496444702\n",
      "Q Loss:  0.03350217267870903\n",
      "Policy Loss:  -0.8131510019302368\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 72005 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0003493934345897287\n",
      "Q Loss:  0.01291629858314991\n",
      "Policy Loss:  0.056457169353961945\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 72009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0005115003441460431\n",
      "Q Loss:  0.0006458102725446224\n",
      "Policy Loss:  0.016062380746006966\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 72013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.998154013766907e-05\n",
      "Q Loss:  0.0019678303506225348\n",
      "Policy Loss:  0.022130649536848068\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 72017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.658881425857544\n",
      "Q Loss:  0.012119486927986145\n",
      "Policy Loss:  0.3994618058204651\n",
      "[(0.00021, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00021 tau*: 0.00011 Episode: 72041 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  47359.265625\n",
      "Q Loss:  41056.55078125\n",
      "Policy Loss:  -4.941410064697266\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 72059 length: 18 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00033617831650190055\n",
      "Q Loss:  41.76275634765625\n",
      "Policy Loss:  2.2619776725769043\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 72063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0001574606285430491\n",
      "Q Loss:  0.00021090095106046647\n",
      "Policy Loss:  -0.00032163242576643825\n",
      "[(0.00022, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00022 tau*: 0.00011 Episode: 72067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0001709290372673422\n",
      "Q Loss:  0.0002922076964750886\n",
      "Policy Loss:  0.0006241470109671354\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00014174586976878345\n",
      "Q Loss:  0.0025797130074352026\n",
      "Policy Loss:  0.013556056655943394\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.6735782027244568\n",
      "Q Loss:  0.08628813922405243\n",
      "Policy Loss:  -3.2607779502868652\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  1.6214699745178223\n",
      "Q Loss:  0.010443366132676601\n",
      "Policy Loss:  -0.5828296542167664\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72117 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1.685427014308516e-05\n",
      "Q Loss:  0.00015182426432147622\n",
      "Policy Loss:  0.008330618031322956\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014651060104370117\n",
      "Value Loss:  1.2555391549540218e-05\n",
      "Q Loss:  0.00010371528333052993\n",
      "Policy Loss:  0.005125886760652065\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  3.037567512365058e-05\n",
      "Q Loss:  3.22825217153877e-05\n",
      "Policy Loss:  0.0031506225932389498\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  20865.9375\n",
      "Q Loss:  18578.1015625\n",
      "Policy Loss:  -12.018714904785156\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72170 length: 41 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  6.620358908548951e-05\n",
      "Q Loss:  41.57426071166992\n",
      "Policy Loss:  2.2466087341308594\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72174 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0009123339550569654\n",
      "Q Loss:  0.00031406572088599205\n",
      "Policy Loss:  0.005754365120083094\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.6966164771001786e-05\n",
      "Q Loss:  83.05447387695312\n",
      "Policy Loss:  4.457644462585449\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07301616668701172\n",
      "Value Loss:  5.288574902806431e-05\n",
      "Q Loss:  0.0007300797733478248\n",
      "Policy Loss:  0.014081883244216442\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.4589608326787129e-05\n",
      "Q Loss:  5.316704846336506e-05\n",
      "Policy Loss:  -0.0029982279520481825\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00012674395111389458\n",
      "Q Loss:  0.0006497973809018731\n",
      "Policy Loss:  0.004641283769160509\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0007139410590752959\n",
      "Q Loss:  0.00016363075701519847\n",
      "Policy Loss:  0.003386902855709195\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  0.0001226741587743163\n",
      "Q Loss:  0.0008043281850405037\n",
      "Policy Loss:  -0.009442348033189774\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00013197274529375136\n",
      "Q Loss:  0.0005725675146095455\n",
      "Policy Loss:  -0.01640971750020981\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72206 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.212773976381868e-05\n",
      "Q Loss:  0.0003073581028729677\n",
      "Policy Loss:  -0.009452683851122856\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72210 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  4.6328234020620584e-05\n",
      "Q Loss:  0.0004902121727354825\n",
      "Policy Loss:  -0.012267550453543663\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.3699263632297516\n",
      "Q Loss:  0.1293952912092209\n",
      "Policy Loss:  -1.949531078338623\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72218 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.9885499477386475\n",
      "Q Loss:  0.0443938784301281\n",
      "Policy Loss:  -0.6735019087791443\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72279 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00016912276623770595\n",
      "Q Loss:  0.00041860120836645365\n",
      "Policy Loss:  -0.011850635521113873\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00024010099878069013\n",
      "Q Loss:  0.0008243115153163671\n",
      "Policy Loss:  -0.012622734531760216\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72287 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.36863118410110474\n",
      "Q Loss:  0.04645339399576187\n",
      "Policy Loss:  -2.0410239696502686\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72291 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04301023483276367\n",
      "Value Loss:  184.1324462890625\n",
      "Q Loss:  9.155096054077148\n",
      "Policy Loss:  -24.620603561401367\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72326 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.6151989698410034\n",
      "Q Loss:  0.05428557097911835\n",
      "Policy Loss:  -1.3039554357528687\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72367 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  1597.440185546875\n",
      "Q Loss:  0.0028936020098626614\n",
      "Policy Loss:  -229.92355346679688\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00019137228082399815\n",
      "Q Loss:  0.0001093230239348486\n",
      "Policy Loss:  0.007580092176795006\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  3.908328653778881e-05\n",
      "Q Loss:  0.0006633931770920753\n",
      "Policy Loss:  0.18450982868671417\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.9708431363105774\n",
      "Q Loss:  0.025483760982751846\n",
      "Policy Loss:  -1.0701630115509033\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72447 length: 68 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03700900077819824\n",
      "Value Loss:  0.0003120247565675527\n",
      "Q Loss:  0.0002412326430203393\n",
      "Policy Loss:  0.010550160892307758\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00015371970948763192\n",
      "Q Loss:  3.563193968147971e-05\n",
      "Policy Loss:  0.0010305950418114662\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.2072033882141113\n",
      "Q Loss:  0.04615752398967743\n",
      "Policy Loss:  -0.8693998456001282\n",
      "[(0.00023, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00023 tau*: 0.00011 Episode: 72507 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013391971588134766\n",
      "Value Loss:  1581.989501953125\n",
      "Q Loss:  946.8311767578125\n",
      "Policy Loss:  -196.51710510253906\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  3.1232397304847836e-05\n",
      "Q Loss:  0.00022204738343134522\n",
      "Policy Loss:  0.00542808510363102\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00024538443540222943\n",
      "Q Loss:  0.0002570975630078465\n",
      "Policy Loss:  0.0034305935259908438\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001967110438272357\n",
      "Q Loss:  0.0006442731246352196\n",
      "Policy Loss:  0.006976936012506485\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00025577237829566\n",
      "Q Loss:  0.0005879945820197463\n",
      "Policy Loss:  0.017018785700201988\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.8787840604782104\n",
      "Q Loss:  2.3418023586273193\n",
      "Policy Loss:  -0.42533236742019653\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72596 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  2.970501736854203e-05\n",
      "Q Loss:  0.0002532021899241954\n",
      "Policy Loss:  0.0067990864627063274\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  153.39451599121094\n",
      "Q Loss:  3.992988348007202\n",
      "Policy Loss:  -22.093265533447266\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72641 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  9.808967297431082e-05\n",
      "Q Loss:  0.0050188819877803326\n",
      "Policy Loss:  0.024433061480522156\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00011098575487267226\n",
      "Q Loss:  0.005388617515563965\n",
      "Policy Loss:  0.21760079264640808\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.8933961391448975\n",
      "Q Loss:  0.04073468595743179\n",
      "Policy Loss:  -1.6127548217773438\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72733 length: 84 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00018595797882881016\n",
      "Q Loss:  0.00012288667494431138\n",
      "Policy Loss:  0.0036156661808490753\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500771522521973\n",
      "Value Loss:  0.00028764622402377427\n",
      "Q Loss:  0.0007443712675012648\n",
      "Policy Loss:  0.013061673380434513\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0004314687685109675\n",
      "Q Loss:  0.00025638932129368186\n",
      "Policy Loss:  -0.0018127107759937644\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72745 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.570783054688945e-05\n",
      "Q Loss:  0.00019123824313282967\n",
      "Policy Loss:  0.006818406283855438\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 72749 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.1295742988586426\n",
      "Q Loss:  0.10830911248922348\n",
      "Policy Loss:  -0.8222105503082275\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 72781 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  8.049444295465946e-05\n",
      "Q Loss:  0.00017400170327164233\n",
      "Policy Loss:  -8.978787809610367e-05\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 72785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.274999496876262e-05\n",
      "Q Loss:  0.0010474734008312225\n",
      "Policy Loss:  0.20257145166397095\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 72789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  22513.205078125\n",
      "Q Loss:  19876.08984375\n",
      "Policy Loss:  -20.38495445251465\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 72827 length: 38 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.3376153707504272\n",
      "Q Loss:  0.3488973379135132\n",
      "Policy Loss:  -3.8004913330078125\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72831 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  1.0220695912721567e-05\n",
      "Q Loss:  0.008391328155994415\n",
      "Policy Loss:  0.040984924882650375\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72835 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015005350112915039\n",
      "Value Loss:  0.43441322445869446\n",
      "Q Loss:  0.15103232860565186\n",
      "Policy Loss:  -2.0311360359191895\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72839 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.7203197280177847e-05\n",
      "Q Loss:  0.0028400339651852846\n",
      "Policy Loss:  0.22275519371032715\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72843 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0180051326751709\n",
      "Value Loss:  8.320833206176758\n",
      "Q Loss:  0.060686513781547546\n",
      "Policy Loss:  19.464576721191406\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 72850 length: 7 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  0.0008104125154204667\n",
      "Q Loss:  0.002097579650580883\n",
      "Policy Loss:  0.026521306484937668\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.001502220518887043\n",
      "Q Loss:  0.0002832889440469444\n",
      "Policy Loss:  -0.0005369849968701601\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015155792236328125\n",
      "Value Loss:  7.26205762475729e-05\n",
      "Q Loss:  0.0006520230090245605\n",
      "Policy Loss:  0.2010553479194641\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.9014115333557129\n",
      "Q Loss:  0.5432280898094177\n",
      "Policy Loss:  -5.502861022949219\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.9017537832260132\n",
      "Q Loss:  0.23469692468643188\n",
      "Policy Loss:  -3.752078056335449\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.0383970737457275\n",
      "Q Loss:  0.03756316751241684\n",
      "Policy Loss:  -0.5017907619476318\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72899 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0009705832926556468\n",
      "Q Loss:  0.0025316006503999233\n",
      "Policy Loss:  -0.02310773730278015\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72903 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  0.013154854066669941\n",
      "Q Loss:  0.004983364604413509\n",
      "Policy Loss:  -0.03280624747276306\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72907 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015596151351928711\n",
      "Value Loss:  3.5073651815764606e-05\n",
      "Q Loss:  0.002341835293918848\n",
      "Policy Loss:  0.0154249407351017\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.4386023283004761\n",
      "Q Loss:  0.3856023848056793\n",
      "Policy Loss:  -3.040489435195923\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.9525678157806396\n",
      "Q Loss:  0.10578931123018265\n",
      "Policy Loss:  -1.0958340167999268\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72949 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.001743266941048205\n",
      "Q Loss:  0.0004384400090202689\n",
      "Policy Loss:  0.2358066737651825\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72953 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  1.447901964187622\n",
      "Q Loss:  0.023004261776804924\n",
      "Policy Loss:  -0.7527093887329102\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72993 length: 40 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0066438340581953526\n",
      "Q Loss:  0.010850640945136547\n",
      "Policy Loss:  0.052551742643117905\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 72997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0017498258966952562\n",
      "Q Loss:  0.0003504405030980706\n",
      "Policy Loss:  0.21113166213035583\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 73001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.266459345817566\n",
      "Q Loss:  0.03517571836709976\n",
      "Policy Loss:  -0.8543643355369568\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73048 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  0.00021049259521532804\n",
      "Q Loss:  0.00028917015879414976\n",
      "Policy Loss:  0.19008329510688782\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73052 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.7374907732009888\n",
      "Q Loss:  5.559875011444092\n",
      "Policy Loss:  -0.37263423204421997\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73142 length: 90 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.294791218242608e-05\n",
      "Q Loss:  0.0007121776579879224\n",
      "Policy Loss:  -0.011970242485404015\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.002298542531207204\n",
      "Q Loss:  0.0029905608389526606\n",
      "Policy Loss:  -0.028897423297166824\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00022116117179393768\n",
      "Q Loss:  0.07283023744821548\n",
      "Policy Loss:  0.12204596400260925\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73154 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.4457198977470398\n",
      "Q Loss:  0.15303385257720947\n",
      "Policy Loss:  -1.7509429454803467\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.3334136009216309\n",
      "Q Loss:  0.2584931552410126\n",
      "Policy Loss:  -4.670586109161377\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 73162 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  1.304915189743042\n",
      "Q Loss:  0.24535170197486877\n",
      "Policy Loss:  -4.37743616104126\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.5404624938964844\n",
      "Q Loss:  0.028890786692500114\n",
      "Policy Loss:  1.0658330917358398\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73182 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00013743901217821985\n",
      "Q Loss:  0.00027740822406485677\n",
      "Policy Loss:  -0.0035316029097884893\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  8.138404518831521e-05\n",
      "Q Loss:  0.00023732849513180554\n",
      "Policy Loss:  0.00966719165444374\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.002948074834421277\n",
      "Q Loss:  0.001956529449671507\n",
      "Policy Loss:  0.20701728761196136\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03800821304321289\n",
      "Value Loss:  2.825329542160034\n",
      "Q Loss:  0.03585837036371231\n",
      "Policy Loss:  0.36655861139297485\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73215 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00010026326344814152\n",
      "Q Loss:  0.0011743917129933834\n",
      "Policy Loss:  0.01949479803442955\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00022023878409527242\n",
      "Q Loss:  0.0014770171837881207\n",
      "Policy Loss:  0.018513083457946777\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.00024889796623028815\n",
      "Q Loss:  0.00038160060648806393\n",
      "Policy Loss:  0.007351520471274853\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.3916330337524414\n",
      "Q Loss:  0.3068031668663025\n",
      "Policy Loss:  -2.903900384902954\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.1670422554016113\n",
      "Q Loss:  0.2089511752128601\n",
      "Policy Loss:  -3.330639123916626\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.37961798906326294\n",
      "Q Loss:  0.14533500373363495\n",
      "Policy Loss:  -2.6072516441345215\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.2204669221537188e-05\n",
      "Q Loss:  0.005777023267000914\n",
      "Policy Loss:  0.024872269481420517\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0008488866151310503\n",
      "Q Loss:  0.006047831382602453\n",
      "Policy Loss:  -0.004146263003349304\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0016975824255496264\n",
      "Q Loss:  0.002309354953467846\n",
      "Policy Loss:  -0.012297088280320168\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.030303716659546\n",
      "Q Loss:  0.07232167571783066\n",
      "Policy Loss:  -2.5582451820373535\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.1832995414733887\n",
      "Q Loss:  0.06793329119682312\n",
      "Policy Loss:  -1.538556456565857\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73323 length: 68 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0011173912789672613\n",
      "Q Loss:  0.0006772128399461508\n",
      "Policy Loss:  -0.02166210673749447\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73327 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.174553032498807e-05\n",
      "Q Loss:  0.0005581158329732716\n",
      "Policy Loss:  -0.00943915918469429\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73331 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.5983988642692566\n",
      "Q Loss:  0.1662854701280594\n",
      "Policy Loss:  -2.185772180557251\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73335 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.107491374015808\n",
      "Q Loss:  0.02730714902281761\n",
      "Policy Loss:  -0.7959561347961426\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73398 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0003995309816673398\n",
      "Q Loss:  41.50651168823242\n",
      "Policy Loss:  2.2350268363952637\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00037378480192273855\n",
      "Q Loss:  41.38146209716797\n",
      "Policy Loss:  2.2238597869873047\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 73406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015098220319487154\n",
      "Q Loss:  0.001653084415011108\n",
      "Policy Loss:  -0.020832659676671028\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73410 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03925156593322754\n",
      "Value Loss:  0.0005652150139212608\n",
      "Q Loss:  0.00041070542647503316\n",
      "Policy Loss:  0.010230489075183868\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73414 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00033373688347637653\n",
      "Q Loss:  0.0003757934900932014\n",
      "Policy Loss:  -0.001290253596380353\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73418 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0010354159167036414\n",
      "Q Loss:  0.005768351722508669\n",
      "Policy Loss:  0.011355806142091751\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.000767299032304436\n",
      "Q Loss:  0.0004828428500331938\n",
      "Policy Loss:  -0.016527168452739716\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  0.235181987285614\n",
      "Q Loss:  0.13923780620098114\n",
      "Policy Loss:  -1.8675596714019775\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.9196690917015076\n",
      "Q Loss:  0.0127637954428792\n",
      "Policy Loss:  -2.3040668964385986\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  1.18408203125\n",
      "Q Loss:  0.02820269763469696\n",
      "Policy Loss:  -0.3163776099681854\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73492 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.3732553017907776e-05\n",
      "Q Loss:  0.004265682306140661\n",
      "Policy Loss:  0.017741134390234947\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73496 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.8283910751342773\n",
      "Q Loss:  0.011467991396784782\n",
      "Policy Loss:  0.7669302821159363\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73520 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0007038653129711747\n",
      "Q Loss:  0.0008838732610456645\n",
      "Policy Loss:  0.003619034308940172\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73524 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.965278387069702\n",
      "Q Loss:  6.955737113952637\n",
      "Policy Loss:  2.6321256160736084\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73547 length: 23 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02600574493408203\n",
      "Value Loss:  0.0007757643470540643\n",
      "Q Loss:  0.0014180027646943927\n",
      "Policy Loss:  -0.018039757385849953\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0006459156866185367\n",
      "Q Loss:  0.0011311022099107504\n",
      "Policy Loss:  -5.384255200624466e-05\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0005493580247275531\n",
      "Q Loss:  0.00992219615727663\n",
      "Policy Loss:  -0.05469512194395065\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00014319115143734962\n",
      "Q Loss:  0.004683039616793394\n",
      "Policy Loss:  -0.006161728408187628\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73563 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.00015219835040625185\n",
      "Q Loss:  0.0006498664151877165\n",
      "Policy Loss:  -0.015426738187670708\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73567 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015586614608764648\n",
      "Value Loss:  116.90296173095703\n",
      "Q Loss:  402.2386474609375\n",
      "Policy Loss:  -10.460006713867188\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73621 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014820337295532227\n",
      "Value Loss:  0.0005807465058751404\n",
      "Q Loss:  0.00028687663143500686\n",
      "Policy Loss:  0.013573866337537766\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73625 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0004773140244651586\n",
      "Q Loss:  0.0007857722230255604\n",
      "Policy Loss:  -0.014222297817468643\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  256.1517639160156\n",
      "Q Loss:  1012.5713500976562\n",
      "Policy Loss:  -17.040910720825195\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73678 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1559.25\n",
      "Q Loss:  5381.13818359375\n",
      "Policy Loss:  -92.4080581665039\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 73682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00026537140365689993\n",
      "Q Loss:  0.0008600774453952909\n",
      "Policy Loss:  0.011091483756899834\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0001043300362653099\n",
      "Q Loss:  2.3668526409892365e-05\n",
      "Policy Loss:  -0.0007332807872444391\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  6.813973595853895e-05\n",
      "Q Loss:  0.0022866372019052505\n",
      "Policy Loss:  0.018843553960323334\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  0.9310464262962341\n",
      "Q Loss:  0.036445826292037964\n",
      "Policy Loss:  -0.8989027142524719\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73777 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00011913527850992978\n",
      "Q Loss:  0.00029575100052170455\n",
      "Policy Loss:  0.005240974016487598\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73781 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00017021945677697659\n",
      "Q Loss:  0.001953138504177332\n",
      "Policy Loss:  0.012194898910820484\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00010539516370045021\n",
      "Q Loss:  0.0382540188729763\n",
      "Policy Loss:  0.26217523217201233\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.9316686391830444\n",
      "Q Loss:  0.022032126784324646\n",
      "Policy Loss:  -0.2871547341346741\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73825 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.0067976713180542\n",
      "Q Loss:  0.020678436383605003\n",
      "Policy Loss:  -0.49242255091667175\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73892 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  15734.376953125\n",
      "Q Loss:  13627.1572265625\n",
      "Policy Loss:  -12.074566841125488\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73946 length: 54 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.25097915530204773\n",
      "Q Loss:  0.14021091163158417\n",
      "Policy Loss:  -0.6330788135528564\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 73950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.0925540924072266\n",
      "Q Loss:  2.495242118835449\n",
      "Policy Loss:  -0.2376607209444046\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74013 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  5.860583041794598e-05\n",
      "Q Loss:  0.0015309895388782024\n",
      "Policy Loss:  -0.002887340961024165\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.000248285272391513\n",
      "Q Loss:  0.00020815391326323152\n",
      "Policy Loss:  -0.00813262164592743\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012978076934814453\n",
      "Value Loss:  0.26461583375930786\n",
      "Q Loss:  0.014310554601252079\n",
      "Policy Loss:  -1.6202573776245117\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  6.300961494445801\n",
      "Q Loss:  0.0020819492638111115\n",
      "Policy Loss:  5.971822261810303\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74035 length: 10 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  300.98968505859375\n",
      "Q Loss:  851.5027465820312\n",
      "Policy Loss:  -31.64297866821289\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74117 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.369381904602051\n",
      "Q Loss:  0.008321384899318218\n",
      "Policy Loss:  -0.057062942534685135\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74144 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014654397964477539\n",
      "Value Loss:  1.5209299325942993\n",
      "Q Loss:  3.5636250972747803\n",
      "Policy Loss:  -0.06148751452565193\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74188 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  213.34445190429688\n",
      "Q Loss:  415.58343505859375\n",
      "Policy Loss:  -24.520862579345703\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74246 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.00038557715015485883\n",
      "Q Loss:  0.002927294699475169\n",
      "Policy Loss:  -0.003936572931706905\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  4.998349322704598e-05\n",
      "Q Loss:  0.0005911387270316482\n",
      "Policy Loss:  0.013879526406526566\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  6.875451799714938e-05\n",
      "Q Loss:  5.3832201956538484e-05\n",
      "Policy Loss:  0.002510222140699625\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74258 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  2.591156771813985e-05\n",
      "Q Loss:  0.0037400820292532444\n",
      "Policy Loss:  -0.029583431780338287\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74262 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.880190372467041\n",
      "Q Loss:  0.04094744846224785\n",
      "Policy Loss:  -1.1433112621307373\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74337 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  14857.2548828125\n",
      "Q Loss:  12838.373046875\n",
      "Policy Loss:  -32.94342803955078\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74395 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00014134451339486986\n",
      "Q Loss:  0.00040996604366227984\n",
      "Policy Loss:  0.014864123426377773\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74399 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  152.97645568847656\n",
      "Q Loss:  560.8099975585938\n",
      "Policy Loss:  -10.964529991149902\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74480 length: 81 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.4103590250015259\n",
      "Q Loss:  0.43003156781196594\n",
      "Policy Loss:  -3.134899854660034\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74484 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  1.5542421340942383\n",
      "Q Loss:  0.04139997437596321\n",
      "Policy Loss:  -1.6437468528747559\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74528 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  8.75303812790662e-05\n",
      "Q Loss:  0.00017338377074338496\n",
      "Policy Loss:  0.009333035908639431\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.6689535186742432e-05\n",
      "Q Loss:  0.004834883380681276\n",
      "Policy Loss:  0.05849157273769379\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74536 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.8569978475570679\n",
      "Q Loss:  0.2058538794517517\n",
      "Policy Loss:  -2.0837318897247314\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.1366558074951172\n",
      "Q Loss:  3.137418270111084\n",
      "Policy Loss:  -0.3075065314769745\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74591 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1546.228271484375\n",
      "Q Loss:  0.004410596564412117\n",
      "Policy Loss:  -225.95855712890625\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00011135370004922152\n",
      "Q Loss:  0.00036025448935106397\n",
      "Policy Loss:  0.010209488682448864\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.316451304475777e-05\n",
      "Q Loss:  0.0003819889680016786\n",
      "Policy Loss:  0.007846507243812084\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04501056671142578\n",
      "Value Loss:  7.791937969159335e-05\n",
      "Q Loss:  0.022305086255073547\n",
      "Policy Loss:  0.08083344250917435\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  215.02734375\n",
      "Q Loss:  120.64153289794922\n",
      "Policy Loss:  -30.612014770507812\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74693 length: 86 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01196146011352539\n",
      "Value Loss:  32674.341796875\n",
      "Q Loss:  28171.01953125\n",
      "Policy Loss:  -17.58742904663086\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74719 length: 26 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.8691239953041077\n",
      "Q Loss:  0.08446140587329865\n",
      "Policy Loss:  -2.9979727268218994\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 74723 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.2984304428100586\n",
      "Q Loss:  0.4518507719039917\n",
      "Policy Loss:  -5.088131904602051\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74727 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.7013935446739197\n",
      "Q Loss:  0.014205703511834145\n",
      "Policy Loss:  -0.3595150113105774\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74805 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  51445.57421875\n",
      "Q Loss:  44413.51953125\n",
      "Policy Loss:  -21.432357788085938\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74838 length: 33 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  165.74542236328125\n",
      "Q Loss:  557.31005859375\n",
      "Policy Loss:  -13.998652458190918\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74876 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.432496542809531e-05\n",
      "Q Loss:  0.0002895080833695829\n",
      "Policy Loss:  0.007575905416160822\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  487.8810119628906\n",
      "Q Loss:  825.9550170898438\n",
      "Policy Loss:  -52.05648422241211\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74919 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  91.74109649658203\n",
      "Q Loss:  0.08861382305622101\n",
      "Policy Loss:  -14.092470169067383\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 74989 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.4834892749786377\n",
      "Q Loss:  0.03399317339062691\n",
      "Policy Loss:  0.01752461865544319\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75012 length: 23 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.4115447998046875\n",
      "Q Loss:  0.06197270005941391\n",
      "Policy Loss:  -1.548832654953003\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.3248913288116455\n",
      "Q Loss:  0.08139331638813019\n",
      "Policy Loss:  -0.12629830837249756\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75044 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  202.56675720214844\n",
      "Q Loss:  404.0473937988281\n",
      "Policy Loss:  -20.09148406982422\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75108 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1615.806396484375\n",
      "Q Loss:  6354.00830078125\n",
      "Policy Loss:  -94.90625762939453\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002515447558835149\n",
      "Q Loss:  0.0009153918945230544\n",
      "Policy Loss:  0.003634839551523328\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75116 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.449255645042285e-05\n",
      "Q Loss:  0.03949931636452675\n",
      "Policy Loss:  0.056098777800798416\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.8606534004211426\n",
      "Q Loss:  0.25785496830940247\n",
      "Policy Loss:  -0.9156666994094849\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.8554311990737915\n",
      "Q Loss:  0.538429319858551\n",
      "Policy Loss:  -2.1766035556793213\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  32528.25390625\n",
      "Q Loss:  27956.310546875\n",
      "Policy Loss:  -22.330678939819336\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75154 length: 26 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00018389453180134296\n",
      "Q Loss:  0.001528767985291779\n",
      "Policy Loss:  0.017755234614014626\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.44023239146918e-05\n",
      "Q Loss:  0.00036536058178171515\n",
      "Policy Loss:  -0.001020127208903432\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75162 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.4662225112260785e-05\n",
      "Q Loss:  0.0001689022028585896\n",
      "Policy Loss:  -0.006310497410595417\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.6126607079058886e-05\n",
      "Q Loss:  0.00021327266586013138\n",
      "Policy Loss:  -0.0035253686364740133\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75170 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.915185804245993e-05\n",
      "Q Loss:  0.00045513344230130315\n",
      "Policy Loss:  -0.013252553530037403\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75174 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03651118278503418\n",
      "Value Loss:  5.766103640780784e-05\n",
      "Q Loss:  0.000720015203114599\n",
      "Policy Loss:  0.004633669275790453\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  29110.982421875\n",
      "Q Loss:  25136.75390625\n",
      "Policy Loss:  -18.313762664794922\n",
      "[(0.00029, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00029 tau*: 0.00011 Episode: 75207 length: 29 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  3315.423828125\n",
      "Q Loss:  6461.8251953125\n",
      "Policy Loss:  -200.86827087402344\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00011003980762325227\n",
      "Q Loss:  8.54976533446461e-05\n",
      "Policy Loss:  -0.0018634590087458491\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0001031784777296707\n",
      "Q Loss:  3.3584881748538464e-05\n",
      "Policy Loss:  -0.002959905657917261\n",
      "[(0.00027, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00027 tau*: 0.00011 Episode: 75219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015644073486328125\n",
      "Value Loss:  7.709048077231273e-06\n",
      "Q Loss:  0.005224599968641996\n",
      "Policy Loss:  0.23785433173179626\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 75223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.8146297931671143\n",
      "Q Loss:  0.40014392137527466\n",
      "Policy Loss:  -2.7239041328430176\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 75227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  329.147705078125\n",
      "Q Loss:  838.62109375\n",
      "Policy Loss:  -37.26423263549805\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 75328 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  6.779244358767755e-06\n",
      "Q Loss:  0.0027801005635410547\n",
      "Policy Loss:  0.03280239552259445\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 75332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.037007808685302734\n",
      "Value Loss:  0.39792895317077637\n",
      "Q Loss:  0.021850761026144028\n",
      "Policy Loss:  -1.8865864276885986\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 75336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2820818424224854\n",
      "Q Loss:  0.0033459365367889404\n",
      "Policy Loss:  -0.5859652161598206\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 75381 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03900957107543945\n",
      "Value Loss:  8.698630699655041e-05\n",
      "Q Loss:  0.01025997195392847\n",
      "Policy Loss:  -0.039960555732250214\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 75385 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00022328892373479903\n",
      "Q Loss:  0.01098615676164627\n",
      "Policy Loss:  -0.040707945823669434\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75389 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.988920666917693e-05\n",
      "Q Loss:  0.004335243254899979\n",
      "Policy Loss:  -0.013605711050331593\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00011035738134523854\n",
      "Q Loss:  0.0002047652524197474\n",
      "Policy Loss:  -0.003258147044107318\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.106339035090059e-05\n",
      "Q Loss:  0.00011297861055936664\n",
      "Policy Loss:  0.008159618824720383\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801130294799805\n",
      "Value Loss:  1.0236926755169407e-05\n",
      "Q Loss:  0.00040622722008265555\n",
      "Policy Loss:  0.00553045654669404\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002012252807617\n",
      "Value Loss:  1.6962538893494639e-06\n",
      "Q Loss:  0.00017062175902538002\n",
      "Policy Loss:  0.009103057906031609\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75409 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  5.8146510127699e-05\n",
      "Q Loss:  0.0002553150989115238\n",
      "Policy Loss:  0.0004945430555380881\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75413 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  1.1471949619590305e-05\n",
      "Q Loss:  0.0004038764163851738\n",
      "Policy Loss:  0.00800522230565548\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  2.9703994641749887e-06\n",
      "Q Loss:  0.0007083641830831766\n",
      "Policy Loss:  0.20304007828235626\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.525052547454834\n",
      "Q Loss:  0.22614867985248566\n",
      "Policy Loss:  -4.748025417327881\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  3.363962411880493\n",
      "Q Loss:  0.007622998673468828\n",
      "Policy Loss:  1.047945499420166\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75442 length: 17 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0001395953440805897\n",
      "Q Loss:  6.071982716093771e-05\n",
      "Policy Loss:  -0.0026410084683448076\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.3668097257614136\n",
      "Q Loss:  0.04463227093219757\n",
      "Policy Loss:  -0.2957767844200134\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75488 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.002009750809520483\n",
      "Q Loss:  0.032981809228658676\n",
      "Policy Loss:  0.0539519339799881\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75492 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.0001675039529800415\n",
      "Q Loss:  0.030864445492625237\n",
      "Policy Loss:  0.04738227277994156\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75496 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0003656884655356407\n",
      "Q Loss:  0.0019374230178073049\n",
      "Policy Loss:  0.009903894737362862\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75500 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  0.0007108980789780617\n",
      "Q Loss:  0.028447384014725685\n",
      "Policy Loss:  0.041714370250701904\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75504 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0012973188422620296\n",
      "Q Loss:  0.0037680461537092924\n",
      "Policy Loss:  -0.030399411916732788\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75508 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  4.7181685658870265e-05\n",
      "Q Loss:  0.0029057986102998257\n",
      "Policy Loss:  -0.02500597946345806\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75512 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.6573019567877054e-05\n",
      "Q Loss:  0.00047995816566981375\n",
      "Policy Loss:  0.18339064717292786\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75516 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  162.6943817138672\n",
      "Q Loss:  540.3462524414062\n",
      "Policy Loss:  -14.355231285095215\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75557 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  5.785323810414411e-05\n",
      "Q Loss:  0.002777199726551771\n",
      "Policy Loss:  -0.024602141231298447\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  3.969098179368302e-05\n",
      "Q Loss:  0.002643430605530739\n",
      "Policy Loss:  -0.029191261157393456\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75565 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.4299232134362683e-05\n",
      "Q Loss:  0.003046872094273567\n",
      "Policy Loss:  -0.02906797081232071\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75569 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00018003321019932628\n",
      "Q Loss:  0.0017458726651966572\n",
      "Policy Loss:  -0.020353039726614952\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75573 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  6.179655611049384e-05\n",
      "Q Loss:  0.003677499247714877\n",
      "Policy Loss:  -0.021908365190029144\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75577 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04301023483276367\n",
      "Value Loss:  3.281094541307539e-05\n",
      "Q Loss:  0.006875914987176657\n",
      "Policy Loss:  -0.03747262433171272\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75581 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.3925568055128679e-05\n",
      "Q Loss:  5.091783532407135e-05\n",
      "Policy Loss:  0.00030118520953692496\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75585 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.00013324673636816442\n",
      "Q Loss:  0.0017100051045417786\n",
      "Policy Loss:  0.025089461356401443\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  8.468099986203015e-05\n",
      "Q Loss:  4.323355824453756e-05\n",
      "Policy Loss:  0.004317791201174259\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  160.20907592773438\n",
      "Q Loss:  382.46142578125\n",
      "Policy Loss:  -17.927724838256836\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75717 length: 124 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  5.970468919258565e-06\n",
      "Q Loss:  2.449752537359018e-05\n",
      "Policy Loss:  0.0019099218770861626\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  7.915062269603368e-06\n",
      "Q Loss:  0.0001852803397923708\n",
      "Policy Loss:  0.005547254346311092\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75725 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  5.408220204117242e-06\n",
      "Q Loss:  0.0006561679183505476\n",
      "Policy Loss:  0.19326794147491455\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  155.95326232910156\n",
      "Q Loss:  342.9888000488281\n",
      "Policy Loss:  -15.89340877532959\n",
      "[(0.00024, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00024 tau*: 0.00011 Episode: 75814 length: 85 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  7.164499402279034e-05\n",
      "Q Loss:  154.70957946777344\n",
      "Policy Loss:  7.64908504486084\n",
      "[(0.00026, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00026 tau*: 0.00011 Episode: 75818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0005660541355609894\n",
      "Q Loss:  0.3417610228061676\n",
      "Policy Loss:  -0.3042301535606384\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 75822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.758878640132025e-05\n",
      "Q Loss:  0.0844009518623352\n",
      "Policy Loss:  -0.09755590558052063\n",
      "[(0.0003, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0003 tau*: 0.00011 Episode: 75826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00036534504033625126\n",
      "Q Loss:  0.004836506210267544\n",
      "Policy Loss:  0.0210946723818779\n",
      "[(0.00032, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00032 tau*: 0.00011 Episode: 75830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021005868911743164\n",
      "Value Loss:  6.960951850487618e-07\n",
      "Q Loss:  0.00010438587923999876\n",
      "Policy Loss:  0.19844259321689606\n",
      "[(0.00033, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00033 tau*: 0.00011 Episode: 75834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  197.1093292236328\n",
      "Q Loss:  54.69407272338867\n",
      "Policy Loss:  -27.6025447845459\n",
      "[(0.00035, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00035 tau*: 0.00011 Episode: 75901 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0013751204824075103\n",
      "Q Loss:  0.027060173451900482\n",
      "Policy Loss:  -0.06161949411034584\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 75905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005115033709444106\n",
      "Q Loss:  0.0011210791999474168\n",
      "Policy Loss:  0.015174847096204758\n",
      "[(0.00037, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00037 tau*: 0.00011 Episode: 75909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.4024638235569\n",
      "Q Loss:  0.03691418468952179\n",
      "Policy Loss:  -1.958634614944458\n",
      "[(0.00037, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00037 tau*: 0.00011 Episode: 75913 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.9010137319564819\n",
      "Q Loss:  5.699350833892822\n",
      "Policy Loss:  -0.039403609931468964\n",
      "[(0.00038, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00038 tau*: 0.00011 Episode: 75982 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.3831865948741324e-06\n",
      "Q Loss:  0.0008123417501337826\n",
      "Policy Loss:  0.015424194745719433\n",
      "[(0.00038, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00038 tau*: 0.00011 Episode: 75986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.3312539926555473e-06\n",
      "Q Loss:  0.0001039612470776774\n",
      "Policy Loss:  0.2048407346010208\n",
      "[(0.00038, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00038 tau*: 0.00011 Episode: 75990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.9476497769355774\n",
      "Q Loss:  0.057165224105119705\n",
      "Policy Loss:  -1.0028268098831177\n",
      "[(0.00038, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00038 tau*: 0.00011 Episode: 76059 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001318156428169459\n",
      "Q Loss:  0.01700834184885025\n",
      "Policy Loss:  0.05353733152151108\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012562990188598633\n",
      "Value Loss:  0.00011186969641130418\n",
      "Q Loss:  0.0008052682969719172\n",
      "Policy Loss:  0.01315036229789257\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.40348339080810547\n",
      "Q Loss:  0.03106178157031536\n",
      "Policy Loss:  -1.980991005897522\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  5.045482158660889\n",
      "Q Loss:  0.1807800829410553\n",
      "Policy Loss:  5.2769999504089355\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76083 length: 12 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.983830538345501e-05\n",
      "Q Loss:  7.649927283637226e-05\n",
      "Policy Loss:  0.19071117043495178\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76087 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.7668360471725464\n",
      "Q Loss:  0.016075434163212776\n",
      "Policy Loss:  -1.052156686782837\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76122 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3271.40283203125\n",
      "Q Loss:  7165.18212890625\n",
      "Policy Loss:  -194.9935302734375\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 76126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  14684.173828125\n",
      "Q Loss:  12916.208984375\n",
      "Policy Loss:  -20.20439338684082\n",
      "[(0.00031, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00031 tau*: 0.00011 Episode: 76184 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1623.56640625\n",
      "Q Loss:  6303.13330078125\n",
      "Policy Loss:  -82.39451599121094\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 76188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00011864938278449699\n",
      "Q Loss:  0.033786267042160034\n",
      "Policy Loss:  0.06900287419557571\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 76192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  8.100579179881606e-06\n",
      "Q Loss:  986.7706909179688\n",
      "Policy Loss:  10.727499008178711\n",
      "[(0.00018, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00018 tau*: 0.00011 Episode: 76196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1603.022705078125\n",
      "Q Loss:  53.024776458740234\n",
      "Policy Loss:  -217.2451629638672\n",
      "[(0.00017, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00017 tau*: 0.00011 Episode: 76200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  1.1224495210626628e-05\n",
      "Q Loss:  53.90261459350586\n",
      "Policy Loss:  2.7512667179107666\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007623129058629274\n",
      "Q Loss:  54.6816291809082\n",
      "Policy Loss:  2.819434642791748\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76208 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0011336010647937655\n",
      "Q Loss:  0.2094120979309082\n",
      "Policy Loss:  0.21371933817863464\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76212 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000412968045566231\n",
      "Q Loss:  0.13748982548713684\n",
      "Policy Loss:  0.13125959038734436\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76216 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.365033626323566e-05\n",
      "Q Loss:  0.037512004375457764\n",
      "Policy Loss:  0.052738361060619354\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76220 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0003310584870632738\n",
      "Q Loss:  840.78564453125\n",
      "Policy Loss:  5.803513526916504\n",
      "[(0.00016, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00016 tau*: 0.00011 Episode: 76224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1555.6976318359375\n",
      "Q Loss:  5384.80908203125\n",
      "Policy Loss:  -60.60059356689453\n",
      "[(0.0002, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0002 tau*: 0.00011 Episode: 76228 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0012938035652041435\n",
      "Q Loss:  0.0017686299979686737\n",
      "Policy Loss:  -0.018606942147016525\n",
      "[(0.00025, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00025 tau*: 0.00011 Episode: 76232 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0028205811977386475\n",
      "Q Loss:  0.0014212711248546839\n",
      "Policy Loss:  -0.046047043055295944\n",
      "[(0.00028, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00028 tau*: 0.00011 Episode: 76236 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.758864709699992e-05\n",
      "Q Loss:  0.0001245436433237046\n",
      "Policy Loss:  -0.007649351377040148\n",
      "[(0.00031, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00031 tau*: 0.00011 Episode: 76240 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05701327323913574\n",
      "Value Loss:  1.876092369457183e-06\n",
      "Q Loss:  0.0036489495541900396\n",
      "Policy Loss:  -0.03091242164373398\n",
      "[(0.00034, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00034 tau*: 0.00011 Episode: 76244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.4212193489074707\n",
      "Q Loss:  0.10476168245077133\n",
      "Policy Loss:  2.158656358718872\n",
      "[(0.00035, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00035 tau*: 0.00011 Episode: 76261 length: 17 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  2.3981454432941973e-05\n",
      "Q Loss:  0.061187706887722015\n",
      "Policy Loss:  -0.12114900350570679\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 76265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.941735096508637e-05\n",
      "Q Loss:  0.039870161563158035\n",
      "Policy Loss:  -0.07495641708374023\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 76269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490117073059082\n",
      "Value Loss:  0.7184314727783203\n",
      "Q Loss:  0.0463443361222744\n",
      "Policy Loss:  -0.8539284467697144\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 76352 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.861300552263856e-05\n",
      "Q Loss:  115.30418395996094\n",
      "Policy Loss:  6.655332565307617\n",
      "[(0.00037, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00037 tau*: 0.00011 Episode: 76356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0008750325068831444\n",
      "Q Loss:  0.14763736724853516\n",
      "Policy Loss:  -0.2739856243133545\n",
      "[(0.00037, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00037 tau*: 0.00011 Episode: 76360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00017914721684064716\n",
      "Q Loss:  0.05516792833805084\n",
      "Policy Loss:  -0.0868731290102005\n",
      "[(0.00036, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00036 tau*: 0.00011 Episode: 76364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.200959225883707e-05\n",
      "Q Loss:  57.102054595947266\n",
      "Policy Loss:  3.461142063140869\n",
      "[(0.00038, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00038 tau*: 0.00011 Episode: 76368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  4.0569375414634123e-05\n",
      "Q Loss:  0.0019688995089381933\n",
      "Policy Loss:  -0.018874935805797577\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.189966107835062e-05\n",
      "Q Loss:  0.0009103115880861878\n",
      "Policy Loss:  -0.006799798458814621\n",
      "[(0.00039, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00039 tau*: 0.00011 Episode: 76376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.695153984357603e-05\n",
      "Q Loss:  0.005676813889294863\n",
      "Policy Loss:  0.03927338123321533\n",
      "[(0.0004, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.0004 tau*: 0.00011 Episode: 76380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.9305088520050049\n",
      "Q Loss:  3.309377431869507\n",
      "Policy Loss:  -0.7852060794830322\n",
      "[(0.00041, 0.00011), (1.0, 0.00011)]\n",
      "Alpha*: 0.00041 tau*: 0.00011 Episode: 76450 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1.7961758203455247e-05\n",
      "Q Loss:  0.008762639947235584\n",
      "Policy Loss:  0.030715573579072952\n",
      "[(0.00041, 0.00011), (-0.0, 0.0), (1.0, 0.00011)]\n",
      "No updates performed, episode: 76454 length: 4 #teleports:0\n",
      "Converged to the original problem, episode 76454\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  4.320701918913983e-06\n",
      "Q Loss:  0.0026357523165643215\n",
      "Policy Loss:  0.0015527468640357256\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76458 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  6.318852683762088e-05\n",
      "Q Loss:  0.00016355060506612062\n",
      "Policy Loss:  0.008016946725547314\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018474102020263672\n",
      "Value Loss:  77.02767944335938\n",
      "Q Loss:  257.7524108886719\n",
      "Policy Loss:  -8.319107055664062\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76540 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0007611496257595718\n",
      "Q Loss:  0.0004932316951453686\n",
      "Policy Loss:  0.0017985794693231583\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021005630493164062\n",
      "Value Loss:  7.902063225628808e-05\n",
      "Q Loss:  0.00035131341428495944\n",
      "Policy Loss:  0.009828902781009674\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.1878504753112793\n",
      "Q Loss:  0.15571945905685425\n",
      "Policy Loss:  -1.1878615617752075\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 76599 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0003461927408352494\n",
      "Q Loss:  0.0037994738668203354\n",
      "Policy Loss:  0.032685309648513794\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 76603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00011133649968542159\n",
      "Q Loss:  0.02024618163704872\n",
      "Policy Loss:  -0.0418061763048172\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 76607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7.011960406089202e-05\n",
      "Q Loss:  0.02049272507429123\n",
      "Policy Loss:  -0.0518084317445755\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 76611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500843048095703\n",
      "Value Loss:  2.2328312397003174\n",
      "Q Loss:  0.09418164193630219\n",
      "Policy Loss:  -1.2292757034301758\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76647 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.312274879543111e-05\n",
      "Q Loss:  0.012489527463912964\n",
      "Policy Loss:  0.023623045533895493\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76651 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012010574340820312\n",
      "Value Loss:  1.952426646312233e-05\n",
      "Q Loss:  0.01113490667194128\n",
      "Policy Loss:  0.03442312031984329\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.1146584749221802\n",
      "Q Loss:  0.3587927520275116\n",
      "Policy Loss:  -4.438838005065918\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.5504850149154663\n",
      "Q Loss:  0.34379613399505615\n",
      "Policy Loss:  -2.9191651344299316\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  117.89048767089844\n",
      "Q Loss:  256.4347839355469\n",
      "Policy Loss:  -14.013396263122559\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76764 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.053011417388916016\n",
      "Value Loss:  0.000491853803396225\n",
      "Q Loss:  0.0028326779138296843\n",
      "Policy Loss:  -0.01677173376083374\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 76768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  8.127387900458416e-07\n",
      "Q Loss:  0.0005311380373314023\n",
      "Policy Loss:  0.006207812111824751\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0003066315548494458\n",
      "Q Loss:  0.0009608195396140218\n",
      "Policy Loss:  0.00690830685198307\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  9.085232886718586e-05\n",
      "Q Loss:  0.0005688573583029211\n",
      "Policy Loss:  -0.017204295843839645\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  1.0084233283996582\n",
      "Q Loss:  0.30075955390930176\n",
      "Policy Loss:  -2.9611902236938477\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.1406798362731934\n",
      "Q Loss:  0.14916905760765076\n",
      "Policy Loss:  -1.8138000965118408\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76857 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02100539207458496\n",
      "Value Loss:  0.0002445310237817466\n",
      "Q Loss:  0.0030434285290539265\n",
      "Policy Loss:  0.006269717589020729\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76861 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00029690799419768155\n",
      "Q Loss:  0.0019043107749894261\n",
      "Policy Loss:  0.0019231075420975685\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76865 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002573023084551096\n",
      "Q Loss:  0.0042129443027079105\n",
      "Policy Loss:  0.018462371081113815\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0003104233182966709\n",
      "Q Loss:  0.003280334174633026\n",
      "Policy Loss:  0.014531813561916351\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.4483419358730316\n",
      "Q Loss:  0.2375849485397339\n",
      "Policy Loss:  -1.888784408569336\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011011123657226562\n",
      "Value Loss:  1.8497785276849754e-05\n",
      "Q Loss:  0.0010459405602887273\n",
      "Policy Loss:  -0.013203281909227371\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.889865517616272\n",
      "Q Loss:  0.02268000692129135\n",
      "Policy Loss:  -0.48971301317214966\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76944 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.00012200140190543607\n",
      "Q Loss:  0.0030737286433577538\n",
      "Policy Loss:  0.00327292294241488\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.340123506262898e-05\n",
      "Q Loss:  0.09233817458152771\n",
      "Policy Loss:  0.079512819647789\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 76952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052283525466918945\n",
      "Value Loss:  0.0005992578808218241\n",
      "Q Loss:  109.15423583984375\n",
      "Policy Loss:  6.786081790924072\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 76956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  2.449215571687091e-06\n",
      "Q Loss:  0.0005678084562532604\n",
      "Policy Loss:  0.003888556268066168\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 76960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.035009145736694336\n",
      "Value Loss:  0.41155490279197693\n",
      "Q Loss:  0.03287145867943764\n",
      "Policy Loss:  -1.991829514503479\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 76964 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.6681716442108154\n",
      "Q Loss:  0.10093653202056885\n",
      "Policy Loss:  -1.553581714630127\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 77008 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  7.351850217673928e-05\n",
      "Q Loss:  0.001745545188896358\n",
      "Policy Loss:  -0.0203445702791214\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 77012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.00017409378779120743\n",
      "Q Loss:  0.00013928711996413767\n",
      "Policy Loss:  -0.0030118501745164394\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 77016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011529684066772461\n",
      "Value Loss:  0.00016335207328666002\n",
      "Q Loss:  0.003188079223036766\n",
      "Policy Loss:  -0.027191240340471268\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 77020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00014410728181246668\n",
      "Q Loss:  0.0034629523288458586\n",
      "Policy Loss:  -0.034993112087249756\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 77024 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.5344936400651932e-05\n",
      "Q Loss:  0.0010823524789884686\n",
      "Policy Loss:  -0.012055082246661186\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 77028 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  4.162166442256421e-05\n",
      "Q Loss:  0.002540257992222905\n",
      "Policy Loss:  -0.03014390915632248\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 77032 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  64.71102142333984\n",
      "Q Loss:  222.80552673339844\n",
      "Policy Loss:  -5.958512306213379\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77124 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004057990154251456\n",
      "Q Loss:  0.00025771892978809774\n",
      "Policy Loss:  -0.003348494879901409\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0001838475145632401\n",
      "Q Loss:  0.002375206910073757\n",
      "Policy Loss:  0.20651501417160034\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.1299476623535156\n",
      "Q Loss:  0.19951584935188293\n",
      "Policy Loss:  -5.769587516784668\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.7377684712409973\n",
      "Q Loss:  0.3612505793571472\n",
      "Policy Loss:  -4.6136860847473145\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  247.5853729248047\n",
      "Q Loss:  835.271484375\n",
      "Policy Loss:  -5.90629768371582\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77164 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  4.727150371763855e-05\n",
      "Q Loss:  0.00486016646027565\n",
      "Policy Loss:  0.23449304699897766\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04301023483276367\n",
      "Value Loss:  1.6794536113739014\n",
      "Q Loss:  0.07315967977046967\n",
      "Policy Loss:  -1.1613738536834717\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77216 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  138.04812622070312\n",
      "Q Loss:  78.82978057861328\n",
      "Policy Loss:  -18.2449951171875\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 77259 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1467.0924072265625\n",
      "Q Loss:  844.4901123046875\n",
      "Policy Loss:  -182.7086944580078\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 77263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1463.065673828125\n",
      "Q Loss:  0.0026653637178242207\n",
      "Policy Loss:  -219.7958984375\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 77267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.3097271221340634e-05\n",
      "Q Loss:  0.0006343937129713595\n",
      "Policy Loss:  -0.011561785824596882\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 77271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.336618076195009e-05\n",
      "Q Loss:  0.00049079570453614\n",
      "Policy Loss:  -0.0011890127789229155\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 77275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  9.363252502225805e-06\n",
      "Q Loss:  0.00040934199932962656\n",
      "Policy Loss:  -0.00852317363023758\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 77279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0003783496795222163\n",
      "Q Loss:  0.0002573709934949875\n",
      "Policy Loss:  -0.0015508949290961027\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 77283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.4210563424276188e-05\n",
      "Q Loss:  0.08425389975309372\n",
      "Policy Loss:  0.19067102670669556\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 77287 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  2.1834747791290283\n",
      "Q Loss:  0.07784167677164078\n",
      "Policy Loss:  0.05639487877488136\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 77315 length: 28 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04500985145568848\n",
      "Value Loss:  0.00024455704260617495\n",
      "Q Loss:  0.00022558409546036273\n",
      "Policy Loss:  0.007631493732333183\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 77319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.3239290714263916\n",
      "Q Loss:  0.022746775299310684\n",
      "Policy Loss:  -1.4401434659957886\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 77323 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.9451264142990112\n",
      "Q Loss:  0.07338786125183105\n",
      "Policy Loss:  -0.48462480306625366\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 77359 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.659384285332635e-05\n",
      "Q Loss:  0.00023162306752055883\n",
      "Policy Loss:  0.008442969992756844\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 77363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.4451692550210282e-05\n",
      "Q Loss:  0.01615196466445923\n",
      "Policy Loss:  0.2371579110622406\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 77367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.318101167678833\n",
      "Q Loss:  0.04581444337964058\n",
      "Policy Loss:  -1.638900637626648\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 77428 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  168.15216064453125\n",
      "Q Loss:  573.4341430664062\n",
      "Policy Loss:  -7.130404949188232\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 77462 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014370441436767578\n",
      "Value Loss:  7.902855577412993e-05\n",
      "Q Loss:  0.0073068938218057156\n",
      "Policy Loss:  -0.02709423005580902\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 77466 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.034006595611572266\n",
      "Value Loss:  7.60494003770873e-05\n",
      "Q Loss:  0.0003407432814128697\n",
      "Policy Loss:  0.009141847491264343\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 77470 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.5751567591214553e-05\n",
      "Q Loss:  0.00047912553418427706\n",
      "Policy Loss:  0.013381626456975937\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 77474 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.2899120520160068e-05\n",
      "Q Loss:  0.00021339140948839486\n",
      "Policy Loss:  -0.002165683079510927\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.4637217873314512e-06\n",
      "Q Loss:  0.00023303370107896626\n",
      "Policy Loss:  0.0010364032350480556\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00014634791295975447\n",
      "Q Loss:  0.0001719816355034709\n",
      "Policy Loss:  0.006739590782672167\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301426887512207\n",
      "Value Loss:  1.0367487668991089\n",
      "Q Loss:  3.278440475463867\n",
      "Policy Loss:  -0.6101701855659485\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77552 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.33709701895713806\n",
      "Q Loss:  0.1752595752477646\n",
      "Policy Loss:  -2.60537052154541\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.0725916581577621e-05\n",
      "Q Loss:  1.4234758964448702e-05\n",
      "Policy Loss:  -0.004818894900381565\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.9488917589187622\n",
      "Q Loss:  0.034977346658706665\n",
      "Policy Loss:  -1.1546367406845093\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77602 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.050009727478027344\n",
      "Value Loss:  1.4062922673474532e-05\n",
      "Q Loss:  0.0001848316314863041\n",
      "Policy Loss:  0.0065556736662983894\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.8509550651942845e-06\n",
      "Q Loss:  0.00019486132077872753\n",
      "Policy Loss:  0.004668493755161762\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  6.584904622286558e-05\n",
      "Q Loss:  0.283027708530426\n",
      "Policy Loss:  -0.005646637640893459\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  134.5138397216797\n",
      "Q Loss:  10.17458438873291\n",
      "Policy Loss:  -18.827058792114258\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77656 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.4896196262270678e-05\n",
      "Q Loss:  6.36151380604133e-05\n",
      "Policy Loss:  0.18067458271980286\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 77660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  45361.37890625\n",
      "Q Loss:  40159.40625\n",
      "Policy Loss:  -35.06185531616211\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77679 length: 19 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.7140118479728699\n",
      "Q Loss:  6.980383396148682\n",
      "Policy Loss:  0.08738119155168533\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77771 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.2730742692947388\n",
      "Q Loss:  3.713181495666504\n",
      "Policy Loss:  -0.5103682279586792\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77830 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  2.6951658583129756e-05\n",
      "Q Loss:  9.757699444890022e-06\n",
      "Policy Loss:  -0.000936445314437151\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900885581970215\n",
      "Value Loss:  2.6709640223998576e-05\n",
      "Q Loss:  8.956973033491522e-06\n",
      "Policy Loss:  0.00033969979267567396\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.1289550457149744e-05\n",
      "Q Loss:  1.6147516362252645e-05\n",
      "Policy Loss:  0.0023594240192323923\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.0593771934509277\n",
      "Q Loss:  15.297039031982422\n",
      "Policy Loss:  1.250402808189392\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77898 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.36213386058807373\n",
      "Q Loss:  0.02200227975845337\n",
      "Policy Loss:  -1.7103418111801147\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 77902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  42.8868522644043\n",
      "Q Loss:  170.99085998535156\n",
      "Policy Loss:  -4.998411655426025\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78037 length: 135 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.4146080017089844\n",
      "Q Loss:  0.04136531427502632\n",
      "Policy Loss:  -1.398362636566162\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78089 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019002676010131836\n",
      "Value Loss:  1436.029296875\n",
      "Q Loss:  5677.2529296875\n",
      "Policy Loss:  -85.84466552734375\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78093 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  4.536290362011641e-05\n",
      "Q Loss:  53.96722412109375\n",
      "Policy Loss:  2.570979356765747\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78097 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  1434.2110595703125\n",
      "Q Loss:  6361.3828125\n",
      "Policy Loss:  -73.25962829589844\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78101 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2860.58935546875\n",
      "Q Loss:  756.762451171875\n",
      "Policy Loss:  -388.02020263671875\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78105 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.073463636203087e-06\n",
      "Q Loss:  748.2044677734375\n",
      "Policy Loss:  5.282907009124756\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1411.9747314453125\n",
      "Q Loss:  4926.8818359375\n",
      "Policy Loss:  -84.27363586425781\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01711249351501465\n",
      "Value Loss:  0.00046416494296863675\n",
      "Q Loss:  0.00077550153946504\n",
      "Policy Loss:  0.00833735428750515\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78117 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00029266547062434256\n",
      "Q Loss:  0.00011868560977745801\n",
      "Policy Loss:  -0.00316506065428257\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0001773868134478107\n",
      "Q Loss:  0.0024045705795288086\n",
      "Policy Loss:  0.0179497841745615\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.11102557182312012\n",
      "Value Loss:  0.38176193833351135\n",
      "Q Loss:  0.02739269845187664\n",
      "Policy Loss:  -1.3780009746551514\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.6111165285110474\n",
      "Q Loss:  0.12527763843536377\n",
      "Policy Loss:  -0.37034016847610474\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78168 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0004785392666235566\n",
      "Q Loss:  0.0006536142900586128\n",
      "Policy Loss:  -0.015473190695047379\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78172 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.9285271167755127\n",
      "Q Loss:  3.9377799034118652\n",
      "Policy Loss:  -0.15111997723579407\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78238 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00010354946425650269\n",
      "Q Loss:  0.006894949823617935\n",
      "Policy Loss:  -0.040935419499874115\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0004332502721808851\n",
      "Q Loss:  0.0031466817017644644\n",
      "Policy Loss:  -0.005306456703692675\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02500462532043457\n",
      "Value Loss:  0.00010023318463936448\n",
      "Q Loss:  0.00010266077879350632\n",
      "Policy Loss:  0.0005593861569650471\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.2761560356011614e-05\n",
      "Q Loss:  0.024387728422880173\n",
      "Policy Loss:  0.06899729371070862\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.1796069145202637\n",
      "Q Loss:  0.07581061869859695\n",
      "Policy Loss:  -0.9750378131866455\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78311 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.33671107707778e-05\n",
      "Q Loss:  0.003712083911523223\n",
      "Policy Loss:  0.029500121250748634\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78315 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  3.866382030537352e-06\n",
      "Q Loss:  0.016317207366228104\n",
      "Policy Loss:  0.24113106727600098\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.9096206426620483\n",
      "Q Loss:  10.342556953430176\n",
      "Policy Loss:  0.3801611661911011\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78398 length: 79 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.3468778133392334\n",
      "Q Loss:  0.10438738763332367\n",
      "Policy Loss:  -0.9651538729667664\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 78449 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5.491796400747262e-05\n",
      "Q Loss:  0.00029225595062598586\n",
      "Policy Loss:  0.005109178833663464\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  8.015189814614132e-05\n",
      "Q Loss:  0.00016593692998867482\n",
      "Policy Loss:  0.0038614203222095966\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.533226729108719e-06\n",
      "Q Loss:  0.026566587388515472\n",
      "Policy Loss:  0.09183239936828613\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  6.462155852204887e-06\n",
      "Q Loss:  0.00037228857399895787\n",
      "Policy Loss:  -0.01661188155412674\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78465 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.3059751583787147e-06\n",
      "Q Loss:  0.008532467298209667\n",
      "Policy Loss:  0.042099274694919586\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78469 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600503921508789\n",
      "Value Loss:  0.40400075912475586\n",
      "Q Loss:  0.3238532841205597\n",
      "Policy Loss:  -0.7225435376167297\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.0337765216827393\n",
      "Q Loss:  7.871296405792236\n",
      "Policy Loss:  -0.1076396107673645\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 78544 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  1313.9617919921875\n",
      "Q Loss:  4618.31640625\n",
      "Policy Loss:  -79.51875305175781\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00012102812615921721\n",
      "Q Loss:  0.0006663545500487089\n",
      "Policy Loss:  -0.007682278286665678\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00021395296789705753\n",
      "Q Loss:  0.0005016736104153097\n",
      "Policy Loss:  -0.0023461708333343267\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003557205200195\n",
      "Value Loss:  8.486219303449616e-05\n",
      "Q Loss:  0.0011871927417814732\n",
      "Policy Loss:  -0.008835216984152794\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 78560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005578994750977\n",
      "Value Loss:  2.4666631361469626e-05\n",
      "Q Loss:  0.009210772812366486\n",
      "Policy Loss:  -0.06063727289438248\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 78564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.194162130355835\n",
      "Q Loss:  0.015618674457073212\n",
      "Policy Loss:  -1.846623182296753\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 78568 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  246041.921875\n",
      "Q Loss:  214776.828125\n",
      "Policy Loss:  110.51417541503906\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 78575 length: 7 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  67.12711334228516\n",
      "Q Loss:  3.5349223613739014\n",
      "Policy Loss:  -11.320585250854492\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 78655 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  1349.68505859375\n",
      "Q Loss:  69.19620513916016\n",
      "Policy Loss:  -198.97618103027344\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 78659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  4.148284915572731e-07\n",
      "Q Loss:  0.0011543813161551952\n",
      "Policy Loss:  -0.0007497917395085096\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 78663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00015840382548049092\n",
      "Q Loss:  0.0007793399272486567\n",
      "Policy Loss:  -0.0051378835923969746\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 78667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014270305633544922\n",
      "Value Loss:  0.0003824849263764918\n",
      "Q Loss:  0.004158637952059507\n",
      "Policy Loss:  -0.030007125809788704\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019005298614501953\n",
      "Value Loss:  0.3931586742401123\n",
      "Q Loss:  0.6308127641677856\n",
      "Policy Loss:  -1.8640981912612915\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.173306941986084\n",
      "Q Loss:  0.24516549706459045\n",
      "Policy Loss:  -4.293309211730957\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78679 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  1.4066660696698818e-05\n",
      "Q Loss:  0.002494125161319971\n",
      "Policy Loss:  -0.01883646287024021\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.7497500777244568\n",
      "Q Loss:  0.2241966426372528\n",
      "Policy Loss:  -0.6888553500175476\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.3188260793685913\n",
      "Q Loss:  0.09579557925462723\n",
      "Policy Loss:  -1.2616662979125977\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 78745 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0009133770363405347\n",
      "Q Loss:  0.00039467529859393835\n",
      "Policy Loss:  -0.013708924874663353\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 78749 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.205630001612008e-05\n",
      "Q Loss:  0.012862909585237503\n",
      "Policy Loss:  0.03677479922771454\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 78753 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0002125101163983345\n",
      "Q Loss:  69.33262634277344\n",
      "Policy Loss:  2.9563984870910645\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 78757 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00015043458552099764\n",
      "Q Loss:  0.0027366499416530132\n",
      "Policy Loss:  -0.01881975680589676\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 78761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.0003869654901791364\n",
      "Q Loss:  0.0019238120876252651\n",
      "Policy Loss:  -0.006276922300457954\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.001146144699305296\n",
      "Q Loss:  0.0038207825273275375\n",
      "Policy Loss:  0.02385731227695942\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0005334393354132771\n",
      "Q Loss:  0.0005806479603052139\n",
      "Policy Loss:  -0.012498804368078709\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  0.0001861436467152089\n",
      "Q Loss:  0.0024835963267832994\n",
      "Policy Loss:  0.002226322889328003\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78777 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.523221832641866e-07\n",
      "Q Loss:  0.0078064147382974625\n",
      "Policy Loss:  0.05648140236735344\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78781 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00010489980195416138\n",
      "Q Loss:  0.0032187101896852255\n",
      "Policy Loss:  0.010126985609531403\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.028995037078857422\n",
      "Value Loss:  2.3520133254351094e-06\n",
      "Q Loss:  0.005048743449151516\n",
      "Policy Loss:  0.03737734258174896\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.5883380174636841\n",
      "Q Loss:  0.0426904521882534\n",
      "Policy Loss:  -2.112614154815674\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.575961709022522\n",
      "Q Loss:  0.13947179913520813\n",
      "Policy Loss:  -2.095288038253784\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 78797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1159065961837769\n",
      "Q Loss:  0.06402242928743362\n",
      "Policy Loss:  -3.6394662857055664\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 78801 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.486825704574585\n",
      "Q Loss:  0.023345548659563065\n",
      "Policy Loss:  -0.9566636681556702\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 78852 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.7162158489227295\n",
      "Q Loss:  34.92345428466797\n",
      "Policy Loss:  4.815458297729492\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 78891 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00017187952471431345\n",
      "Q Loss:  0.0002789095160551369\n",
      "Policy Loss:  -0.0024262829683721066\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 78895 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  0.23497267067432404\n",
      "Q Loss:  0.013812846504151821\n",
      "Policy Loss:  -1.1850124597549438\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 78899 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300975799560547\n",
      "Value Loss:  0.452813059091568\n",
      "Q Loss:  0.12875798344612122\n",
      "Policy Loss:  -2.959362745285034\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 78903 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.2161121517419815\n",
      "Q Loss:  0.13028071820735931\n",
      "Policy Loss:  -1.1166006326675415\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 78907 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.0005345927202142775\n",
      "Q Loss:  0.001874827197752893\n",
      "Policy Loss:  -0.0010487455874681473\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 78911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.3929661810398102\n",
      "Q Loss:  0.12429249286651611\n",
      "Policy Loss:  -1.4869282245635986\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 78915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00029863021336495876\n",
      "Q Loss:  0.0011290931142866611\n",
      "Policy Loss:  -0.024869509041309357\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 78919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.5301368236541748\n",
      "Q Loss:  0.15688903629779816\n",
      "Policy Loss:  -2.706368923187256\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 78923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013637304306030273\n",
      "Value Loss:  0.16580215096473694\n",
      "Q Loss:  0.1016748696565628\n",
      "Policy Loss:  -1.6066412925720215\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 78927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005548413028009236\n",
      "Q Loss:  0.00021639891201630235\n",
      "Policy Loss:  0.005827658344060183\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 78931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.8761627984531515e-07\n",
      "Q Loss:  0.0005475690704770386\n",
      "Policy Loss:  -0.013157457113265991\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 78935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00048724887892603874\n",
      "Q Loss:  0.002107266103848815\n",
      "Policy Loss:  -0.011562826111912727\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012913942337036133\n",
      "Value Loss:  1.5134168052099994e-06\n",
      "Q Loss:  0.00041784479981288314\n",
      "Policy Loss:  0.012780122458934784\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0013388755032792687\n",
      "Q Loss:  0.0010144037660211325\n",
      "Policy Loss:  -0.019377239048480988\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02500605583190918\n",
      "Value Loss:  0.0014772046124562621\n",
      "Q Loss:  0.0011737640015780926\n",
      "Policy Loss:  -0.010666372254490852\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 78951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0006792140193283558\n",
      "Q Loss:  0.0024499655701220036\n",
      "Policy Loss:  -0.02165978029370308\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78955 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.10674801468849182\n",
      "Q Loss:  0.14970694482326508\n",
      "Policy Loss:  -1.2721540927886963\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78959 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00010476263560121879\n",
      "Q Loss:  0.0019436703296378255\n",
      "Policy Loss:  0.02640720084309578\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78963 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031601667404174805\n",
      "Value Loss:  0.09760820865631104\n",
      "Q Loss:  0.012498535215854645\n",
      "Policy Loss:  -0.6910585761070251\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 78967 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.5103353261947632\n",
      "Q Loss:  0.023718569427728653\n",
      "Policy Loss:  0.01732398010790348\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79021 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.000538482388947159\n",
      "Q Loss:  0.003429291071370244\n",
      "Policy Loss:  -0.03237035870552063\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0009403490694239736\n",
      "Q Loss:  0.0005007992149330676\n",
      "Policy Loss:  -0.008857965469360352\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0011598942801356316\n",
      "Q Loss:  0.001976620638743043\n",
      "Policy Loss:  0.02047901228070259\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.000983300618827343\n",
      "Q Loss:  0.0055270083248615265\n",
      "Policy Loss:  0.02208554558455944\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00046597918844781816\n",
      "Q Loss:  0.0009882901795208454\n",
      "Policy Loss:  0.013935847207903862\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0004658251127693802\n",
      "Q Loss:  0.0005253559211269021\n",
      "Policy Loss:  0.011848868802189827\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400087833404541\n",
      "Value Loss:  1.1676198710119934e-06\n",
      "Q Loss:  0.0036237062886357307\n",
      "Policy Loss:  -0.0025558837223798037\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  9.443115413887426e-05\n",
      "Q Loss:  0.011144719086587429\n",
      "Policy Loss:  0.12608341872692108\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  1.800817608833313\n",
      "Q Loss:  0.03447141870856285\n",
      "Policy Loss:  0.6107349991798401\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79099 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0001385074865538627\n",
      "Q Loss:  0.00038786366349086165\n",
      "Policy Loss:  -0.0064199576154351234\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  5.677325248718262\n",
      "Q Loss:  0.039263587445020676\n",
      "Policy Loss:  4.576794624328613\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79117 length: 14 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0010703853331506252\n",
      "Q Loss:  0.02058815211057663\n",
      "Policy Loss:  -0.06004004180431366\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  0.0007459264015778899\n",
      "Q Loss:  7.850331712688785e-06\n",
      "Policy Loss:  9.559618774801493e-05\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.00015649243141524494\n",
      "Q Loss:  0.0007472314173355699\n",
      "Policy Loss:  -0.008595440536737442\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.0002842544636223465\n",
      "Q Loss:  0.0018041905714198947\n",
      "Policy Loss:  0.010817380622029305\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79133 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018001794815063477\n",
      "Value Loss:  0.0020567879546433687\n",
      "Q Loss:  0.0007618029485456645\n",
      "Policy Loss:  0.00015206867828965187\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79137 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.20055362582206726\n",
      "Q Loss:  0.012436723336577415\n",
      "Policy Loss:  -1.3152806758880615\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79141 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.122602939605713\n",
      "Q Loss:  0.03479233384132385\n",
      "Policy Loss:  -0.369418203830719\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79215 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012325286865234375\n",
      "Value Loss:  0.20537444949150085\n",
      "Q Loss:  0.014006834477186203\n",
      "Policy Loss:  -1.222198724746704\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.561856746673584\n",
      "Q Loss:  0.03118165023624897\n",
      "Policy Loss:  0.5115436911582947\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79249 length: 30 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.00030255099409259856\n",
      "Q Loss:  0.008067219518125057\n",
      "Policy Loss:  0.04959680140018463\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0013663119170814753\n",
      "Q Loss:  0.004001414868980646\n",
      "Policy Loss:  0.034820809960365295\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.21727286279201508\n",
      "Q Loss:  0.012226051650941372\n",
      "Policy Loss:  -1.4033403396606445\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.326505184173584\n",
      "Q Loss:  0.062359049916267395\n",
      "Policy Loss:  -2.5119028091430664\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 79265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.471406519878656e-05\n",
      "Q Loss:  0.0011224958579987288\n",
      "Policy Loss:  0.009763360023498535\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 79269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018012046813964844\n",
      "Value Loss:  10495.1201171875\n",
      "Q Loss:  9270.7197265625\n",
      "Policy Loss:  -21.941789627075195\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 79351 length: 82 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3132.40966796875\n",
      "Q Loss:  6038.234375\n",
      "Policy Loss:  -184.82940673828125\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 79355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00019968350534327328\n",
      "Q Loss:  0.09526275843381882\n",
      "Policy Loss:  -0.08703690767288208\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08401870727539062\n",
      "Value Loss:  0.00012241874355822802\n",
      "Q Loss:  0.06744507700204849\n",
      "Policy Loss:  -0.06529214978218079\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500889778137207\n",
      "Value Loss:  5.021758988732472e-05\n",
      "Q Loss:  0.07427804172039032\n",
      "Policy Loss:  -0.06956235319375992\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0005642385222017765\n",
      "Q Loss:  0.0012014283565804362\n",
      "Policy Loss:  0.019173113629221916\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0002806356642395258\n",
      "Q Loss:  0.010101253166794777\n",
      "Policy Loss:  0.056492242962121964\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.0012887009652331471\n",
      "Q Loss:  0.0044805691577494144\n",
      "Policy Loss:  0.043988071382045746\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0017736530862748623\n",
      "Q Loss:  0.0009763884590938687\n",
      "Policy Loss:  -0.004806391894817352\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.10105165094137192\n",
      "Q Loss:  0.14581678807735443\n",
      "Policy Loss:  -0.6946003437042236\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.39971211552619934\n",
      "Q Loss:  2.7356117016097414e-07\n",
      "Policy Loss:  -0.6668270230293274\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.342565894126892\n",
      "Q Loss:  0.015919890254735947\n",
      "Policy Loss:  0.009381105192005634\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79449 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.025006771087646484\n",
      "Value Loss:  0.0008865147246979177\n",
      "Q Loss:  0.0002840957895386964\n",
      "Policy Loss:  -0.013360674493014812\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.0006402131402865052\n",
      "Q Loss:  0.0012839167611673474\n",
      "Policy Loss:  0.02363898977637291\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00037862634053453803\n",
      "Q Loss:  0.0014618131099268794\n",
      "Policy Loss:  0.010738421231508255\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0014556183014065027\n",
      "Q Loss:  0.003945250529795885\n",
      "Policy Loss:  -0.01579151675105095\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79465 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0010632633930072188\n",
      "Q Loss:  0.0034398671705275774\n",
      "Policy Loss:  0.0028873521368950605\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79469 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0008765785023570061\n",
      "Q Loss:  0.49365800619125366\n",
      "Policy Loss:  0.25079700350761414\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0006487184436991811\n",
      "Q Loss:  69.9749526977539\n",
      "Policy Loss:  3.0943496227264404\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 79477 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033007144927978516\n",
      "Value Loss:  1528.3603515625\n",
      "Q Loss:  5978.0849609375\n",
      "Policy Loss:  -60.80511474609375\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00014405448746401817\n",
      "Q Loss:  69.66683959960938\n",
      "Policy Loss:  2.8695287704467773\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 79485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.000911518931388855\n",
      "Q Loss:  0.006663150154054165\n",
      "Policy Loss:  -0.04192240536212921\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 79489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00047769583761692047\n",
      "Q Loss:  0.007452795747667551\n",
      "Policy Loss:  -0.04379068687558174\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 79493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.400621012086049e-05\n",
      "Q Loss:  0.0038924177642911673\n",
      "Policy Loss:  -0.0036515588872134686\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 79497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.2510736882686615\n",
      "Q Loss:  0.06135990470647812\n",
      "Policy Loss:  -0.5186812877655029\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 79501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013010978698730469\n",
      "Value Loss:  0.24533486366271973\n",
      "Q Loss:  0.0027668518014252186\n",
      "Policy Loss:  -0.5095102787017822\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 79505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.314468115568161\n",
      "Q Loss:  0.054114945232868195\n",
      "Policy Loss:  -1.1502829790115356\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 79509 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.22191067039966583\n",
      "Q Loss:  0.0037959676701575518\n",
      "Policy Loss:  -0.41154733300209045\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 79513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  121.45553588867188\n",
      "Q Loss:  444.3053894042969\n",
      "Policy Loss:  -5.769928932189941\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 79613 length: 100 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  0.002152528613805771\n",
      "Q Loss:  0.006220024079084396\n",
      "Policy Loss:  -0.001958375796675682\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 79617 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0014857110800221562\n",
      "Q Loss:  0.0006604519439861178\n",
      "Policy Loss:  0.0118203554302454\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79621 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  35708.25390625\n",
      "Q Loss:  30957.8828125\n",
      "Policy Loss:  -46.53397750854492\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79645 length: 24 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005942832212895155\n",
      "Q Loss:  69.41888427734375\n",
      "Policy Loss:  2.9037179946899414\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0003318272065371275\n",
      "Q Loss:  0.0007612484623678029\n",
      "Policy Loss:  -0.006180647760629654\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002017224469454959\n",
      "Q Loss:  0.003788278205320239\n",
      "Policy Loss:  -0.02741941809654236\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0003735866048373282\n",
      "Q Loss:  0.001719280262477696\n",
      "Policy Loss:  -0.007311911787837744\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.001353460131213069\n",
      "Q Loss:  0.0014012465253472328\n",
      "Policy Loss:  -0.025434071198105812\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79665 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04600977897644043\n",
      "Value Loss:  0.10167721658945084\n",
      "Q Loss:  0.003527553752064705\n",
      "Policy Loss:  -0.6785328984260559\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100539207458496\n",
      "Value Loss:  1.417655348777771\n",
      "Q Loss:  0.008978291414678097\n",
      "Policy Loss:  0.13524897396564484\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79728 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.000615269411355257\n",
      "Q Loss:  0.000335823860950768\n",
      "Policy Loss:  -0.007869677618145943\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79732 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  7.936432666610926e-05\n",
      "Q Loss:  0.0005296451272442937\n",
      "Policy Loss:  0.003033609129488468\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  2.0335260160209145e-06\n",
      "Q Loss:  0.0019896305166184902\n",
      "Policy Loss:  0.07722342759370804\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79740 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  53497.2890625\n",
      "Q Loss:  47429.28125\n",
      "Policy Loss:  -8.985136032104492\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 79756 length: 16 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0009895534021779895\n",
      "Q Loss:  0.37770211696624756\n",
      "Policy Loss:  -0.2617315649986267\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 79760 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0017174453241750598\n",
      "Q Loss:  0.0029577473178505898\n",
      "Policy Loss:  0.02338343858718872\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 79764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0010080605279654264\n",
      "Q Loss:  0.005283959209918976\n",
      "Policy Loss:  0.04785601794719696\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 79768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0009780206019058824\n",
      "Q Loss:  0.0019435363356024027\n",
      "Policy Loss:  0.01945148967206478\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 79772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0003959008026868105\n",
      "Q Loss:  0.0008448630105704069\n",
      "Policy Loss:  0.004208128433674574\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 79776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00019561126828193665\n",
      "Q Loss:  0.0005874673370271921\n",
      "Policy Loss:  -0.0039295353926718235\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04362821578979492\n",
      "Value Loss:  3.066887074965052e-05\n",
      "Q Loss:  0.0004145742568653077\n",
      "Policy Loss:  0.0006285968702286482\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  159.43702697753906\n",
      "Q Loss:  242.93150329589844\n",
      "Policy Loss:  -19.03056526184082\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79903 length: 119 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00041471648728474975\n",
      "Q Loss:  0.0005465131253004074\n",
      "Policy Loss:  -0.0010011708363890648\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79907 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06032511964440346\n",
      "Q Loss:  0.03660852462053299\n",
      "Policy Loss:  -0.5540587902069092\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.001862362027168274\n",
      "Q Loss:  0.00043347111204639077\n",
      "Policy Loss:  -0.005184944253414869\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 79915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.4305215851636603e-05\n",
      "Q Loss:  0.0004182358970865607\n",
      "Policy Loss:  0.08519961684942245\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 79919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.044008731842041016\n",
      "Value Loss:  3.4009015560150146\n",
      "Q Loss:  0.011416904628276825\n",
      "Policy Loss:  1.3943911790847778\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 79943 length: 24 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  137.0397186279297\n",
      "Q Loss:  454.7940673828125\n",
      "Policy Loss:  -7.292276382446289\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 79990 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.024830341339111328\n",
      "Value Loss:  0.00011392583837732673\n",
      "Q Loss:  0.0012828665785491467\n",
      "Policy Loss:  0.017448853701353073\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 79994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  13882.2373046875\n",
      "Q Loss:  12001.525390625\n",
      "Policy Loss:  -9.793522834777832\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80055 length: 61 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0003062835894525051\n",
      "Q Loss:  0.05242443457245827\n",
      "Policy Loss:  -0.046795763075351715\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.0003331117914058268\n",
      "Q Loss:  0.0010777944698929787\n",
      "Policy Loss:  0.026947639882564545\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031006574630737305\n",
      "Value Loss:  0.0008311926503665745\n",
      "Q Loss:  0.0004705104511231184\n",
      "Policy Loss:  0.004656991921365261\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020144939422607422\n",
      "Value Loss:  0.0005388204008340836\n",
      "Q Loss:  0.0009950934909284115\n",
      "Policy Loss:  0.01081595104187727\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  5.126749965711497e-05\n",
      "Q Loss:  0.0012161551276221871\n",
      "Policy Loss:  0.01633143052458763\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  0.00019164083641953766\n",
      "Q Loss:  0.0023841438814997673\n",
      "Policy Loss:  0.025093767791986465\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.00046005603508092463\n",
      "Q Loss:  0.00030826596776023507\n",
      "Policy Loss:  0.007850686088204384\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80083 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  0.0002412503818050027\n",
      "Q Loss:  6.894506077514961e-05\n",
      "Policy Loss:  0.00169115059543401\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80087 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.805981457233429\n",
      "Q Loss:  2.734764337539673\n",
      "Policy Loss:  0.005180961452424526\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 80189 length: 102 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013263463973999023\n",
      "Value Loss:  1613.78076171875\n",
      "Q Loss:  5328.88134765625\n",
      "Policy Loss:  -93.35427856445312\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 80193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0016458199825137854\n",
      "Q Loss:  0.0001756428537191823\n",
      "Policy Loss:  -0.010098112747073174\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  0.0005461137043312192\n",
      "Q Loss:  0.000477476540254429\n",
      "Policy Loss:  -0.011559359729290009\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.27303558960557e-05\n",
      "Q Loss:  0.0009128825622610748\n",
      "Policy Loss:  -0.013466063886880875\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 80205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  2.3410877474816516e-05\n",
      "Q Loss:  0.0005598671268671751\n",
      "Policy Loss:  -0.014462022110819817\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 80209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017978191375732422\n",
      "Value Loss:  2.599181971163489e-05\n",
      "Q Loss:  0.00036012515192851424\n",
      "Policy Loss:  -0.00811733864247799\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 80213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.3238095309352502e-05\n",
      "Q Loss:  0.003027708502486348\n",
      "Policy Loss:  0.07824498414993286\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 80217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.09994996339082718\n",
      "Q Loss:  0.02692589908838272\n",
      "Policy Loss:  -1.131990909576416\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 80221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.921855856489856e-06\n",
      "Q Loss:  2.4085105906124227e-05\n",
      "Policy Loss:  5.536057869903743e-05\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 80225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05660748481750488\n",
      "Value Loss:  1.3575990124081727e-05\n",
      "Q Loss:  5.290808985591866e-05\n",
      "Policy Loss:  0.004901919048279524\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 80229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  42318.82421875\n",
      "Q Loss:  36806.921875\n",
      "Policy Loss:  -6.5106377601623535\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 80249 length: 20 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.001564370235428214\n",
      "Q Loss:  0.0006651429575867951\n",
      "Policy Loss:  0.0010517500340938568\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 80253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6.865102477604523e-06\n",
      "Q Loss:  0.00028906299849040806\n",
      "Policy Loss:  -0.0022619410883635283\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 80257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.9439225070527755e-05\n",
      "Q Loss:  0.00012296263594180346\n",
      "Policy Loss:  0.003001251257956028\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 80261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.4766924323339481e-05\n",
      "Q Loss:  0.000189859390957281\n",
      "Policy Loss:  0.0023797303438186646\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 80265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  1.2212370847919374e-07\n",
      "Q Loss:  0.001904086908325553\n",
      "Policy Loss:  0.0853186696767807\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 80269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  187.35037231445312\n",
      "Q Loss:  648.0861206054688\n",
      "Policy Loss:  -17.018909454345703\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 80339 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1632.3262939453125\n",
      "Q Loss:  5246.17919921875\n",
      "Policy Loss:  -109.32833862304688\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 80343 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002185694029321894\n",
      "Q Loss:  0.010864252224564552\n",
      "Policy Loss:  0.05567013472318649\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 80347 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.0002737759205047041\n",
      "Q Loss:  0.0018704684916883707\n",
      "Policy Loss:  0.021413607522845268\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 80351 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00015746956341899931\n",
      "Q Loss:  0.0008461892721243203\n",
      "Policy Loss:  0.007805566769093275\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 80355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  4.531940703600412e-06\n",
      "Q Loss:  0.005692392587661743\n",
      "Policy Loss:  0.03816920518875122\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 80359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00040551842539571226\n",
      "Q Loss:  68.18843078613281\n",
      "Policy Loss:  2.8623266220092773\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011504650115966797\n",
      "Value Loss:  18779.55859375\n",
      "Q Loss:  16345.4755859375\n",
      "Policy Loss:  -11.988141059875488\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80408 length: 45 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03500819206237793\n",
      "Value Loss:  0.362968385219574\n",
      "Q Loss:  0.07253704220056534\n",
      "Policy Loss:  -2.320629596710205\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  139.97808837890625\n",
      "Q Loss:  476.6074523925781\n",
      "Policy Loss:  -15.335021018981934\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80506 length: 94 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.24020013213157654\n",
      "Q Loss:  0.05092327296733856\n",
      "Policy Loss:  -0.7014010548591614\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  14563.4150390625\n",
      "Q Loss:  12625.4033203125\n",
      "Policy Loss:  -11.892236709594727\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80568 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0008880740497261286\n",
      "Q Loss:  0.00102977454662323\n",
      "Policy Loss:  -0.017429187893867493\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00012970523675903678\n",
      "Q Loss:  67.65033721923828\n",
      "Policy Loss:  2.8350844383239746\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80576 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  3.6714121961267665e-05\n",
      "Q Loss:  0.0006831430946476758\n",
      "Policy Loss:  -0.008905467577278614\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80580 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  8.748505933908746e-05\n",
      "Q Loss:  0.0010106000117957592\n",
      "Policy Loss:  -0.006076348014175892\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80584 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00021861855930183083\n",
      "Q Loss:  0.0011982179712504148\n",
      "Policy Loss:  -0.006184512749314308\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900909423828125\n",
      "Value Loss:  3.2425388781121e-05\n",
      "Q Loss:  0.00027788832085207105\n",
      "Policy Loss:  0.009406091645359993\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.7447222237242386e-05\n",
      "Q Loss:  0.00014036678476259112\n",
      "Policy Loss:  0.003054507076740265\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.540534503874369e-05\n",
      "Q Loss:  0.0002615223347675055\n",
      "Policy Loss:  0.0026953350752592087\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  7.914525667729322e-06\n",
      "Q Loss:  2.5320850909338333e-05\n",
      "Policy Loss:  -0.001487076049670577\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80604 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  6.907423085067421e-06\n",
      "Q Loss:  0.0003971749683842063\n",
      "Policy Loss:  0.006197463255375624\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80608 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.6430101823061705e-05\n",
      "Q Loss:  3.072222898481414e-05\n",
      "Policy Loss:  -0.0037012624088674784\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80612 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  45.62322998046875\n",
      "Q Loss:  143.5677947998047\n",
      "Policy Loss:  -4.737185001373291\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80760 length: 148 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  6.079653303459054e-06\n",
      "Q Loss:  0.00010624999413266778\n",
      "Policy Loss:  0.0007156989304348826\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006481170654297\n",
      "Value Loss:  0.11339140683412552\n",
      "Q Loss:  0.024939382448792458\n",
      "Policy Loss:  -0.5720857977867126\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  102.37410736083984\n",
      "Q Loss:  367.8998718261719\n",
      "Policy Loss:  -9.174750328063965\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80834 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00045625021448358893\n",
      "Q Loss:  0.00013860437320545316\n",
      "Policy Loss:  -0.004644015338271856\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 80838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015993356704711914\n",
      "Value Loss:  2.7954134941101074\n",
      "Q Loss:  0.018347421661019325\n",
      "Policy Loss:  0.6505568027496338\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80865 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.862455221475102e-05\n",
      "Q Loss:  0.0001446670212317258\n",
      "Policy Loss:  -0.003915014211088419\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.10202312469482422\n",
      "Value Loss:  1.922360206663143e-05\n",
      "Q Loss:  3.128429671050981e-05\n",
      "Policy Loss:  0.002099649515002966\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.7575546735315584e-05\n",
      "Q Loss:  6.336586375255138e-05\n",
      "Policy Loss:  0.10897677391767502\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400920867919922\n",
      "Value Loss:  0.3620988726615906\n",
      "Q Loss:  0.07147839665412903\n",
      "Policy Loss:  -1.3568629026412964\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.3604382872581482\n",
      "Q Loss:  0.1613527536392212\n",
      "Policy Loss:  -1.9471015930175781\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 80885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  27631.234375\n",
      "Q Loss:  24585.125\n",
      "Policy Loss:  -63.795684814453125\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80916 length: 31 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.0005424724658951163\n",
      "Q Loss:  0.00038477868656627834\n",
      "Policy Loss:  -1.7010606825351715e-05\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00016162838437594473\n",
      "Q Loss:  0.00044059136416763067\n",
      "Policy Loss:  0.0133314598351717\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  4.369956150185317e-05\n",
      "Q Loss:  0.004360577557235956\n",
      "Policy Loss:  0.027255579829216003\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.6190104484558105\n",
      "Q Loss:  0.016511010006070137\n",
      "Policy Loss:  0.1072571724653244\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80977 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  1.4338286746351514e-05\n",
      "Q Loss:  0.006118756253272295\n",
      "Policy Loss:  0.02661963738501072\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  2.563720590842422e-05\n",
      "Q Loss:  0.007521514315158129\n",
      "Policy Loss:  0.13529616594314575\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 80985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.1940630674362183\n",
      "Q Loss:  0.02187308296561241\n",
      "Policy Loss:  -0.05267026275396347\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 81051 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014522314071655273\n",
      "Value Loss:  40428.24609375\n",
      "Q Loss:  35945.8359375\n",
      "Policy Loss:  -15.757100105285645\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81072 length: 21 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.619107519625686e-05\n",
      "Q Loss:  0.024615805596113205\n",
      "Policy Loss:  0.0884322077035904\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.36237525939941406\n",
      "Q Loss:  0.023392878472805023\n",
      "Policy Loss:  -0.7042974233627319\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.4813152253627777\n",
      "Q Loss:  0.023326732218265533\n",
      "Policy Loss:  -1.0576280355453491\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  37377.40625\n",
      "Q Loss:  32572.904296875\n",
      "Policy Loss:  -24.815528869628906\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81129 length: 45 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01559901237487793\n",
      "Value Loss:  0.0010417730081826448\n",
      "Q Loss:  0.0021186198573559523\n",
      "Policy Loss:  0.013440847396850586\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81133 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0002810688456520438\n",
      "Q Loss:  0.0011755320010706782\n",
      "Policy Loss:  0.002195409731939435\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81137 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00012807692110072821\n",
      "Q Loss:  0.0013754840474575758\n",
      "Policy Loss:  0.012825931422412395\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81141 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  3.671055310405791e-05\n",
      "Q Loss:  9.183168003801256e-05\n",
      "Policy Loss:  0.006023514084517956\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81145 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  6.61326848785393e-05\n",
      "Q Loss:  0.026806354522705078\n",
      "Policy Loss:  0.09138698130846024\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81149 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.7767815589904785\n",
      "Q Loss:  0.02800804376602173\n",
      "Policy Loss:  0.3305905759334564\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81194 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0001273311354452744\n",
      "Q Loss:  0.0013379721203818917\n",
      "Policy Loss:  0.01654636487364769\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0003997286839876324\n",
      "Q Loss:  0.0002297937317052856\n",
      "Policy Loss:  0.00923953764140606\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.00012957923172507435\n",
      "Q Loss:  2.4386385121033527e-05\n",
      "Policy Loss:  0.0002049278700724244\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81206 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.808083991112653e-05\n",
      "Q Loss:  4.4184853322803974e-05\n",
      "Policy Loss:  -0.005654993467032909\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81210 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.1529307559831068e-05\n",
      "Q Loss:  0.0005729670519940555\n",
      "Policy Loss:  0.10137800872325897\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 81214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  29907.025390625\n",
      "Q Loss:  26012.6171875\n",
      "Policy Loss:  -22.304702758789062\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81242 length: 28 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  83702.359375\n",
      "Q Loss:  72739.0625\n",
      "Policy Loss:  -36.524147033691406\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81252 length: 10 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00033081634319387376\n",
      "Q Loss:  0.0041755493730306625\n",
      "Policy Loss:  -0.03446313738822937\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81256 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0006239559734240174\n",
      "Q Loss:  0.0011213284451514482\n",
      "Policy Loss:  -0.017144599929451942\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.357238233089447\n",
      "Q Loss:  0.10102281719446182\n",
      "Policy Loss:  -0.058891311287879944\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.12112613022327423\n",
      "Q Loss:  0.10444869101047516\n",
      "Policy Loss:  -0.12007670104503632\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  3.385636568069458\n",
      "Q Loss:  0.0007441555499099195\n",
      "Policy Loss:  0.7517459988594055\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81290 length: 22 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.8383641242980957\n",
      "Q Loss:  0.027904042974114418\n",
      "Policy Loss:  0.7375900149345398\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81317 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.038008689880371094\n",
      "Value Loss:  0.0008891192846931517\n",
      "Q Loss:  0.0022995895706117153\n",
      "Policy Loss:  0.011700847186148167\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0009208259871229529\n",
      "Q Loss:  0.0004972583847120404\n",
      "Policy Loss:  0.007579499389976263\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013341903686523438\n",
      "Value Loss:  0.00043583381921052933\n",
      "Q Loss:  0.0007011341513134539\n",
      "Policy Loss:  0.016623737290501595\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.8790524083888158e-05\n",
      "Q Loss:  0.0002342635707464069\n",
      "Policy Loss:  0.008392911404371262\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  3.119202301604673e-05\n",
      "Q Loss:  0.0016540936194360256\n",
      "Policy Loss:  0.11561986804008484\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81337 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.6152357459068298\n",
      "Q Loss:  0.09362825751304626\n",
      "Policy Loss:  -0.6377851963043213\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81341 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  9.721844980958849e-05\n",
      "Q Loss:  0.00021906141773797572\n",
      "Policy Loss:  0.007519414648413658\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.4585781693458557\n",
      "Q Loss:  0.01642472669482231\n",
      "Policy Loss:  -0.30774036049842834\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 81349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  108.8339614868164\n",
      "Q Loss:  332.1822204589844\n",
      "Policy Loss:  -10.91214370727539\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81423 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.050011396408081055\n",
      "Value Loss:  0.00016376777784898877\n",
      "Q Loss:  8.40252178022638e-05\n",
      "Policy Loss:  0.00545016024261713\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0005557248368859291\n",
      "Q Loss:  0.0006078533479012549\n",
      "Policy Loss:  -0.0019299921113997698\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0005179260042496026\n",
      "Q Loss:  0.0015020504361018538\n",
      "Policy Loss:  0.015226145274937153\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.14280763268470764\n",
      "Q Loss:  0.004306492395699024\n",
      "Policy Loss:  -0.1350553333759308\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  142.5994873046875\n",
      "Q Loss:  429.24114990234375\n",
      "Policy Loss:  -14.613631248474121\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81496 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014592885971069336\n",
      "Value Loss:  0.00012363404675852507\n",
      "Q Loss:  9.115070861298591e-05\n",
      "Policy Loss:  0.12014345824718475\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81500 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  88.58845520019531\n",
      "Q Loss:  266.3525085449219\n",
      "Policy Loss:  -9.18738079071045\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81592 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.13964906334877014\n",
      "Q Loss:  0.19621743261814117\n",
      "Policy Loss:  -0.3207845985889435\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.41613805294036865\n",
      "Q Loss:  0.010734546929597855\n",
      "Policy Loss:  -0.19962304830551147\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  85.07737731933594\n",
      "Q Loss:  252.60293579101562\n",
      "Policy Loss:  -9.12752914428711\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81696 length: 96 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0003118935856036842\n",
      "Q Loss:  0.0007190355681814253\n",
      "Policy Loss:  0.006416029296815395\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0008328916155733168\n",
      "Q Loss:  0.0005997808766551316\n",
      "Policy Loss:  -0.000121342483907938\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00027287518605589867\n",
      "Q Loss:  0.0004619667015504092\n",
      "Policy Loss:  0.12022031843662262\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81708 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.2575298249721527\n",
      "Q Loss:  0.1517305076122284\n",
      "Policy Loss:  0.07071152329444885\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.6829188466072083\n",
      "Q Loss:  5.08209228515625\n",
      "Policy Loss:  0.29238614439964294\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81825 length: 113 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00033636842272244394\n",
      "Q Loss:  0.0005723810754716396\n",
      "Policy Loss:  -0.006645777262747288\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81829 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0008010305464267731\n",
      "Q Loss:  0.0003719186643138528\n",
      "Policy Loss:  0.006308304145932198\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 81833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0003631887666415423\n",
      "Q Loss:  0.00034033984411507845\n",
      "Policy Loss:  -0.0036053014919161797\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005340576171875\n",
      "Value Loss:  0.0004167848383076489\n",
      "Q Loss:  0.0006513322005048394\n",
      "Policy Loss:  -0.009538090787827969\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81841 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014000415802001953\n",
      "Value Loss:  0.0009013026719912887\n",
      "Q Loss:  0.0009469941724091768\n",
      "Policy Loss:  -0.0011139502748847008\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.11725865304470062\n",
      "Q Loss:  0.056646931916475296\n",
      "Policy Loss:  -0.08924897015094757\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81849 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  1.098171353340149\n",
      "Q Loss:  4.058263301849365\n",
      "Policy Loss:  0.34325775504112244\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 81920 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2030.7255859375\n",
      "Q Loss:  6071.423828125\n",
      "Policy Loss:  -126.5364990234375\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 81924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.00046213981113396585\n",
      "Q Loss:  0.0030950792133808136\n",
      "Policy Loss:  -0.008194580674171448\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 81928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000828801654279232\n",
      "Q Loss:  0.0027071638032794\n",
      "Policy Loss:  -0.007937813177704811\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 81932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00024899261188693345\n",
      "Q Loss:  0.003475447650998831\n",
      "Policy Loss:  -0.02266654185950756\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 81936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.003332890570163727\n",
      "Q Loss:  0.004786251112818718\n",
      "Policy Loss:  -0.034717801958322525\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 81940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.002837639069184661\n",
      "Q Loss:  0.0025032723788172007\n",
      "Policy Loss:  -0.01653566211462021\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 81944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.003847797866910696\n",
      "Q Loss:  0.001393915037624538\n",
      "Policy Loss:  -0.014588972553610802\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 81948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.001237155869603157\n",
      "Q Loss:  0.0002260407927678898\n",
      "Policy Loss:  0.016355115920305252\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 81952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004613876342773\n",
      "Value Loss:  0.00037776195676997304\n",
      "Q Loss:  0.002038253005594015\n",
      "Policy Loss:  0.1273057460784912\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 81956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.603070020675659\n",
      "Q Loss:  0.007881452329456806\n",
      "Policy Loss:  0.8106794953346252\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 81977 length: 21 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.004187364596873522\n",
      "Q Loss:  0.0014962598215788603\n",
      "Policy Loss:  0.039444610476493835\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 81981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.34540510177612305\n",
      "Q Loss:  0.05469612777233124\n",
      "Policy Loss:  -0.41039252281188965\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 81985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.3462446331977844\n",
      "Q Loss:  0.06329834461212158\n",
      "Policy Loss:  -0.3892829120159149\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 81989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.4550592601299286\n",
      "Q Loss:  0.057057008147239685\n",
      "Policy Loss:  -0.6939101219177246\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 81993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  1.4413460493087769\n",
      "Q Loss:  0.03716238960623741\n",
      "Policy Loss:  0.1731470823287964\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82049 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  74.74337005615234\n",
      "Q Loss:  219.60467529296875\n",
      "Policy Loss:  -8.12247371673584\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 82157 length: 108 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1997.5238037109375\n",
      "Q Loss:  5995.98876953125\n",
      "Policy Loss:  -111.98531341552734\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82161 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.004461140837520361\n",
      "Q Loss:  0.0010786508210003376\n",
      "Policy Loss:  -0.011950541287660599\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82165 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0016867606900632381\n",
      "Q Loss:  0.0008590720826759934\n",
      "Policy Loss:  0.007709681987762451\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82169 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  5.4100666602607816e-05\n",
      "Q Loss:  0.0010210382752120495\n",
      "Policy Loss:  0.02620193175971508\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82173 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0016869670944288373\n",
      "Q Loss:  0.012346765026450157\n",
      "Policy Loss:  0.047653310000896454\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82177 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.014048231765627861\n",
      "Q Loss:  0.009315930306911469\n",
      "Policy Loss:  0.03831188753247261\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00033605715725570917\n",
      "Q Loss:  0.004644167143851519\n",
      "Policy Loss:  -0.00442414591088891\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.2873356342315674\n",
      "Q Loss:  0.00404938030987978\n",
      "Policy Loss:  -0.09740246832370758\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.28024566173553467\n",
      "Q Loss:  0.175061896443367\n",
      "Policy Loss:  -0.32713568210601807\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.17958541214466095\n",
      "Q Loss:  0.004442235920578241\n",
      "Policy Loss:  -0.07637202739715576\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.1711556762456894\n",
      "Q Loss:  0.12073090672492981\n",
      "Policy Loss:  0.10315875709056854\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.3247531056404114\n",
      "Q Loss:  0.0010552892927080393\n",
      "Policy Loss:  -0.25358444452285767\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700733184814453\n",
      "Value Loss:  0.30345821380615234\n",
      "Q Loss:  0.05267536640167236\n",
      "Policy Loss:  -0.24211373925209045\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.07038776576519012\n",
      "Q Loss:  0.002699874574318528\n",
      "Policy Loss:  -0.03745392709970474\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.12876088917255402\n",
      "Q Loss:  0.06957447528839111\n",
      "Policy Loss:  -0.27568602561950684\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.04357212409377098\n",
      "Q Loss:  0.018193015828728676\n",
      "Policy Loss:  -0.1124749407172203\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.8543830513954163\n",
      "Q Loss:  0.011480712331831455\n",
      "Policy Loss:  0.09787171334028244\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82321 length: 100 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.006089730188250542\n",
      "Q Loss:  0.0007635850924998522\n",
      "Policy Loss:  0.002125539816915989\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0006026240298524499\n",
      "Q Loss:  0.005361906252801418\n",
      "Policy Loss:  0.10245990753173828\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 82329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  21310.255859375\n",
      "Q Loss:  18460.6484375\n",
      "Policy Loss:  -19.87572479248047\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 82368 length: 39 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.030006885528564453\n",
      "Value Loss:  0.013869138434529305\n",
      "Q Loss:  0.010806315578520298\n",
      "Policy Loss:  0.005990216508507729\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 82372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.02046808786690235\n",
      "Q Loss:  0.007814176380634308\n",
      "Policy Loss:  0.028162607923150063\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.046091124415397644\n",
      "Q Loss:  0.00449167937040329\n",
      "Policy Loss:  -0.018969476222991943\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.3486013412475586\n",
      "Q Loss:  0.01782737858593464\n",
      "Policy Loss:  0.6313884258270264\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82417 length: 37 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  2.375540361754247e-06\n",
      "Q Loss:  0.014695262536406517\n",
      "Policy Loss:  -0.08079855144023895\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.003753247205168009\n",
      "Q Loss:  0.015048671513795853\n",
      "Policy Loss:  -0.07192961871623993\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00582111906260252\n",
      "Q Loss:  0.017725225538015366\n",
      "Policy Loss:  -0.05674714595079422\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82429 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.003256443189457059\n",
      "Q Loss:  139.41732788085938\n",
      "Policy Loss:  5.733952045440674\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000398719945224002\n",
      "Q Loss:  276.98175048828125\n",
      "Policy Loss:  11.452735900878906\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82437 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0026604006998240948\n",
      "Q Loss:  68.16271209716797\n",
      "Policy Loss:  2.7956490516662598\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  0.0053168111480772495\n",
      "Q Loss:  0.0024224084336310625\n",
      "Policy Loss:  -0.0010227863676846027\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.004134187009185553\n",
      "Q Loss:  0.0142915528267622\n",
      "Policy Loss:  0.05417405813932419\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.037977807223796844\n",
      "Q Loss:  0.06324033439159393\n",
      "Policy Loss:  0.08293468505144119\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.041168488562107086\n",
      "Q Loss:  0.016238531097769737\n",
      "Policy Loss:  0.037156254053115845\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  0.011822233907878399\n",
      "Q Loss:  0.004310838878154755\n",
      "Policy Loss:  -0.04361071437597275\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  0.03414729982614517\n",
      "Q Loss:  0.006318219006061554\n",
      "Policy Loss:  -0.14940576255321503\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82465 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0010315690888091922\n",
      "Q Loss:  0.017026254907250404\n",
      "Policy Loss:  -0.07365387678146362\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82469 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.001439036219380796\n",
      "Q Loss:  0.00214557396247983\n",
      "Policy Loss:  -0.02826165407896042\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  178.09230041503906\n",
      "Q Loss:  519.5291137695312\n",
      "Policy Loss:  -17.666982650756836\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82518 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.047883447259664536\n",
      "Q Loss:  0.02998233400285244\n",
      "Policy Loss:  -0.08133098483085632\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.002014966681599617\n",
      "Q Loss:  0.003819324541836977\n",
      "Policy Loss:  -0.01788817159831524\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.004702518228441477\n",
      "Q Loss:  60.2717399597168\n",
      "Policy Loss:  2.6658167839050293\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0014140192652121186\n",
      "Q Loss:  0.0016069471603259444\n",
      "Policy Loss:  0.022196663543581963\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002670247631613165\n",
      "Q Loss:  0.0038717675488442183\n",
      "Policy Loss:  0.031229589134454727\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.06659192591905594\n",
      "Q Loss:  0.0572066605091095\n",
      "Policy Loss:  0.0455007329583168\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  82993.375\n",
      "Q Loss:  71892.4609375\n",
      "Policy Loss:  -61.96527099609375\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82552 length: 10 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  74.8235092163086\n",
      "Q Loss:  215.6687774658203\n",
      "Policy Loss:  -8.15009880065918\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82660 length: 108 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2012.104248046875\n",
      "Q Loss:  5853.50341796875\n",
      "Policy Loss:  -128.42835998535156\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  2021.092529296875\n",
      "Q Loss:  7063.27001953125\n",
      "Policy Loss:  -90.05904388427734\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2025.118408203125\n",
      "Q Loss:  1138.2493896484375\n",
      "Policy Loss:  -232.8426055908203\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 82672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  2024.65966796875\n",
      "Q Loss:  2207.295654296875\n",
      "Policy Loss:  -219.1054229736328\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2020.18359375\n",
      "Q Loss:  181.2340850830078\n",
      "Policy Loss:  -218.29489135742188\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82680 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0003456099075265229\n",
      "Q Loss:  122.5424575805664\n",
      "Policy Loss:  5.4596452713012695\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82684 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005018935771659017\n",
      "Q Loss:  0.000594068318605423\n",
      "Policy Loss:  0.00706120952963829\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82688 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00018713332246989012\n",
      "Q Loss:  62.19976806640625\n",
      "Policy Loss:  2.737532138824463\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.03763269633054733\n",
      "Q Loss:  0.06701479852199554\n",
      "Policy Loss:  0.15060460567474365\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.00136638805270195\n",
      "Q Loss:  0.04206257313489914\n",
      "Policy Loss:  -0.07287859171628952\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 82700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  0.060462985187768936\n",
      "Q Loss:  0.01360313594341278\n",
      "Policy Loss:  -0.08702148497104645\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 82704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013416767120361328\n",
      "Value Loss:  143.33175659179688\n",
      "Q Loss:  467.93060302734375\n",
      "Policy Loss:  -14.61857795715332\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 82815 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02700662612915039\n",
      "Value Loss:  26781.833984375\n",
      "Q Loss:  23164.48046875\n",
      "Policy Loss:  -25.474136352539062\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 82846 length: 31 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  0.0012600725749507546\n",
      "Q Loss:  0.012598496861755848\n",
      "Policy Loss:  0.015264318324625492\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 82850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015593290328979492\n",
      "Value Loss:  1.0093132257461548\n",
      "Q Loss:  0.02851315774023533\n",
      "Policy Loss:  0.07725168764591217\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82935 length: 85 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.001126292161643505\n",
      "Q Loss:  0.022464575245976448\n",
      "Policy Loss:  0.031048724427819252\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200103759765625\n",
      "Value Loss:  0.007737359963357449\n",
      "Q Loss:  0.005222801119089127\n",
      "Policy Loss:  0.03490797430276871\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 82943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.005108826793730259\n",
      "Q Loss:  0.001971846679225564\n",
      "Policy Loss:  -0.0315348319709301\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  4.422993242769735e-06\n",
      "Q Loss:  0.0030489254277199507\n",
      "Policy Loss:  -0.03040534257888794\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 82951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0012083792826160789\n",
      "Q Loss:  0.004006248898804188\n",
      "Policy Loss:  -0.01948714256286621\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 82955 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.010365144349634647\n",
      "Q Loss:  0.014832945540547371\n",
      "Policy Loss:  -0.08156490325927734\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 82959 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100966453552246\n",
      "Value Loss:  0.006100581958889961\n",
      "Q Loss:  0.011637862771749496\n",
      "Policy Loss:  -0.051912352442741394\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 82963 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.005392833612859249\n",
      "Q Loss:  0.0002647944784257561\n",
      "Policy Loss:  -0.020468875765800476\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 82967 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.001059768721461296\n",
      "Q Loss:  0.0017204821342602372\n",
      "Policy Loss:  -0.016996510326862335\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 82971 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.002630789065733552\n",
      "Q Loss:  0.01238347589969635\n",
      "Policy Loss:  0.041922613978385925\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 82975 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0009943251498043537\n",
      "Q Loss:  0.013009951449930668\n",
      "Policy Loss:  0.11411194503307343\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 82979 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.23719145357608795\n",
      "Q Loss:  0.04667871445417404\n",
      "Policy Loss:  -0.32024115324020386\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 82983 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.07844439148902893\n",
      "Q Loss:  0.02450289949774742\n",
      "Policy Loss:  0.06845691800117493\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 82987 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.15500690042972565\n",
      "Q Loss:  0.04909539222717285\n",
      "Policy Loss:  -0.2414492517709732\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 82991 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.22771239280700684\n",
      "Q Loss:  0.08663885295391083\n",
      "Policy Loss:  -0.39066749811172485\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 82995 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.2934782803058624\n",
      "Q Loss:  0.06339485198259354\n",
      "Policy Loss:  -0.4948662519454956\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 82999 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.3411890268325806\n",
      "Q Loss:  0.015765784308314323\n",
      "Policy Loss:  0.25593301653862\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83059 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05301165580749512\n",
      "Value Loss:  0.011242235079407692\n",
      "Q Loss:  0.017577696591615677\n",
      "Policy Loss:  -0.005559709854424\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.0009848830522969365\n",
      "Q Loss:  0.004518500529229641\n",
      "Policy Loss:  0.03370580077171326\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0008123129373416305\n",
      "Q Loss:  0.006859624292701483\n",
      "Policy Loss:  0.03209991753101349\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.06137077137827873\n",
      "Q Loss:  0.04858725517988205\n",
      "Policy Loss:  -0.06739746034145355\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.11884283274412155\n",
      "Q Loss:  0.03215222805738449\n",
      "Policy Loss:  0.08738412708044052\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 83079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.05724046751856804\n",
      "Q Loss:  0.03576826676726341\n",
      "Policy Loss:  0.057864777743816376\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 83083 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.2801904678344727\n",
      "Q Loss:  0.009660693816840649\n",
      "Policy Loss:  0.23414923250675201\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83148 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.8955245614051819\n",
      "Q Loss:  0.011587820947170258\n",
      "Policy Loss:  0.16881659626960754\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83242 length: 94 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0031901353504508734\n",
      "Q Loss:  0.009438853710889816\n",
      "Policy Loss:  0.05174397677183151\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 83246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00508875073865056\n",
      "Q Loss:  0.001347195589914918\n",
      "Policy Loss:  -0.0064567383378744125\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 83250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0013192323967814445\n",
      "Q Loss:  0.0023093251511454582\n",
      "Policy Loss:  0.02109951339662075\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 83254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03400707244873047\n",
      "Value Loss:  0.0014440447557717562\n",
      "Q Loss:  0.005058154463768005\n",
      "Policy Loss:  0.03932410106062889\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 83258 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014000415802001953\n",
      "Value Loss:  9412.58984375\n",
      "Q Loss:  8415.6142578125\n",
      "Policy Loss:  -18.419158935546875\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 83347 length: 89 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.14995113015174866\n",
      "Q Loss:  0.05099422484636307\n",
      "Policy Loss:  -0.2414814829826355\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 83351 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.05026472732424736\n",
      "Q Loss:  0.01747920550405979\n",
      "Policy Loss:  -0.013220474123954773\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 83355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.04883094131946564\n",
      "Q Loss:  0.004480383824557066\n",
      "Policy Loss:  -0.01082686334848404\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 83359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.04715992882847786\n",
      "Q Loss:  0.01907261461019516\n",
      "Policy Loss:  -0.08673001825809479\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 83363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011895179748535156\n",
      "Value Loss:  0.09077062457799911\n",
      "Q Loss:  0.020386982709169388\n",
      "Policy Loss:  -0.08459343016147614\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0436459556221962\n",
      "Q Loss:  0.006397202145308256\n",
      "Policy Loss:  0.008634425699710846\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.1257888674736023\n",
      "Q Loss:  0.03580471873283386\n",
      "Policy Loss:  -0.11353155225515366\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.3212231397628784\n",
      "Q Loss:  12.078814506530762\n",
      "Policy Loss:  0.7918919324874878\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83440 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.6619929075241089\n",
      "Q Loss:  0.0170722808688879\n",
      "Policy Loss:  0.24846377968788147\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83492 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.5523706674575806\n",
      "Q Loss:  9.523303031921387\n",
      "Policy Loss:  0.6927014589309692\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83547 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.021581344306468964\n",
      "Q Loss:  0.011594799347221851\n",
      "Policy Loss:  -0.0822107344865799\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0010971281444653869\n",
      "Q Loss:  0.001728975446894765\n",
      "Policy Loss:  0.008995721116662025\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  27910.2265625\n",
      "Q Loss:  24954.884765625\n",
      "Policy Loss:  -45.6279182434082\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83585 length: 30 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2001.7984619140625\n",
      "Q Loss:  7099.4296875\n",
      "Policy Loss:  -85.56340026855469\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  30706.576171875\n",
      "Q Loss:  26511.32421875\n",
      "Policy Loss:  -30.145465850830078\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 83616 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03400778770446777\n",
      "Value Loss:  71.88085174560547\n",
      "Q Loss:  251.5786590576172\n",
      "Policy Loss:  -7.450900554656982\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 83729 length: 113 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  20404.5234375\n",
      "Q Loss:  17798.84375\n",
      "Policy Loss:  -41.98199462890625\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 83811 length: 82 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2023.951171875\n",
      "Q Loss:  5951.1357421875\n",
      "Policy Loss:  -128.31362915039062\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 83815 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.010274183936417103\n",
      "Q Loss:  0.011259107850492\n",
      "Policy Loss:  0.0610586479306221\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 83819 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.004846066702157259\n",
      "Q Loss:  0.003426145762205124\n",
      "Policy Loss:  -0.00027990154922008514\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 83823 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  14272.044921875\n",
      "Q Loss:  12413.802734375\n",
      "Policy Loss:  -14.114922523498535\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83881 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  24339.611328125\n",
      "Q Loss:  21042.798828125\n",
      "Policy Loss:  -24.3349666595459\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83915 length: 34 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.0019348314963281155\n",
      "Q Loss:  0.003253520466387272\n",
      "Policy Loss:  -0.02662704512476921\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  0.002649057889357209\n",
      "Q Loss:  0.00015412764332722872\n",
      "Policy Loss:  -0.004819496069103479\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0004053590237163007\n",
      "Q Loss:  0.00047064395039342344\n",
      "Policy Loss:  0.008758044801652431\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  13769.2724609375\n",
      "Q Loss:  11988.4111328125\n",
      "Policy Loss:  -13.990572929382324\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 83987 length: 60 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  18767.685546875\n",
      "Q Loss:  16242.267578125\n",
      "Policy Loss:  -19.19170379638672\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 84031 length: 44 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.9721203446388245\n",
      "Q Loss:  6.25167179107666\n",
      "Policy Loss:  0.4197123050689697\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 84118 length: 87 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.001527663436718285\n",
      "Q Loss:  67.7779312133789\n",
      "Policy Loss:  2.8826956748962402\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 84122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0004337316786404699\n",
      "Q Loss:  0.0033682617358863354\n",
      "Policy Loss:  0.00044263945892453194\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 84126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.005208452232182026\n",
      "Q Loss:  0.006324844900518656\n",
      "Policy Loss:  0.04718326777219772\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.07300755381584167\n",
      "Q Loss:  0.0651521310210228\n",
      "Policy Loss:  -0.06316046416759491\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84134 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.21670883893966675\n",
      "Q Loss:  0.04156950116157532\n",
      "Policy Loss:  -0.1401781439781189\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84138 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0015786468284204602\n",
      "Q Loss:  0.004343830980360508\n",
      "Policy Loss:  0.042087361216545105\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84142 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.2174569070339203\n",
      "Q Loss:  0.03255455568432808\n",
      "Policy Loss:  -0.12114748358726501\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.6959444880485535\n",
      "Q Loss:  4.523775100708008\n",
      "Policy Loss:  0.29822468757629395\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84266 length: 120 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100778579711914\n",
      "Value Loss:  7.433920836774632e-05\n",
      "Q Loss:  0.004674334544688463\n",
      "Policy Loss:  0.026832636445760727\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0005159424617886543\n",
      "Q Loss:  0.003997656516730785\n",
      "Policy Loss:  0.021943476051092148\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84274 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.139927938580513\n",
      "Q Loss:  0.05036614090204239\n",
      "Policy Loss:  -0.12184183299541473\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84278 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.06863237917423248\n",
      "Q Loss:  0.032411232590675354\n",
      "Policy Loss:  0.05628015100955963\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84282 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.3013277053833008\n",
      "Q Loss:  12.883164405822754\n",
      "Policy Loss:  0.8042721748352051\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84345 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.001558729913085699\n",
      "Q Loss:  0.0018362689297646284\n",
      "Policy Loss:  0.0029870830476284027\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0005278731696307659\n",
      "Q Loss:  0.001988030271604657\n",
      "Policy Loss:  0.09030909836292267\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  17482.416015625\n",
      "Q Loss:  15109.5244140625\n",
      "Policy Loss:  -19.321130752563477\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84400 length: 47 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.5512468814849854\n",
      "Q Loss:  0.012422631494700909\n",
      "Policy Loss:  0.46029984951019287\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84432 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  2.8560538339661434e-05\n",
      "Q Loss:  0.001334795611910522\n",
      "Policy Loss:  0.011688067577779293\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00017919451056513935\n",
      "Q Loss:  0.0006468385690823197\n",
      "Policy Loss:  0.01229814812541008\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008196066482923925\n",
      "Q Loss:  0.0006521926261484623\n",
      "Policy Loss:  -0.004351372830569744\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001346378558082506\n",
      "Q Loss:  0.006047484464943409\n",
      "Policy Loss:  0.03250899165868759\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.0012332062469795346\n",
      "Q Loss:  0.00028188707074150443\n",
      "Policy Loss:  0.08458483219146729\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.28859958052635193\n",
      "Q Loss:  0.043766677379608154\n",
      "Policy Loss:  -0.21747897565364838\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.07149460911750793\n",
      "Q Loss:  0.006589229218661785\n",
      "Policy Loss:  0.02360384911298752\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84460 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.8588816523551941\n",
      "Q Loss:  0.004633897915482521\n",
      "Policy Loss:  0.11670339852571487\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84557 length: 97 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.000314400065690279\n",
      "Q Loss:  0.00032636275864206254\n",
      "Policy Loss:  -0.007423935923725367\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101203918457031\n",
      "Value Loss:  0.00020087178563699126\n",
      "Q Loss:  0.0003925546770915389\n",
      "Policy Loss:  -0.005954005755484104\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84565 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  4.409169196151197e-05\n",
      "Q Loss:  0.00036802119575440884\n",
      "Policy Loss:  -0.00931732077151537\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84569 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.270749453397002e-05\n",
      "Q Loss:  9.46599684539251e-05\n",
      "Policy Loss:  -0.004156413953751326\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84573 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  2.8386684789438732e-05\n",
      "Q Loss:  0.0003680411318782717\n",
      "Policy Loss:  -0.005684465169906616\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84577 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.13589908182621002\n",
      "Q Loss:  0.034468360245227814\n",
      "Policy Loss:  -0.021663352847099304\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84581 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0002319423801964149\n",
      "Q Loss:  0.0008198113064281642\n",
      "Policy Loss:  -0.012156322598457336\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84585 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.19812101125717163\n",
      "Q Loss:  0.06898289918899536\n",
      "Policy Loss:  -0.1490834802389145\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84589 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.19263407588005066\n",
      "Q Loss:  0.03602372854948044\n",
      "Policy Loss:  -0.13527755439281464\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.12320327013731003\n",
      "Q Loss:  0.033324919641017914\n",
      "Policy Loss:  0.006150931119918823\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 84597 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2.861218214035034\n",
      "Q Loss:  0.00982891395688057\n",
      "Policy Loss:  0.5191316604614258\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84626 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  21247.36328125\n",
      "Q Loss:  18920.076171875\n",
      "Policy Loss:  -44.21950149536133\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84665 length: 39 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  0.05699082836508751\n",
      "Q Loss:  0.06903748214244843\n",
      "Policy Loss:  -0.039284829050302505\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.05630851909518242\n",
      "Q Loss:  0.029286308214068413\n",
      "Policy Loss:  -0.04539237171411514\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84673 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  4.616667138179764e-05\n",
      "Q Loss:  2.6186680770479143e-05\n",
      "Policy Loss:  0.0016036398010328412\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84677 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.0117757230764255e-05\n",
      "Q Loss:  0.0015221848152577877\n",
      "Policy Loss:  0.013018612749874592\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84681 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.5880570319714025e-05\n",
      "Q Loss:  0.0014653685502707958\n",
      "Policy Loss:  0.017162254080176353\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84685 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  8.206900383811444e-05\n",
      "Q Loss:  0.006482141092419624\n",
      "Policy Loss:  0.0408749021589756\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84689 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  9.093982953345403e-05\n",
      "Q Loss:  0.0044913445599377155\n",
      "Policy Loss:  0.026719212532043457\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84693 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00010314749670214951\n",
      "Q Loss:  0.001712810480967164\n",
      "Policy Loss:  0.014185408130288124\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84697 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.10323040932416916\n",
      "Q Loss:  0.054773326963186264\n",
      "Policy Loss:  0.005806788802146912\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 84701 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701113700866699\n",
      "Value Loss:  0.10129094123840332\n",
      "Q Loss:  0.02605840377509594\n",
      "Policy Loss:  0.004194527864456177\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84705 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.4288277626037598\n",
      "Q Loss:  0.007027096580713987\n",
      "Policy Loss:  0.39190274477005005\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84740 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007053404115140438\n",
      "Q Loss:  9.493373363511637e-05\n",
      "Policy Loss:  0.006025566719472408\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84744 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.0122970454394817e-05\n",
      "Q Loss:  0.0011650449596345425\n",
      "Policy Loss:  0.08254893124103546\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.1937079131603241\n",
      "Q Loss:  0.017270617187023163\n",
      "Policy Loss:  -0.1721910983324051\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84752 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.1886659860610962\n",
      "Q Loss:  0.014536155387759209\n",
      "Policy Loss:  -0.1534184366464615\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84756 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.09009424597024918\n",
      "Q Loss:  0.02271999977529049\n",
      "Policy Loss:  -0.07862222194671631\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84760 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012042999267578125\n",
      "Value Loss:  6.163582293083891e-05\n",
      "Q Loss:  0.001395813305862248\n",
      "Policy Loss:  0.01621251553297043\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.040680915117263794\n",
      "Q Loss:  0.022406255826354027\n",
      "Policy Loss:  0.04881978780031204\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.4904321586946025e-05\n",
      "Q Loss:  0.0008850909071043134\n",
      "Policy Loss:  0.010999279096722603\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.0184346542228013e-05\n",
      "Q Loss:  2.3908291950647254e-06\n",
      "Policy Loss:  0.0009047678904607892\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 84776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  118.15982055664062\n",
      "Q Loss:  340.5750732421875\n",
      "Policy Loss:  -11.377825736999512\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84854 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.0383276831998955e-06\n",
      "Q Loss:  9.040217992151156e-05\n",
      "Policy Loss:  -0.008770857006311417\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.06677623838186264\n",
      "Q Loss:  0.019024530425667763\n",
      "Policy Loss:  0.00554310530424118\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301450729370117\n",
      "Value Loss:  4.050988354720175e-05\n",
      "Q Loss:  0.0004971558810211718\n",
      "Policy Loss:  -0.018153782933950424\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.08231647068169e-05\n",
      "Q Loss:  0.00046344782458618283\n",
      "Policy Loss:  -0.014563677832484245\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.546823841636069e-05\n",
      "Q Loss:  6.421044963644817e-05\n",
      "Policy Loss:  -0.0019623353146016598\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84874 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013005971908569336\n",
      "Value Loss:  0.02960188314318657\n",
      "Q Loss:  0.04428419843316078\n",
      "Policy Loss:  -0.049641989171504974\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84878 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.6657885313034058\n",
      "Q Loss:  0.005617209244519472\n",
      "Policy Loss:  0.25157561898231506\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84931 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  5.522176252270583e-06\n",
      "Q Loss:  0.0002301021304447204\n",
      "Policy Loss:  -0.005711981561034918\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015001535415649414\n",
      "Value Loss:  1.7042627860064385e-06\n",
      "Q Loss:  7.482913497369736e-05\n",
      "Policy Loss:  -8.080335101112723e-05\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 84939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  299.0298156738281\n",
      "Q Loss:  671.8555297851562\n",
      "Policy Loss:  -30.908777236938477\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 85092 length: 153 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6725.41845703125\n",
      "Q Loss:  5784.62939453125\n",
      "Policy Loss:  -16.35444450378418\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 85215 length: 123 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.0573064577765763e-06\n",
      "Q Loss:  0.0004871401470154524\n",
      "Policy Loss:  0.05665748566389084\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 85219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.08504293113946915\n",
      "Q Loss:  0.016919489949941635\n",
      "Policy Loss:  -0.009278250858187675\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 85223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.153045892715454\n",
      "Q Loss:  0.003342829179018736\n",
      "Policy Loss:  0.1712978631258011\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 85299 length: 76 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  32718.205078125\n",
      "Q Loss:  28348.57421875\n",
      "Policy Loss:  -35.72624206542969\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 85349 length: 50 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00043594714952632785\n",
      "Q Loss:  67.5368881225586\n",
      "Policy Loss:  2.86909556388855\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 85353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001360549358651042\n",
      "Q Loss:  0.00010893035505432636\n",
      "Policy Loss:  -0.004354443401098251\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 85357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.630786811001599e-05\n",
      "Q Loss:  0.0002711346896830946\n",
      "Policy Loss:  -0.001959915040060878\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 85361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4250872135162354\n",
      "Q Loss:  0.006535562686622143\n",
      "Policy Loss:  0.225729838013649\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 85423 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  1.346821665763855\n",
      "Q Loss:  0.0025145355612039566\n",
      "Policy Loss:  0.19670632481575012\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 85488 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.6983973409878672e-06\n",
      "Q Loss:  0.0030221305787563324\n",
      "Policy Loss:  0.03309640288352966\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 85492 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  5.447770118713379\n",
      "Q Loss:  0.014956207945942879\n",
      "Policy Loss:  0.9432194232940674\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 85508 length: 16 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2331.7021484375\n",
      "Q Loss:  6465.2451171875\n",
      "Policy Loss:  -141.30215454101562\n",
      "[(0.00044, 0), (0.00044, 0.0)]\n",
      "Alpha*: 0.00044 tau*: 0 Episode: 85512 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.00018823915161192417\n",
      "Q Loss:  0.00047992117470130324\n",
      "Policy Loss:  -0.005046412814408541\n",
      "[(0.00047, 0), (0.00047, 0.0)]\n",
      "Alpha*: 0.00047 tau*: 0 Episode: 85516 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016031742095947266\n",
      "Value Loss:  0.0002825952251441777\n",
      "Q Loss:  0.00012391414202284068\n",
      "Policy Loss:  -0.0058432877995073795\n",
      "[(0.00051, 0), (0.00051, 0.0)]\n",
      "Alpha*: 0.00051 tau*: 0 Episode: 85520 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.876531890360638e-05\n",
      "Q Loss:  0.0008928993484005332\n",
      "Policy Loss:  0.01559955533593893\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 85524 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200674057006836\n",
      "Value Loss:  0.044701024889945984\n",
      "Q Loss:  0.010571003891527653\n",
      "Policy Loss:  0.006214108318090439\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 85528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.513389285420999e-05\n",
      "Q Loss:  0.00023439718643203378\n",
      "Policy Loss:  0.0061032697558403015\n",
      "[(0.00059, 0), (0.00059, 0.0)]\n",
      "Alpha*: 0.00059 tau*: 0 Episode: 85532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.04809867963194847\n",
      "Q Loss:  0.011867017485201359\n",
      "Policy Loss:  0.002236306667327881\n",
      "[(0.00062, 0), (0.00062, 0.0)]\n",
      "Alpha*: 0.00062 tau*: 0 Episode: 85536 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  490.3646240234375\n",
      "Q Loss:  1626.097900390625\n",
      "Policy Loss:  -44.3763542175293\n",
      "[(0.00064, 0), (0.00064, 0.0)]\n",
      "Alpha*: 0.00064 tau*: 0 Episode: 85593 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012604475021362305\n",
      "Value Loss:  0.0008804669487290084\n",
      "Q Loss:  66.59488677978516\n",
      "Policy Loss:  2.821439743041992\n",
      "[(0.00066, 0), (0.00066, 0.0)]\n",
      "Alpha*: 0.00066 tau*: 0 Episode: 85597 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  0.00036574076511897147\n",
      "Q Loss:  0.0016382880276069045\n",
      "Policy Loss:  0.016539571806788445\n",
      "[(0.00068, 0), (0.00068, 0.0)]\n",
      "Alpha*: 0.00068 tau*: 0 Episode: 85601 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0010271337814629078\n",
      "Q Loss:  0.0009657939081080258\n",
      "Policy Loss:  -0.008497894741594791\n",
      "[(0.00068, 0), (0.00068, 0.0)]\n",
      "Alpha*: 0.00068 tau*: 0 Episode: 85605 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  0.00016570455045439303\n",
      "Q Loss:  0.000503388000652194\n",
      "Policy Loss:  0.008082715794444084\n",
      "[(0.00068, 0), (0.00068, 0.0)]\n",
      "Alpha*: 0.00068 tau*: 0 Episode: 85609 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.056946009397506714\n",
      "Q Loss:  0.015801506116986275\n",
      "Policy Loss:  -0.003134649246931076\n",
      "[(0.00068, 0), (0.00068, 0.0)]\n",
      "Alpha*: 0.00068 tau*: 0 Episode: 85613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  14853.7744140625\n",
      "Q Loss:  12942.3427734375\n",
      "Policy Loss:  -16.674612045288086\n",
      "[(0.00068, 0), (0.00068, 0.0)]\n",
      "Alpha*: 0.00068 tau*: 0 Episode: 85668 length: 55 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  2314.9892578125\n",
      "Q Loss:  6420.92919921875\n",
      "Policy Loss:  -127.67835235595703\n",
      "[(0.00065, 0), (0.00065, 0.0)]\n",
      "Alpha*: 0.00065 tau*: 0 Episode: 85672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.00010237503738608211\n",
      "Q Loss:  0.00011071156768593937\n",
      "Policy Loss:  -0.001980855595320463\n",
      "[(0.00064, 0), (0.00064, 0.0)]\n",
      "Alpha*: 0.00064 tau*: 0 Episode: 85676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.000235751795116812\n",
      "Q Loss:  0.0003422976587899029\n",
      "Policy Loss:  0.01244765892624855\n",
      "[(0.00062, 0), (0.00062, 0.0)]\n",
      "Alpha*: 0.00062 tau*: 0 Episode: 85680 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06168660148978233\n",
      "Q Loss:  0.016449609771370888\n",
      "Policy Loss:  -0.0009178183972835541\n",
      "[(0.0006, 0), (0.0006, 0.0)]\n",
      "Alpha*: 0.0006 tau*: 0 Episode: 85684 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  17055.056640625\n",
      "Q Loss:  15066.1708984375\n",
      "Policy Loss:  -57.33506774902344\n",
      "[(0.00059, 0), (0.00059, 0.0)]\n",
      "Alpha*: 0.00059 tau*: 0 Episode: 85733 length: 49 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00021367488079704344\n",
      "Q Loss:  0.00021391523478087038\n",
      "Policy Loss:  0.008427022956311703\n",
      "[(0.00057, 0), (0.00057, 0.0)]\n",
      "Alpha*: 0.00057 tau*: 0 Episode: 85737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.7350458519067615e-05\n",
      "Q Loss:  0.00022352012456394732\n",
      "Policy Loss:  0.0036373313050717115\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 85741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.7838294045068324e-05\n",
      "Q Loss:  1.2046590200043283e-05\n",
      "Policy Loss:  0.0005847054999321699\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 85745 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  3.978335007559508e-05\n",
      "Q Loss:  7.20700336387381e-05\n",
      "Policy Loss:  -0.0015963470796123147\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 85749 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.06602265685796738\n",
      "Q Loss:  0.013612901791930199\n",
      "Policy Loss:  0.00986926257610321\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 85753 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  105.90989685058594\n",
      "Q Loss:  350.1014099121094\n",
      "Policy Loss:  -10.291703224182129\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 85841 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00010677881073206663\n",
      "Q Loss:  0.00023113461793400347\n",
      "Policy Loss:  -0.007795195560902357\n",
      "[(0.00052, 0), (0.00052, 0.0)]\n",
      "Alpha*: 0.00052 tau*: 0 Episode: 85845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.5042684078216553\n",
      "Q Loss:  0.009269490838050842\n",
      "Policy Loss:  0.2356676459312439\n",
      "[(0.00052, 0), (0.00052, 0.0)]\n",
      "Alpha*: 0.00052 tau*: 0 Episode: 85900 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2310.171142578125\n",
      "Q Loss:  6324.30517578125\n",
      "Policy Loss:  -128.4324493408203\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 85904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001160254905698821\n",
      "Q Loss:  0.00011690847168210894\n",
      "Policy Loss:  0.002417672425508499\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 85908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0004697356198448688\n",
      "Q Loss:  0.0006128682289272547\n",
      "Policy Loss:  0.003198771271854639\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 85912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.000648747431114316\n",
      "Q Loss:  0.00012210798740852624\n",
      "Policy Loss:  -0.0035422302316874266\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 85916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  0.00010502912482479587\n",
      "Q Loss:  4.865813389187679e-05\n",
      "Policy Loss:  0.0014590391656383872\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 85920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00012084065383533016\n",
      "Q Loss:  0.0001704862661426887\n",
      "Policy Loss:  -0.003961957525461912\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 85924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.9763445379794575e-05\n",
      "Q Loss:  4.382215047371574e-05\n",
      "Policy Loss:  0.0029671755619347095\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 85928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.07453979551792145\n",
      "Q Loss:  0.02032415010035038\n",
      "Policy Loss:  0.10321762412786484\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 85932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.9945641160011292\n",
      "Q Loss:  3.2025787830352783\n",
      "Policy Loss:  0.3071575462818146\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 86013 length: 81 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.55367979966104e-05\n",
      "Q Loss:  2.701359335333109e-05\n",
      "Policy Loss:  -0.00031360177672468126\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.4319197109434754e-05\n",
      "Q Loss:  5.266190419206396e-05\n",
      "Policy Loss:  0.004253171384334564\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  131.17654418945312\n",
      "Q Loss:  349.128662109375\n",
      "Policy Loss:  -13.514016151428223\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86091 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000858074112329632\n",
      "Q Loss:  0.000823697482701391\n",
      "Policy Loss:  0.0098597826436162\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86095 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.0288928933732677e-05\n",
      "Q Loss:  8.585883188061416e-05\n",
      "Policy Loss:  -0.0011841492960229516\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86099 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  7.3066598815785255e-06\n",
      "Q Loss:  6.909172225277871e-05\n",
      "Policy Loss:  -0.0016963129164651036\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.16055426001548767\n",
      "Q Loss:  0.03285127133131027\n",
      "Policy Loss:  -0.039508551359176636\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027004241943359375\n",
      "Value Loss:  4.646765228244476e-05\n",
      "Q Loss:  9.558744932292029e-05\n",
      "Policy Loss:  -0.0054262615740299225\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.100797817343846e-06\n",
      "Q Loss:  1.7776399545255117e-05\n",
      "Policy Loss:  0.0020069978199899197\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86115 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.07992272078990936\n",
      "Q Loss:  0.01704386994242668\n",
      "Policy Loss:  0.10982625931501389\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86119 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.3176291882991791\n",
      "Q Loss:  0.061723493039608\n",
      "Policy Loss:  -0.23721885681152344\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0772915706038475\n",
      "Q Loss:  0.016739079728722572\n",
      "Policy Loss:  0.028202638030052185\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86127 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2611536476470064e-05\n",
      "Q Loss:  5.0573078624438494e-05\n",
      "Policy Loss:  0.004786502569913864\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.552541551878676e-05\n",
      "Q Loss:  6.297496292972937e-05\n",
      "Policy Loss:  0.002764109754934907\n",
      "[(0.00056, 0), (0.00056, 0.0)]\n",
      "Alpha*: 0.00056 tau*: 0 Episode: 86135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.1423727124929428\n",
      "Q Loss:  0.02396605722606182\n",
      "Policy Loss:  -0.01548643410205841\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 86139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.6793651580810547\n",
      "Q Loss:  0.01871611550450325\n",
      "Policy Loss:  0.24014484882354736\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 86189 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002967720211017877\n",
      "Q Loss:  0.0004022326320409775\n",
      "Policy Loss:  0.0066194674000144005\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 86193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.0004469960695132613\n",
      "Q Loss:  0.00045042840065434575\n",
      "Policy Loss:  -6.6873617470264435e-06\n",
      "[(0.00055, 0), (0.00055, 0.0)]\n",
      "Alpha*: 0.00055 tau*: 0 Episode: 86197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  2258.151123046875\n",
      "Q Loss:  7247.25\n",
      "Policy Loss:  -127.7728271484375\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 86201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.579941767384298e-05\n",
      "Q Loss:  7.271194772329181e-05\n",
      "Policy Loss:  0.002780469134449959\n",
      "[(0.00054, 0), (0.00054, 0.0)]\n",
      "Alpha*: 0.00054 tau*: 0 Episode: 86205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  3.350211272845627e-06\n",
      "Q Loss:  0.00011629541404545307\n",
      "Policy Loss:  0.001284558791667223\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 86209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.714287595357746e-05\n",
      "Q Loss:  0.0003229948924854398\n",
      "Policy Loss:  0.00019289914052933455\n",
      "[(0.00053, 0), (0.00053, 0.0)]\n",
      "Alpha*: 0.00053 tau*: 0 Episode: 86213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.3776982086710632e-05\n",
      "Q Loss:  0.000206178636290133\n",
      "Policy Loss:  0.00580912921577692\n",
      "[(0.00052, 0), (0.00052, 0.0)]\n",
      "Alpha*: 0.00052 tau*: 0 Episode: 86217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  3.947405275539495e-05\n",
      "Q Loss:  0.00034970935666933656\n",
      "Policy Loss:  0.004617355763912201\n",
      "[(0.00052, 0), (0.00052, 0.0)]\n",
      "Alpha*: 0.00052 tau*: 0 Episode: 86221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.644605749286711e-05\n",
      "Q Loss:  0.0010965639958158135\n",
      "Policy Loss:  0.015054658055305481\n",
      "[(0.00051, 0), (0.00051, 0.0)]\n",
      "Alpha*: 0.00051 tau*: 0 Episode: 86225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027005672454833984\n",
      "Value Loss:  2.8334996386547573e-05\n",
      "Q Loss:  0.000469601945951581\n",
      "Policy Loss:  0.007825084030628204\n",
      "[(0.00051, 0), (0.00051, 0.0)]\n",
      "Alpha*: 0.00051 tau*: 0 Episode: 86229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000783920288086\n",
      "Value Loss:  1.580646767251892e-06\n",
      "Q Loss:  0.0006880349246785045\n",
      "Policy Loss:  0.004893794190138578\n",
      "[(0.00051, 0), (0.00051, 0.0)]\n",
      "Alpha*: 0.00051 tau*: 0 Episode: 86233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  2.0141493223491125e-05\n",
      "Q Loss:  0.0036460820119827986\n",
      "Policy Loss:  0.030659331008791924\n",
      "[(0.0005, 0), (0.0005, 0.0)]\n",
      "Alpha*: 0.0005 tau*: 0 Episode: 86237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.26254940032959\n",
      "Q Loss:  0.008496706373989582\n",
      "Policy Loss:  0.3737001121044159\n",
      "[(0.0005, 0), (0.0005, 0.0)]\n",
      "Alpha*: 0.0005 tau*: 0 Episode: 86274 length: 37 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  2.6628855266608298e-05\n",
      "Q Loss:  0.00034280188265256584\n",
      "Policy Loss:  -0.00531660346314311\n",
      "[(0.00049, 0), (0.00049, 0.0)]\n",
      "Alpha*: 0.00049 tau*: 0 Episode: 86278 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.270108421333134e-05\n",
      "Q Loss:  0.0003237240307498723\n",
      "Policy Loss:  -0.010243626311421394\n",
      "[(0.00049, 0), (0.00049, 0.0)]\n",
      "Alpha*: 0.00049 tau*: 0 Episode: 86282 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  3.554076101863757e-05\n",
      "Q Loss:  0.0017341409111395478\n",
      "Policy Loss:  0.012166216969490051\n",
      "[(0.00049, 0), (0.00049, 0.0)]\n",
      "Alpha*: 0.00049 tau*: 0 Episode: 86286 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  362.4287109375\n",
      "Q Loss:  1080.9185791015625\n",
      "Policy Loss:  -34.66623306274414\n",
      "[(0.00048, 0), (0.00048, 0.0)]\n",
      "Alpha*: 0.00048 tau*: 0 Episode: 86384 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.854298145393841e-05\n",
      "Q Loss:  0.0016459760954603553\n",
      "Policy Loss:  0.01146966964006424\n",
      "[(0.00047, 0), (0.00047, 0.0)]\n",
      "Alpha*: 0.00047 tau*: 0 Episode: 86388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.062140870839357376\n",
      "Q Loss:  0.08111780881881714\n",
      "Policy Loss:  0.08086881786584854\n",
      "[(0.00046, 0), (0.00046, 0.0)]\n",
      "Alpha*: 0.00046 tau*: 0 Episode: 86392 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.3790470361709595\n",
      "Q Loss:  0.01766967959702015\n",
      "Policy Loss:  0.22000303864479065\n",
      "[(0.00046, 0), (0.00046, 0.0)]\n",
      "Alpha*: 0.00046 tau*: 0 Episode: 86454 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  8.157998672686517e-05\n",
      "Q Loss:  0.00042645656503736973\n",
      "Policy Loss:  0.009508330374956131\n",
      "[(0.00045, 0), (0.00045, 0.0)]\n",
      "Alpha*: 0.00045 tau*: 0 Episode: 86458 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012588262557983398\n",
      "Value Loss:  1.0731869224400725e-05\n",
      "Q Loss:  8.658691513119265e-05\n",
      "Policy Loss:  -0.004309724550694227\n",
      "[(0.00044, 0), (0.00044, 0.0)]\n",
      "Alpha*: 0.00044 tau*: 0 Episode: 86462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.0529676476144232e-05\n",
      "Q Loss:  9.307458094554022e-05\n",
      "Policy Loss:  0.002140465658158064\n",
      "[(0.00044, 0), (0.00044, 0.0)]\n",
      "Alpha*: 0.00044 tau*: 0 Episode: 86466 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.3740212782286108e-05\n",
      "Q Loss:  0.0024488128256052732\n",
      "Policy Loss:  0.017324406653642654\n",
      "[(0.00043, 0), (0.00043, 0.0)]\n",
      "Alpha*: 0.00043 tau*: 0 Episode: 86470 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013000726699829102\n",
      "Value Loss:  1.4000179362483323e-05\n",
      "Q Loss:  0.004605811554938555\n",
      "Policy Loss:  0.024069882929325104\n",
      "[(0.00043, 0), (0.00043, 0.0)]\n",
      "Alpha*: 0.00043 tau*: 0 Episode: 86474 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  1.0902324902417604e-05\n",
      "Q Loss:  0.0001381727633997798\n",
      "Policy Loss:  -0.0016647559823468328\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 86478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500082015991211\n",
      "Value Loss:  0.19892486929893494\n",
      "Q Loss:  0.002670588903129101\n",
      "Policy Loss:  0.01803542673587799\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 86482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  8300.712890625\n",
      "Q Loss:  7511.44189453125\n",
      "Policy Loss:  -17.84737205505371\n",
      "[(0.00042, 0), (0.00042, 0.0)]\n",
      "Alpha*: 0.00042 tau*: 0 Episode: 86582 length: 100 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.06509473919868469\n",
      "Q Loss:  0.04378214478492737\n",
      "Policy Loss:  0.07778416574001312\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.128543883562088\n",
      "Q Loss:  0.04126446321606636\n",
      "Policy Loss:  -0.04701028764247894\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86590 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01701498031616211\n",
      "Value Loss:  0.06286634504795074\n",
      "Q Loss:  0.03826761990785599\n",
      "Policy Loss:  0.06193133816123009\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  11813.6455078125\n",
      "Q Loss:  10915.9853515625\n",
      "Policy Loss:  -36.047611236572266\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86665 length: 71 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.2492477000923827e-05\n",
      "Q Loss:  9.728372242534533e-05\n",
      "Policy Loss:  0.004468523897230625\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.059359110891819\n",
      "Q Loss:  0.0025139357894659042\n",
      "Policy Loss:  0.039728693664073944\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86673 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.0756211280822754\n",
      "Q Loss:  0.004248055629432201\n",
      "Policy Loss:  0.31565865874290466\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86713 length: 40 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.694243890910002e-07\n",
      "Q Loss:  0.0003560430486686528\n",
      "Policy Loss:  0.06360304355621338\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.05822731554508209\n",
      "Q Loss:  0.02432388812303543\n",
      "Policy Loss:  -0.0620264858007431\n",
      "[(0.00041, 0), (0.00041, 0.0)]\n",
      "Alpha*: 0.00041 tau*: 0 Episode: 86721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  3.622080157583696e-06\n",
      "Q Loss:  0.001546226441860199\n",
      "Policy Loss:  -0.02740342542529106\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86725 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  2.8023639515595278e-06\n",
      "Q Loss:  0.00014625780750066042\n",
      "Policy Loss:  -0.007258431985974312\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.2427687983727083e-06\n",
      "Q Loss:  0.0008154288516379893\n",
      "Policy Loss:  -0.016414809972047806\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046009063720703125\n",
      "Value Loss:  0.057120852172374725\n",
      "Q Loss:  0.006728128995746374\n",
      "Policy Loss:  0.021708153188228607\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.22637633979320526\n",
      "Q Loss:  0.023369137197732925\n",
      "Policy Loss:  -0.1500622034072876\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  146.97750854492188\n",
      "Q Loss:  483.2956237792969\n",
      "Policy Loss:  -13.873558044433594\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86802 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2221.09130859375\n",
      "Q Loss:  5930.673828125\n",
      "Policy Loss:  -126.96560668945312\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00023943136329762638\n",
      "Q Loss:  0.001708900323137641\n",
      "Policy Loss:  -0.019232960417866707\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.000224844814511016\n",
      "Q Loss:  0.00019635145145002753\n",
      "Policy Loss:  -0.010173111222684383\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00018340282258577645\n",
      "Q Loss:  0.00017375861352775246\n",
      "Policy Loss:  -0.0026000954676419497\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003795623779297\n",
      "Value Loss:  0.10330402851104736\n",
      "Q Loss:  0.006752289365977049\n",
      "Policy Loss:  0.017349109053611755\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.20251286029815674\n",
      "Q Loss:  0.030440431088209152\n",
      "Policy Loss:  -0.10788511484861374\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.416686326498166e-05\n",
      "Q Loss:  0.0007176028448157012\n",
      "Policy Loss:  0.08369259536266327\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.04688087850809097\n",
      "Q Loss:  0.024448160082101822\n",
      "Policy Loss:  -0.021354230120778084\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014781475067138672\n",
      "Value Loss:  0.09003943204879761\n",
      "Q Loss:  0.026206912472844124\n",
      "Policy Loss:  0.03256991133093834\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400944709777832\n",
      "Value Loss:  3.736221697181463e-05\n",
      "Q Loss:  0.00020949606550857425\n",
      "Policy Loss:  0.007292057387530804\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.4101962480926886e-05\n",
      "Q Loss:  6.554368155775592e-05\n",
      "Policy Loss:  0.0028092367574572563\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86846 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.03940677270293236\n",
      "Q Loss:  0.0021364609710872173\n",
      "Policy Loss:  0.04975663125514984\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.03773966804146767\n",
      "Q Loss:  0.020286787301301956\n",
      "Policy Loss:  -0.026745904237031937\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.07211596518754959\n",
      "Q Loss:  0.02119898982346058\n",
      "Policy Loss:  0.025585763156414032\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.034175191074609756\n",
      "Q Loss:  0.019084634259343147\n",
      "Policy Loss:  0.03980369493365288\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.0609116442501545e-05\n",
      "Q Loss:  0.00021767834550701082\n",
      "Policy Loss:  -8.326489478349686e-05\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012615203857421875\n",
      "Value Loss:  0.09208682179450989\n",
      "Q Loss:  0.017590081319212914\n",
      "Policy Loss:  0.001542573794722557\n",
      "[(0.0004, 0), (0.0004, 0.0)]\n",
      "Alpha*: 0.0004 tau*: 0 Episode: 86870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014769792556762695\n",
      "Value Loss:  1.5124030113220215\n",
      "Q Loss:  0.0020235388074070215\n",
      "Policy Loss:  0.22848273813724518\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 86928 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.6081808805465698\n",
      "Q Loss:  5.646026611328125\n",
      "Policy Loss:  0.3201085925102234\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 87075 length: 147 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.342311048181728e-06\n",
      "Q Loss:  0.0014115143567323685\n",
      "Policy Loss:  0.040725044906139374\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 87079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.02595466561615467\n",
      "Q Loss:  0.011097013019025326\n",
      "Policy Loss:  -0.046810224652290344\n",
      "[(0.00039, 0), (0.00039, 0.0)]\n",
      "Alpha*: 0.00039 tau*: 0 Episode: 87083 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.025116417557001114\n",
      "Q Loss:  0.002930478658527136\n",
      "Policy Loss:  0.016185712069272995\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 87087 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.0123528242111206\n",
      "Q Loss:  0.007479359861463308\n",
      "Policy Loss:  0.12499089539051056\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 87176 length: 89 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.025005102157592773\n",
      "Value Loss:  1.023629283736227e-05\n",
      "Q Loss:  0.0003404393792152405\n",
      "Policy Loss:  -0.01258779689669609\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 87180 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.023211056366562843\n",
      "Q Loss:  0.007779489271342754\n",
      "Policy Loss:  0.06948254257440567\n",
      "[(0.00038, 0), (0.00038, 0.0)]\n",
      "Alpha*: 0.00038 tau*: 0 Episode: 87184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.780222773551941\n",
      "Q Loss:  5.532675743103027\n",
      "Policy Loss:  0.48912107944488525\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 87234 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0004391389375086874\n",
      "Q Loss:  0.00048678313032723963\n",
      "Policy Loss:  -0.010228050872683525\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 87238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003732681274414\n",
      "Value Loss:  9.545071225147694e-05\n",
      "Q Loss:  0.0007291416404768825\n",
      "Policy Loss:  -0.01383993960916996\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 87242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.33876518602483e-05\n",
      "Q Loss:  0.0001667715550865978\n",
      "Policy Loss:  -0.0073346639983356\n",
      "[(0.00037, 0), (0.00037, 0.0)]\n",
      "Alpha*: 0.00037 tau*: 0 Episode: 87246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.0717185381945455e-06\n",
      "Q Loss:  0.00021268465206958354\n",
      "Policy Loss:  0.04256758093833923\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0230267271399498\n",
      "Q Loss:  0.004869990982115269\n",
      "Policy Loss:  0.013230182230472565\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.7854962348937988\n",
      "Q Loss:  0.005089482758194208\n",
      "Policy Loss:  0.09571592509746552\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87368 length: 114 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.0599843739764765e-05\n",
      "Q Loss:  0.00015385843289550394\n",
      "Policy Loss:  -0.0026370184496045113\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.023244662210345268\n",
      "Q Loss:  0.005839336197823286\n",
      "Policy Loss:  0.006852397695183754\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.6554293632507324\n",
      "Q Loss:  0.005273040849715471\n",
      "Policy Loss:  0.0802411213517189\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87513 length: 137 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  4.501912371779326e-06\n",
      "Q Loss:  0.00019014628196600825\n",
      "Policy Loss:  0.008558451198041439\n",
      "[(0.00036, 0), (0.00036, 0.0)]\n",
      "Alpha*: 0.00036 tau*: 0 Episode: 87517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  6.342842971207574e-05\n",
      "Q Loss:  0.0001543564285384491\n",
      "Policy Loss:  0.005967002362012863\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 87521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.1184425602550618e-05\n",
      "Q Loss:  0.00017211782687809318\n",
      "Policy Loss:  0.007089162711054087\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 87525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.04763288050889969\n",
      "Q Loss:  0.012629304081201553\n",
      "Policy Loss:  -0.02533021569252014\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 87529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.04729214310646057\n",
      "Q Loss:  0.023146098479628563\n",
      "Policy Loss:  -0.061108991503715515\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 87533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02400517463684082\n",
      "Value Loss:  0.04642748087644577\n",
      "Q Loss:  0.011007838882505894\n",
      "Policy Loss:  -0.011773385107517242\n",
      "[(0.00035, 0), (0.00035, 0.0)]\n",
      "Alpha*: 0.00035 tau*: 0 Episode: 87537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.2912424802780151\n",
      "Q Loss:  3.971923828125\n",
      "Policy Loss:  0.34417036175727844\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 87606 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.06717485189437866\n",
      "Q Loss:  0.012729577720165253\n",
      "Policy Loss:  -0.03729894757270813\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 87610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.9041560888290405\n",
      "Q Loss:  11.649476051330566\n",
      "Policy Loss:  0.791124165058136\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 87657 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  1.6133717508637346e-05\n",
      "Q Loss:  0.00013418641174212098\n",
      "Policy Loss:  0.003995540551841259\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 87661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.044079266488552094\n",
      "Q Loss:  0.006517705507576466\n",
      "Policy Loss:  0.01782529428601265\n",
      "[(0.00034, 0), (0.00034, 0.0)]\n",
      "Alpha*: 0.00034 tau*: 0 Episode: 87665 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  182.73699951171875\n",
      "Q Loss:  478.74615478515625\n",
      "Policy Loss:  -18.699745178222656\n",
      "[(0.00033, 0), (0.00033, 0.0)]\n",
      "Alpha*: 0.00033 tau*: 0 Episode: 87713 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900506019592285\n",
      "Value Loss:  2170.004638671875\n",
      "Q Loss:  5742.65234375\n",
      "Policy Loss:  -126.00537109375\n",
      "[(0.00032, 0), (0.00032, 0.0)]\n",
      "Alpha*: 0.00032 tau*: 0 Episode: 87717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002735900925472379\n",
      "Q Loss:  0.001219017431139946\n",
      "Policy Loss:  -0.012194087728857994\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 87721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00021359261882025748\n",
      "Q Loss:  2.8831822419306263e-05\n",
      "Policy Loss:  0.0014788794796913862\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 87725 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  4.3822851694130804e-06\n",
      "Q Loss:  0.00015467798220925033\n",
      "Policy Loss:  0.00830133631825447\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 87729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.047889821231365204\n",
      "Q Loss:  0.011664467863738537\n",
      "Policy Loss:  0.008365347981452942\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 87733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.7032094547175802e-05\n",
      "Q Loss:  0.006898131221532822\n",
      "Policy Loss:  0.049077365547418594\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 87737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  8082.43359375\n",
      "Q Loss:  7524.615234375\n",
      "Policy Loss:  -25.078523635864258\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 87841 length: 104 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.04836210981011391\n",
      "Q Loss:  0.023635469377040863\n",
      "Policy Loss:  0.018395625054836273\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 87845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.333242416381836\n",
      "Q Loss:  0.005839336197823286\n",
      "Policy Loss:  0.2038320153951645\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 87912 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.5217203074134886e-05\n",
      "Q Loss:  0.0008549892227165401\n",
      "Policy Loss:  0.008413523435592651\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 87916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012505769729614258\n",
      "Value Loss:  1.0038644075393677\n",
      "Q Loss:  0.003812092822045088\n",
      "Policy Loss:  0.15497910976409912\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 88005 length: 89 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2138.064697265625\n",
      "Q Loss:  5622.580078125\n",
      "Policy Loss:  -125.5442886352539\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00012623044312931597\n",
      "Q Loss:  0.0011328988475725055\n",
      "Policy Loss:  -0.0199587419629097\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006943125044927001\n",
      "Q Loss:  0.0018287742277607322\n",
      "Policy Loss:  0.01329778227955103\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0016145557165145874\n",
      "Q Loss:  0.0001252552610822022\n",
      "Policy Loss:  0.0054205190390348434\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.32417533476837e-05\n",
      "Q Loss:  66.22637939453125\n",
      "Policy Loss:  2.801901340484619\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  2.8045320505043492e-05\n",
      "Q Loss:  3.346073208376765e-05\n",
      "Policy Loss:  -0.0035784440115094185\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00011319703480694443\n",
      "Q Loss:  0.001169041614048183\n",
      "Policy Loss:  -0.014300139620900154\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0008789105922915041\n",
      "Q Loss:  0.0019609888549894094\n",
      "Policy Loss:  -0.025994181632995605\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0005825702100992203\n",
      "Q Loss:  0.0007289195200428367\n",
      "Policy Loss:  -0.012539568357169628\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.2458838429884054e-05\n",
      "Q Loss:  0.000103416656202171\n",
      "Policy Loss:  -0.00017103689606301486\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  387.28594970703125\n",
      "Q Loss:  968.0036010742188\n",
      "Policy Loss:  -39.79698181152344\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88132 length: 87 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00013689440675079823\n",
      "Q Loss:  0.0003390983329154551\n",
      "Policy Loss:  0.012950383126735687\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.4447672331007197e-05\n",
      "Q Loss:  0.00033526451443322003\n",
      "Policy Loss:  0.011042430065572262\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  4.6721466787857935e-05\n",
      "Q Loss:  9.390728519065306e-05\n",
      "Policy Loss:  0.005801131948828697\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.030128099024295807\n",
      "Q Loss:  0.007148050237447023\n",
      "Policy Loss:  0.06853880733251572\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701042175292969\n",
      "Value Loss:  30888.375\n",
      "Q Loss:  27925.01171875\n",
      "Policy Loss:  -59.86830139160156\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88175 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  9.33410137804458e-06\n",
      "Q Loss:  0.000371105270460248\n",
      "Policy Loss:  0.04652601480484009\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88179 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.0711795091629028\n",
      "Q Loss:  0.004706043284386396\n",
      "Policy Loss:  0.14722996950149536\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88261 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.030006885528564453\n",
      "Value Loss:  5.458569376060041e-06\n",
      "Q Loss:  0.00020416337065398693\n",
      "Policy Loss:  -0.007613910362124443\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.06906086951494217\n",
      "Q Loss:  0.015204599127173424\n",
      "Policy Loss:  -0.023384366184473038\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.14056898653507233\n",
      "Q Loss:  0.026773229241371155\n",
      "Policy Loss:  -0.13493463397026062\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.619091510772705\n",
      "Q Loss:  0.006032481323927641\n",
      "Policy Loss:  0.23004566133022308\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88327 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.9571911692619324\n",
      "Q Loss:  0.0033703132066875696\n",
      "Policy Loss:  0.1495727002620697\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88418 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4226.26953125\n",
      "Q Loss:  11995.08203125\n",
      "Policy Loss:  -31.085363388061523\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.384959174785763e-05\n",
      "Q Loss:  0.00020262015459593385\n",
      "Policy Loss:  0.00910971499979496\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00014525307051371783\n",
      "Q Loss:  0.0018433625809848309\n",
      "Policy Loss:  0.02648250013589859\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  2.114465314662084e-05\n",
      "Q Loss:  0.0007334158872254193\n",
      "Policy Loss:  0.009423056617379189\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.03802892565727234\n",
      "Q Loss:  0.02359444461762905\n",
      "Policy Loss:  0.05377183109521866\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  0.07641430199146271\n",
      "Q Loss:  0.000786986667662859\n",
      "Policy Loss:  0.04065273329615593\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.037949252873659134\n",
      "Q Loss:  0.02801370620727539\n",
      "Policy Loss:  0.006778847426176071\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.07499120384454727\n",
      "Q Loss:  0.02864145301282406\n",
      "Policy Loss:  0.05178892984986305\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88450 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.07332389056682587\n",
      "Q Loss:  0.0013602657709270716\n",
      "Policy Loss:  0.05328795313835144\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88454 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.0455089807510376\n",
      "Q Loss:  0.007116443943232298\n",
      "Policy Loss:  0.17897078394889832\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88537 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  2063.486083984375\n",
      "Q Loss:  5365.69384765625\n",
      "Policy Loss:  -110.43948364257812\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.8159853425459005e-05\n",
      "Q Loss:  0.0009698581998236477\n",
      "Policy Loss:  0.01675345003604889\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88545 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00014835366164334118\n",
      "Q Loss:  0.0002692387788556516\n",
      "Policy Loss:  -0.005370167084038258\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88549 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.653211989440024e-05\n",
      "Q Loss:  0.0004460649797692895\n",
      "Policy Loss:  0.010332279838621616\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88553 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025622129440307617\n",
      "Value Loss:  8.356112812180072e-05\n",
      "Q Loss:  0.00032241936423815787\n",
      "Policy Loss:  0.007763962261378765\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88557 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.050011396408081055\n",
      "Value Loss:  0.06542352586984634\n",
      "Q Loss:  0.021140921860933304\n",
      "Policy Loss:  0.029159996658563614\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  19002.23046875\n",
      "Q Loss:  17268.14453125\n",
      "Policy Loss:  -37.26700973510742\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88605 length: 44 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.4538760297000408e-05\n",
      "Q Loss:  3.547179949237034e-05\n",
      "Policy Loss:  -0.002013896591961384\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88609 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.4507412910461426\n",
      "Q Loss:  0.0075074899941682816\n",
      "Policy Loss:  0.20168717205524445\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88670 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  5.470343239721842e-06\n",
      "Q Loss:  0.0001460670173401013\n",
      "Policy Loss:  -0.006239093374460936\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5.3311261581256986e-05\n",
      "Q Loss:  0.0005512010538950562\n",
      "Policy Loss:  -0.016087926924228668\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88678 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  4.109064320800826e-05\n",
      "Q Loss:  0.0006787776947021484\n",
      "Policy Loss:  -0.014388720504939556\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.03361637145280838\n",
      "Q Loss:  0.0033077045809477568\n",
      "Policy Loss:  0.019996417686343193\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.06741568446159363\n",
      "Q Loss:  0.01530116330832243\n",
      "Policy Loss:  -0.06031355261802673\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900885581970215\n",
      "Value Loss:  1.6863079508766532e-05\n",
      "Q Loss:  0.00012648427218664438\n",
      "Policy Loss:  -0.004317851271480322\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.68834537564544e-05\n",
      "Q Loss:  1.397589312546188e-05\n",
      "Policy Loss:  -0.001787754474207759\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88698 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.03288310393691063\n",
      "Q Loss:  0.011770064011216164\n",
      "Policy Loss:  0.022251291200518608\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88702 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  15055.49609375\n",
      "Q Loss:  13452.625\n",
      "Policy Loss:  -15.773541450500488\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88757 length: 55 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  8.626951603218913e-05\n",
      "Q Loss:  0.0003430313372518867\n",
      "Policy Loss:  -0.009353217668831348\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.3448355275613721e-05\n",
      "Q Loss:  0.0008046713192015886\n",
      "Policy Loss:  -0.015165703371167183\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.957533181164763e-07\n",
      "Q Loss:  0.000631980481557548\n",
      "Policy Loss:  -0.013672463595867157\n",
      "[(0.00031, 0), (0.00031, 0.0)]\n",
      "Alpha*: 0.00031 tau*: 0 Episode: 88769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1472207006590907e-05\n",
      "Q Loss:  0.0027521667070686817\n",
      "Policy Loss:  -0.02885603904724121\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.737466719641816e-06\n",
      "Q Loss:  0.002395134884864092\n",
      "Policy Loss:  -0.015355926938354969\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88777 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.933753608493134e-05\n",
      "Q Loss:  5.727657116949558e-05\n",
      "Policy Loss:  -0.0035151115152984858\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88781 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.333100772171747e-05\n",
      "Q Loss:  0.00014399123028852046\n",
      "Policy Loss:  0.002764374017715454\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029005765914916992\n",
      "Value Loss:  7.845865184208378e-06\n",
      "Q Loss:  4.257283580955118e-05\n",
      "Policy Loss:  0.0018864928279072046\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.03268749266862869\n",
      "Q Loss:  0.009981042705476284\n",
      "Policy Loss:  0.03240251913666725\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  90.98845672607422\n",
      "Q Loss:  285.2541198730469\n",
      "Policy Loss:  -9.118304252624512\n",
      "[(0.0003, 0), (0.0003, 0.0)]\n",
      "Alpha*: 0.0003 tau*: 0 Episode: 88884 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00014087418094277382\n",
      "Q Loss:  0.00015909395006019622\n",
      "Policy Loss:  0.005614598281681538\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.2022614100715145e-05\n",
      "Q Loss:  0.0003667676355689764\n",
      "Policy Loss:  0.011211516335606575\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.237009074538946e-06\n",
      "Q Loss:  0.0004379958554636687\n",
      "Policy Loss:  0.01236613467335701\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.175190047637443e-06\n",
      "Q Loss:  0.00010447757813381031\n",
      "Policy Loss:  0.0038872510194778442\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.032963406294584274\n",
      "Q Loss:  0.008609593845903873\n",
      "Policy Loss:  0.029651019722223282\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.0051235221908428e-05\n",
      "Q Loss:  2.009295712923631e-05\n",
      "Policy Loss:  0.0005171370576135814\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.03274832293391228\n",
      "Q Loss:  0.007603941950947046\n",
      "Policy Loss:  0.023069150745868683\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013005971908569336\n",
      "Value Loss:  0.03245881199836731\n",
      "Q Loss:  0.0061217257753014565\n",
      "Policy Loss:  0.024242326617240906\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06801509857177734\n",
      "Value Loss:  0.0960368812084198\n",
      "Q Loss:  0.018601922318339348\n",
      "Policy Loss:  -0.10157065838575363\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  2.703066002140986e-07\n",
      "Q Loss:  0.023583587259054184\n",
      "Policy Loss:  0.005304347723722458\n",
      "[(0.00029, 0), (0.00029, 0.0)]\n",
      "Alpha*: 0.00029 tau*: 0 Episode: 88924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.03019852004945278\n",
      "Q Loss:  0.006786250043660402\n",
      "Policy Loss:  -0.022749830037355423\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011646747589111328\n",
      "Value Loss:  1.0180061508435756e-05\n",
      "Q Loss:  0.0001407971722073853\n",
      "Policy Loss:  0.005791306030005217\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 88932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.0855756998062134\n",
      "Q Loss:  0.007878121919929981\n",
      "Policy Loss:  0.16045473515987396\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89014 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00014840340008959174\n",
      "Q Loss:  0.0008394131436944008\n",
      "Policy Loss:  0.009344140067696571\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89018 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0004665538144763559\n",
      "Q Loss:  0.0004912656731903553\n",
      "Policy Loss:  0.009312044829130173\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89022 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0009585261577740312\n",
      "Q Loss:  0.00015521283785346895\n",
      "Policy Loss:  0.00760413333773613\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89026 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04601097106933594\n",
      "Value Loss:  2.7534588298294693e-05\n",
      "Q Loss:  133.8382110595703\n",
      "Policy Loss:  5.67354679107666\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89030 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.0137780666118488e-05\n",
      "Q Loss:  66.53900146484375\n",
      "Policy Loss:  2.8419547080993652\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.000151846616063267\n",
      "Q Loss:  0.0015412956709042192\n",
      "Policy Loss:  -0.003589751198887825\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005559851415455341\n",
      "Q Loss:  0.0007754022954031825\n",
      "Policy Loss:  -0.021685242652893066\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 89042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.3559874787461013e-05\n",
      "Q Loss:  0.00020541445701383054\n",
      "Policy Loss:  -0.006678878795355558\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.051750145852565765\n",
      "Q Loss:  0.011130611412227154\n",
      "Policy Loss:  -0.0246158204972744\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0508156456053257\n",
      "Q Loss:  0.030644990503787994\n",
      "Policy Loss:  -0.022761300206184387\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.024687012657523155\n",
      "Q Loss:  0.002694954164326191\n",
      "Policy Loss:  -0.04588064178824425\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2.0686113202827983e-05\n",
      "Q Loss:  0.0022684126161038876\n",
      "Policy Loss:  -0.014939052984118462\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100823402404785\n",
      "Value Loss:  0.001804459374397993\n",
      "Q Loss:  0.0018295926274731755\n",
      "Policy Loss:  -0.02754492685198784\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  1.2010470527457073e-05\n",
      "Q Loss:  0.00014563222066499293\n",
      "Policy Loss:  -0.004326626658439636\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.3319140382227488e-05\n",
      "Q Loss:  0.0002486917073838413\n",
      "Policy Loss:  -0.006430085748434067\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 89074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.2082612556696404e-05\n",
      "Q Loss:  0.00013459406909532845\n",
      "Policy Loss:  -0.0046349456533789635\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.307796633744147e-06\n",
      "Q Loss:  0.0007299158023670316\n",
      "Policy Loss:  0.016504084691405296\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89082 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.3246440074872226e-06\n",
      "Q Loss:  0.00042425564606674016\n",
      "Policy Loss:  0.011005940847098827\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.020374998450279236\n",
      "Q Loss:  0.001870095613412559\n",
      "Policy Loss:  0.012318359687924385\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.6977574825286865\n",
      "Q Loss:  0.006533846724778414\n",
      "Policy Loss:  0.24701814353466034\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89143 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00010938620835077018\n",
      "Q Loss:  0.00011789327254518867\n",
      "Policy Loss:  0.004997932352125645\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  5.334779780241661e-05\n",
      "Q Loss:  0.0012977300211787224\n",
      "Policy Loss:  0.004356496036052704\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0510103702545166\n",
      "Value Loss:  0.002523392904549837\n",
      "Q Loss:  0.0007883384823799133\n",
      "Policy Loss:  0.011279845610260963\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89155 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005817413330078\n",
      "Value Loss:  0.0009342429111711681\n",
      "Q Loss:  0.0004972784081473947\n",
      "Policy Loss:  -0.0012104110792279243\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89159 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00036701973294839263\n",
      "Q Loss:  0.0001675454550422728\n",
      "Policy Loss:  -0.0028732416685670614\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011994600296020508\n",
      "Value Loss:  0.0001659443078096956\n",
      "Q Loss:  0.00039937166729941964\n",
      "Policy Loss:  -0.007243386935442686\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89167 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04122646525502205\n",
      "Q Loss:  0.010827804915606976\n",
      "Policy Loss:  -0.03124341368675232\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 89171 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.02046654000878334\n",
      "Q Loss:  0.009867623448371887\n",
      "Policy Loss:  0.006632301956415176\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89175 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.020121801644563675\n",
      "Q Loss:  0.0010763454483821988\n",
      "Policy Loss:  -0.032619401812553406\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89179 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.4621250961208716e-05\n",
      "Q Loss:  0.00020402803784236312\n",
      "Policy Loss:  0.00523276487365365\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89183 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.019363347440958023\n",
      "Q Loss:  0.001545377541333437\n",
      "Policy Loss:  0.014758924022316933\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  2.6442015171051025\n",
      "Q Loss:  0.010838395915925503\n",
      "Policy Loss:  0.3621845245361328\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89221 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5.085791781311855e-05\n",
      "Q Loss:  0.00013770177611149848\n",
      "Policy Loss:  0.0033548600040376186\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  4.704463935922831e-05\n",
      "Q Loss:  0.0003130748518742621\n",
      "Policy Loss:  0.005623740144073963\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  6.447541818488389e-05\n",
      "Q Loss:  0.00030018656980246305\n",
      "Policy Loss:  0.0016342841554433107\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.02051812782883644\n",
      "Q Loss:  0.0019266807939857244\n",
      "Policy Loss:  0.01357639767229557\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  6577.234375\n",
      "Q Loss:  5989.7021484375\n",
      "Policy Loss:  -13.878673553466797\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89364 length: 127 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.028005599975585938\n",
      "Value Loss:  4105.25048828125\n",
      "Q Loss:  7240.47705078125\n",
      "Policy Loss:  -254.53517150878906\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 89368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  2044.45361328125\n",
      "Q Loss:  7267.921875\n",
      "Policy Loss:  -97.6102294921875\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 89372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2032.557373046875\n",
      "Q Loss:  6229.87451171875\n",
      "Policy Loss:  -96.49362182617188\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 89376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2017.40185546875\n",
      "Q Loss:  5151.2001953125\n",
      "Policy Loss:  -109.48150634765625\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 89380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.006831910461187363\n",
      "Q Loss:  0.0026422461960464716\n",
      "Policy Loss:  -0.01825368031859398\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 89384 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.001433313125744462\n",
      "Q Loss:  0.0028075689915567636\n",
      "Policy Loss:  0.021036671474575996\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 89388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.001021286123432219\n",
      "Q Loss:  0.0010611051693558693\n",
      "Policy Loss:  0.014849357306957245\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 89392 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0001403174683218822\n",
      "Q Loss:  0.0018762729596346617\n",
      "Policy Loss:  0.07104412466287613\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89396 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.023238884285092354\n",
      "Q Loss:  0.043448884040117264\n",
      "Policy Loss:  0.06613394618034363\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89400 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  2.0529792308807373\n",
      "Q Loss:  0.007505887653678656\n",
      "Policy Loss:  0.35870668292045593\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89443 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0006415065145120025\n",
      "Q Loss:  0.0052875736728310585\n",
      "Policy Loss:  0.04009849578142166\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  2.1969242880004458e-05\n",
      "Q Loss:  0.00875333696603775\n",
      "Policy Loss:  0.04895559698343277\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.3349886760115623e-05\n",
      "Q Loss:  0.012073200196027756\n",
      "Policy Loss:  0.05493089556694031\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.2340101420704741e-05\n",
      "Q Loss:  0.012464729137718678\n",
      "Policy Loss:  0.05374017357826233\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.02680807374417782\n",
      "Q Loss:  0.047238752245903015\n",
      "Policy Loss:  0.03981732204556465\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0016521761426702142\n",
      "Q Loss:  0.008078589104115963\n",
      "Policy Loss:  -0.04486054554581642\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0003726094146259129\n",
      "Q Loss:  0.0003110529505647719\n",
      "Policy Loss:  0.00574552733451128\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0290067195892334\n",
      "Value Loss:  0.027775932103395462\n",
      "Q Loss:  0.0014869520673528314\n",
      "Policy Loss:  0.058377765119075775\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.05572686344385147\n",
      "Q Loss:  0.08286985754966736\n",
      "Policy Loss:  0.004224523901939392\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  148.66067504882812\n",
      "Q Loss:  0.006043531466275454\n",
      "Policy Loss:  -19.144184112548828\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89530 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.05606965348124504\n",
      "Q Loss:  0.027048926800489426\n",
      "Policy Loss:  0.034709930419921875\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00016399359446950257\n",
      "Q Loss:  0.00010089473653351888\n",
      "Policy Loss:  -0.0015317671932280064\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.08439194411039352\n",
      "Q Loss:  0.02740183286368847\n",
      "Policy Loss:  -0.036226555705070496\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  1.8524987697601318\n",
      "Q Loss:  0.011820873245596886\n",
      "Policy Loss:  0.2745785415172577\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89590 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0019947930704802275\n",
      "Q Loss:  81.0978775024414\n",
      "Policy Loss:  3.017886161804199\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0014653789112344384\n",
      "Q Loss:  0.02433026395738125\n",
      "Policy Loss:  -0.03219275176525116\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 89598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.01041879691183567\n",
      "Q Loss:  0.02062768116593361\n",
      "Policy Loss:  0.03405023738741875\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 89602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.015582771971821785\n",
      "Q Loss:  0.007744675502181053\n",
      "Policy Loss:  0.02639351785182953\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 89606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0029253114480525255\n",
      "Q Loss:  0.002261572051793337\n",
      "Policy Loss:  -0.01901686191558838\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 89610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0007058483315631747\n",
      "Q Loss:  0.0026517650112509727\n",
      "Policy Loss:  -0.024284452199935913\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 89614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.0014143872540444136\n",
      "Q Loss:  0.010713807307183743\n",
      "Policy Loss:  0.02234097570180893\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 89618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0018320160452276468\n",
      "Q Loss:  0.004349819850176573\n",
      "Policy Loss:  -0.0038143927231431007\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.001045562676154077\n",
      "Q Loss:  0.011773580685257912\n",
      "Policy Loss:  0.030432961881160736\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0008514057844877243\n",
      "Q Loss:  0.0029210944194346666\n",
      "Policy Loss:  -0.03215992823243141\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000307713431539014\n",
      "Q Loss:  0.001015004119835794\n",
      "Policy Loss:  -0.016797605901956558\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01608443260192871\n",
      "Value Loss:  8.658635488245636e-05\n",
      "Q Loss:  0.0005560293211601675\n",
      "Policy Loss:  0.038977958261966705\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89638 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.11570090800523758\n",
      "Q Loss:  0.017464134842157364\n",
      "Policy Loss:  -0.09234773367643356\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89642 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.8826553969120141e-06\n",
      "Q Loss:  0.0001333057734882459\n",
      "Policy Loss:  0.0011666282080113888\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89646 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0024966197088360786\n",
      "Q Loss:  0.0037274989299476147\n",
      "Policy Loss:  -0.0002719992771744728\n",
      "[(0.00019, 0), (0.00019, 0.0)]\n",
      "Alpha*: 0.00019 tau*: 0 Episode: 89650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0009457186097279191\n",
      "Q Loss:  0.00021187294623814523\n",
      "Policy Loss:  0.016386061906814575\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89654 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.455369632225484e-05\n",
      "Q Loss:  0.00021537128486670554\n",
      "Policy Loss:  0.0073365881107747555\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89658 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400944709777832\n",
      "Value Loss:  0.0032195975072681904\n",
      "Q Loss:  0.013249806128442287\n",
      "Policy Loss:  -0.04062415286898613\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  8529.2958984375\n",
      "Q Loss:  7631.12158203125\n",
      "Policy Loss:  -8.892227172851562\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89760 length: 98 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.05177837237715721\n",
      "Q Loss:  0.012924181297421455\n",
      "Policy Loss:  -0.039365287870168686\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5.217273428570479e-05\n",
      "Q Loss:  0.0004755431436933577\n",
      "Policy Loss:  0.009404027834534645\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89768 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.940926636569202e-05\n",
      "Q Loss:  0.00038153413333930075\n",
      "Policy Loss:  0.0103895403444767\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700139045715332\n",
      "Value Loss:  0.0010966474656015635\n",
      "Q Loss:  0.0003557730233296752\n",
      "Policy Loss:  0.002007045317441225\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.04902802035212517\n",
      "Q Loss:  0.022643977776169777\n",
      "Policy Loss:  -0.036287371069192886\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.023952841758728027\n",
      "Q Loss:  0.00997381191700697\n",
      "Policy Loss:  -0.011195477098226547\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.06992879509925842\n",
      "Q Loss:  0.012261446565389633\n",
      "Policy Loss:  -0.0051247309893369675\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89788 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.02232007496058941\n",
      "Q Loss:  0.010235409252345562\n",
      "Policy Loss:  0.041127994656562805\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89792 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  2.1908133930992335e-05\n",
      "Q Loss:  0.0010668982286006212\n",
      "Policy Loss:  0.015475057065486908\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89796 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.721653825370595e-05\n",
      "Q Loss:  0.0004908139235340059\n",
      "Policy Loss:  0.012466127052903175\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001203536987305\n",
      "Value Loss:  3.7070844882691745e-06\n",
      "Q Loss:  0.0005865636048838496\n",
      "Policy Loss:  0.013649320229887962\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89804 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101156234741211\n",
      "Value Loss:  0.03789600729942322\n",
      "Q Loss:  0.009287740103900433\n",
      "Policy Loss:  0.014737024903297424\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 89808 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030006885528564453\n",
      "Value Loss:  0.03620723634958267\n",
      "Q Loss:  0.002758369082584977\n",
      "Policy Loss:  0.014662884175777435\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500795364379883\n",
      "Value Loss:  1.8736793994903564\n",
      "Q Loss:  0.02613350749015808\n",
      "Policy Loss:  0.23493684828281403\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89861 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.8977291584014893\n",
      "Q Loss:  0.015628745779395103\n",
      "Policy Loss:  0.2690838873386383\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89909 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012004613876342773\n",
      "Value Loss:  3.4527110983617604e-05\n",
      "Q Loss:  0.00027719794888980687\n",
      "Policy Loss:  0.04724285751581192\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89913 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.034520700573921204\n",
      "Q Loss:  0.00792368408292532\n",
      "Policy Loss:  0.005309823900461197\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.7467402219772339\n",
      "Q Loss:  0.018168503418564796\n",
      "Policy Loss:  0.2516496181488037\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89969 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012004613876342773\n",
      "Value Loss:  0.03548431396484375\n",
      "Q Loss:  0.007682724855840206\n",
      "Policy Loss:  -0.0012164115905761719\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4642928647390363e-07\n",
      "Q Loss:  0.00010318066051695496\n",
      "Policy Loss:  -0.004761449061334133\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 89977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  23292.7421875\n",
      "Q Loss:  21738.33203125\n",
      "Policy Loss:  -60.48898696899414\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90050 length: 73 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1853.55908203125\n",
      "Q Loss:  5475.638671875\n",
      "Policy Loss:  -117.29581451416016\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.004438868258148432\n",
      "Q Loss:  81.01970672607422\n",
      "Policy Loss:  3.175771474838257\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.018744798377156258\n",
      "Q Loss:  0.017666330561041832\n",
      "Policy Loss:  -0.05237589776515961\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.008044893853366375\n",
      "Q Loss:  0.03737704083323479\n",
      "Policy Loss:  0.06816951930522919\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  0.0010815556161105633\n",
      "Q Loss:  0.008962462656199932\n",
      "Policy Loss:  -0.010150648653507233\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0033502457663416862\n",
      "Q Loss:  0.023278187960386276\n",
      "Policy Loss:  0.024187486618757248\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.009462801739573479\n",
      "Q Loss:  0.01278502307832241\n",
      "Policy Loss:  0.08817307651042938\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016086101531982422\n",
      "Value Loss:  0.0015909633366391063\n",
      "Q Loss:  0.004295200575143099\n",
      "Policy Loss:  0.008589081466197968\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90082 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00018624827498570085\n",
      "Q Loss:  0.00259655830450356\n",
      "Policy Loss:  -0.0060673970729112625\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00018572210683487356\n",
      "Q Loss:  0.0007287116022780538\n",
      "Policy Loss:  -0.009153652004897594\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0007526124245487154\n",
      "Q Loss:  0.0006781659321859479\n",
      "Policy Loss:  0.0188298337161541\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.02128930389881134\n",
      "Q Loss:  0.008468556217849255\n",
      "Policy Loss:  0.03361181169748306\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90098 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005214080447331071\n",
      "Q Loss:  0.0015209806151688099\n",
      "Policy Loss:  0.024540143087506294\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90102 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600550651550293\n",
      "Value Loss:  0.00048389731091447175\n",
      "Q Loss:  0.0007015406154096127\n",
      "Policy Loss:  0.00048608705401420593\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90106 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.021109050139784813\n",
      "Q Loss:  0.005349791143089533\n",
      "Policy Loss:  0.025149188935756683\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90110 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.8427500947382214e-07\n",
      "Q Loss:  9.207529365085065e-05\n",
      "Policy Loss:  -0.004630114417523146\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.00014307827223092318\n",
      "Q Loss:  0.0007419766625389457\n",
      "Policy Loss:  0.015420559793710709\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0001739399740472436\n",
      "Q Loss:  0.0006694560870528221\n",
      "Policy Loss:  0.01702921651303768\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.020891353487968445\n",
      "Q Loss:  0.003075363812968135\n",
      "Policy Loss:  0.001009039580821991\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006242752075195\n",
      "Value Loss:  0.0003061802708543837\n",
      "Q Loss:  0.0004899372579529881\n",
      "Policy Loss:  0.03334509953856468\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600550651550293\n",
      "Value Loss:  0.06075415760278702\n",
      "Q Loss:  0.013262270018458366\n",
      "Policy Loss:  -0.09998849779367447\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90134 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  35120.2421875\n",
      "Q Loss:  31816.57421875\n",
      "Policy Loss:  -65.7673110961914\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90182 length: 48 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.6510392427444458\n",
      "Q Loss:  0.02981789968907833\n",
      "Policy Loss:  0.22942283749580383\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90237 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0005842154496349394\n",
      "Q Loss:  0.0009634916204959154\n",
      "Policy Loss:  -0.01850217767059803\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00015648975386284292\n",
      "Q Loss:  0.00012864108430221677\n",
      "Policy Loss:  -0.006324087269604206\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018002748489379883\n",
      "Value Loss:  0.06094178557395935\n",
      "Q Loss:  0.013460171408951283\n",
      "Policy Loss:  -0.039463020861148834\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.04029929265379906\n",
      "Q Loss:  0.008123112842440605\n",
      "Policy Loss:  -0.044735267758369446\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 90253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.8489118929210235e-06\n",
      "Q Loss:  0.00023216764384415\n",
      "Policy Loss:  0.0065719448029994965\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005143650341778994\n",
      "Q Loss:  0.024456797167658806\n",
      "Policy Loss:  0.04751395061612129\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.019109126180410385\n",
      "Q Loss:  0.007220972329378128\n",
      "Policy Loss:  0.06037634611129761\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.037391673773527145\n",
      "Q Loss:  0.009282846935093403\n",
      "Policy Loss:  -0.02865719050168991\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00011895728675881401\n",
      "Q Loss:  0.0004281442961655557\n",
      "Policy Loss:  0.04816989228129387\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.03516604006290436\n",
      "Q Loss:  0.015112068504095078\n",
      "Policy Loss:  0.04455775022506714\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.05067598819732666\n",
      "Q Loss:  0.009270694106817245\n",
      "Policy Loss:  -0.04836394265294075\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.0526652336120605\n",
      "Q Loss:  8.14163875579834\n",
      "Policy Loss:  0.4287433326244354\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90367 length: 86 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1895.2659912109375\n",
      "Q Loss:  5680.9169921875\n",
      "Policy Loss:  -87.65535736083984\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1892.46630859375\n",
      "Q Loss:  6461.3359375\n",
      "Policy Loss:  -87.16600799560547\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004770278930664\n",
      "Value Loss:  3771.5888671875\n",
      "Q Loss:  10902.345703125\n",
      "Policy Loss:  -29.029064178466797\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 90379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1871.70849609375\n",
      "Q Loss:  4532.80517578125\n",
      "Policy Loss:  -134.0040740966797\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 90383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00045810395386070013\n",
      "Q Loss:  0.0011859491933137178\n",
      "Policy Loss:  -0.011707600206136703\n",
      "[(0.00015, 0), (0.00015, 0.0)]\n",
      "Alpha*: 0.00015 tau*: 0 Episode: 90387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006775549263693392\n",
      "Q Loss:  0.005082633811980486\n",
      "Policy Loss:  -0.033471785485744476\n",
      "[(0.00015, 0), (0.00015, 0.0)]\n",
      "Alpha*: 0.00015 tau*: 0 Episode: 90391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000873513170517981\n",
      "Q Loss:  0.006878722459077835\n",
      "Policy Loss:  0.04376192390918732\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 90395 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00031113115255720913\n",
      "Q Loss:  0.00706001790240407\n",
      "Policy Loss:  0.0397028923034668\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 90399 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0005430247983895242\n",
      "Q Loss:  0.0075904373079538345\n",
      "Policy Loss:  0.03079226240515709\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 90403 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0004403450293466449\n",
      "Q Loss:  0.008715081959962845\n",
      "Policy Loss:  0.045520082116127014\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 90407 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0003625251410994679\n",
      "Q Loss:  0.001624682336114347\n",
      "Policy Loss:  0.005107668228447437\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0005293723661452532\n",
      "Q Loss:  0.11693915724754333\n",
      "Policy Loss:  -0.1749037355184555\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90415 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05701279640197754\n",
      "Value Loss:  0.0003032963431905955\n",
      "Q Loss:  0.001870113192126155\n",
      "Policy Loss:  -0.020438555628061295\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90419 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006267076823860407\n",
      "Q Loss:  0.0002620446030050516\n",
      "Policy Loss:  -0.004770494066178799\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90423 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02400517463684082\n",
      "Value Loss:  8.73044045874849e-05\n",
      "Q Loss:  0.0028151480946689844\n",
      "Policy Loss:  0.0023961863480508327\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0006975872674956918\n",
      "Q Loss:  0.021974463015794754\n",
      "Policy Loss:  0.08429765701293945\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.0003515342250466347\n",
      "Q Loss:  0.009266406297683716\n",
      "Policy Loss:  0.04192628711462021\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001553405891172588\n",
      "Q Loss:  0.00022166853887028992\n",
      "Policy Loss:  0.0001540802768431604\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  5.6292847148142755e-05\n",
      "Q Loss:  0.004879129119217396\n",
      "Policy Loss:  0.0044846246019005775\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  8.436452480964363e-05\n",
      "Q Loss:  0.001622205600142479\n",
      "Policy Loss:  -0.002519328612834215\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0001901380019262433\n",
      "Q Loss:  0.0014836168847978115\n",
      "Policy Loss:  -0.008980566635727882\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003031267551705241\n",
      "Q Loss:  0.002040356397628784\n",
      "Policy Loss:  -0.00787352118641138\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00034249527379870415\n",
      "Q Loss:  0.006973813753575087\n",
      "Policy Loss:  0.023196008056402206\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0002867880975827575\n",
      "Q Loss:  0.00408893683925271\n",
      "Policy Loss:  0.01574120856821537\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00020150233467575163\n",
      "Q Loss:  2.943627623608336e-05\n",
      "Policy Loss:  0.0003079432062804699\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.00018512555107008666\n",
      "Q Loss:  0.0017508879536762834\n",
      "Policy Loss:  0.0623922161757946\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.026234876364469528\n",
      "Q Loss:  0.1511186957359314\n",
      "Policy Loss:  0.13226385414600372\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.1941866874694824\n",
      "Q Loss:  0.025901487097144127\n",
      "Policy Loss:  0.21529288589954376\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90552 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.2580986022949219\n",
      "Q Loss:  0.030117876827716827\n",
      "Policy Loss:  0.23963361978530884\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90625 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.00013868336100131273\n",
      "Q Loss:  0.01256322767585516\n",
      "Policy Loss:  -0.02774251066148281\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9.448964556213468e-05\n",
      "Q Loss:  0.0003802988212555647\n",
      "Policy Loss:  0.0062753576785326\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.014233333989977837\n",
      "Q Loss:  0.009333539754152298\n",
      "Policy Loss:  0.06255270540714264\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.05786119028925896\n",
      "Q Loss:  0.05605204775929451\n",
      "Policy Loss:  0.07531486451625824\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012000560760498047\n",
      "Value Loss:  0.8212579488754272\n",
      "Q Loss:  0.015411916188895702\n",
      "Policy Loss:  0.12851685285568237\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90753 length: 112 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0006533993873745203\n",
      "Q Loss:  0.03448965772986412\n",
      "Policy Loss:  -0.09555058181285858\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90757 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.001637305598706007\n",
      "Q Loss:  0.00019380194135010242\n",
      "Policy Loss:  0.004489234648644924\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00020769044931512326\n",
      "Q Loss:  0.0008185611222870648\n",
      "Policy Loss:  -0.010429590940475464\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.01478553470224142\n",
      "Q Loss:  0.012260050512850285\n",
      "Policy Loss:  0.005161387845873833\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.2165337800979614\n",
      "Q Loss:  0.005306474398821592\n",
      "Policy Loss:  0.15659403800964355\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 90844 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1711.3857421875\n",
      "Q Loss:  4754.80224609375\n",
      "Policy Loss:  -111.78689575195312\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.12795114517211914\n",
      "Value Loss:  0.000284508743789047\n",
      "Q Loss:  0.006263413466513157\n",
      "Policy Loss:  0.01617155596613884\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.2258183232916053e-05\n",
      "Q Loss:  0.0004483953816816211\n",
      "Policy Loss:  0.004723172634840012\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  2.1977650249027647e-05\n",
      "Q Loss:  0.0022336156107485294\n",
      "Policy Loss:  -0.0020348152611404657\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00018733393517322838\n",
      "Q Loss:  0.003599724266678095\n",
      "Policy Loss:  -0.023456748574972153\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.0157350301742554\n",
      "Q Loss:  0.006825691554695368\n",
      "Policy Loss:  0.14015401899814606\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 90954 length: 90 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014615058898925781\n",
      "Value Loss:  2.8128801204729825e-05\n",
      "Q Loss:  0.00058387202443555\n",
      "Policy Loss:  0.0089553352445364\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  0.00024019302509259433\n",
      "Q Loss:  0.0010453748982399702\n",
      "Policy Loss:  0.0011033625341951847\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.04970339685678482\n",
      "Q Loss:  0.010413747280836105\n",
      "Policy Loss:  -0.023851977661252022\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 90966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.1341217756271362\n",
      "Q Loss:  0.0029028744902461767\n",
      "Policy Loss:  0.17258726060390472\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 91046 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  2.1718742573284544e-06\n",
      "Q Loss:  0.0002327505499124527\n",
      "Policy Loss:  0.0038190644700080156\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 91050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.017111361026763916\n",
      "Q Loss:  0.0031880540773272514\n",
      "Policy Loss:  0.026890380308032036\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 91054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.03447563201189041\n",
      "Q Loss:  0.010269912891089916\n",
      "Policy Loss:  0.004576951265335083\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  120.6172103881836\n",
      "Q Loss:  350.3466491699219\n",
      "Policy Loss:  -13.700749397277832\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91226 length: 168 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.3755299025651766e-06\n",
      "Q Loss:  0.0002671754627954215\n",
      "Policy Loss:  0.0030239284969866276\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.049180567264557e-06\n",
      "Q Loss:  0.00047064939280971885\n",
      "Policy Loss:  0.05432431399822235\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.05199004337191582\n",
      "Q Loss:  0.009058966301381588\n",
      "Policy Loss:  -0.025140976533293724\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.05116952210664749\n",
      "Q Loss:  0.008620113134384155\n",
      "Policy Loss:  -0.02258056402206421\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.291466474533081\n",
      "Q Loss:  20.427412033081055\n",
      "Policy Loss:  0.8454691767692566\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91312 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1674.7191162109375\n",
      "Q Loss:  0.0121231097728014\n",
      "Policy Loss:  -235.32530212402344\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.004852723330259323\n",
      "Q Loss:  0.006021710112690926\n",
      "Policy Loss:  0.0007413867861032486\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.00035529115120880306\n",
      "Q Loss:  0.004683719947934151\n",
      "Policy Loss:  0.014517327770590782\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00019187889120075852\n",
      "Q Loss:  0.0031284417491406202\n",
      "Policy Loss:  0.011126930825412273\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.00013622123515233397\n",
      "Q Loss:  0.001096228719688952\n",
      "Policy Loss:  -0.0033188594970852137\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.048811718821525574\n",
      "Q Loss:  0.007917944341897964\n",
      "Policy Loss:  -0.02889867126941681\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0004826928488910198\n",
      "Q Loss:  0.001439340179786086\n",
      "Policy Loss:  0.01990916021168232\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  7.694875239394605e-05\n",
      "Q Loss:  0.0008261373732239008\n",
      "Policy Loss:  -0.0025750009808689356\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  3.893188841175288e-05\n",
      "Q Loss:  0.0005506557645276189\n",
      "Policy Loss:  0.0006736523355357349\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 91348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07401728630065918\n",
      "Value Loss:  1.5076999261509627e-05\n",
      "Q Loss:  0.0016042746137827635\n",
      "Policy Loss:  0.03485427051782608\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 91352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.044610410928726196\n",
      "Q Loss:  0.008938274346292019\n",
      "Policy Loss:  -0.019318819046020508\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  11910.4091796875\n",
      "Q Loss:  11154.6455078125\n",
      "Policy Loss:  -30.62687873840332\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91428 length: 72 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.4737933270225767e-05\n",
      "Q Loss:  0.0014288750244304538\n",
      "Policy Loss:  0.010031874291598797\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  2.233904888271354e-05\n",
      "Q Loss:  0.0004095867625437677\n",
      "Policy Loss:  -0.008882067166268826\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00012086259812349454\n",
      "Q Loss:  0.0003712883626576513\n",
      "Policy Loss:  0.006531042512506247\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1.9484154108795337e-05\n",
      "Q Loss:  0.00017495447536930442\n",
      "Policy Loss:  0.0017566053429618478\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.5957763253027224e-06\n",
      "Q Loss:  5.510747359949164e-05\n",
      "Policy Loss:  0.0003747165319509804\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011610269546508789\n",
      "Value Loss:  2.129711901943665e-05\n",
      "Q Loss:  4.578846710501239e-05\n",
      "Policy Loss:  0.003256802447140217\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00027880555717274547\n",
      "Q Loss:  0.00032807188108563423\n",
      "Policy Loss:  0.006114979274570942\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  47.05496597290039\n",
      "Q Loss:  111.70033264160156\n",
      "Policy Loss:  -5.797364711761475\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91598 length: 142 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.9007987905060872e-06\n",
      "Q Loss:  0.00015215809980873019\n",
      "Policy Loss:  -0.0028839404694736004\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.6276917449431494e-06\n",
      "Q Loss:  0.00020100048277527094\n",
      "Policy Loss:  -0.003098243148997426\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.808590190601535e-05\n",
      "Q Loss:  0.00021947006462141871\n",
      "Policy Loss:  0.00634576054289937\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015506744384765625\n",
      "Value Loss:  7.37415120966034e-06\n",
      "Q Loss:  0.0005699212197214365\n",
      "Policy Loss:  -0.0061254920437932014\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.4777191255416255e-06\n",
      "Q Loss:  0.00041316417627967894\n",
      "Policy Loss:  -0.0010063177905976772\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.002031486015766859\n",
      "Q Loss:  0.01683502085506916\n",
      "Policy Loss:  -0.035607047379016876\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0019122996600344777\n",
      "Q Loss:  0.0007536091725341976\n",
      "Policy Loss:  -0.007920240983366966\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.000629293848760426\n",
      "Q Loss:  0.00027881364803761244\n",
      "Policy Loss:  0.005685542710125446\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.209904166898923e-05\n",
      "Q Loss:  0.0005150929209776223\n",
      "Policy Loss:  0.01209332887083292\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030006885528564453\n",
      "Value Loss:  4.690527930506505e-05\n",
      "Q Loss:  0.00013058882905170321\n",
      "Policy Loss:  0.0037326521705836058\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91638 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  7.39636379876174e-05\n",
      "Q Loss:  9.478033462073654e-05\n",
      "Policy Loss:  0.006602543871849775\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91642 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  4.1853549191728234e-05\n",
      "Q Loss:  0.0005747496616095304\n",
      "Policy Loss:  0.009237762540578842\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91646 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  1.746457019180525e-05\n",
      "Q Loss:  0.00035265920450910926\n",
      "Policy Loss:  0.001148562878370285\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00043431721860542893\n",
      "Q Loss:  0.0010695981327444315\n",
      "Policy Loss:  -0.002420104341581464\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91654 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.015044375322759151\n",
      "Q Loss:  0.0029036449268460274\n",
      "Policy Loss:  0.034332480281591415\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91658 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.043467771261930466\n",
      "Q Loss:  0.009149710647761822\n",
      "Policy Loss:  -0.04992792755365372\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  69.57476806640625\n",
      "Q Loss:  165.22630310058594\n",
      "Policy Loss:  -8.494318962097168\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91758 length: 96 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.105453677359037e-05\n",
      "Q Loss:  0.00012886160402558744\n",
      "Policy Loss:  -0.0023274451959878206\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.599301999201998e-05\n",
      "Q Loss:  0.0001244530430994928\n",
      "Policy Loss:  -0.0006550605176016688\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  8.701440492586698e-06\n",
      "Q Loss:  0.0005203494802117348\n",
      "Policy Loss:  -0.004361538682132959\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06501388549804688\n",
      "Value Loss:  0.041608721017837524\n",
      "Q Loss:  0.0031163343228399754\n",
      "Policy Loss:  0.004701418802142143\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.02714684046804905\n",
      "Q Loss:  0.006269334349781275\n",
      "Policy Loss:  -0.02805819734930992\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91778 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.00010560693044681102\n",
      "Q Loss:  0.0002826743293553591\n",
      "Policy Loss:  -0.005371334962546825\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00010056055907625705\n",
      "Q Loss:  0.00011753004946513101\n",
      "Policy Loss:  -0.004157469142228365\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.012455807998776436\n",
      "Q Loss:  0.006754727568477392\n",
      "Policy Loss:  0.025830071419477463\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 91790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  96.74589538574219\n",
      "Q Loss:  269.667236328125\n",
      "Policy Loss:  -11.658926963806152\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91927 length: 137 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018002748489379883\n",
      "Value Loss:  3.420508801355027e-05\n",
      "Q Loss:  9.023112943395972e-05\n",
      "Policy Loss:  -0.0008228381047956645\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  2.396121999481693e-05\n",
      "Q Loss:  3.1208630389301106e-05\n",
      "Policy Loss:  0.003795742755755782\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  6.327250048343558e-06\n",
      "Q Loss:  0.00014842867676634341\n",
      "Policy Loss:  0.03934139758348465\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 91939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.443655014038086\n",
      "Q Loss:  0.0019377870485186577\n",
      "Policy Loss:  0.2147294282913208\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92003 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.011554698459804058\n",
      "Q Loss:  0.006669478956609964\n",
      "Policy Loss:  0.05464188754558563\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92007 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  22223.255859375\n",
      "Q Loss:  20180.9375\n",
      "Policy Loss:  -20.390888214111328\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92045 length: 38 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.012275025248527527\n",
      "Q Loss:  0.006502901669591665\n",
      "Policy Loss:  0.010289104655385017\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.012713846750557423\n",
      "Q Loss:  0.0058319903910160065\n",
      "Policy Loss:  0.01899520494043827\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  13187.67578125\n",
      "Q Loss:  11982.6005859375\n",
      "Policy Loss:  -12.162422180175781\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92117 length: 64 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.02706949971616268\n",
      "Q Loss:  0.00612384220585227\n",
      "Policy Loss:  -0.04014597460627556\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  87.61921691894531\n",
      "Q Loss:  248.2181396484375\n",
      "Policy Loss:  -10.14852523803711\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92198 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04348510503768921\n",
      "Q Loss:  0.009191428311169147\n",
      "Policy Loss:  -0.03831492364406586\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.0232129096984863\n",
      "Q Loss:  0.004617741331458092\n",
      "Policy Loss:  0.2833370566368103\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92247 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0003141503257211298\n",
      "Q Loss:  0.000716472277417779\n",
      "Policy Loss:  -0.013104700483381748\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  5.3528281569015235e-05\n",
      "Q Loss:  0.00012266771227587014\n",
      "Policy Loss:  0.0067461710423231125\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  6.277143256738782e-05\n",
      "Q Loss:  0.00044903240632265806\n",
      "Policy Loss:  -0.004852527752518654\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.5301091025321512e-06\n",
      "Q Loss:  0.00016537241754122078\n",
      "Policy Loss:  0.0068732621148228645\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  2.1869433112442493e-05\n",
      "Q Loss:  0.0003285804414190352\n",
      "Policy Loss:  0.008907846175134182\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014025688171386719\n",
      "Value Loss:  7.213133358163759e-06\n",
      "Q Loss:  0.00014302547788247466\n",
      "Policy Loss:  0.006664497312158346\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 92271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  2.8437227229005657e-05\n",
      "Q Loss:  0.00022582935343962163\n",
      "Policy Loss:  0.006617407314479351\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500913619995117\n",
      "Value Loss:  0.9502587914466858\n",
      "Q Loss:  0.005555070471018553\n",
      "Policy Loss:  0.12977103888988495\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92370 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01260232925415039\n",
      "Value Loss:  10747.9111328125\n",
      "Q Loss:  9862.4423828125\n",
      "Policy Loss:  -20.16646385192871\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92449 length: 79 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.1858995650254656e-06\n",
      "Q Loss:  0.00022008491214364767\n",
      "Policy Loss:  0.007212455850094557\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.04517800360918045\n",
      "Q Loss:  0.015488988719880581\n",
      "Policy Loss:  -0.025980941951274872\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  0.022994505241513252\n",
      "Q Loss:  0.0031949211843311787\n",
      "Policy Loss:  -0.02424318715929985\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.06961749494075775\n",
      "Q Loss:  0.03402743488550186\n",
      "Policy Loss:  -0.08300016075372696\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92465 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.04592009633779526\n",
      "Q Loss:  0.009834840893745422\n",
      "Policy Loss:  -0.002571403980255127\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92469 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.06734952330589294\n",
      "Q Loss:  0.015165417455136776\n",
      "Policy Loss:  -0.026819638907909393\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.830070686992258e-05\n",
      "Q Loss:  0.002380002522841096\n",
      "Policy Loss:  0.027894895523786545\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92477 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.9009049942251295e-05\n",
      "Q Loss:  0.0011050228495150805\n",
      "Policy Loss:  0.01592792011797428\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012000322341918945\n",
      "Value Loss:  3.7294026697054505e-05\n",
      "Q Loss:  0.0015800197143107653\n",
      "Policy Loss:  0.014781871810555458\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7930.984375\n",
      "Q Loss:  8101.62353515625\n",
      "Policy Loss:  -54.708473205566406\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92598 length: 113 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00011125063610961661\n",
      "Q Loss:  0.0010441207559779286\n",
      "Policy Loss:  0.01941978931427002\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0022086421959102154\n",
      "Q Loss:  0.003488046582788229\n",
      "Policy Loss:  0.026237813755869865\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03100728988647461\n",
      "Value Loss:  0.0002009778982028365\n",
      "Q Loss:  0.00031923947972245514\n",
      "Policy Loss:  0.01060810312628746\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400968551635742\n",
      "Value Loss:  1.51372614709544e-05\n",
      "Q Loss:  0.0008790327701717615\n",
      "Policy Loss:  -0.016125451773405075\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  8.33868543850258e-05\n",
      "Q Loss:  0.00011359554628143087\n",
      "Policy Loss:  -0.004232766572386026\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  6.171459244797006e-05\n",
      "Q Loss:  0.0003064503544010222\n",
      "Policy Loss:  -0.0063689942471683025\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.00012938963482156396\n",
      "Q Loss:  0.0002261643239762634\n",
      "Policy Loss:  -0.006845187395811081\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.0227362256264314e-06\n",
      "Q Loss:  8.33597150631249e-05\n",
      "Policy Loss:  0.0033010300248861313\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00035374745493754745\n",
      "Q Loss:  7.802837353665382e-05\n",
      "Policy Loss:  -0.0037220807280391455\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.000588029797654599\n",
      "Q Loss:  0.0018625762313604355\n",
      "Policy Loss:  0.014813623391091824\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92638 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00011647091014310718\n",
      "Q Loss:  239.619384765625\n",
      "Policy Loss:  7.562044620513916\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92642 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.252946281572804e-05\n",
      "Q Loss:  238.4583282470703\n",
      "Policy Loss:  7.531167984008789\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 92646 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0001037923721014522\n",
      "Q Loss:  118.1130142211914\n",
      "Policy Loss:  3.736316680908203\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 92650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1721.934326171875\n",
      "Q Loss:  4777.58740234375\n",
      "Policy Loss:  -111.98336791992188\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 92654 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0003116183215752244\n",
      "Q Loss:  0.001153399352915585\n",
      "Policy Loss:  -0.018260031938552856\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 92658 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  5.048334514867747e-07\n",
      "Q Loss:  6.374021177180111e-05\n",
      "Policy Loss:  -0.005177678540349007\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.050011396408081055\n",
      "Value Loss:  0.000287962204311043\n",
      "Q Loss:  0.0007188759627752006\n",
      "Policy Loss:  -0.012633118778467178\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92666 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00015755699132569134\n",
      "Q Loss:  0.0004694031667895615\n",
      "Policy Loss:  -0.009165451861917973\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92670 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00011252147669438273\n",
      "Q Loss:  0.0003605026286095381\n",
      "Policy Loss:  -0.009855091571807861\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.4506169463857077e-05\n",
      "Q Loss:  0.002329032402485609\n",
      "Policy Loss:  0.023032888770103455\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92678 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.04869314283132553\n",
      "Q Loss:  0.009582094848155975\n",
      "Policy Loss:  -0.07092026621103287\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  6.383559139067074e-06\n",
      "Q Loss:  0.0017672237008810043\n",
      "Policy Loss:  0.027838561683893204\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  130.04103088378906\n",
      "Q Loss:  364.2138671875\n",
      "Policy Loss:  -14.697922706604004\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92739 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.11342693446204e-05\n",
      "Q Loss:  0.0006761139957234263\n",
      "Policy Loss:  -0.005969764664769173\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92743 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04600858688354492\n",
      "Value Loss:  5.4187519708648324e-05\n",
      "Q Loss:  0.00034264306304976344\n",
      "Policy Loss:  0.04009721428155899\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92747 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.06472243368625641\n",
      "Q Loss:  0.0071792686358094215\n",
      "Policy Loss:  -0.06999488174915314\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92751 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.06373114883899689\n",
      "Q Loss:  0.004994696471840143\n",
      "Policy Loss:  -0.056218862533569336\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.04588986560702324\n",
      "Q Loss:  0.008502840064466\n",
      "Policy Loss:  -0.02985212206840515\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.506500434014015e-05\n",
      "Q Loss:  0.00018042723240796477\n",
      "Policy Loss:  0.0060249255038797855\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 92763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.8792886137962341\n",
      "Q Loss:  0.002419978380203247\n",
      "Policy Loss:  0.14805343747138977\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92867 length: 104 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0870199203491211\n",
      "Value Loss:  0.013289614580571651\n",
      "Q Loss:  0.010356060229241848\n",
      "Policy Loss:  0.04152681678533554\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92871 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  8.106473615043797e-06\n",
      "Q Loss:  0.0005404002731665969\n",
      "Policy Loss:  0.009083324111998081\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92875 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  5.6862081692088395e-06\n",
      "Q Loss:  0.0005384396063163877\n",
      "Policy Loss:  0.010179586708545685\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.453728251974098e-06\n",
      "Q Loss:  0.006644005887210369\n",
      "Policy Loss:  0.004016752354800701\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.023519063368439674\n",
      "Q Loss:  0.01134884636849165\n",
      "Policy Loss:  0.04029493406414986\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92887 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.033971428871154785\n",
      "Q Loss:  0.010806135833263397\n",
      "Policy Loss:  0.030173687264323235\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92891 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.9124132394790649\n",
      "Q Loss:  0.0026158010587096214\n",
      "Policy Loss:  0.1504010111093521\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92992 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1686.28173828125\n",
      "Q Loss:  3974.336181640625\n",
      "Policy Loss:  -129.19493103027344\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 92996 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0009126049117185175\n",
      "Q Loss:  226.18646240234375\n",
      "Policy Loss:  7.3593854904174805\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 93000 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018013715744018555\n",
      "Value Loss:  0.0005110925412736833\n",
      "Q Loss:  112.37741088867188\n",
      "Policy Loss:  3.662421941757202\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 93004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.00013005785876885056\n",
      "Q Loss:  0.0005775581812486053\n",
      "Policy Loss:  -0.013031491078436375\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 93008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  3.3074000384658575e-05\n",
      "Q Loss:  0.0006621899083256721\n",
      "Policy Loss:  -0.005921116564422846\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 93012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0002973647788167\n",
      "Q Loss:  7.381883915513754e-05\n",
      "Policy Loss:  0.0005233972915448248\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00010090747673530132\n",
      "Q Loss:  0.0007346262573264539\n",
      "Policy Loss:  0.02354215830564499\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.499415397644043\n",
      "Q Loss:  0.0024567118380218744\n",
      "Policy Loss:  0.19862453639507294\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93082 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.028690334409475327\n",
      "Q Loss:  0.00572484266012907\n",
      "Policy Loss:  -0.06667861342430115\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00013750471407547593\n",
      "Q Loss:  0.001074611907824874\n",
      "Policy Loss:  -0.018769951537251472\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.099126817891374e-05\n",
      "Q Loss:  0.00020084467541892081\n",
      "Policy Loss:  -0.0016301777213811874\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.02891479805111885\n",
      "Q Loss:  0.006515843793749809\n",
      "Policy Loss:  -0.032126534730196\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93098 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.009506420232355595\n",
      "Q Loss:  0.001278805430047214\n",
      "Policy Loss:  0.005772254429757595\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93102 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.01848575472831726\n",
      "Q Loss:  0.0037781333085149527\n",
      "Policy Loss:  -0.0066476911306381226\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93106 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013011693954467773\n",
      "Value Loss:  112.00556182861328\n",
      "Q Loss:  291.22406005859375\n",
      "Policy Loss:  -13.307730674743652\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 93225 length: 119 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  3306.294921875\n",
      "Q Loss:  5249.76220703125\n",
      "Policy Loss:  -214.1431427001953\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 93229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0009981844341382384\n",
      "Q Loss:  107.43940734863281\n",
      "Policy Loss:  3.581793785095215\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  3.1480438337894157e-05\n",
      "Q Loss:  0.0008850582526065409\n",
      "Policy Loss:  -0.012123160064220428\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 93237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  6.066899368306622e-05\n",
      "Q Loss:  0.0002821125672198832\n",
      "Policy Loss:  -0.005971502512693405\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 93241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00031874628621153533\n",
      "Q Loss:  0.005465497262775898\n",
      "Policy Loss:  0.016768286004662514\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 93245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012269020080566406\n",
      "Value Loss:  0.03318996727466583\n",
      "Q Loss:  0.0004002370988018811\n",
      "Policy Loss:  -0.017320942133665085\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 93249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.008206098340451717\n",
      "Q Loss:  0.0103289894759655\n",
      "Policy Loss:  0.032773423939943314\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 93253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00036397905205376446\n",
      "Q Loss:  0.0030043479055166245\n",
      "Policy Loss:  0.03488919883966446\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 93257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.022323600947856903\n",
      "Q Loss:  0.002671469934284687\n",
      "Policy Loss:  0.010745404288172722\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 93261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.02114463597536087\n",
      "Q Loss:  0.008480523712933064\n",
      "Policy Loss:  0.011753084138035774\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  0.00024213020515162498\n",
      "Q Loss:  0.004715785384178162\n",
      "Policy Loss:  0.03695828467607498\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05601239204406738\n",
      "Value Loss:  1.677778720855713\n",
      "Q Loss:  0.0030324594117701054\n",
      "Policy Loss:  0.26460543274879456\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93325 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.470835534040816e-05\n",
      "Q Loss:  112.18004608154297\n",
      "Policy Loss:  3.70523738861084\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801225662231445\n",
      "Value Loss:  7.972589060045721e-07\n",
      "Q Loss:  8.274375431938097e-05\n",
      "Policy Loss:  0.004332289099693298\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  0.0001299287105211988\n",
      "Q Loss:  0.00019806349882856011\n",
      "Policy Loss:  0.0036977464333176613\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93337 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.75019922608044e-05\n",
      "Q Loss:  0.001932387356646359\n",
      "Policy Loss:  0.014766624197363853\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93341 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013006210327148438\n",
      "Value Loss:  0.012336301617324352\n",
      "Q Loss:  0.0049484712071716785\n",
      "Policy Loss:  -0.01554233580827713\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.018206357955932617\n",
      "Q Loss:  0.0034142914228141308\n",
      "Policy Loss:  0.008170087821781635\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.011837358586490154\n",
      "Q Loss:  0.0032599109690636396\n",
      "Policy Loss:  0.007775936275720596\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  14575.2421875\n",
      "Q Loss:  13654.72265625\n",
      "Policy Loss:  -36.72008514404297\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93412 length: 59 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00015912132221274078\n",
      "Q Loss:  0.00023077359946910292\n",
      "Policy Loss:  -0.009906754828989506\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  9.718637738842517e-05\n",
      "Q Loss:  0.00014102598652243614\n",
      "Policy Loss:  -0.0074172243475914\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.01762585574761e-05\n",
      "Q Loss:  2.9818165785400197e-05\n",
      "Policy Loss:  -0.008258686400949955\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011008262634277344\n",
      "Value Loss:  0.011127826757729053\n",
      "Q Loss:  0.0005197045393288136\n",
      "Policy Loss:  0.0062283799052238464\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0109688276425004\n",
      "Q Loss:  0.007512834854424\n",
      "Policy Loss:  -0.013646312057971954\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.005379228852689266\n",
      "Q Loss:  0.002894337521865964\n",
      "Policy Loss:  -0.01002348493784666\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00011955898662563413\n",
      "Q Loss:  0.00022016791626811028\n",
      "Policy Loss:  -0.001599355018697679\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02504420280456543\n",
      "Value Loss:  6.53732058708556e-05\n",
      "Q Loss:  5.496072117239237e-05\n",
      "Policy Loss:  0.002538365311920643\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  5.129109922563657e-06\n",
      "Q Loss:  0.00018422905122861266\n",
      "Policy Loss:  -0.0006782867130823433\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.8392957726027817e-05\n",
      "Q Loss:  0.00010526685218792409\n",
      "Policy Loss:  -0.0030078717973083258\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  5.3021565690869465e-05\n",
      "Q Loss:  0.00023147395404521376\n",
      "Policy Loss:  -0.0067650978453457355\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001010549021884799\n",
      "Q Loss:  0.00016453916032332927\n",
      "Policy Loss:  -0.006381619721651077\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93460 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.053499525180086e-06\n",
      "Q Loss:  6.5953436205745675e-06\n",
      "Policy Loss:  0.0012517893919721246\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  8.920906680032203e-08\n",
      "Q Loss:  6.827582546975464e-05\n",
      "Policy Loss:  0.0011701020412147045\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00045090127969160676\n",
      "Q Loss:  0.0002755164750851691\n",
      "Policy Loss:  0.006612014956772327\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93472 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005442572291940451\n",
      "Q Loss:  0.0001868868712335825\n",
      "Policy Loss:  -0.0005078065441921353\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93476 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.0003386742318980396\n",
      "Q Loss:  0.00024733046302571893\n",
      "Policy Loss:  -0.006623946130275726\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93480 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.395473711658269e-05\n",
      "Q Loss:  0.00029712222749367356\n",
      "Policy Loss:  -0.010017825290560722\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93484 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00014390044088941067\n",
      "Q Loss:  0.00014662854664493352\n",
      "Policy Loss:  -0.0004384010098874569\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93488 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00016950495773926377\n",
      "Q Loss:  7.556423224741593e-05\n",
      "Policy Loss:  -0.00022318854462355375\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93492 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.00026316550793126225\n",
      "Q Loss:  0.0009470238583162427\n",
      "Policy Loss:  -0.015081549063324928\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93496 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301474571228027\n",
      "Value Loss:  0.0008910659234970808\n",
      "Q Loss:  0.0019787705969065428\n",
      "Policy Loss:  0.019038161262869835\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93500 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.716167688369751\n",
      "Q Loss:  0.0024094439577311277\n",
      "Policy Loss:  0.37735337018966675\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93535 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  2.1694037059205584e-05\n",
      "Q Loss:  2.5488025130471215e-05\n",
      "Policy Loss:  -0.0007496364414691925\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.5149059587856755e-05\n",
      "Q Loss:  7.957266643643379e-05\n",
      "Policy Loss:  -0.003581151133403182\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.9488096515706275e-06\n",
      "Q Loss:  0.00017184131138492376\n",
      "Policy Loss:  0.005880027078092098\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.0011393266031518579\n",
      "Q Loss:  0.0006715006893500686\n",
      "Policy Loss:  -0.01572376862168312\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.000547966395970434\n",
      "Q Loss:  0.00032945629209280014\n",
      "Policy Loss:  -0.005925305187702179\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0008483745623379946\n",
      "Q Loss:  0.00500556081533432\n",
      "Policy Loss:  -0.002312928205356002\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  67.23365783691406\n",
      "Q Loss:  0.004217145964503288\n",
      "Policy Loss:  -9.394431114196777\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93655 length: 96 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00012592280108947307\n",
      "Q Loss:  0.0002967484761029482\n",
      "Policy Loss:  0.009353581815958023\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  5.0071466830559075e-05\n",
      "Q Loss:  0.00011252253170823678\n",
      "Policy Loss:  0.00044368760427460074\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00011191248631803319\n",
      "Q Loss:  0.0009649997227825224\n",
      "Policy Loss:  0.02125411666929722\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  5.954176594968885e-05\n",
      "Q Loss:  0.0005695940344594419\n",
      "Policy Loss:  0.00557059608399868\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0005149769713170826\n",
      "Q Loss:  0.00030274418531917036\n",
      "Policy Loss:  0.035885632038116455\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  227.8589630126953\n",
      "Q Loss:  620.3279418945312\n",
      "Policy Loss:  -26.615262985229492\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93787 length: 112 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0001958919019671157\n",
      "Q Loss:  0.0002278065076097846\n",
      "Policy Loss:  0.009489243850111961\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00038123398553580046\n",
      "Q Loss:  0.0005851094610989094\n",
      "Policy Loss:  0.03173179179430008\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93795 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.02147742547094822\n",
      "Q Loss:  0.005107458680868149\n",
      "Policy Loss:  -0.0380716472864151\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.010987576097249985\n",
      "Q Loss:  0.002030658768489957\n",
      "Policy Loss:  0.014985539950430393\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00014035541971679777\n",
      "Q Loss:  0.0017248594667762518\n",
      "Policy Loss:  0.021233495324850082\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002865983988158405\n",
      "Q Loss:  0.00019539853383321315\n",
      "Policy Loss:  0.006415488664060831\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93811 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  86.92887878417969\n",
      "Q Loss:  119.93042755126953\n",
      "Policy Loss:  -11.541312217712402\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93958 length: 147 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.564021583064459e-05\n",
      "Q Loss:  4.0195278415922076e-05\n",
      "Policy Loss:  0.003842455567792058\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03400731086730957\n",
      "Value Loss:  0.0001371633989037946\n",
      "Q Loss:  0.0003378847031854093\n",
      "Policy Loss:  -0.0023265762720257044\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 93966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002716552116908133\n",
      "Q Loss:  0.0007052733562886715\n",
      "Policy Loss:  -0.013548145070672035\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00036222150083631277\n",
      "Q Loss:  0.00032896758057177067\n",
      "Policy Loss:  0.0036809220910072327\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00033117906423285604\n",
      "Q Loss:  0.00034859456354752183\n",
      "Policy Loss:  -0.0027372208423912525\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00012776760559063405\n",
      "Q Loss:  0.00020810389833059162\n",
      "Policy Loss:  -0.008133243769407272\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 93982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.948017418384552\n",
      "Q Loss:  0.006681222468614578\n",
      "Policy Loss:  0.11215820163488388\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 94080 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  9414.185546875\n",
      "Q Loss:  8585.3427734375\n",
      "Policy Loss:  -8.56633186340332\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94170 length: 90 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  13447.767578125\n",
      "Q Loss:  12256.685546875\n",
      "Policy Loss:  -12.402281761169434\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94233 length: 63 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.105187690583989e-05\n",
      "Q Loss:  0.0002234665007563308\n",
      "Policy Loss:  -0.00039029179606586695\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  9.720344678498805e-05\n",
      "Q Loss:  0.0003835611278191209\n",
      "Policy Loss:  0.01079314574599266\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00012282228271942586\n",
      "Q Loss:  0.00032121510594151914\n",
      "Policy Loss:  0.009221171960234642\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.016037408262491226\n",
      "Q Loss:  0.0022926339879631996\n",
      "Policy Loss:  0.007680725306272507\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  131.50411987304688\n",
      "Q Loss:  354.19427490234375\n",
      "Policy Loss:  -15.331902503967285\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94347 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  4.1698385757626966e-05\n",
      "Q Loss:  0.00017645473417360336\n",
      "Policy Loss:  0.004849722608923912\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94351 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00012629551929421723\n",
      "Q Loss:  0.00012701432569883764\n",
      "Policy Loss:  -0.0009676951449364424\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  4.2913012293865904e-05\n",
      "Q Loss:  9.0392044512555e-05\n",
      "Policy Loss:  -0.0025807591155171394\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  6.0480964748421684e-05\n",
      "Q Loss:  4.4249936763662845e-05\n",
      "Policy Loss:  -0.0025849866215139627\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.248427517770324e-05\n",
      "Q Loss:  2.697978197829798e-05\n",
      "Policy Loss:  0.004007644020020962\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.993369632051326e-05\n",
      "Q Loss:  2.437834882584866e-05\n",
      "Policy Loss:  0.0005192200187593699\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.03958364203572273\n",
      "Q Loss:  0.010620860382914543\n",
      "Policy Loss:  -0.019092578440904617\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 94375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.019885431975126266\n",
      "Q Loss:  0.0032195637468248606\n",
      "Policy Loss:  -0.021750517189502716\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.019757935777306557\n",
      "Q Loss:  0.004538490902632475\n",
      "Policy Loss:  0.01866992376744747\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.019521448761224747\n",
      "Q Loss:  0.004436141811311245\n",
      "Policy Loss:  -0.01763814687728882\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  0.01920374110341072\n",
      "Q Loss:  0.003685956122353673\n",
      "Policy Loss:  0.02494310587644577\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.018806885927915573\n",
      "Q Loss:  0.0052996850572526455\n",
      "Policy Loss:  -0.0170754287391901\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94395 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.966904816683382e-05\n",
      "Q Loss:  0.00027538579888641834\n",
      "Policy Loss:  0.010001503862440586\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94399 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  9.873248200165108e-05\n",
      "Q Loss:  0.00016942044021561742\n",
      "Policy Loss:  0.005296693183481693\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94403 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.28464185865596e-05\n",
      "Q Loss:  5.133146623848006e-05\n",
      "Policy Loss:  0.0020543450955301523\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94407 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  4.193772474536672e-05\n",
      "Q Loss:  6.472638779086992e-05\n",
      "Policy Loss:  0.04193145036697388\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.696041464805603\n",
      "Q Loss:  0.0030298056080937386\n",
      "Policy Loss:  0.10076947510242462\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94542 length: 131 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.016758473590016365\n",
      "Q Loss:  0.01990361325442791\n",
      "Policy Loss:  -0.028389036655426025\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94546 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025004863739013672\n",
      "Value Loss:  0.06629657745361328\n",
      "Q Loss:  0.01068820059299469\n",
      "Policy Loss:  -0.07977774739265442\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94550 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.03193705156445503\n",
      "Q Loss:  0.006517832167446613\n",
      "Policy Loss:  0.046084530651569366\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  19668.3125\n",
      "Q Loss:  17864.736328125\n",
      "Policy Loss:  -18.49455451965332\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94597 length: 43 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  0.0003781067789532244\n",
      "Q Loss:  0.0005589396459981799\n",
      "Policy Loss:  0.01452723890542984\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94601 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00010561980889178813\n",
      "Q Loss:  8.037641964619979e-05\n",
      "Policy Loss:  0.004869289696216583\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94605 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  3.840693898382597e-05\n",
      "Q Loss:  4.518969035416376e-06\n",
      "Policy Loss:  -0.0030105726327747107\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94609 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  4.6865883632563055e-05\n",
      "Q Loss:  0.0001346062053926289\n",
      "Policy Loss:  -0.00562721211463213\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00024376504006795585\n",
      "Q Loss:  0.00026061502285301685\n",
      "Policy Loss:  -0.00965955387800932\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94617 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00015612240531481802\n",
      "Q Loss:  0.0002446334983687848\n",
      "Policy Loss:  -0.008550411090254784\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94621 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.239652480464429e-05\n",
      "Q Loss:  3.6073623050469905e-05\n",
      "Policy Loss:  -0.002284090034663677\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94625 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  8.39732529129833e-05\n",
      "Q Loss:  0.0004348206566646695\n",
      "Policy Loss:  0.004476066678762436\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301450729370117\n",
      "Value Loss:  0.028209207579493523\n",
      "Q Loss:  0.002440400654450059\n",
      "Policy Loss:  0.012251988053321838\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049010515213012695\n",
      "Value Loss:  0.027644973248243332\n",
      "Q Loss:  0.006540418136864901\n",
      "Policy Loss:  -0.01886633411049843\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.013385966420173645\n",
      "Q Loss:  0.005924173630774021\n",
      "Policy Loss:  0.027321821078658104\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  11728.7236328125\n",
      "Q Loss:  10650.859375\n",
      "Policy Loss:  -11.34390640258789\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94713 length: 72 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00019178037473466247\n",
      "Q Loss:  3.7180794606683776e-05\n",
      "Policy Loss:  -0.004441568627953529\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.1885517835617065\n",
      "Q Loss:  0.0016056463355198503\n",
      "Policy Loss:  0.18099679052829742\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94794 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.270808808039874e-05\n",
      "Q Loss:  1.9606983187259175e-05\n",
      "Policy Loss:  0.0027149803936481476\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  6.581105117220432e-05\n",
      "Q Loss:  0.0004990509478375316\n",
      "Policy Loss:  0.009469497948884964\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04000433534383774\n",
      "Q Loss:  0.013870703056454659\n",
      "Policy Loss:  -0.045220036059617996\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.05296061933040619\n",
      "Q Loss:  0.008665284141898155\n",
      "Policy Loss:  -0.05973120778799057\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  0.012837236747145653\n",
      "Q Loss:  0.005591738969087601\n",
      "Policy Loss:  0.02795461378991604\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.7411894077667966e-05\n",
      "Q Loss:  0.00011222565808566287\n",
      "Policy Loss:  0.004097362980246544\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.2842873729823623e-05\n",
      "Q Loss:  0.002856713952496648\n",
      "Policy Loss:  0.01964385434985161\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 94822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04862713813781738\n",
      "Value Loss:  1665.572021484375\n",
      "Q Loss:  4692.3994140625\n",
      "Policy Loss:  -92.57390594482422\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 94826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  8.935387995734345e-06\n",
      "Q Loss:  0.00042914962978102267\n",
      "Policy Loss:  0.0029536138754338026\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 94830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.247146757232258e-06\n",
      "Q Loss:  1.4723744243383408e-05\n",
      "Policy Loss:  0.001403330359607935\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 94834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.3077063158561941e-05\n",
      "Q Loss:  2.198953734477982e-05\n",
      "Policy Loss:  0.0005981486174277961\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 94838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.898026135284454e-05\n",
      "Q Loss:  6.84831029502675e-05\n",
      "Policy Loss:  0.006208022125065327\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 94842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  7.390892278635874e-05\n",
      "Q Loss:  0.00010836221917998046\n",
      "Policy Loss:  0.003975276369601488\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 94846 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  5.0382201152388006e-05\n",
      "Q Loss:  2.943746767414268e-05\n",
      "Policy Loss:  0.002151922322809696\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 94850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  1.2001192772004288e-05\n",
      "Q Loss:  0.00023802905343472958\n",
      "Policy Loss:  -0.008764524012804031\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 94854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.009759485721588135\n",
      "Q Loss:  0.0002511395141482353\n",
      "Policy Loss:  0.029917148873209953\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 94858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.7015213966369629\n",
      "Q Loss:  13.924355506896973\n",
      "Policy Loss:  0.5486716628074646\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 94990 length: 132 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  2.1613523131236434e-06\n",
      "Q Loss:  0.0012186801759526134\n",
      "Policy Loss:  0.013928478583693504\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 94994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.028779668733477592\n",
      "Q Loss:  0.00018934192485176027\n",
      "Policy Loss:  0.024999793618917465\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 94998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.03760790824890137\n",
      "Q Loss:  3.109742101514712e-05\n",
      "Policy Loss:  -0.009467912837862968\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 95002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.026901524513959885\n",
      "Q Loss:  0.007994118146598339\n",
      "Policy Loss:  0.026737859472632408\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95006 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  60.109405517578125\n",
      "Q Loss:  174.48092651367188\n",
      "Policy Loss:  -6.771766662597656\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95117 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00020817079348489642\n",
      "Q Loss:  0.00027605079230852425\n",
      "Policy Loss:  -0.009590566158294678\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  1.6092000007629395\n",
      "Q Loss:  0.0017146490281447768\n",
      "Policy Loss:  0.2403634488582611\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95179 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.8844755433965474e-05\n",
      "Q Loss:  0.004252513870596886\n",
      "Policy Loss:  -0.017479708418250084\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95183 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  2.8940705306013115e-05\n",
      "Q Loss:  0.00030901312129572034\n",
      "Policy Loss:  -0.009376339614391327\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 95187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1641.3304443359375\n",
      "Q Loss:  5139.7255859375\n",
      "Policy Loss:  -91.19865417480469\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 95191 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1637.123291015625\n",
      "Q Loss:  4161.919921875\n",
      "Policy Loss:  -72.47077941894531\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 95195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.8487462006742135e-05\n",
      "Q Loss:  0.00010874001600313932\n",
      "Policy Loss:  0.005858766846358776\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 95199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.279042958747596e-05\n",
      "Q Loss:  0.00012120440078433603\n",
      "Policy Loss:  0.0014903168193995953\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 95203 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  1.6501849131600466e-06\n",
      "Q Loss:  0.0021352481562644243\n",
      "Policy Loss:  -0.016369640827178955\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 95207 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.992939284420572e-05\n",
      "Q Loss:  5.219069862505421e-05\n",
      "Policy Loss:  0.0018367620650678873\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 95211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001487720583099872\n",
      "Q Loss:  0.00012146500375820324\n",
      "Policy Loss:  0.002070198766887188\n",
      "[(0.00018, 0), (0.00018, 0.0)]\n",
      "Alpha*: 0.00018 tau*: 0 Episode: 95215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.234423249727115e-05\n",
      "Q Loss:  0.00032595437369309366\n",
      "Policy Loss:  0.009153908118605614\n",
      "[(0.0002, 0), (0.0002, 0.0)]\n",
      "Alpha*: 0.0002 tau*: 0 Episode: 95219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  12923.298828125\n",
      "Q Loss:  11977.8583984375\n",
      "Policy Loss:  -22.168498992919922\n",
      "[(0.00021, 0), (0.00021, 0.0)]\n",
      "Alpha*: 0.00021 tau*: 0 Episode: 95285 length: 66 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03300786018371582\n",
      "Value Loss:  65119.80859375\n",
      "Q Loss:  59343.921875\n",
      "Policy Loss:  -56.0839729309082\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 95311 length: 26 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.010031468234956264\n",
      "Q Loss:  0.009676124900579453\n",
      "Policy Loss:  0.03596031293272972\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 95315 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.02127084881067276\n",
      "Q Loss:  0.009023260325193405\n",
      "Policy Loss:  0.02180502936244011\n",
      "[(0.00023, 0), (0.00023, 0.0)]\n",
      "Alpha*: 0.00023 tau*: 0 Episode: 95319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  3.998656029580161e-05\n",
      "Q Loss:  0.000502662907820195\n",
      "Policy Loss:  0.007274256553500891\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 95323 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  3.123446003883146e-05\n",
      "Q Loss:  0.0069976383820176125\n",
      "Policy Loss:  0.008217265829443932\n",
      "[(0.00024, 0), (0.00024, 0.0)]\n",
      "Alpha*: 0.00024 tau*: 0 Episode: 95327 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.807498812675476\n",
      "Q Loss:  0.005115935113281012\n",
      "Policy Loss:  0.25321656465530396\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 95378 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.104060543701053e-05\n",
      "Q Loss:  0.00029941066168248653\n",
      "Policy Loss:  0.0015480320435017347\n",
      "[(0.00025, 0), (0.00025, 0.0)]\n",
      "Alpha*: 0.00025 tau*: 0 Episode: 95382 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0001424994261469692\n",
      "Q Loss:  0.0002870400494430214\n",
      "Policy Loss:  0.007769329007714987\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 95386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0013113184832036495\n",
      "Q Loss:  0.00021130178356543183\n",
      "Policy Loss:  -0.004362370353192091\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 95390 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.5264755095122382e-05\n",
      "Q Loss:  3.0044546292629093e-05\n",
      "Policy Loss:  0.0014238521689549088\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 95394 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.04555005580186844\n",
      "Q Loss:  0.00887143611907959\n",
      "Policy Loss:  -0.023706570267677307\n",
      "[(0.00026, 0), (0.00026, 0.0)]\n",
      "Alpha*: 0.00026 tau*: 0 Episode: 95398 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.127746458631009e-05\n",
      "Q Loss:  0.00041510682785883546\n",
      "Policy Loss:  0.009609730914235115\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015074491500854492\n",
      "Value Loss:  0.03115493431687355\n",
      "Q Loss:  0.01626518927514553\n",
      "Policy Loss:  0.0017088130116462708\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  1.2453031539916992\n",
      "Q Loss:  13.132713317871094\n",
      "Policy Loss:  0.6081287860870361\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95479 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.041008949279785156\n",
      "Value Loss:  5.4104195442050695e-05\n",
      "Q Loss:  0.00016463965584989637\n",
      "Policy Loss:  0.0076872375793755054\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00010582592949504033\n",
      "Q Loss:  0.0001765618653735146\n",
      "Policy Loss:  0.004862655885517597\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012950897216796875\n",
      "Value Loss:  3.476248821243644e-05\n",
      "Q Loss:  6.272415339481086e-05\n",
      "Policy Loss:  -0.002384057268500328\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00025491786072961986\n",
      "Q Loss:  0.0002536475076340139\n",
      "Policy Loss:  0.010292058810591698\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.0314182873116806e-05\n",
      "Q Loss:  0.0001160056417575106\n",
      "Policy Loss:  -0.007110477425158024\n",
      "[(0.00027, 0), (0.00027, 0.0)]\n",
      "Alpha*: 0.00027 tau*: 0 Episode: 95499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.3269002010929398e-05\n",
      "Q Loss:  0.0003361936833243817\n",
      "Policy Loss:  -0.010673094540834427\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.200263644335791e-05\n",
      "Q Loss:  0.00012577352754306048\n",
      "Policy Loss:  -0.0007877477910369635\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  5.4544674640055746e-05\n",
      "Q Loss:  0.0011835051700472832\n",
      "Policy Loss:  0.009768370538949966\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.8740400264505297e-05\n",
      "Q Loss:  0.003114490769803524\n",
      "Policy Loss:  0.031411390751600266\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.1586322216317058e-05\n",
      "Q Loss:  0.0024704509414732456\n",
      "Policy Loss:  0.02373729832470417\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00011368505511200055\n",
      "Q Loss:  0.000583947345148772\n",
      "Policy Loss:  -0.0008594423998147249\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.00035667745396494865\n",
      "Q Loss:  0.0006982963532209396\n",
      "Policy Loss:  -0.0053993104957044125\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00021250041027087718\n",
      "Q Loss:  5.052553751738742e-05\n",
      "Policy Loss:  -0.0006872615776956081\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.4684834241052158e-05\n",
      "Q Loss:  0.00010864601790672168\n",
      "Policy Loss:  0.006001549772918224\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.5157412892440334e-05\n",
      "Q Loss:  6.791499617975205e-05\n",
      "Policy Loss:  0.001494969823397696\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.544087535876315e-05\n",
      "Q Loss:  0.0001606088044354692\n",
      "Policy Loss:  0.006560677196830511\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.4432543796137907e-05\n",
      "Q Loss:  5.0892282160930336e-05\n",
      "Policy Loss:  0.04084259644150734\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  1.3231979608535767\n",
      "Q Loss:  0.009430859237909317\n",
      "Policy Loss:  0.16439180076122284\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95616 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.967143756104633e-05\n",
      "Q Loss:  0.00018406379967927933\n",
      "Policy Loss:  0.0013682777062058449\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.907006587018259e-05\n",
      "Q Loss:  3.307711085653864e-05\n",
      "Policy Loss:  -0.0018645741511136293\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.893280341391801e-06\n",
      "Q Loss:  3.5098546504741535e-05\n",
      "Policy Loss:  -0.0024861134588718414\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.020092492923140526\n",
      "Q Loss:  0.02459564618766308\n",
      "Policy Loss:  -0.04592156410217285\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.02021697536110878\n",
      "Q Loss:  0.0030123358592391014\n",
      "Policy Loss:  0.004833081737160683\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.2756595611572266\n",
      "Q Loss:  0.005043840501457453\n",
      "Policy Loss:  0.18120689690113068\n",
      "[(0.00028, 0), (0.00028, 0.0)]\n",
      "Alpha*: 0.00028 tau*: 0 Episode: 95707 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.048010826110839844\n",
      "Value Loss:  1705.8890380859375\n",
      "Q Loss:  4085.3798828125\n",
      "Policy Loss:  -92.68833923339844\n",
      "[(0.00022, 0), (0.00022, 0.0)]\n",
      "Alpha*: 0.00022 tau*: 0 Episode: 95711 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.00013923484948463738\n",
      "Q Loss:  119.23849487304688\n",
      "Policy Loss:  3.8884634971618652\n",
      "[(0.00017, 0), (0.00017, 0.0)]\n",
      "Alpha*: 0.00017 tau*: 0 Episode: 95715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  5.0255297537660226e-05\n",
      "Q Loss:  0.00019574433099478483\n",
      "Policy Loss:  0.0007578758522868156\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 95719 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.901902214740403e-05\n",
      "Q Loss:  2.5761799406609498e-05\n",
      "Policy Loss:  -0.002244669711217284\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 95723 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  8.370174327865243e-05\n",
      "Q Loss:  5.925692312302999e-05\n",
      "Policy Loss:  -0.002373786410316825\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 95727 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.021872544661164284\n",
      "Q Loss:  0.001094627077691257\n",
      "Policy Loss:  0.04107958450913429\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 95731 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.06567685306072235\n",
      "Q Loss:  0.024956095963716507\n",
      "Policy Loss:  -0.08555686473846436\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 95735 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  1.1494113206863403\n",
      "Q Loss:  0.005805428605526686\n",
      "Policy Loss:  0.15485811233520508\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 95813 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  3368.59521484375\n",
      "Q Loss:  4587.02001953125\n",
      "Policy Loss:  -217.6212158203125\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 95817 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.179647607496008e-05\n",
      "Q Loss:  0.000803012284450233\n",
      "Policy Loss:  0.011577130295336246\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 95821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00024725490948185325\n",
      "Q Loss:  6.4781556829984765e-06\n",
      "Policy Loss:  0.0012127477675676346\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 95825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00011212575191166252\n",
      "Q Loss:  0.00012049698852933943\n",
      "Policy Loss:  -0.004156934563070536\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 95829 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  3.0813258490525186e-05\n",
      "Q Loss:  0.0003820870188064873\n",
      "Policy Loss:  -0.010945785790681839\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 95833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  2.65381604549475e-05\n",
      "Q Loss:  0.00020553870126605034\n",
      "Policy Loss:  -0.008810366503894329\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 95837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  3.588157824196969e-06\n",
      "Q Loss:  0.00017262519395444542\n",
      "Policy Loss:  0.0002883425622712821\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 95841 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.1804785344793345e-06\n",
      "Q Loss:  0.00012401615094859153\n",
      "Policy Loss:  0.0021424514707177877\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 95845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0435318723320961\n",
      "Q Loss:  0.009521820582449436\n",
      "Policy Loss:  -0.016557786613702774\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 95849 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.021482570096850395\n",
      "Q Loss:  0.006714352406561375\n",
      "Policy Loss:  0.023823432624340057\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 95853 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  96.23854064941406\n",
      "Q Loss:  150.46253967285156\n",
      "Policy Loss:  -12.321033477783203\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 95989 length: 136 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00020130627672187984\n",
      "Q Loss:  0.00019351733499206603\n",
      "Policy Loss:  0.0035278210416436195\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 95993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  9.4458409876097e-05\n",
      "Q Loss:  0.00011478866508696228\n",
      "Policy Loss:  0.004819113295525312\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 95997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2.8858212317572907e-05\n",
      "Q Loss:  0.0005141010624356568\n",
      "Policy Loss:  -0.01170285977423191\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.4770292182220146e-05\n",
      "Q Loss:  0.00040843599708750844\n",
      "Policy Loss:  -0.00804377906024456\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00030296811019070446\n",
      "Q Loss:  2.018598206632305e-05\n",
      "Policy Loss:  -0.004112462513148785\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  50.589149475097656\n",
      "Q Loss:  144.56121826171875\n",
      "Policy Loss:  -5.769449710845947\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96138 length: 129 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05263400077819824\n",
      "Value Loss:  2.8708320314763114e-05\n",
      "Q Loss:  0.0003675944753922522\n",
      "Policy Loss:  0.008809211663901806\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96142 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.446348480589222e-05\n",
      "Q Loss:  0.00028598878998309374\n",
      "Policy Loss:  0.009379355236887932\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.468441718723625e-05\n",
      "Q Loss:  0.0006214277818799019\n",
      "Policy Loss:  0.011877466924488544\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.057880480308086e-05\n",
      "Q Loss:  0.00011331378482282162\n",
      "Policy Loss:  0.005801009479910135\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96154 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  4.483986413106322e-05\n",
      "Q Loss:  3.966092481277883e-05\n",
      "Policy Loss:  0.0020103147253394127\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  6.152189598651603e-05\n",
      "Q Loss:  4.122448808629997e-05\n",
      "Policy Loss:  0.00096398766618222\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96162 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.0530247638816945e-05\n",
      "Q Loss:  0.0003822168509941548\n",
      "Policy Loss:  -0.004052453674376011\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00018589635146781802\n",
      "Q Loss:  2.8755050152540207e-05\n",
      "Policy Loss:  -0.0035995058715343475\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96170 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010996103286743164\n",
      "Value Loss:  0.00016863492783159018\n",
      "Q Loss:  0.0004406370280776173\n",
      "Policy Loss:  0.009756801649928093\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96174 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  2.7248319383943453e-05\n",
      "Q Loss:  0.0006455945549532771\n",
      "Policy Loss:  0.05582944303750992\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.062868632376194\n",
      "Q Loss:  0.011317930184304714\n",
      "Policy Loss:  -0.046983979642391205\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  9.34456184040755e-05\n",
      "Q Loss:  0.00026898947544395924\n",
      "Policy Loss:  0.003735559294000268\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.350583862513304e-05\n",
      "Q Loss:  0.0002202912583015859\n",
      "Policy Loss:  0.04663771390914917\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0793968141078949\n",
      "Q Loss:  0.01171341072767973\n",
      "Policy Loss:  -0.06274719536304474\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  1.3997948169708252\n",
      "Q Loss:  7.20932674407959\n",
      "Policy Loss:  0.4546263515949249\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96258 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0002700726909097284\n",
      "Q Loss:  0.0003849330241791904\n",
      "Policy Loss:  -0.0036643105559051037\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96262 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.7059379135607742e-05\n",
      "Q Loss:  0.00016768927162047476\n",
      "Policy Loss:  -0.004510575905442238\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96266 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.10773791372776e-05\n",
      "Q Loss:  0.00020079920068383217\n",
      "Policy Loss:  -0.003935715649276972\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.4948483769549057e-05\n",
      "Q Loss:  7.103539974195883e-05\n",
      "Policy Loss:  0.0012484502512961626\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96274 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  40.837432861328125\n",
      "Q Loss:  95.17362213134766\n",
      "Policy Loss:  -5.021850109100342\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96432 length: 158 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  2.2190264644450508e-05\n",
      "Q Loss:  3.08330163534265e-05\n",
      "Policy Loss:  -0.0052125705406069756\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.036680664867162704\n",
      "Q Loss:  0.009527732618153095\n",
      "Policy Loss:  0.014566503465175629\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  8.165342478605453e-06\n",
      "Q Loss:  4.2175604903604835e-05\n",
      "Policy Loss:  0.002221453934907913\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.035963043570518494\n",
      "Q Loss:  0.0021143171470612288\n",
      "Policy Loss:  0.012026254087686539\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.05273254215717316\n",
      "Q Loss:  0.009354673326015472\n",
      "Policy Loss:  -0.045882079750299454\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.03369898349046707\n",
      "Q Loss:  0.008386344648897648\n",
      "Policy Loss:  0.054826706647872925\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  57.53583908081055\n",
      "Q Loss:  134.10096740722656\n",
      "Policy Loss:  -7.043436527252197\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96568 length: 112 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.040008544921875\n",
      "Value Loss:  0.030889922752976418\n",
      "Q Loss:  0.001603296143002808\n",
      "Policy Loss:  0.010715052485466003\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.8369571566581726\n",
      "Q Loss:  0.002014769008383155\n",
      "Policy Loss:  0.1210852637887001\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96681 length: 109 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.6473635469083092e-06\n",
      "Q Loss:  9.433242667000741e-05\n",
      "Policy Loss:  0.0341307558119297\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96685 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  24827.45703125\n",
      "Q Loss:  23178.888671875\n",
      "Policy Loss:  -50.56123733520508\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96754 length: 69 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4481791367870755e-05\n",
      "Q Loss:  0.00020922868861816823\n",
      "Policy Loss:  -0.007688828743994236\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00011193325917702168\n",
      "Q Loss:  0.00029519881354644895\n",
      "Policy Loss:  -0.008593851700425148\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.9443477867753245e-05\n",
      "Q Loss:  0.00015530759992543608\n",
      "Policy Loss:  -0.004780979361385107\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0276586152613163\n",
      "Q Loss:  0.0069836778566241264\n",
      "Policy Loss:  0.04418142884969711\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.05430694296956062\n",
      "Q Loss:  0.0021556417923420668\n",
      "Policy Loss:  -0.046572234481573105\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  18675.83984375\n",
      "Q Loss:  17600.568359375\n",
      "Policy Loss:  -46.54712677001953\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96820 length: 46 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.02600574493408203\n",
      "Value Loss:  0.0002256958105135709\n",
      "Q Loss:  230.93814086914062\n",
      "Policy Loss:  7.933803558349609\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.8656828615348786e-06\n",
      "Q Loss:  1.3135602785041556e-05\n",
      "Policy Loss:  0.0018081257585436106\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 96828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00011805081157945096\n",
      "Q Loss:  0.00011295631702523679\n",
      "Policy Loss:  0.00021298450883477926\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 96832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.012827474623918533\n",
      "Q Loss:  0.015816930681467056\n",
      "Policy Loss:  -0.011726554483175278\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 96836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.7538703083992004\n",
      "Q Loss:  0.0031709792092442513\n",
      "Policy Loss:  0.10476861149072647\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 96960 length: 124 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.03807895630598068\n",
      "Q Loss:  0.006736123934388161\n",
      "Policy Loss:  -0.041289180517196655\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 96964 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.012430096045136452\n",
      "Q Loss:  0.0009085198398679495\n",
      "Policy Loss:  0.022642575204372406\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 96968 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  188485.171875\n",
      "Q Loss:  173422.140625\n",
      "Policy Loss:  -112.17467498779297\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 96977 length: 9 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.189194548118394e-06\n",
      "Q Loss:  0.0007406824734061956\n",
      "Policy Loss:  0.011749794706702232\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 96981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.320509858895093e-05\n",
      "Q Loss:  2.3406246327795088e-05\n",
      "Policy Loss:  -0.0009112036204896867\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 96985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.01572907157242298\n",
      "Q Loss:  0.011936412192881107\n",
      "Policy Loss:  0.006008988246321678\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 96989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  7625.17333984375\n",
      "Q Loss:  7191.0712890625\n",
      "Policy Loss:  -21.141122817993164\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 97101 length: 112 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00030978783615864813\n",
      "Q Loss:  0.0006152004352770746\n",
      "Policy Loss:  0.01011332031339407\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 97105 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002658701268956065\n",
      "Q Loss:  0.00011508404713822529\n",
      "Policy Loss:  -0.0015278547070920467\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 97109 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00015216541942209005\n",
      "Q Loss:  0.00013019179459661245\n",
      "Policy Loss:  0.003708451986312866\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 97113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.494036693358794e-05\n",
      "Q Loss:  0.00037263083504512906\n",
      "Policy Loss:  0.009688196703791618\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 97117 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.020896967500448227\n",
      "Q Loss:  0.00926272477954626\n",
      "Policy Loss:  0.03393568843603134\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 97121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490114688873291\n",
      "Value Loss:  0.04272914677858353\n",
      "Q Loss:  0.011634977534413338\n",
      "Policy Loss:  0.0072316862642765045\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  16055.5537109375\n",
      "Q Loss:  14715.017578125\n",
      "Policy Loss:  -15.176423072814941\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97177 length: 52 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  87814.2734375\n",
      "Q Loss:  80168.3515625\n",
      "Policy Loss:  -77.79988861083984\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97196 length: 19 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.006323602981865406\n",
      "Q Loss:  0.0016602587420493364\n",
      "Policy Loss:  -0.01820765994489193\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0007841700571589172\n",
      "Q Loss:  0.0002733540895860642\n",
      "Policy Loss:  0.009165830910205841\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.026140926405787468\n",
      "Q Loss:  0.008423112332820892\n",
      "Policy Loss:  0.028648357838392258\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97208 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3.5304925441741943\n",
      "Q Loss:  18.241008758544922\n",
      "Policy Loss:  1.0750900506973267\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97233 length: 25 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00027576310094445944\n",
      "Q Loss:  0.0003297879302408546\n",
      "Policy Loss:  -0.014157108031213284\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011789083480834961\n",
      "Value Loss:  0.00039649143582209945\n",
      "Q Loss:  0.00040113425347954035\n",
      "Policy Loss:  -0.011967836879193783\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00021477659174706787\n",
      "Q Loss:  0.019743258133530617\n",
      "Policy Loss:  0.024616355076432228\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.07117800414562225\n",
      "Q Loss:  0.017659880220890045\n",
      "Policy Loss:  -0.015333432704210281\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.14732439815998077\n",
      "Q Loss:  0.03467899560928345\n",
      "Policy Loss:  -0.1415441781282425\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.11073420196771622\n",
      "Q Loss:  0.023331135511398315\n",
      "Policy Loss:  -0.0762612521648407\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00017907317669596523\n",
      "Q Loss:  0.00616417545825243\n",
      "Policy Loss:  0.04222531616687775\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00011114697554148734\n",
      "Q Loss:  0.00601849565282464\n",
      "Policy Loss:  0.036879200488328934\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00012564868666231632\n",
      "Q Loss:  0.0018916628323495388\n",
      "Policy Loss:  0.01753544621169567\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03160834312438965\n",
      "Value Loss:  0.03445303812623024\n",
      "Q Loss:  0.017276087775826454\n",
      "Policy Loss:  0.049937572330236435\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 97273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.03376450389623642\n",
      "Q Loss:  0.01586587354540825\n",
      "Policy Loss:  0.046026937663555145\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.09856085479259491\n",
      "Q Loss:  0.004455497954040766\n",
      "Policy Loss:  -0.00024565309286117554\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300572395324707\n",
      "Value Loss:  0.12548209726810455\n",
      "Q Loss:  0.004026943817734718\n",
      "Policy Loss:  -0.061995938420295715\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97285 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  10984.6533203125\n",
      "Q Loss:  10038.955078125\n",
      "Policy Loss:  -12.02489185333252\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97360 length: 75 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.02812305837869644\n",
      "Q Loss:  0.01742427609860897\n",
      "Policy Loss:  -0.014104507863521576\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.07802271842956543\n",
      "Q Loss:  0.0008993361261673272\n",
      "Policy Loss:  0.032531578093767166\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.024571465328335762\n",
      "Q Loss:  0.017571352422237396\n",
      "Policy Loss:  -0.019786396995186806\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 97372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  25715.40234375\n",
      "Q Loss:  23362.58984375\n",
      "Policy Loss:  -28.62944793701172\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97404 length: 32 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0012047712225466967\n",
      "Q Loss:  0.0018164091743528843\n",
      "Policy Loss:  -0.01441507413983345\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.04164715111255646\n",
      "Q Loss:  0.002400397090241313\n",
      "Policy Loss:  0.028247952461242676\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  117.95648193359375\n",
      "Q Loss:  290.3421936035156\n",
      "Policy Loss:  -12.077096939086914\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97561 length: 149 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0005522663705050945\n",
      "Q Loss:  6.747224688297138e-05\n",
      "Policy Loss:  -0.0052450234070420265\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97565 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00047595848445780575\n",
      "Q Loss:  8.791645086603239e-05\n",
      "Policy Loss:  -0.0005903770215809345\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97569 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  7.414594438159838e-05\n",
      "Q Loss:  0.00019950672867707908\n",
      "Policy Loss:  0.010327419266104698\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97573 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.000149474959471263\n",
      "Q Loss:  0.0034796358086168766\n",
      "Policy Loss:  -0.029812149703502655\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97577 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.017556345090270042\n",
      "Q Loss:  0.038653552532196045\n",
      "Policy Loss:  0.021916091442108154\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97581 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.05120467767119408\n",
      "Q Loss:  0.01393674872815609\n",
      "Policy Loss:  -0.023159978911280632\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97585 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.2172681093215942\n",
      "Q Loss:  0.008805148303508759\n",
      "Policy Loss:  0.18507122993469238\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97660 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  0.0029991341289132833\n",
      "Q Loss:  0.004056639038026333\n",
      "Policy Loss:  0.02431546151638031\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.004442653618752956\n",
      "Q Loss:  0.0025252755731344223\n",
      "Policy Loss:  0.034314580261707306\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  7.278663542820141e-05\n",
      "Q Loss:  0.0005878654774278402\n",
      "Policy Loss:  0.041870929300785065\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.76083904504776\n",
      "Q Loss:  3.781660795211792\n",
      "Policy Loss:  0.23886743187904358\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97793 length: 121 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.06042289361357689\n",
      "Q Loss:  0.0011073957430198789\n",
      "Policy Loss:  -0.04214472696185112\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.014652672223746777\n",
      "Q Loss:  0.009541679173707962\n",
      "Policy Loss:  0.0031170248985290527\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97801 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  8.804391109151766e-05\n",
      "Q Loss:  0.0005147215561009943\n",
      "Policy Loss:  -0.015443861484527588\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97805 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.246527947136201e-05\n",
      "Q Loss:  0.002543153939768672\n",
      "Policy Loss:  0.025854576379060745\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97809 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  9.77779200184159e-06\n",
      "Q Loss:  0.0023099416866898537\n",
      "Policy Loss:  0.018767772242426872\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97813 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002769862476270646\n",
      "Q Loss:  0.002599109895527363\n",
      "Policy Loss:  -0.0006791173946112394\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97817 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.01285636704415083\n",
      "Q Loss:  0.0008959922124631703\n",
      "Policy Loss:  0.013398205861449242\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.03633146733045578\n",
      "Q Loss:  0.006363201420754194\n",
      "Policy Loss:  -0.04309092462062836\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000666850246489048\n",
      "Q Loss:  0.0007957410416565835\n",
      "Policy Loss:  -0.011604984290897846\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97829 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.683854058384895e-05\n",
      "Q Loss:  0.00034861866151914\n",
      "Policy Loss:  -0.006630081683397293\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.00017623149324208498\n",
      "Q Loss:  0.0004878674808423966\n",
      "Policy Loss:  0.009518753737211227\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  0.0007327520288527012\n",
      "Q Loss:  0.001041966606862843\n",
      "Policy Loss:  -0.012839874252676964\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97841 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.2732564755424391e-05\n",
      "Q Loss:  0.00035701165325008333\n",
      "Policy Loss:  0.011686833575367928\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  0.018622245639562607\n",
      "Q Loss:  0.011994578875601292\n",
      "Policy Loss:  -0.03677203506231308\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97849 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.035472650080919266\n",
      "Q Loss:  0.0032914511393755674\n",
      "Policy Loss:  -0.04736153408885002\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97853 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.4492251873016357\n",
      "Q Loss:  0.002019644482061267\n",
      "Policy Loss:  0.34842535853385925\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97891 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0006083772168494761\n",
      "Q Loss:  0.0006585186347365379\n",
      "Policy Loss:  0.013654549606144428\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97895 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  7.138077489798889e-05\n",
      "Q Loss:  0.00010123821994056925\n",
      "Policy Loss:  -0.0062669795006513596\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97899 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2.660904884338379\n",
      "Q Loss:  0.0024503949098289013\n",
      "Policy Loss:  0.3846951723098755\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97934 length: 35 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0044137039221823215\n",
      "Q Loss:  0.009039604105055332\n",
      "Policy Loss:  -0.03237908333539963\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.003101095324382186\n",
      "Q Loss:  0.0007618534727953374\n",
      "Policy Loss:  -0.015026053413748741\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  0.00011420842201914638\n",
      "Q Loss:  0.008996373973786831\n",
      "Policy Loss:  0.005636980757117271\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 97946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.03444264456629753\n",
      "Q Loss:  0.011702151969075203\n",
      "Policy Loss:  0.0033136047422885895\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 97950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.208268404006958\n",
      "Q Loss:  0.004056274890899658\n",
      "Policy Loss:  0.18230228126049042\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 98026 length: 76 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.012535969726741314\n",
      "Q Loss:  0.0013376976130530238\n",
      "Policy Loss:  0.0338069386780262\n",
      "[(0.00013, 0), (0.00013, 0.0)]\n",
      "Alpha*: 0.00013 tau*: 0 Episode: 98030 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.2233898639678955\n",
      "Q Loss:  0.0028389550279825926\n",
      "Policy Loss:  0.1893853098154068\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 98105 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  22754.306640625\n",
      "Q Loss:  20797.720703125\n",
      "Policy Loss:  -24.404638290405273\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 98141 length: 36 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002459268143866211\n",
      "Q Loss:  113.98233795166016\n",
      "Policy Loss:  3.743447780609131\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 98145 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600550651550293\n",
      "Value Loss:  0.002730185631662607\n",
      "Q Loss:  0.0010622100671753287\n",
      "Policy Loss:  0.026034995913505554\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 98149 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.330171840498224e-05\n",
      "Q Loss:  0.0009601744823157787\n",
      "Policy Loss:  0.012483309023082256\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98153 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  1.3590133676188998e-05\n",
      "Q Loss:  0.011472358368337154\n",
      "Policy Loss:  0.03169306367635727\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98157 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06141413003206253\n",
      "Q Loss:  0.01278742216527462\n",
      "Policy Loss:  -0.06477734446525574\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98161 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.04205847531557083\n",
      "Q Loss:  0.01066085509955883\n",
      "Policy Loss:  0.019475653767585754\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98165 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.04242536053061485\n",
      "Q Loss:  0.009878733195364475\n",
      "Policy Loss:  -0.03863423690199852\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98169 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  77.55387115478516\n",
      "Q Loss:  42.92356872558594\n",
      "Policy Loss:  -8.68598461151123\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98288 length: 119 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00010380588355474174\n",
      "Q Loss:  112.45662689208984\n",
      "Policy Loss:  3.7296948432922363\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3.110454781563021e-05\n",
      "Q Loss:  0.002262483350932598\n",
      "Policy Loss:  0.024811916053295135\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.041008949279785156\n",
      "Value Loss:  0.0005075000808574259\n",
      "Q Loss:  0.0008934991201385856\n",
      "Policy Loss:  -0.007024927996098995\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800583839416504\n",
      "Value Loss:  0.00022169452859088778\n",
      "Q Loss:  0.0008287308737635612\n",
      "Policy Loss:  -0.0025549172423779964\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  6.65913539705798e-05\n",
      "Q Loss:  0.0018372687045484781\n",
      "Policy Loss:  0.05388353765010834\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.5382461547851562\n",
      "Q Loss:  15.30286979675293\n",
      "Policy Loss:  0.7214664816856384\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98366 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00022841597092337906\n",
      "Q Loss:  0.003676733234897256\n",
      "Policy Loss:  -0.03068087063729763\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98370 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001977256906684488\n",
      "Q Loss:  0.002297093626111746\n",
      "Policy Loss:  -0.02170276828110218\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98374 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.5612609786330722e-05\n",
      "Q Loss:  0.0007979710935615003\n",
      "Policy Loss:  0.037157878279685974\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 98378 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.09792297333478928\n",
      "Q Loss:  0.03813948854804039\n",
      "Policy Loss:  -0.14593613147735596\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98382 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.09695837646722794\n",
      "Q Loss:  0.025024183094501495\n",
      "Policy Loss:  -0.12457028031349182\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  1.8002965589403175e-05\n",
      "Q Loss:  2.9150909540476277e-05\n",
      "Policy Loss:  0.00012883637100458145\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98390 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06738345324993134\n",
      "Q Loss:  0.02674366533756256\n",
      "Policy Loss:  -0.055866092443466187\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98394 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.125967264175415\n",
      "Q Loss:  0.0036075350362807512\n",
      "Policy Loss:  0.3226015865802765\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98436 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012088775634765625\n",
      "Value Loss:  0.0003310473694000393\n",
      "Q Loss:  0.00012677174527198076\n",
      "Policy Loss:  -0.002373355906456709\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00016625641728751361\n",
      "Q Loss:  0.00015416558017022908\n",
      "Policy Loss:  0.0026344144716858864\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400087833404541\n",
      "Value Loss:  3.6172830732539296e-05\n",
      "Q Loss:  3.377305984031409e-05\n",
      "Policy Loss:  -0.0003058579168282449\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 98448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  2301.4697265625\n",
      "Q Loss:  5880.7333984375\n",
      "Policy Loss:  -140.2851104736328\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 98452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.3013396710448433e-05\n",
      "Q Loss:  329.4733581542969\n",
      "Policy Loss:  10.912918090820312\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 98456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2291.87109375\n",
      "Q Loss:  5846.39453125\n",
      "Policy Loss:  -139.86492919921875\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 98460 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2282.582275390625\n",
      "Q Loss:  5923.59375\n",
      "Policy Loss:  -121.41375732421875\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 98464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0008431294118054211\n",
      "Q Loss:  0.002074219286441803\n",
      "Policy Loss:  0.00224269088357687\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 98468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.003148191375657916\n",
      "Q Loss:  0.015443772077560425\n",
      "Policy Loss:  0.0762033611536026\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 98472 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0013858687598258257\n",
      "Q Loss:  0.0010667711030691862\n",
      "Policy Loss:  0.013516838662326336\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 98476 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0005016651120968163\n",
      "Q Loss:  0.002960037672892213\n",
      "Policy Loss:  0.023080945014953613\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 98480 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.020579753443598747\n",
      "Q Loss:  0.01299996767193079\n",
      "Policy Loss:  0.08885219693183899\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 98484 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.8720958828926086\n",
      "Q Loss:  0.057499680668115616\n",
      "Policy Loss:  0.24320128560066223\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 98590 length: 106 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00010179750097449869\n",
      "Q Loss:  0.0004886116948910058\n",
      "Policy Loss:  0.04155097156763077\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 98594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  372.5372619628906\n",
      "Q Loss:  920.3334350585938\n",
      "Policy Loss:  -36.50830078125\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 98689 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0001961516245501116\n",
      "Q Loss:  0.0008023917325772345\n",
      "Policy Loss:  -0.0003606276586651802\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 98693 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04164516180753708\n",
      "Q Loss:  0.022790784016251564\n",
      "Policy Loss:  0.10657186061143875\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 98697 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.04162086173892021\n",
      "Q Loss:  0.08041509985923767\n",
      "Policy Loss:  0.1039838045835495\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98701 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.02048373781144619\n",
      "Q Loss:  0.058579590171575546\n",
      "Policy Loss:  0.10386065393686295\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98705 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  0.7266407012939453\n",
      "Q Loss:  0.010836344212293625\n",
      "Policy Loss:  0.11927345395088196\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98829 length: 124 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0012111011892557144\n",
      "Q Loss:  0.0012855872046202421\n",
      "Policy Loss:  -0.023212984204292297\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00023980412515811622\n",
      "Q Loss:  5.406960553955287e-05\n",
      "Policy Loss:  -0.006080462131649256\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  8.623829489806667e-05\n",
      "Q Loss:  0.0001398850290570408\n",
      "Policy Loss:  -0.004675595089793205\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98841 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.019570473581552505\n",
      "Q Loss:  0.033412497490644455\n",
      "Policy Loss:  -0.03301722928881645\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.038651492446660995\n",
      "Q Loss:  0.011615434661507607\n",
      "Policy Loss:  -0.004721015691757202\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98849 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  4.8370288823207375e-06\n",
      "Q Loss:  0.002077148761600256\n",
      "Policy Loss:  -0.030629754066467285\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98853 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0001609055616427213\n",
      "Q Loss:  0.0002749364939518273\n",
      "Policy Loss:  -0.003891815198585391\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98857 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00021438326803036034\n",
      "Q Loss:  0.0015214190352708101\n",
      "Policy Loss:  -0.012063657864928246\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98861 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.05284833535552025\n",
      "Q Loss:  0.013787463307380676\n",
      "Policy Loss:  -0.04958066716790199\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98865 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.05069328472018242\n",
      "Q Loss:  0.013116755522787571\n",
      "Policy Loss:  -0.09965118765830994\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.015882359817624092\n",
      "Q Loss:  0.004858880303800106\n",
      "Policy Loss:  -0.012235434725880623\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  0.04461979866027832\n",
      "Q Loss:  0.009887040592730045\n",
      "Policy Loss:  -0.038671255111694336\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.108154361252673e-06\n",
      "Q Loss:  0.001507437089458108\n",
      "Policy Loss:  -0.011722728610038757\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047011613845825195\n",
      "Value Loss:  0.02521613985300064\n",
      "Q Loss:  0.019192637875676155\n",
      "Policy Loss:  -0.04912036284804344\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.023015614598989487\n",
      "Q Loss:  0.014668856747448444\n",
      "Policy Loss:  -0.03062869980931282\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 98889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  75.47431945800781\n",
      "Q Loss:  208.15135192871094\n",
      "Policy Loss:  -7.321059703826904\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99004 length: 115 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.019290588796138763\n",
      "Q Loss:  0.005284507758915424\n",
      "Policy Loss:  0.02660100720822811\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.023270845413208\n",
      "Q Loss:  0.004809227306395769\n",
      "Policy Loss:  0.14743784070014954\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99099 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  4.4271000660955906e-05\n",
      "Q Loss:  0.0038929241709411144\n",
      "Policy Loss:  0.03967295587062836\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.4777437172597274e-05\n",
      "Q Loss:  0.0031063053756952286\n",
      "Policy Loss:  0.05663013458251953\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9921.552734375\n",
      "Q Loss:  9055.6953125\n",
      "Policy Loss:  -11.372154235839844\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99190 length: 83 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00015294438344426453\n",
      "Q Loss:  4.402955528348684e-05\n",
      "Policy Loss:  -0.003162883687764406\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.229738260619342e-05\n",
      "Q Loss:  0.003099870402365923\n",
      "Policy Loss:  0.044135093688964844\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.0842536687850952\n",
      "Q Loss:  5.670019626617432\n",
      "Policy Loss:  0.3271733224391937\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99284 length: 86 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0009565515210852027\n",
      "Q Loss:  0.004501150455325842\n",
      "Policy Loss:  -0.038530848920345306\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.031974301848095e-05\n",
      "Q Loss:  0.0013913444709032774\n",
      "Policy Loss:  -0.016484415158629417\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  9.994641914090607e-08\n",
      "Q Loss:  0.0010227286256849766\n",
      "Policy Loss:  0.010834397748112679\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00011225712660234421\n",
      "Q Loss:  0.0035396788734942675\n",
      "Policy Loss:  0.02171199396252632\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010285139083862305\n",
      "Value Loss:  0.017322804778814316\n",
      "Q Loss:  0.012367725372314453\n",
      "Policy Loss:  0.02816290408372879\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  108.76427459716797\n",
      "Q Loss:  275.181396484375\n",
      "Policy Loss:  -11.309460639953613\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99384 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  0.0007638788083568215\n",
      "Q Loss:  0.0015964031917974353\n",
      "Policy Loss:  0.020014606416225433\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99388 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00049701111856848\n",
      "Q Loss:  0.0009311065659858286\n",
      "Policy Loss:  0.0010318225249648094\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99392 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.000591539079323411\n",
      "Q Loss:  0.0006750237662345171\n",
      "Policy Loss:  -0.002035966143012047\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99396 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00014351159916259348\n",
      "Q Loss:  0.0006244431133382022\n",
      "Policy Loss:  -0.007096512243151665\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99400 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.030554482713341713\n",
      "Q Loss:  0.005585954524576664\n",
      "Policy Loss:  -0.014245707541704178\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99404 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  202.4591827392578\n",
      "Q Loss:  412.7615661621094\n",
      "Policy Loss:  -21.47776985168457\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99447 length: 43 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.03247610479593277\n",
      "Q Loss:  0.007186227012425661\n",
      "Policy Loss:  -0.0401945635676384\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.0137098797713406e-05\n",
      "Q Loss:  0.0020350241102278233\n",
      "Policy Loss:  0.013958918862044811\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0002119365381076932\n",
      "Q Loss:  0.002775192027911544\n",
      "Policy Loss:  -0.013464859686791897\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.6051639318466187\n",
      "Q Loss:  0.0033883503638207912\n",
      "Policy Loss:  0.08209496736526489\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99612 length: 153 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.689892714144662e-05\n",
      "Q Loss:  121.70063781738281\n",
      "Policy Loss:  3.846667766571045\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99616 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.1769094271585345e-05\n",
      "Q Loss:  121.40270233154297\n",
      "Policy Loss:  3.9001095294952393\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0626230239868164\n",
      "Value Loss:  1.6923697330639698e-05\n",
      "Q Loss:  0.003149841446429491\n",
      "Policy Loss:  -0.015421954914927483\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 99624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001203536987305\n",
      "Value Loss:  3.4494917144911597e-06\n",
      "Q Loss:  0.000255031103733927\n",
      "Policy Loss:  0.009543908759951591\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 99628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0012686570407822728\n",
      "Q Loss:  0.0005820051301270723\n",
      "Policy Loss:  0.005930359475314617\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 99632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.027678782120347023\n",
      "Q Loss:  0.022654442116618156\n",
      "Policy Loss:  -0.05783917009830475\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 99636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01499176025390625\n",
      "Value Loss:  0.04158300906419754\n",
      "Q Loss:  0.010805074125528336\n",
      "Policy Loss:  -0.046419657766819\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 99640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.013557196594774723\n",
      "Q Loss:  0.0017734982538968325\n",
      "Policy Loss:  -0.022852089256048203\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 99644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.02635984681546688\n",
      "Q Loss:  0.0065955501049757\n",
      "Policy Loss:  -0.009213592857122421\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 99648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0600130558013916\n",
      "Value Loss:  0.0252817515283823\n",
      "Q Loss:  0.004983541090041399\n",
      "Policy Loss:  -0.03327561169862747\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 99652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  2.373196548433043e-05\n",
      "Q Loss:  0.0002968754852190614\n",
      "Policy Loss:  0.006264277268201113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00044500373769551516\n",
      "Q Loss:  0.001623785006813705\n",
      "Policy Loss:  0.027469033375382423\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.0034405679325573e-05\n",
      "Q Loss:  1.091683543563704e-06\n",
      "Policy Loss:  -0.0020405403338372707\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.00016278547991532832\n",
      "Q Loss:  0.0011100801639258862\n",
      "Policy Loss:  0.015354632399976254\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  9.613848669687286e-05\n",
      "Q Loss:  0.0007715897518210113\n",
      "Policy Loss:  0.008876362815499306\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.7669397493591532e-05\n",
      "Q Loss:  5.946685269009322e-05\n",
      "Policy Loss:  -0.003023047698661685\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  9.880217112367973e-05\n",
      "Q Loss:  0.003992550075054169\n",
      "Policy Loss:  -0.020693231374025345\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99680 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.909537038765848e-05\n",
      "Q Loss:  0.00031450088135898113\n",
      "Policy Loss:  -0.010803560726344585\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99684 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  9.901518205879256e-05\n",
      "Q Loss:  0.0028629214502871037\n",
      "Policy Loss:  -0.026325669139623642\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99688 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0001490553840994835\n",
      "Q Loss:  0.0009244218235835433\n",
      "Policy Loss:  -0.017233241349458694\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004541397094727\n",
      "Value Loss:  9.968776430469006e-05\n",
      "Q Loss:  4.651866765925661e-05\n",
      "Policy Loss:  -0.005152164027094841\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.01655440963804722\n",
      "Q Loss:  0.004238795954734087\n",
      "Policy Loss:  0.010675761848688126\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  14968.708984375\n",
      "Q Loss:  13667.4580078125\n",
      "Policy Loss:  -17.002817153930664\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99755 length: 55 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0002435973729006946\n",
      "Q Loss:  0.0001318282593274489\n",
      "Policy Loss:  -0.0017020090017467737\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.8593414248898625e-05\n",
      "Q Loss:  5.287937892717309e-05\n",
      "Policy Loss:  0.004637403413653374\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.2630469427676871e-05\n",
      "Q Loss:  0.0003586327948141843\n",
      "Policy Loss:  0.033992793411016464\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.024998664855957\n",
      "Q Loss:  0.002534971572458744\n",
      "Policy Loss:  0.15842588245868683\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99858 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  2.8966494937776588e-05\n",
      "Q Loss:  0.00012048684584442526\n",
      "Policy Loss:  -0.003150717820972204\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99862 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.1759689843747765e-05\n",
      "Q Loss:  0.000198731868294999\n",
      "Policy Loss:  -0.004470201674848795\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00010153427865589038\n",
      "Q Loss:  0.0010993799660354853\n",
      "Policy Loss:  0.015063661150634289\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.7762911486206576e-05\n",
      "Q Loss:  0.0002445061400067061\n",
      "Policy Loss:  0.003121193964034319\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99874 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.2544757737487089e-05\n",
      "Q Loss:  1.7197287888848223e-05\n",
      "Policy Loss:  -0.002787237521260977\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99878 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  3.5138568819093052e-06\n",
      "Q Loss:  0.001181386411190033\n",
      "Policy Loss:  0.008586437441408634\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99882 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  9.621282515581697e-06\n",
      "Q Loss:  0.0010394961573183537\n",
      "Policy Loss:  0.008825982920825481\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99886 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04200887680053711\n",
      "Value Loss:  7.576239568152232e-06\n",
      "Q Loss:  0.00041219417471438646\n",
      "Policy Loss:  0.011147215962409973\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99890 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  3.2032708077167626e-06\n",
      "Q Loss:  2.824749390129e-05\n",
      "Policy Loss:  -0.0001381518377456814\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99894 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  7.0050273279775865e-06\n",
      "Q Loss:  0.0013633345952257514\n",
      "Policy Loss:  0.013220277614891529\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99898 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  2.349211172258947e-06\n",
      "Q Loss:  7.803287189744879e-06\n",
      "Policy Loss:  -0.0013552739983424544\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.021851077675819397\n",
      "Q Loss:  0.005951636005192995\n",
      "Policy Loss:  0.001122690737247467\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 99906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.03257355839014053\n",
      "Q Loss:  0.008034679107367992\n",
      "Policy Loss:  -0.01232948713004589\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 99910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.187351916902116e-07\n",
      "Q Loss:  0.001309310318902135\n",
      "Policy Loss:  0.018778424710035324\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 99914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.020504744723439217\n",
      "Q Loss:  0.006140196695923805\n",
      "Policy Loss:  -0.0037971213459968567\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 99918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.019672835245728493\n",
      "Q Loss:  0.013805544003844261\n",
      "Policy Loss:  0.020266473293304443\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 99922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.2723233699798584\n",
      "Q Loss:  0.0019560162909328938\n",
      "Policy Loss:  0.1889018714427948\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 99995 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  11579.83203125\n",
      "Q Loss:  10626.509765625\n",
      "Policy Loss:  -13.106771469116211\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100066 length: 71 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.427918611327186e-05\n",
      "Q Loss:  0.0002670825633686036\n",
      "Policy Loss:  0.0037721998523920774\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.314092853339389e-05\n",
      "Q Loss:  0.00017384070088155568\n",
      "Policy Loss:  -0.006022281013429165\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  9.776679689821322e-06\n",
      "Q Loss:  3.5787128581432626e-05\n",
      "Policy Loss:  0.030138136819005013\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  15505.185546875\n",
      "Q Loss:  14154.072265625\n",
      "Policy Loss:  -17.832778930664062\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100131 length: 53 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3.0807004804955795e-05\n",
      "Q Loss:  0.00012292222527321428\n",
      "Policy Loss:  -0.00357552757486701\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  4.987053762306459e-05\n",
      "Q Loss:  0.00016554919420741498\n",
      "Policy Loss:  0.0009075772250071168\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  3.652673331089318e-05\n",
      "Q Loss:  0.00014949704927857965\n",
      "Policy Loss:  -0.005112853832542896\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.436785431811586e-05\n",
      "Q Loss:  2.845030030584894e-05\n",
      "Policy Loss:  -0.0024542391765862703\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.0285792996000964e-05\n",
      "Q Loss:  1.4799455129832495e-05\n",
      "Policy Loss:  0.00035474105970934033\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04200911521911621\n",
      "Value Loss:  7.496148555219406e-06\n",
      "Q Loss:  6.571641279151663e-06\n",
      "Policy Loss:  0.0006466797785833478\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100155 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  7.362466476479312e-07\n",
      "Q Loss:  0.0002504091535229236\n",
      "Policy Loss:  0.0021437550894916058\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100159 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00012066875933669508\n",
      "Q Loss:  0.0001575010537635535\n",
      "Policy Loss:  -0.006578512489795685\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016380786895751953\n",
      "Value Loss:  0.025719184428453445\n",
      "Q Loss:  0.008293026126921177\n",
      "Policy Loss:  -0.021348675712943077\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100167 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.3680202960968018\n",
      "Q Loss:  0.00521828792989254\n",
      "Policy Loss:  0.1950049251317978\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100234 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  1.4075712897465564e-05\n",
      "Q Loss:  7.067547812766861e-06\n",
      "Policy Loss:  0.0007764032343402505\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  8369.7451171875\n",
      "Q Loss:  7638.3544921875\n",
      "Policy Loss:  -9.863859176635742\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100336 length: 98 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0003474199038464576\n",
      "Q Loss:  0.000170951709151268\n",
      "Policy Loss:  0.0022385157644748688\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0003867460764013231\n",
      "Q Loss:  0.025452379137277603\n",
      "Policy Loss:  0.052941203117370605\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700828552246094\n",
      "Value Loss:  2.664168732735561e-06\n",
      "Q Loss:  0.0004697355325333774\n",
      "Policy Loss:  0.009033937007188797\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.8622143872780725e-05\n",
      "Q Loss:  0.00036835274659097195\n",
      "Policy Loss:  0.008414456620812416\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  3.902866956195794e-05\n",
      "Q Loss:  0.00013036440941505134\n",
      "Policy Loss:  -0.004283261485397816\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.579569809313398e-05\n",
      "Q Loss:  9.102400508709252e-05\n",
      "Policy Loss:  0.0016203396953642368\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.6590003471937962e-05\n",
      "Q Loss:  0.0006696638301946223\n",
      "Policy Loss:  0.0436825305223465\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.03502635285258293\n",
      "Q Loss:  0.006695219315588474\n",
      "Policy Loss:  -0.017545178532600403\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.7272957595414482e-05\n",
      "Q Loss:  0.00030346272978931665\n",
      "Policy Loss:  0.00988466665148735\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.8714653530623764e-05\n",
      "Q Loss:  0.00024664285592734814\n",
      "Policy Loss:  -0.006860628724098206\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013195991516113281\n",
      "Value Loss:  7.379478483926505e-05\n",
      "Q Loss:  0.0001188024616567418\n",
      "Policy Loss:  -0.006513876840472221\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03400754928588867\n",
      "Value Loss:  1.4458281611950952e-06\n",
      "Q Loss:  1.8090244338964112e-05\n",
      "Policy Loss:  0.00017346673121210188\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100384 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.9750185012817383\n",
      "Q Loss:  0.004015213809907436\n",
      "Policy Loss:  0.13354650139808655\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100477 length: 93 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011588096618652344\n",
      "Value Loss:  0.0009267338900826871\n",
      "Q Loss:  115.89806365966797\n",
      "Policy Loss:  3.72808837890625\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 100481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.168694481952116e-05\n",
      "Q Loss:  3.689424556796439e-05\n",
      "Policy Loss:  0.0015627314569428563\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  3.3305354008916765e-05\n",
      "Q Loss:  2.0732451957883313e-05\n",
      "Policy Loss:  -0.0010688609909266233\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  4.215189619571902e-05\n",
      "Q Loss:  5.0157515943283215e-05\n",
      "Policy Loss:  -0.00029180466663092375\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004966735839844\n",
      "Value Loss:  0.6522687077522278\n",
      "Q Loss:  0.0036128228530287743\n",
      "Policy Loss:  0.0887095034122467\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100631 length: 138 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.4714394385227934e-05\n",
      "Q Loss:  0.00011439527588663623\n",
      "Policy Loss:  0.0057933395728468895\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0001603223936399445\n",
      "Q Loss:  0.00045271564158611\n",
      "Policy Loss:  -0.00851552002131939\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.0572764697135426e-05\n",
      "Q Loss:  0.00016149415750987828\n",
      "Policy Loss:  0.004620648920536041\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.2088173864176497e-05\n",
      "Q Loss:  6.959419988561422e-05\n",
      "Policy Loss:  -0.002428505104035139\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  1.1728546269296203e-05\n",
      "Q Loss:  2.4102937459247187e-05\n",
      "Policy Loss:  0.000604506116360426\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100651 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.968058535974706e-06\n",
      "Q Loss:  9.315191709902138e-05\n",
      "Policy Loss:  0.0019357646815478802\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 100655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.2378637620713562e-05\n",
      "Q Loss:  0.00026081965188495815\n",
      "Policy Loss:  0.03833241015672684\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 100659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.06593115627765656\n",
      "Q Loss:  0.02319796197116375\n",
      "Policy Loss:  -0.07639998942613602\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 100663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.04335087537765503\n",
      "Q Loss:  0.031012261286377907\n",
      "Policy Loss:  -0.07566920667886734\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04800748825073242\n",
      "Value Loss:  0.06318169832229614\n",
      "Q Loss:  0.03421817719936371\n",
      "Policy Loss:  -0.09139950573444366\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.04003385454416275\n",
      "Q Loss:  0.0053047132678329945\n",
      "Policy Loss:  0.03748142346739769\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  99.16071319580078\n",
      "Q Loss:  4.953772068023682\n",
      "Policy Loss:  -11.527464866638184\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100767 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.030211029108614e-05\n",
      "Q Loss:  0.0014547168975695968\n",
      "Policy Loss:  0.02029700018465519\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.03497353568673134\n",
      "Q Loss:  0.004746297374367714\n",
      "Policy Loss:  0.013287410140037537\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.04999135062098503\n",
      "Q Loss:  0.009092248976230621\n",
      "Policy Loss:  0.0028421208262443542\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100779 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.03110327385365963\n",
      "Q Loss:  0.014672599732875824\n",
      "Policy Loss:  0.0184352807700634\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  1.2793196219718084e-05\n",
      "Q Loss:  0.009785797446966171\n",
      "Policy Loss:  0.05527893453836441\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049010515213012695\n",
      "Value Loss:  0.01327759400010109\n",
      "Q Loss:  0.005125465802848339\n",
      "Policy Loss:  0.024163879454135895\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  0.7109758853912354\n",
      "Q Loss:  0.003642857074737549\n",
      "Policy Loss:  0.1173788383603096\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100921 length: 130 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0006022761226631701\n",
      "Q Loss:  0.0011676179710775614\n",
      "Policy Loss:  0.011618397198617458\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100925 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0002716505550779402\n",
      "Q Loss:  0.0008541501592844725\n",
      "Policy Loss:  -0.005611133296042681\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100929 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  6.249735452001914e-05\n",
      "Q Loss:  0.0004133155453018844\n",
      "Policy Loss:  -0.003419780172407627\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100933 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.6305693103931844e-05\n",
      "Q Loss:  0.00014025643758941442\n",
      "Policy Loss:  -0.004577355459332466\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100937 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.5811062338761985e-05\n",
      "Q Loss:  0.000741933414246887\n",
      "Policy Loss:  0.007549744099378586\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100941 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200793266296387\n",
      "Value Loss:  1.8828766769729555e-05\n",
      "Q Loss:  0.0001537121570436284\n",
      "Policy Loss:  -0.0011864429106935859\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100945 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  9.5299719760078e-06\n",
      "Q Loss:  0.0008787658298388124\n",
      "Policy Loss:  0.036697134375572205\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 100949 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  111.16326141357422\n",
      "Q Loss:  229.47850036621094\n",
      "Policy Loss:  -11.556439399719238\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101031 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0004346389614511281\n",
      "Q Loss:  0.0006056481506675482\n",
      "Policy Loss:  0.009430530481040478\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0003435507242102176\n",
      "Q Loss:  7.118673966033384e-05\n",
      "Policy Loss:  0.0016009423416107893\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.4116593522194307e-06\n",
      "Q Loss:  9.452164135836938e-07\n",
      "Policy Loss:  -0.0004324253823142499\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101043 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  8.27951225801371e-06\n",
      "Q Loss:  7.332479526667157e-06\n",
      "Policy Loss:  -0.001436924678273499\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101047 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  8.967461440079205e-07\n",
      "Q Loss:  0.0006684493855573237\n",
      "Policy Loss:  -0.013613851740956306\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101051 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.568525688839145e-06\n",
      "Q Loss:  0.00015479768626391888\n",
      "Policy Loss:  -0.00559746939688921\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101055 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.8548123736982234e-05\n",
      "Q Loss:  0.00035805098013952374\n",
      "Policy Loss:  -0.006877570413053036\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101059 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  6.561072495969711e-06\n",
      "Q Loss:  3.189701237715781e-05\n",
      "Policy Loss:  -3.252738679293543e-05\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101063 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.1192501915502362e-05\n",
      "Q Loss:  1.3130204024491832e-05\n",
      "Policy Loss:  0.0023225382901728153\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101067 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.1502186680445448e-05\n",
      "Q Loss:  0.0015147756785154343\n",
      "Policy Loss:  -0.01944010704755783\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101071 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2881470865977462e-05\n",
      "Q Loss:  0.00046765460865572095\n",
      "Policy Loss:  -0.005374437663704157\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  19506.1171875\n",
      "Q Loss:  17799.1171875\n",
      "Policy Loss:  -22.626678466796875\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101117 length: 42 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015217304229736328\n",
      "Value Loss:  117648.9765625\n",
      "Q Loss:  108712.1953125\n",
      "Policy Loss:  -131.9967803955078\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101131 length: 14 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0006414024392142892\n",
      "Q Loss:  0.000592237280216068\n",
      "Policy Loss:  -0.013958954252302647\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001068115234375\n",
      "Value Loss:  0.000139112351462245\n",
      "Q Loss:  0.0007145706913433969\n",
      "Policy Loss:  -0.009746724739670753\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.0909812519676052e-05\n",
      "Q Loss:  0.002517673186957836\n",
      "Policy Loss:  0.02326127141714096\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  5.573425005422905e-05\n",
      "Q Loss:  6.878163549117744e-05\n",
      "Policy Loss:  0.005053956527262926\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 101147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.01614522747695446\n",
      "Q Loss:  0.012278922833502293\n",
      "Policy Loss:  0.06237294524908066\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.05111697316169739\n",
      "Q Loss:  0.0116985272616148\n",
      "Policy Loss:  -0.024746248498558998\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101155 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.05233784765005112\n",
      "Q Loss:  0.022536057978868484\n",
      "Policy Loss:  -0.02608213573694229\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101159 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.58523428440094\n",
      "Q Loss:  0.005059618968516588\n",
      "Policy Loss:  0.24941612780094147\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101216 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005092936335131526\n",
      "Q Loss:  0.0006493628607131541\n",
      "Policy Loss:  -0.002028073649853468\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101220 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.1988975529675372e-05\n",
      "Q Loss:  0.0005259218160063028\n",
      "Policy Loss:  0.049983911216259\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.05695274472236633\n",
      "Q Loss:  0.010995311662554741\n",
      "Policy Loss:  -0.010834963992238045\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101228 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.03791316971182823\n",
      "Q Loss:  0.010409527458250523\n",
      "Policy Loss:  0.016600988805294037\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 101232 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  26465.52734375\n",
      "Q Loss:  24805.482421875\n",
      "Policy Loss:  -56.10185623168945\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 101263 length: 31 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.05001091957092285\n",
      "Value Loss:  0.00010577587090665475\n",
      "Q Loss:  0.0004909962881356478\n",
      "Policy Loss:  0.010103967040777206\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 101267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0004307782801333815\n",
      "Q Loss:  231.93002319335938\n",
      "Policy Loss:  7.476809501647949\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 101271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00012187319953227416\n",
      "Q Loss:  231.106201171875\n",
      "Policy Loss:  7.43489933013916\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 101275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.796266800141893e-06\n",
      "Q Loss:  2.078193756460678e-05\n",
      "Policy Loss:  -0.004139472730457783\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 101279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00013724900782108307\n",
      "Q Loss:  0.0005075990920886397\n",
      "Policy Loss:  0.007797490805387497\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  9.321032121079043e-05\n",
      "Q Loss:  0.00019879103638231754\n",
      "Policy Loss:  0.005457264371216297\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101287 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.926159868366085e-05\n",
      "Q Loss:  0.00023582138237543404\n",
      "Policy Loss:  -0.005357641726732254\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101291 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.4246569410024676e-06\n",
      "Q Loss:  0.00025309991906397045\n",
      "Policy Loss:  -0.004950502887368202\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101295 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.8493090465199202e-05\n",
      "Q Loss:  0.0014238252770155668\n",
      "Policy Loss:  -0.01772458478808403\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  2.651424438226968e-05\n",
      "Q Loss:  8.623919711681083e-05\n",
      "Policy Loss:  -0.0046349456533789635\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101303 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07601642608642578\n",
      "Value Loss:  1.892031832539942e-05\n",
      "Q Loss:  0.00010648142051650211\n",
      "Policy Loss:  -0.006148941814899445\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101307 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05501294136047363\n",
      "Value Loss:  1.4259749150369316e-05\n",
      "Q Loss:  7.66660668887198e-05\n",
      "Policy Loss:  -0.0024140954483300447\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101311 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  13010.2001953125\n",
      "Q Loss:  11846.357421875\n",
      "Policy Loss:  -16.767932891845703\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101373 length: 62 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0014368490083143115\n",
      "Q Loss:  0.00256268959492445\n",
      "Policy Loss:  -0.012735547497868538\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  7.405653013847768e-05\n",
      "Q Loss:  0.0002049290924333036\n",
      "Policy Loss:  -0.0021395855583250523\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101381 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013561010360717773\n",
      "Value Loss:  0.04986141622066498\n",
      "Q Loss:  0.024917710572481155\n",
      "Policy Loss:  -0.02647324651479721\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101385 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004375457763672\n",
      "Value Loss:  0.07494457066059113\n",
      "Q Loss:  0.04601236805319786\n",
      "Policy Loss:  -0.11575915664434433\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101389 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.04880782589316368\n",
      "Q Loss:  0.018986063078045845\n",
      "Policy Loss:  -0.09274100512266159\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 101393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00013095702161081135\n",
      "Q Loss:  0.000605147099122405\n",
      "Policy Loss:  0.016545424237847328\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  0.022676164284348488\n",
      "Q Loss:  0.011805913411080837\n",
      "Policy Loss:  0.022562820464372635\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.04354723170399666\n",
      "Q Loss:  0.0035441566724330187\n",
      "Policy Loss:  0.033196933567523956\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900742530822754\n",
      "Value Loss:  601.2552490234375\n",
      "Q Loss:  1185.5322265625\n",
      "Policy Loss:  -56.53019332885742\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101493 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.0001682107977103442\n",
      "Q Loss:  0.0011053523048758507\n",
      "Policy Loss:  -0.015917837619781494\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01263570785522461\n",
      "Value Loss:  0.019515234977006912\n",
      "Q Loss:  0.005303157493472099\n",
      "Policy Loss:  0.025857575237751007\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.5104349586181343e-05\n",
      "Q Loss:  0.0028886827640235424\n",
      "Policy Loss:  0.03458625450730324\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.5214344263076782\n",
      "Q Loss:  14.635778427124023\n",
      "Policy Loss:  0.7263084053993225\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101564 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  96.17411041259766\n",
      "Q Loss:  190.74407958984375\n",
      "Policy Loss:  -9.350708961486816\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101675 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00019135067122988403\n",
      "Q Loss:  1505.922607421875\n",
      "Policy Loss:  10.828445434570312\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101679 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01953434944152832\n",
      "Value Loss:  2647.021240234375\n",
      "Q Loss:  5401.04248046875\n",
      "Policy Loss:  -138.28933715820312\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015001535415649414\n",
      "Value Loss:  0.00014258496230468154\n",
      "Q Loss:  0.0016018595779314637\n",
      "Policy Loss:  0.011568215675652027\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  6.254663458094001e-05\n",
      "Q Loss:  0.0012213473673909903\n",
      "Policy Loss:  0.014235901646316051\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  5.906278965994716e-05\n",
      "Q Loss:  0.000130501517560333\n",
      "Policy Loss:  -0.0019990175496786833\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101695 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002872624609153718\n",
      "Q Loss:  0.0009839336853474379\n",
      "Policy Loss:  0.01742926985025406\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101699 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  9.300801480094378e-07\n",
      "Q Loss:  0.00020982313435524702\n",
      "Policy Loss:  -0.009359650313854218\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101703 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.352446608711034e-05\n",
      "Q Loss:  7.508638373110443e-05\n",
      "Policy Loss:  -0.0073023284785449505\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101707 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.00022386768250726163\n",
      "Q Loss:  0.0021515064872801304\n",
      "Policy Loss:  -0.010911020450294018\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101711 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  9.041751036420465e-05\n",
      "Q Loss:  0.0001511165901320055\n",
      "Policy Loss:  0.002348063513636589\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101715 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.00013994440087117255\n",
      "Q Loss:  0.0003793046926148236\n",
      "Policy Loss:  -0.012065552175045013\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101719 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005745154921896756\n",
      "Q Loss:  0.0007613574853166938\n",
      "Policy Loss:  -0.016689559444785118\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101723 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0229595135897398\n",
      "Q Loss:  0.0017897305078804493\n",
      "Policy Loss:  0.017167316749691963\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101727 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05661344528198242\n",
      "Value Loss:  0.09033752977848053\n",
      "Q Loss:  0.011922765523195267\n",
      "Policy Loss:  -0.06328345835208893\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101731 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.02191123366355896\n",
      "Q Loss:  0.0009671300067566335\n",
      "Policy Loss:  0.02364957705140114\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101735 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.021186113357543945\n",
      "Q Loss:  0.010683310218155384\n",
      "Policy Loss:  -0.008511362597346306\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101739 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.020121434703469276\n",
      "Q Loss:  0.010781864635646343\n",
      "Policy Loss:  0.030113376677036285\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101743 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  147.4635772705078\n",
      "Q Loss:  291.15045166015625\n",
      "Policy Loss:  -14.348431587219238\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101814 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00010146023851120844\n",
      "Q Loss:  0.0007102860836312175\n",
      "Policy Loss:  0.002411691937595606\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.8486425435403362e-05\n",
      "Q Loss:  0.0009754269267432392\n",
      "Policy Loss:  -0.008117743767797947\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.018175022676587105\n",
      "Q Loss:  0.009817834943532944\n",
      "Policy Loss:  0.030455803498625755\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.03536950796842575\n",
      "Q Loss:  0.002036121441051364\n",
      "Policy Loss:  0.010714799165725708\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  17766.892578125\n",
      "Q Loss:  16558.26171875\n",
      "Policy Loss:  -42.35038375854492\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101876 length: 46 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  2.6297017029719427e-05\n",
      "Q Loss:  0.00034376056282781065\n",
      "Policy Loss:  -0.0032517616637051105\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  3.2090556487673894e-05\n",
      "Q Loss:  0.00041426505777053535\n",
      "Policy Loss:  -0.008456747978925705\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101884 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.21750994771719e-05\n",
      "Q Loss:  0.00011173102393513545\n",
      "Policy Loss:  -0.005489787086844444\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05401277542114258\n",
      "Value Loss:  0.016943451017141342\n",
      "Q Loss:  0.016362661495804787\n",
      "Policy Loss:  -0.015025566332042217\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.033578746020793915\n",
      "Q Loss:  0.01282917894423008\n",
      "Policy Loss:  0.010740578174591064\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043009281158447266\n",
      "Value Loss:  3.0381228498299606e-05\n",
      "Q Loss:  7.197540253400803e-05\n",
      "Policy Loss:  0.0014542269054800272\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  6.071527968742885e-05\n",
      "Q Loss:  4.623065615305677e-05\n",
      "Policy Loss:  -0.0018995713908225298\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  4.719881690107286e-05\n",
      "Q Loss:  0.0008917394443415105\n",
      "Policy Loss:  0.01468406617641449\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013964414596557617\n",
      "Value Loss:  0.01537752989679575\n",
      "Q Loss:  0.00624992698431015\n",
      "Policy Loss:  0.03805478662252426\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.014933047816157341\n",
      "Q Loss:  0.0056955283507704735\n",
      "Policy Loss:  0.028546618297696114\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.3390954336500727e-05\n",
      "Q Loss:  0.0014916550135239959\n",
      "Policy Loss:  0.019030017778277397\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  5.736300954595208e-05\n",
      "Q Loss:  0.00012585132208187133\n",
      "Policy Loss:  0.00526104960590601\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.1699017704813741e-05\n",
      "Q Loss:  4.879786865785718e-05\n",
      "Policy Loss:  -0.0012953663244843483\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.01333729550242424\n",
      "Q Loss:  0.0034267189912497997\n",
      "Policy Loss:  0.02345179207623005\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 101932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  150.6763458251953\n",
      "Q Loss:  302.221435546875\n",
      "Policy Loss:  -14.363008499145508\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102002 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  2.2094754967838526e-06\n",
      "Q Loss:  0.00011179552529938519\n",
      "Policy Loss:  -0.005730583798140287\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102006 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.01305464468896389\n",
      "Q Loss:  0.003931472543627024\n",
      "Policy Loss:  0.008246732875704765\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102010 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.9296085834503174\n",
      "Q Loss:  12.889195442199707\n",
      "Policy Loss:  0.5480697751045227\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102109 length: 99 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  5.795586275780806e-06\n",
      "Q Loss:  5.8484514738665894e-05\n",
      "Policy Loss:  -0.005385606084018946\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102113 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  0.013505569659173489\n",
      "Q Loss:  0.004166705999523401\n",
      "Policy Loss:  0.007880810648202896\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102117 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.027185646817088127\n",
      "Q Loss:  0.005630203988403082\n",
      "Policy Loss:  -0.014335229992866516\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  0.013443970121443272\n",
      "Q Loss:  0.0019558395724743605\n",
      "Policy Loss:  -0.026968808844685555\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  321.0995788574219\n",
      "Q Loss:  592.0184936523438\n",
      "Policy Loss:  -31.144428253173828\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102223 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.033342651790008e-05\n",
      "Q Loss:  6.599845073651522e-05\n",
      "Policy Loss:  -0.002560666296631098\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.013441059738397598\n",
      "Q Loss:  0.003034062683582306\n",
      "Policy Loss:  0.011309390887618065\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  188.22927856445312\n",
      "Q Loss:  369.70977783203125\n",
      "Policy Loss:  -18.128883361816406\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102287 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.2637424485292286e-05\n",
      "Q Loss:  2.504024450900033e-05\n",
      "Policy Loss:  -0.002360190497711301\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102291 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  6.071513325878186e-06\n",
      "Q Loss:  0.0004378085723146796\n",
      "Policy Loss:  -0.007813531905412674\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102295 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033007144927978516\n",
      "Value Loss:  1.7895565633807564e-06\n",
      "Q Loss:  1.6073101505753584e-05\n",
      "Policy Loss:  0.002098755445331335\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.7503036260604858\n",
      "Q Loss:  0.003816257929429412\n",
      "Policy Loss:  0.10150798410177231\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102421 length: 122 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.3024661711824592e-05\n",
      "Q Loss:  1270.98681640625\n",
      "Policy Loss:  3.5846197605133057\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2607.072265625\n",
      "Q Loss:  5272.90087890625\n",
      "Policy Loss:  -137.67977905273438\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102429 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  4.532600996753899e-06\n",
      "Q Loss:  5.9346020861994475e-05\n",
      "Policy Loss:  -8.17393884062767e-05\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  9.077904223886435e-07\n",
      "Q Loss:  0.00045873725321143866\n",
      "Policy Loss:  0.004312196746468544\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102437 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00022634615015704185\n",
      "Q Loss:  0.00021763273980468512\n",
      "Policy Loss:  0.00986536219716072\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  6.878195563331246e-05\n",
      "Q Loss:  0.00016184613923542202\n",
      "Policy Loss:  0.003893978428095579\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  2577.392578125\n",
      "Q Loss:  6341.443359375\n",
      "Policy Loss:  -136.4175262451172\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.4871502521127695e-06\n",
      "Q Loss:  217.56500244140625\n",
      "Policy Loss:  7.239045143127441\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.7461312609157176e-06\n",
      "Q Loss:  6.18350095464848e-05\n",
      "Policy Loss:  -0.003851344808936119\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.4972018763946835e-06\n",
      "Q Loss:  0.00030116134439595044\n",
      "Policy Loss:  0.0053646801970899105\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010999679565429688\n",
      "Value Loss:  4.161203833064064e-06\n",
      "Q Loss:  0.0008265476208180189\n",
      "Policy Loss:  0.013644702732563019\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102465 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  1.486678775108885e-05\n",
      "Q Loss:  0.00014043724513612688\n",
      "Policy Loss:  -0.002288633491843939\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102469 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03388381004333496\n",
      "Value Loss:  3.7748093291156692e-06\n",
      "Q Loss:  1206.2464599609375\n",
      "Policy Loss:  3.633399724960327\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06001448631286621\n",
      "Value Loss:  13133.775390625\n",
      "Q Loss:  12021.5927734375\n",
      "Policy Loss:  -25.228113174438477\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102597 length: 124 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  20358.802734375\n",
      "Q Loss:  18831.333984375\n",
      "Policy Loss:  -36.30326461791992\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102677 length: 80 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012013912200927734\n",
      "Value Loss:  0.02303497865796089\n",
      "Q Loss:  0.010483446530997753\n",
      "Policy Loss:  0.03226706013083458\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102681 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  10933.892578125\n",
      "Q Loss:  10004.537109375\n",
      "Policy Loss:  -13.864226341247559\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102755 length: 74 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0710710883140564\n",
      "Q Loss:  0.01955646276473999\n",
      "Policy Loss:  0.025338169187307358\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0937480553984642\n",
      "Q Loss:  3.796274904743768e-05\n",
      "Policy Loss:  -0.01686105877161026\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.08967184275388718\n",
      "Q Loss:  0.01968664862215519\n",
      "Policy Loss:  -0.015512648038566113\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.020782144740223885\n",
      "Q Loss:  0.022810351103544235\n",
      "Policy Loss:  0.06715553998947144\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.403630999964662e-06\n",
      "Q Loss:  0.0017939773388206959\n",
      "Policy Loss:  0.017504878342151642\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.5784440115094185e-05\n",
      "Q Loss:  0.010253168642520905\n",
      "Policy Loss:  0.05613812804222107\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102779 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.04971633478999138\n",
      "Q Loss:  0.012651697732508183\n",
      "Policy Loss:  0.020253505557775497\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.045303214341402054\n",
      "Q Loss:  0.010744065977633\n",
      "Policy Loss:  0.014914286322891712\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  181.4821319580078\n",
      "Q Loss:  352.812255859375\n",
      "Policy Loss:  -17.636335372924805\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102844 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00022244492720346898\n",
      "Q Loss:  0.0003863199381157756\n",
      "Policy Loss:  -0.01207250077277422\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03392314910888672\n",
      "Value Loss:  0.00021769855811726302\n",
      "Q Loss:  0.0001469938870286569\n",
      "Policy Loss:  -0.0060782162472605705\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.805892240256071e-05\n",
      "Q Loss:  0.0007741154986433685\n",
      "Policy Loss:  -0.004778413102030754\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.109263045393163e-06\n",
      "Q Loss:  0.000295409990940243\n",
      "Policy Loss:  0.006417884957045317\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  6.347751423163572e-06\n",
      "Q Loss:  0.0010043068323284388\n",
      "Policy Loss:  -0.005183578468859196\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.2265376173891127e-05\n",
      "Q Loss:  0.007531215436756611\n",
      "Policy Loss:  0.0014392745215445757\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.009753881953656673\n",
      "Q Loss:  0.0026516655925661325\n",
      "Policy Loss:  -0.03840984031558037\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102872 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.1321699225372868e-06\n",
      "Q Loss:  0.0008756848983466625\n",
      "Policy Loss:  -0.009134304709732533\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102876 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.6551221000991063e-06\n",
      "Q Loss:  1.0705836757551879e-05\n",
      "Policy Loss:  -0.001947782700881362\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  9862.33203125\n",
      "Q Loss:  9561.734375\n",
      "Policy Loss:  -45.943416595458984\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102965 length: 85 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.0009622721699997783\n",
      "Q Loss:  0.0002834921469911933\n",
      "Policy Loss:  0.0035255684051662683\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0007940179202705622\n",
      "Q Loss:  0.000437328388215974\n",
      "Policy Loss:  -0.0055043636821210384\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.976561366580427e-05\n",
      "Q Loss:  0.0008804477984085679\n",
      "Policy Loss:  -0.015824884176254272\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030303955078125\n",
      "Value Loss:  0.0002479072427377105\n",
      "Q Loss:  0.0005655898712575436\n",
      "Policy Loss:  -0.016752157360315323\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  0.0005431324243545532\n",
      "Q Loss:  0.0006796302041038871\n",
      "Policy Loss:  -0.01202511414885521\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.811439329292625e-05\n",
      "Q Loss:  1.7520107576274313e-05\n",
      "Policy Loss:  0.0058455634862184525\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  4.744530451716855e-05\n",
      "Q Loss:  0.0021784561686217785\n",
      "Policy Loss:  0.017715923488140106\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 102993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.3237405255495105e-05\n",
      "Q Loss:  0.003171057440340519\n",
      "Policy Loss:  0.026831895112991333\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 102997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.008612953126430511\n",
      "Q Loss:  0.007834909483790398\n",
      "Policy Loss:  0.017509352415800095\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 103001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8694.025390625\n",
      "Q Loss:  8121.39599609375\n",
      "Policy Loss:  -21.82045555114746\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103095 length: 94 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.212876796722412\n",
      "Q Loss:  0.005336039233952761\n",
      "Policy Loss:  0.15572260320186615\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103172 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  5190.00732421875\n",
      "Q Loss:  11212.81640625\n",
      "Policy Loss:  -90.48605346679688\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103176 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.00018710170115809888\n",
      "Q Loss:  360.98358154296875\n",
      "Policy Loss:  11.390106201171875\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103180 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.00035860438947565854\n",
      "Q Loss:  0.0005930177867412567\n",
      "Policy Loss:  0.011591020971536636\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00047549407463520765\n",
      "Q Loss:  0.001965153496712446\n",
      "Policy Loss:  0.02151988446712494\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00012708123540505767\n",
      "Q Loss:  0.0008027115254662931\n",
      "Policy Loss:  0.009132354520261288\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.648702739970759e-05\n",
      "Q Loss:  0.002739342860877514\n",
      "Policy Loss:  -0.01336752064526081\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001579505915287882\n",
      "Q Loss:  0.005172036588191986\n",
      "Policy Loss:  -0.03408662974834442\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.024198157712817192\n",
      "Q Loss:  0.013096548616886139\n",
      "Policy Loss:  -0.031676579266786575\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 103204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.02436378039419651\n",
      "Q Loss:  0.006095225922763348\n",
      "Policy Loss:  -0.05522556230425835\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103208 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  5.689478712156415e-05\n",
      "Q Loss:  0.0017121194396167994\n",
      "Policy Loss:  -0.011928243562579155\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103212 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  5.497267557075247e-05\n",
      "Q Loss:  0.0001853147114161402\n",
      "Policy Loss:  0.004072158131748438\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103216 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400090217590332\n",
      "Value Loss:  0.011730018071830273\n",
      "Q Loss:  0.001738677965477109\n",
      "Policy Loss:  0.011292759329080582\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103220 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.023015284910798073\n",
      "Q Loss:  0.01397827360779047\n",
      "Policy Loss:  -0.031369730830192566\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  175.02749633789062\n",
      "Q Loss:  327.6723327636719\n",
      "Policy Loss:  -17.522171020507812\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103282 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.04539678990840912\n",
      "Q Loss:  0.00883154571056366\n",
      "Policy Loss:  -0.06276711821556091\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103286 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.022418906912207603\n",
      "Q Loss:  0.005543470848351717\n",
      "Policy Loss:  0.04329058900475502\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103290 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  1.5344539880752563\n",
      "Q Loss:  39.35002136230469\n",
      "Policy Loss:  1.478615164756775\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103350 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.011122923344373703\n",
      "Q Loss:  0.011688636615872383\n",
      "Policy Loss:  0.014848386868834496\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103354 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  4.7998524678405374e-05\n",
      "Q Loss:  0.0016507291002199054\n",
      "Policy Loss:  0.022815614938735962\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103358 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1.7073309421539307\n",
      "Q Loss:  0.0014878385700285435\n",
      "Policy Loss:  0.24967196583747864\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103412 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0010131157469004393\n",
      "Q Loss:  0.00018788731540553272\n",
      "Policy Loss:  -0.009534096345305443\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.048010826110839844\n",
      "Value Loss:  0.00010628731979522854\n",
      "Q Loss:  0.00015520687156822532\n",
      "Policy Loss:  0.006833351217210293\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0006856827531009912\n",
      "Q Loss:  0.00042663695057854056\n",
      "Policy Loss:  -0.004723159596323967\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016459226608276367\n",
      "Value Loss:  0.013812740333378315\n",
      "Q Loss:  0.007626964710652828\n",
      "Policy Loss:  0.008691621944308281\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.04231100156903267\n",
      "Q Loss:  0.008115086704492569\n",
      "Policy Loss:  -0.025847185403108597\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  6.228424899745733e-05\n",
      "Q Loss:  0.0017141097923740745\n",
      "Policy Loss:  0.02225641906261444\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.028029493987560272\n",
      "Q Loss:  0.0015863419976085424\n",
      "Policy Loss:  0.02303045243024826\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.054852195084095\n",
      "Q Loss:  0.0009999286849051714\n",
      "Policy Loss:  -0.03383435308933258\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.03894217312335968\n",
      "Q Loss:  0.008696343749761581\n",
      "Policy Loss:  0.016748134046792984\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  22174.78515625\n",
      "Q Loss:  20799.298828125\n",
      "Policy Loss:  -49.105403900146484\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103485 length: 37 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.00024690525606274605\n",
      "Q Loss:  0.00121032795868814\n",
      "Policy Loss:  -0.0012277960777282715\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  0.0008042418048717082\n",
      "Q Loss:  0.000698738032951951\n",
      "Policy Loss:  0.014299770817160606\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  12616.3857421875\n",
      "Q Loss:  11827.818359375\n",
      "Policy Loss:  -29.84592056274414\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103558 length: 65 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  7.720506255282089e-05\n",
      "Q Loss:  0.00055306451395154\n",
      "Policy Loss:  0.011973029002547264\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103562 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  7.978153735166416e-05\n",
      "Q Loss:  0.00012020855501759797\n",
      "Policy Loss:  -0.0004932746523991227\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103566 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.729554691744852e-06\n",
      "Q Loss:  5.959075133432634e-05\n",
      "Policy Loss:  -0.0006068749935366213\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103570 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  7.300529978238046e-05\n",
      "Q Loss:  9.063535981113091e-05\n",
      "Policy Loss:  -0.0032040076330304146\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103574 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.7427555323811248e-05\n",
      "Q Loss:  0.0003769146860577166\n",
      "Policy Loss:  -0.010871844366192818\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103578 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  4.339488077675924e-05\n",
      "Q Loss:  0.00012013810919597745\n",
      "Policy Loss:  -0.0054823593236505985\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.112253034487367e-05\n",
      "Q Loss:  2.7575058993534185e-05\n",
      "Policy Loss:  0.005585383623838425\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  8.788946615823079e-06\n",
      "Q Loss:  1.2238421732035931e-05\n",
      "Policy Loss:  0.005302033852785826\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103590 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.606065421190578e-06\n",
      "Q Loss:  0.00023673604300711304\n",
      "Policy Loss:  -0.007684839889407158\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.0051402568933554e-05\n",
      "Q Loss:  0.00033258850453421474\n",
      "Policy Loss:  -0.0014634307008236647\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002079252153635025\n",
      "Q Loss:  0.00023874553153291345\n",
      "Policy Loss:  0.00958256609737873\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  3.912130341632292e-05\n",
      "Q Loss:  0.0001021748612402007\n",
      "Policy Loss:  0.033419907093048096\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.02588742785155773\n",
      "Q Loss:  0.007749314419925213\n",
      "Policy Loss:  -0.019080307334661484\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.025491435080766678\n",
      "Q Loss:  0.007128019351512194\n",
      "Policy Loss:  0.009117379784584045\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.0444942492758855e-05\n",
      "Q Loss:  1.382561777063529e-06\n",
      "Policy Loss:  -0.003102918155491352\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.242129297286738e-06\n",
      "Q Loss:  4.891886419500224e-05\n",
      "Policy Loss:  -0.00274486537091434\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07401728630065918\n",
      "Value Loss:  0.023434780538082123\n",
      "Q Loss:  0.0013274815864861012\n",
      "Policy Loss:  0.003942318260669708\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  0.033717405050992966\n",
      "Q Loss:  0.005330123007297516\n",
      "Policy Loss:  -0.004573246464133263\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  2.5592854022979736\n",
      "Q Loss:  0.0007916577160358429\n",
      "Policy Loss:  0.3676318824291229\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103666 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.180233241233509e-05\n",
      "Q Loss:  7.675237429793924e-05\n",
      "Policy Loss:  0.0009292386239394546\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103670 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  154.449951171875\n",
      "Q Loss:  323.8479309082031\n",
      "Policy Loss:  -15.463581085205078\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103803 length: 133 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00011338383774273098\n",
      "Q Loss:  0.0001569305022712797\n",
      "Policy Loss:  0.02582097426056862\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.7121084332466125\n",
      "Q Loss:  0.0031191310845315456\n",
      "Policy Loss:  0.09587904810905457\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103937 length: 130 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00018563677440397441\n",
      "Q Loss:  0.0005657423753291368\n",
      "Policy Loss:  -0.00952039286494255\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103941 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.779372779419646e-05\n",
      "Q Loss:  2.826255513355136e-05\n",
      "Policy Loss:  0.0022460627369582653\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103945 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  2.6556177544989623e-05\n",
      "Q Loss:  6.382880383171141e-05\n",
      "Policy Loss:  0.003265569219365716\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103949 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05201220512390137\n",
      "Value Loss:  2.158385996153811e-06\n",
      "Q Loss:  0.0001905481331050396\n",
      "Policy Loss:  0.0054728928953409195\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103953 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100539207458496\n",
      "Value Loss:  4.0293325582752004e-05\n",
      "Q Loss:  0.00017381241195835173\n",
      "Policy Loss:  0.006115668453276157\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018002986907958984\n",
      "Value Loss:  0.0001275264221476391\n",
      "Q Loss:  0.000115448739961721\n",
      "Policy Loss:  -0.004358742851763964\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00013480322377290577\n",
      "Q Loss:  0.00023114362556952983\n",
      "Policy Loss:  0.03921443969011307\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06307826191186905\n",
      "Q Loss:  0.009037325158715248\n",
      "Policy Loss:  -0.07576777040958405\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0465497225522995\n",
      "Q Loss:  0.008998122066259384\n",
      "Policy Loss:  -0.010303938761353493\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 103973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.7272453308105469\n",
      "Q Loss:  22.371437072753906\n",
      "Policy Loss:  0.8271574974060059\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104099 length: 126 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.000276856153504923\n",
      "Q Loss:  0.0004113744362257421\n",
      "Policy Loss:  0.0012424883898347616\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.12402844429016113\n",
      "Value Loss:  0.00017773304716683924\n",
      "Q Loss:  0.0005801618681289256\n",
      "Policy Loss:  0.0075228773057460785\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0003659992653410882\n",
      "Q Loss:  0.001291083637624979\n",
      "Policy Loss:  0.023479292169213295\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00022055396402720362\n",
      "Q Loss:  0.0003670636797323823\n",
      "Policy Loss:  0.00803923700004816\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104115 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  1.347391662420705e-05\n",
      "Q Loss:  0.000637821271084249\n",
      "Policy Loss:  0.01177870575338602\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104119 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  4.435784006773247e-08\n",
      "Q Loss:  0.0005009400192648172\n",
      "Policy Loss:  0.008290407247841358\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.3243861198425293\n",
      "Q Loss:  0.0019452119013294578\n",
      "Policy Loss:  0.18450213968753815\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104192 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  5112.45068359375\n",
      "Q Loss:  10867.8271484375\n",
      "Policy Loss:  -93.77249908447266\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5086.39501953125\n",
      "Q Loss:  11858.3955078125\n",
      "Policy Loss:  -92.62979125976562\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  6.40928874418023e-08\n",
      "Q Loss:  239.08779907226562\n",
      "Policy Loss:  7.612499237060547\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.209370283409953e-05\n",
      "Q Loss:  0.0005329654086381197\n",
      "Policy Loss:  -0.016378208994865417\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104208 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.976802978897467e-05\n",
      "Q Loss:  0.0006144406506791711\n",
      "Policy Loss:  0.008508186787366867\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 104212 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.028006315231323242\n",
      "Value Loss:  0.0010217245435342193\n",
      "Q Loss:  0.0010654786601662636\n",
      "Policy Loss:  -0.0024661393836140633\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104216 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006004333496094\n",
      "Value Loss:  0.0017794826999306679\n",
      "Q Loss:  0.000703799189068377\n",
      "Policy Loss:  -0.0005897290538996458\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104220 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0008074482902884483\n",
      "Q Loss:  0.0024386104196310043\n",
      "Policy Loss:  0.028628956526517868\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00019380694720894098\n",
      "Q Loss:  0.002398774493485689\n",
      "Policy Loss:  0.030900990590453148\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104228 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0332985520362854\n",
      "Q Loss:  0.03179369121789932\n",
      "Policy Loss:  0.0730648785829544\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104232 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.016977794468402863\n",
      "Q Loss:  0.004719964228570461\n",
      "Policy Loss:  0.07294616103172302\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104236 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.04882584512233734\n",
      "Q Loss:  0.03303384780883789\n",
      "Policy Loss:  0.06781534850597382\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104240 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.046957824379205704\n",
      "Q Loss:  0.02870158478617668\n",
      "Policy Loss:  0.05463261902332306\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.05856891721487045\n",
      "Q Loss:  0.002896783174946904\n",
      "Policy Loss:  -0.004543473944067955\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104248 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.05318279191851616\n",
      "Q Loss:  0.0172735583037138\n",
      "Policy Loss:  -0.024851534515619278\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104252 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  12686.216796875\n",
      "Q Loss:  11947.435546875\n",
      "Policy Loss:  -28.17169189453125\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104317 length: 65 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0510101318359375\n",
      "Value Loss:  0.012085936963558197\n",
      "Q Loss:  0.0028161793015897274\n",
      "Policy Loss:  0.032931841909885406\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.030251942574977875\n",
      "Q Loss:  0.0037726096343249083\n",
      "Policy Loss:  -0.013324160128831863\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.0021754503250122\n",
      "Q Loss:  5.630800724029541\n",
      "Policy Loss:  0.28947383165359497\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104418 length: 93 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.9574948207009584e-05\n",
      "Q Loss:  0.010192093439400196\n",
      "Policy Loss:  -0.04244052618741989\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.00023809584672562778\n",
      "Q Loss:  2.3384494852507487e-05\n",
      "Policy Loss:  -0.003613388165831566\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700638771057129\n",
      "Value Loss:  0.0002516438253223896\n",
      "Q Loss:  9.62881968007423e-05\n",
      "Policy Loss:  -0.00283733569085598\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 104430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05501127243041992\n",
      "Value Loss:  0.006604840978980064\n",
      "Q Loss:  0.018672319129109383\n",
      "Policy Loss:  -0.038857996463775635\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 104434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.007170807104557753\n",
      "Q Loss:  0.01813872531056404\n",
      "Policy Loss:  -0.10469061136245728\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.006707749795168638\n",
      "Q Loss:  0.005425083450973034\n",
      "Policy Loss:  0.005207398906350136\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.025483492761850357\n",
      "Q Loss:  0.01797371357679367\n",
      "Policy Loss:  -0.10992785543203354\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004634857177734\n",
      "Value Loss:  0.005300776567310095\n",
      "Q Loss:  0.014104923233389854\n",
      "Policy Loss:  -0.021563241258263588\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104450 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600811958312988\n",
      "Value Loss:  2.102818489074707\n",
      "Q Loss:  0.007447595242410898\n",
      "Policy Loss:  0.2671114206314087\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104495 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.002221460686996579\n",
      "Q Loss:  0.006582777015864849\n",
      "Policy Loss:  0.02667413279414177\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015005826950073242\n",
      "Value Loss:  0.001262142090126872\n",
      "Q Loss:  0.0004355673445388675\n",
      "Policy Loss:  0.0066171856597065926\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0004978427896276116\n",
      "Q Loss:  0.0010120561346411705\n",
      "Policy Loss:  0.02146964892745018\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 104507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.011444663628935814\n",
      "Q Loss:  0.0030006919987499714\n",
      "Policy Loss:  0.009358810260891914\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.005632732529193163\n",
      "Q Loss:  0.00750684691593051\n",
      "Policy Loss:  0.04240437597036362\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.003728287760168314\n",
      "Q Loss:  0.006814324762672186\n",
      "Policy Loss:  0.05035480111837387\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.002508867299184203\n",
      "Q Loss:  0.004560031462460756\n",
      "Policy Loss:  0.02122245356440544\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0020997002720832825\n",
      "Q Loss:  0.007061311509460211\n",
      "Policy Loss:  0.038659874349832535\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0012536324793472886\n",
      "Q Loss:  0.0012003948213532567\n",
      "Policy Loss:  -0.023667970672249794\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  0.0002998063573613763\n",
      "Q Loss:  0.0034561592619866133\n",
      "Policy Loss:  -0.035002700984478\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.011051314882934093\n",
      "Q Loss:  0.003997244406491518\n",
      "Policy Loss:  -0.004958778619766235\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005319595336914\n",
      "Value Loss:  0.0013463645009323955\n",
      "Q Loss:  0.005167907103896141\n",
      "Policy Loss:  0.03352651000022888\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  0.0006431819056160748\n",
      "Q Loss:  0.005347432103008032\n",
      "Policy Loss:  0.03452957421541214\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  0.005105680786073208\n",
      "Q Loss:  0.003395689884200692\n",
      "Policy Loss:  0.00841570645570755\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  0.008897630497813225\n",
      "Q Loss:  0.007871363312005997\n",
      "Policy Loss:  -0.053780294954776764\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.002068753819912672\n",
      "Q Loss:  0.0011153395753353834\n",
      "Policy Loss:  -0.03544814884662628\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0026909448206424713\n",
      "Q Loss:  0.002363574458286166\n",
      "Policy Loss:  -0.03411022946238518\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104563 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0011251970427110791\n",
      "Q Loss:  0.0013567903079092503\n",
      "Policy Loss:  -0.026171164587140083\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104567 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003594967711251229\n",
      "Q Loss:  0.0009428246412426233\n",
      "Policy Loss:  -0.01083219051361084\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104571 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.008411592803895473\n",
      "Q Loss:  0.005657637026160955\n",
      "Policy Loss:  -0.02967037260532379\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.007922765798866749\n",
      "Q Loss:  0.0052123405039310455\n",
      "Policy Loss:  -0.01848129741847515\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104579 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.01116552110761404\n",
      "Q Loss:  0.0025380158331245184\n",
      "Policy Loss:  -0.007032536901533604\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700638771057129\n",
      "Value Loss:  0.006969741079956293\n",
      "Q Loss:  0.0027777226641774178\n",
      "Policy Loss:  -0.0004748683422803879\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  209.51351928710938\n",
      "Q Loss:  485.0491943359375\n",
      "Policy Loss:  -20.61924934387207\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 104632 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02800583839416504\n",
      "Value Loss:  4664.736328125\n",
      "Q Loss:  10631.9345703125\n",
      "Policy Loss:  -84.38897705078125\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 104636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  13171.9697265625\n",
      "Q Loss:  12184.3701171875\n",
      "Policy Loss:  -15.796960830688477\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 104698 length: 62 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.008344477973878384\n",
      "Q Loss:  0.003272449830546975\n",
      "Policy Loss:  0.04933856055140495\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 104702 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.004808272235095501\n",
      "Q Loss:  0.008095849305391312\n",
      "Policy Loss:  0.07114790380001068\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 104706 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.018171366304159164\n",
      "Q Loss:  0.0002643713087309152\n",
      "Policy Loss:  0.007116126827895641\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 104710 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.014110442250967026\n",
      "Q Loss:  0.0061864391900599\n",
      "Policy Loss:  0.02403346076607704\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 104714 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.018787359818816185\n",
      "Q Loss:  0.0007442334899678826\n",
      "Policy Loss:  0.00801435112953186\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104718 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  4778.443359375\n",
      "Q Loss:  4609.53369140625\n",
      "Policy Loss:  -15.606667518615723\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104893 length: 175 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.027005910873413086\n",
      "Value Loss:  0.00017605263565201312\n",
      "Q Loss:  0.00551697239279747\n",
      "Policy Loss:  0.014356368221342564\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0002143462043022737\n",
      "Q Loss:  0.003359904745593667\n",
      "Policy Loss:  0.025736650452017784\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00033113593235611916\n",
      "Q Loss:  0.0027857059612870216\n",
      "Policy Loss:  0.03272542357444763\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.01715993322432041\n",
      "Q Loss:  0.003672264749184251\n",
      "Policy Loss:  -0.0056224362924695015\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.0008269579266197979\n",
      "Q Loss:  0.003620457835495472\n",
      "Policy Loss:  0.021952707320451736\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104913 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.0015196753665804863\n",
      "Q Loss:  0.0023745642974972725\n",
      "Policy Loss:  0.0009368434548377991\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001016616821289\n",
      "Value Loss:  10866.1220703125\n",
      "Q Loss:  10397.5068359375\n",
      "Policy Loss:  -35.50019836425781\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104994 length: 77 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.007571665104478598\n",
      "Q Loss:  0.004359537735581398\n",
      "Policy Loss:  0.011170700192451477\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 104998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  148.15318298339844\n",
      "Q Loss:  268.55865478515625\n",
      "Policy Loss:  -15.619853019714355\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105060 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05501198768615723\n",
      "Value Loss:  2272.678955078125\n",
      "Q Loss:  4160.9990234375\n",
      "Policy Loss:  -164.46566772460938\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105064 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002299455227330327\n",
      "Q Loss:  0.0014984442386776209\n",
      "Policy Loss:  0.011603932827711105\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105068 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001986369607038796\n",
      "Q Loss:  0.001678122440353036\n",
      "Policy Loss:  0.015545817092061043\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105072 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.0001217330209328793\n",
      "Q Loss:  0.001517595606856048\n",
      "Policy Loss:  -0.022911913692951202\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00019164240802638233\n",
      "Q Loss:  0.0019885930232703686\n",
      "Policy Loss:  -0.018378350883722305\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.005538469180464745\n",
      "Q Loss:  0.0023944370914250612\n",
      "Policy Loss:  0.006549885496497154\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  110.91034698486328\n",
      "Q Loss:  238.80722045898438\n",
      "Policy Loss:  -11.383642196655273\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105247 length: 163 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  6.889618816785514e-05\n",
      "Q Loss:  0.0003447741037234664\n",
      "Policy Loss:  -0.007807976566255093\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 105251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  7.998273940756917e-05\n",
      "Q Loss:  0.0006950983661226928\n",
      "Policy Loss:  -0.014306087978184223\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 105255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01681971549987793\n",
      "Value Loss:  8.960833656601608e-05\n",
      "Q Loss:  0.0002917626698035747\n",
      "Policy Loss:  0.0024761492386460304\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 105259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.102706877049059e-05\n",
      "Q Loss:  0.0009037228301167488\n",
      "Policy Loss:  0.022810660302639008\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 105263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.013860036619007587\n",
      "Q Loss:  0.003342075040563941\n",
      "Policy Loss:  -0.046673428267240524\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 105267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00016098670312203467\n",
      "Q Loss:  6.1425642343238e-05\n",
      "Policy Loss:  0.004580956883728504\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 105271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  8.228772639995441e-05\n",
      "Q Loss:  6.928532820893452e-05\n",
      "Policy Loss:  0.0008773873560130596\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.007166482973843813\n",
      "Q Loss:  0.0028182007372379303\n",
      "Policy Loss:  0.0022086557000875473\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  1.2835547924041748\n",
      "Q Loss:  0.0028878143057227135\n",
      "Policy Loss:  0.17004208266735077\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105352 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00010789191583171487\n",
      "Q Loss:  0.0008309598197229207\n",
      "Policy Loss:  -0.01299315132200718\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013605833053588867\n",
      "Value Loss:  7.555208867415786e-05\n",
      "Q Loss:  0.001678986707702279\n",
      "Policy Loss:  0.0396861806511879\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.016313109546899796\n",
      "Q Loss:  0.00278395414352417\n",
      "Policy Loss:  -0.011152846738696098\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.008544840849936008\n",
      "Q Loss:  0.0014220436569303274\n",
      "Policy Loss:  0.002287045121192932\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020005464553833008\n",
      "Value Loss:  0.01664555072784424\n",
      "Q Loss:  0.004072459414601326\n",
      "Policy Loss:  -0.0052675288170576096\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105372 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  6669.7783203125\n",
      "Q Loss:  6197.498046875\n",
      "Policy Loss:  -7.769413948059082\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105495 length: 123 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  5.068986502010375e-05\n",
      "Q Loss:  0.00046849314821884036\n",
      "Policy Loss:  -0.005585086066275835\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.2329589885193855e-05\n",
      "Q Loss:  0.0002832076861523092\n",
      "Policy Loss:  -0.003624191740527749\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  8.574959792895243e-06\n",
      "Q Loss:  0.0002841711975634098\n",
      "Policy Loss:  0.007848701439797878\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.3705040803179145e-05\n",
      "Q Loss:  8.594286919105798e-05\n",
      "Policy Loss:  0.005857657641172409\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.855127811722923e-05\n",
      "Q Loss:  0.0002537278924137354\n",
      "Policy Loss:  0.008988293819129467\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 105515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.016817312687635422\n",
      "Q Loss:  0.002534475177526474\n",
      "Policy Loss:  0.008345263078808784\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 105519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1.1841791868209839\n",
      "Q Loss:  0.003289898857474327\n",
      "Policy Loss:  0.1780262440443039\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 105598 length: 79 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00011480404646135867\n",
      "Q Loss:  0.0006869699573144317\n",
      "Policy Loss:  0.007648932747542858\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 105602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  0.0001533398317405954\n",
      "Q Loss:  913.8051147460938\n",
      "Policy Loss:  4.296350479125977\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  5757.55810546875\n",
      "Q Loss:  5456.10498046875\n",
      "Policy Loss:  -12.34225845336914\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105750 length: 144 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  17271.6171875\n",
      "Q Loss:  16279.50390625\n",
      "Policy Loss:  -38.30036163330078\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 105798 length: 48 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  3.399516936042346e-05\n",
      "Q Loss:  0.0005892951739951968\n",
      "Policy Loss:  -0.00909293070435524\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08801960945129395\n",
      "Value Loss:  4.7648507461417466e-05\n",
      "Q Loss:  0.0012531145475804806\n",
      "Policy Loss:  0.011153924278914928\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00013171060709282756\n",
      "Q Loss:  0.0011447201250120997\n",
      "Policy Loss:  0.010365407913923264\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  4.9847526497615036e-06\n",
      "Q Loss:  0.0017135798698291183\n",
      "Policy Loss:  0.014779915101826191\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.024921273812651634\n",
      "Q Loss:  0.008644131943583488\n",
      "Policy Loss:  0.04939598590135574\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.012750285677611828\n",
      "Q Loss:  0.013617638498544693\n",
      "Policy Loss:  0.027212349697947502\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.3877588510513306\n",
      "Q Loss:  0.0030259755440056324\n",
      "Policy Loss:  0.2177465409040451\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105888 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01059865951538086\n",
      "Value Loss:  0.0005782905500382185\n",
      "Q Loss:  0.00020252572721801698\n",
      "Policy Loss:  -0.009004702791571617\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00012298084038775414\n",
      "Q Loss:  0.001022865530103445\n",
      "Policy Loss:  0.013509106822311878\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001503753155702725\n",
      "Q Loss:  0.0005266675143502653\n",
      "Policy Loss:  0.004078851081430912\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 105900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  77.5140380859375\n",
      "Q Loss:  180.64141845703125\n",
      "Policy Loss:  -7.78992223739624\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106018 length: 118 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  1.2346255061856937e-05\n",
      "Q Loss:  0.0004996773786842823\n",
      "Policy Loss:  0.0353107750415802\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106022 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.06737915426492691\n",
      "Q Loss:  0.011818969622254372\n",
      "Policy Loss:  -0.08460064232349396\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106026 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  9.277680874220096e-06\n",
      "Q Loss:  7.688133337069303e-05\n",
      "Policy Loss:  -0.006135042291134596\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106030 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200603485107422\n",
      "Value Loss:  1.752587741066236e-05\n",
      "Q Loss:  7.498826562368777e-06\n",
      "Policy Loss:  -0.0002461604308336973\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.017111143097281456\n",
      "Q Loss:  0.005191051866859198\n",
      "Policy Loss:  0.012945227324962616\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.05107898637652397\n",
      "Q Loss:  0.022796599194407463\n",
      "Policy Loss:  -0.060201145708560944\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.01650328002870083\n",
      "Q Loss:  0.005305250640958548\n",
      "Policy Loss:  -0.017254505306482315\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  4.064240420120768e-05\n",
      "Q Loss:  3.5482145904097706e-05\n",
      "Policy Loss:  0.004592898767441511\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  5.565210813074373e-05\n",
      "Q Loss:  0.00011588458437472582\n",
      "Policy Loss:  0.008740503340959549\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  8.123843872454017e-05\n",
      "Q Loss:  9.285750275012106e-05\n",
      "Policy Loss:  0.002693197689950466\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.6929275665897876e-05\n",
      "Q Loss:  0.00017673851107247174\n",
      "Policy Loss:  0.003494137665256858\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  4.247347078489838e-06\n",
      "Q Loss:  0.00020926326396875083\n",
      "Policy Loss:  0.0019229600438848138\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.581370265237638e-06\n",
      "Q Loss:  0.000329978036461398\n",
      "Policy Loss:  0.007030175067484379\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  2.13398761843564e-05\n",
      "Q Loss:  0.0002704626531340182\n",
      "Policy Loss:  0.005814713891595602\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.964709190360736e-05\n",
      "Q Loss:  0.00035286511410959065\n",
      "Policy Loss:  0.008579529821872711\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  6.586085987692059e-07\n",
      "Q Loss:  0.0006412889342755079\n",
      "Policy Loss:  0.0478384830057621\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106082 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  241.5817413330078\n",
      "Q Loss:  549.491943359375\n",
      "Policy Loss:  -24.302335739135742\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106233 length: 151 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.0024645987432450056\n",
      "Q Loss:  0.0012613104190677404\n",
      "Policy Loss:  -0.015899885445833206\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.00011836701742140576\n",
      "Q Loss:  1.7930706235347316e-05\n",
      "Policy Loss:  -0.002211092971265316\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  6.607818068005145e-05\n",
      "Q Loss:  5.165543552720919e-05\n",
      "Policy Loss:  -0.003311114851385355\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5.972801773168612e-06\n",
      "Q Loss:  0.0002035388897638768\n",
      "Policy Loss:  0.035229310393333435\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  3.3900773525238037\n",
      "Q Loss:  0.0022084335796535015\n",
      "Policy Loss:  0.4916391968727112\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106276 length: 27 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  0.05706457793712616\n",
      "Q Loss:  0.004393088631331921\n",
      "Policy Loss:  -0.0559970960021019\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002685546875\n",
      "Value Loss:  0.06005106493830681\n",
      "Q Loss:  0.009080753661692142\n",
      "Policy Loss:  -0.0503457672894001\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 106284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.01515731681138277\n",
      "Q Loss:  0.020924367010593414\n",
      "Policy Loss:  -0.011732240207493305\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  1.0671128034591675\n",
      "Q Loss:  7.498717784881592\n",
      "Policy Loss:  0.3565778434276581\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106373 length: 85 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.037009239196777344\n",
      "Value Loss:  0.00023279119341168553\n",
      "Q Loss:  915.5768432617188\n",
      "Policy Loss:  4.422709941864014\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  4540.87646484375\n",
      "Q Loss:  9266.5625\n",
      "Policy Loss:  -79.84033203125\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106381 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  3.0244271329138428e-05\n",
      "Q Loss:  323.4881286621094\n",
      "Policy Loss:  8.847856521606445\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106385 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.350219220825238e-06\n",
      "Q Loss:  1.14185450001969e-05\n",
      "Policy Loss:  0.00048715074080973864\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106389 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  6.95685448590666e-05\n",
      "Q Loss:  2.7660025807563215e-06\n",
      "Policy Loss:  -0.0013504769885912538\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4464.70166015625\n",
      "Q Loss:  9806.00390625\n",
      "Policy Loss:  -77.71519470214844\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2214.765380859375\n",
      "Q Loss:  5018.12060546875\n",
      "Policy Loss:  -118.81246948242188\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  2.871170909202192e-05\n",
      "Q Loss:  0.0010619375389069319\n",
      "Policy Loss:  -0.015567013062536716\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01950836181640625\n",
      "Value Loss:  3.1702362321084365e-05\n",
      "Q Loss:  7.738371641607955e-05\n",
      "Policy Loss:  0.0035334399435669184\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106409 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00017386823310516775\n",
      "Q Loss:  0.00012092845281586051\n",
      "Policy Loss:  0.010086944326758385\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106413 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.00018275385082233697\n",
      "Q Loss:  0.0023407298140227795\n",
      "Policy Loss:  0.0198263768106699\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.00012018217239528894\n",
      "Q Loss:  0.0019579422660171986\n",
      "Policy Loss:  0.014477918855845928\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.01948089525103569\n",
      "Q Loss:  0.0717744305729866\n",
      "Policy Loss:  0.13684965670108795\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  607.6892700195312\n",
      "Q Loss:  1353.0643310546875\n",
      "Policy Loss:  -56.56908416748047\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106550 length: 125 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0001176127843791619\n",
      "Q Loss:  0.0004207092279102653\n",
      "Policy Loss:  -0.012178375385701656\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.04005832597613335\n",
      "Q Loss:  0.020170174539089203\n",
      "Policy Loss:  0.09880293905735016\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 106558 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.1697593927383423\n",
      "Q Loss:  0.008722040802240372\n",
      "Policy Loss:  0.1917516440153122\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106635 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00013839428720530123\n",
      "Q Loss:  0.007280540186911821\n",
      "Policy Loss:  -0.02754712849855423\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  6.416146788978949e-05\n",
      "Q Loss:  0.00046182284131646156\n",
      "Policy Loss:  0.0006953647825866938\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.712918649194762e-05\n",
      "Q Loss:  0.000315504235913977\n",
      "Policy Loss:  -0.0020949095487594604\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01059865951538086\n",
      "Value Loss:  3.401975118322298e-05\n",
      "Q Loss:  0.0008681119652464986\n",
      "Policy Loss:  0.0042486973106861115\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106651 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.00023464977857656777\n",
      "Q Loss:  0.0001488601992605254\n",
      "Policy Loss:  -0.006023750174790621\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00021839526016265154\n",
      "Q Loss:  0.0010261584538966417\n",
      "Policy Loss:  0.0064658718183636665\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00010627316078171134\n",
      "Q Loss:  0.0008157573756761849\n",
      "Policy Loss:  0.0077354274690151215\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0002093104994855821\n",
      "Q Loss:  0.0002442084369249642\n",
      "Policy Loss:  -0.00630070548504591\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.1710802937159315e-05\n",
      "Q Loss:  0.0007131206803023815\n",
      "Policy Loss:  0.04944557696580887\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.08910911530256271\n",
      "Q Loss:  0.00022135414474178106\n",
      "Policy Loss:  -0.03432147949934006\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  1.8527281284332275\n",
      "Q Loss:  15.65974235534668\n",
      "Policy Loss:  0.6850467324256897\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106723 length: 48 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  0.0001258750562556088\n",
      "Q Loss:  0.00021389941684901714\n",
      "Policy Loss:  -0.005657483823597431\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106727 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.06697480380535126\n",
      "Q Loss:  0.01445077732205391\n",
      "Policy Loss:  0.004527617245912552\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106731 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  30686.9375\n",
      "Q Loss:  28797.27734375\n",
      "Policy Loss:  -30.60274887084961\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106758 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.000357459532096982\n",
      "Q Loss:  0.0005462055560201406\n",
      "Policy Loss:  0.005023529753088951\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00024273393501061946\n",
      "Q Loss:  0.0009171894052997231\n",
      "Policy Loss:  0.03951239958405495\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.0090968608856201\n",
      "Q Loss:  0.00841186847537756\n",
      "Policy Loss:  0.12929031252861023\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106855 length: 89 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2032.1126708984375\n",
      "Q Loss:  4202.5380859375\n",
      "Policy Loss:  -87.15131378173828\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106859 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  4.5297179894987494e-05\n",
      "Q Loss:  751.673583984375\n",
      "Policy Loss:  18.860469818115234\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106863 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002016321086557582\n",
      "Q Loss:  0.0022546539548784494\n",
      "Policy Loss:  0.012539885938167572\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106867 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00010409927926957607\n",
      "Q Loss:  182.64202880859375\n",
      "Policy Loss:  4.661128044128418\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106871 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.355994704179466e-05\n",
      "Q Loss:  0.0008205099729821086\n",
      "Policy Loss:  -0.012327071279287338\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106875 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00016045014490373433\n",
      "Q Loss:  0.003490739967674017\n",
      "Policy Loss:  -0.02897314541041851\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00014375188038684428\n",
      "Q Loss:  0.00117572583258152\n",
      "Policy Loss:  0.048283182084560394\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.12606704235076904\n",
      "Q Loss:  0.09581999480724335\n",
      "Policy Loss:  -0.224892258644104\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106887 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.1687676906585693\n",
      "Q Loss:  0.021789660677313805\n",
      "Policy Loss:  0.12017101049423218\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106962 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  2023.3265380859375\n",
      "Q Loss:  3605.84765625\n",
      "Policy Loss:  -156.89849853515625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0005071437335573137\n",
      "Q Loss:  0.0059808604419231415\n",
      "Policy Loss:  -0.02650054357945919\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00016699754633009434\n",
      "Q Loss:  0.0006958819576539099\n",
      "Policy Loss:  0.010503766126930714\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003096660366281867\n",
      "Q Loss:  0.0017549277981743217\n",
      "Policy Loss:  -0.0053776223212480545\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.642934047500603e-05\n",
      "Q Loss:  0.002685748739168048\n",
      "Policy Loss:  -0.009793633595108986\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2002.4517822265625\n",
      "Q Loss:  4311.9013671875\n",
      "Policy Loss:  -133.97940063476562\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00032875873148441315\n",
      "Q Loss:  0.00358630926348269\n",
      "Policy Loss:  0.03529246151447296\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  2.423984551569447e-05\n",
      "Q Loss:  0.00045803157263435423\n",
      "Policy Loss:  0.005179416388273239\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.00014259546878747642\n",
      "Q Loss:  0.002275391947478056\n",
      "Policy Loss:  -0.014267298392951488\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 106998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.06418423354625702\n",
      "Q Loss:  0.0036944299936294556\n",
      "Policy Loss:  0.01840219646692276\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.9898349046707153\n",
      "Q Loss:  0.016842106357216835\n",
      "Policy Loss:  0.2678087651729584\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107046 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  3.092459883191623e-05\n",
      "Q Loss:  0.0013925074599683285\n",
      "Policy Loss:  0.003703363938257098\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.040008544921875\n",
      "Value Loss:  1.4060769899515435e-05\n",
      "Q Loss:  0.008129450492560863\n",
      "Policy Loss:  -0.038923479616642\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  118.57217407226562\n",
      "Q Loss:  287.8292236328125\n",
      "Policy Loss:  -12.182604789733887\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107187 length: 133 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  8.024040653253905e-06\n",
      "Q Loss:  2.940263584605418e-05\n",
      "Policy Loss:  0.004252880811691284\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107191 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004375457763672\n",
      "Value Loss:  0.0005381579976528883\n",
      "Q Loss:  0.0032303195912390947\n",
      "Policy Loss:  0.026607230305671692\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  4.873062061960809e-05\n",
      "Q Loss:  0.005567146465182304\n",
      "Policy Loss:  0.035330526530742645\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02000594139099121\n",
      "Value Loss:  3.454359557508724e-06\n",
      "Q Loss:  0.0032183965668082237\n",
      "Policy Loss:  0.013506910763680935\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107203 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  4.3559877667576075e-05\n",
      "Q Loss:  0.00194566510617733\n",
      "Policy Loss:  0.01807321235537529\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107207 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00011152527440572158\n",
      "Q Loss:  0.00023689738009124994\n",
      "Policy Loss:  -0.007371978834271431\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00019186834106221795\n",
      "Q Loss:  0.0006809316109865904\n",
      "Policy Loss:  -0.009927801787853241\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9.036186384037137e-05\n",
      "Q Loss:  0.0023347625974565744\n",
      "Policy Loss:  -0.008205896243453026\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00012641587818507105\n",
      "Q Loss:  0.005691736005246639\n",
      "Policy Loss:  0.040762193500995636\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00011180745786987245\n",
      "Q Loss:  0.0011493393685668707\n",
      "Policy Loss:  0.013673149049282074\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490117073059082\n",
      "Value Loss:  1.3096199836581945e-05\n",
      "Q Loss:  0.00723701436072588\n",
      "Policy Loss:  0.04243744909763336\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.1349570741003845e-06\n",
      "Q Loss:  2.1938752979622222e-05\n",
      "Policy Loss:  -0.008973803371191025\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.1433736037579365e-05\n",
      "Q Loss:  0.0025752594228833914\n",
      "Policy Loss:  0.013286114670336246\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.038692500442266464\n",
      "Q Loss:  0.042301226407289505\n",
      "Policy Loss:  0.11771450936794281\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  125.33309936523438\n",
      "Q Loss:  283.013916015625\n",
      "Policy Loss:  -13.6790132522583\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107367 length: 124 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014004945755004883\n",
      "Value Loss:  0.0388442724943161\n",
      "Q Loss:  0.03525765612721443\n",
      "Policy Loss:  0.04917784780263901\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.039008140563964844\n",
      "Value Loss:  75989.4140625\n",
      "Q Loss:  71953.140625\n",
      "Policy Loss:  -90.1444091796875\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107393 length: 22 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001595337816979736\n",
      "Q Loss:  0.007256814744323492\n",
      "Policy Loss:  -0.04648856818675995\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0002469213795848191\n",
      "Q Loss:  0.016912754625082016\n",
      "Policy Loss:  -0.0640188455581665\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00013353773101698607\n",
      "Q Loss:  0.0016017549205571413\n",
      "Policy Loss:  -0.019778523594141006\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00023687741486355662\n",
      "Q Loss:  0.014215449802577496\n",
      "Policy Loss:  -0.050780169665813446\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107409 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  4.177168011665344e-05\n",
      "Q Loss:  0.00549329211935401\n",
      "Policy Loss:  -0.027173291891813278\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107413 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.350200808607042e-05\n",
      "Q Loss:  0.005040179006755352\n",
      "Policy Loss:  -0.01704920269548893\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030008792877197266\n",
      "Value Loss:  3.9811391616240144e-05\n",
      "Q Loss:  0.0002722481731325388\n",
      "Policy Loss:  0.01800033450126648\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.04559905827045441\n",
      "Q Loss:  0.00393714290112257\n",
      "Policy Loss:  0.04581036418676376\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.5095924139022827\n",
      "Q Loss:  0.0073538958095014095\n",
      "Policy Loss:  0.24304620921611786\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107481 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.063958375714719e-05\n",
      "Q Loss:  0.003473777323961258\n",
      "Policy Loss:  0.01749350130558014\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  2.4820728867780417e-05\n",
      "Q Loss:  0.005801371298730373\n",
      "Policy Loss:  0.04642075300216675\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.0379279046901502e-05\n",
      "Q Loss:  0.015037738718092442\n",
      "Policy Loss:  0.057570815086364746\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  0.0003004276077263057\n",
      "Q Loss:  0.017602507025003433\n",
      "Policy Loss:  0.06514961272478104\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0002796242479234934\n",
      "Q Loss:  0.019878409802913666\n",
      "Policy Loss:  0.06001655384898186\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001044273376465\n",
      "Value Loss:  6.25797183602117e-05\n",
      "Q Loss:  0.0035780849866569042\n",
      "Policy Loss:  0.02088797278702259\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  3.4347682230873033e-05\n",
      "Q Loss:  0.0006522364565171301\n",
      "Policy Loss:  0.007042817771434784\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107509 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  6.507623038487509e-05\n",
      "Q Loss:  0.0002745475503616035\n",
      "Policy Loss:  -0.0005128078628331423\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.404044370356132e-07\n",
      "Q Loss:  0.00011913431080756709\n",
      "Policy Loss:  -0.007864314131438732\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.230795714945998e-05\n",
      "Q Loss:  0.0038717042189091444\n",
      "Policy Loss:  -0.03554146736860275\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.05428292974829674\n",
      "Q Loss:  0.008809962309896946\n",
      "Policy Loss:  0.025961972773075104\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.10848498344421387\n",
      "Q Loss:  0.022790759801864624\n",
      "Policy Loss:  -0.007514044642448425\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06401491165161133\n",
      "Value Loss:  1.4648079872131348\n",
      "Q Loss:  46.0396728515625\n",
      "Policy Loss:  1.4233651161193848\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107587 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  1.6704709196346812e-05\n",
      "Q Loss:  0.00021009139891248196\n",
      "Policy Loss:  0.07460364699363708\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.05334758758544922\n",
      "Q Loss:  0.017835108563303947\n",
      "Policy Loss:  -0.039042066782712936\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003557205200195\n",
      "Value Loss:  1.4255032510845922e-05\n",
      "Q Loss:  0.0005725601804442704\n",
      "Policy Loss:  0.002027594018727541\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0180056095123291\n",
      "Value Loss:  7.312230991374236e-06\n",
      "Q Loss:  0.00030525197507813573\n",
      "Policy Loss:  0.013940323144197464\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001187324523926\n",
      "Value Loss:  2.125806076946901e-06\n",
      "Q Loss:  0.0003033422399312258\n",
      "Policy Loss:  0.011205964721739292\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.99170990526909e-05\n",
      "Q Loss:  0.0012079514563083649\n",
      "Policy Loss:  -0.00062506616814062\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0019261593697592616\n",
      "Q Loss:  0.03606925532221794\n",
      "Policy Loss:  -0.10300338268280029\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.10251738876104355\n",
      "Q Loss:  0.05860453471541405\n",
      "Policy Loss:  -0.06466184556484222\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.10031239688396454\n",
      "Q Loss:  0.020607957616448402\n",
      "Policy Loss:  0.009020902216434479\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107623 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.8617764711380005\n",
      "Q Loss:  0.007338719442486763\n",
      "Policy Loss:  0.1357765793800354\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107722 length: 99 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.295420411741361e-05\n",
      "Q Loss:  0.009428046643733978\n",
      "Policy Loss:  0.016675323247909546\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107726 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00021756990463472903\n",
      "Q Loss:  0.0006922556785866618\n",
      "Policy Loss:  0.0051760487258434296\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107730 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00016963962116278708\n",
      "Q Loss:  166.16909790039062\n",
      "Policy Loss:  4.474081039428711\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107734 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  3.862469384330325e-06\n",
      "Q Loss:  0.0009939831215888262\n",
      "Policy Loss:  0.00048264721408486366\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0010039584012702107\n",
      "Q Loss:  0.0036574280820786953\n",
      "Policy Loss:  0.00721746776252985\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019095420837402344\n",
      "Value Loss:  1.3728132247924805\n",
      "Q Loss:  0.011745166033506393\n",
      "Policy Loss:  0.1910286843776703\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 107806 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.000999543466605246\n",
      "Q Loss:  0.0013022106140851974\n",
      "Policy Loss:  0.0009563469793647528\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.04331647977232933\n",
      "Q Loss:  0.006851830054074526\n",
      "Policy Loss:  0.021646108478307724\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.08584319800138474\n",
      "Q Loss:  0.018568623811006546\n",
      "Policy Loss:  -0.05570195987820625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1.7435388144804165e-05\n",
      "Q Loss:  0.0007739307475276291\n",
      "Policy Loss:  -0.002339922124519944\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.08188782632350922\n",
      "Q Loss:  0.01791120506823063\n",
      "Policy Loss:  0.008681192994117737\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  7.911171269370243e-05\n",
      "Q Loss:  0.0007639230461791158\n",
      "Policy Loss:  0.0007787728682160378\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  14392.45703125\n",
      "Q Loss:  13755.7490234375\n",
      "Policy Loss:  -28.61867332458496\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107888 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0021753706969320774\n",
      "Q Loss:  0.005249209702014923\n",
      "Policy Loss:  -0.018219944089651108\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  0.00024585347273387015\n",
      "Q Loss:  0.006613641511648893\n",
      "Policy Loss:  -0.023838402703404427\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002757370239123702\n",
      "Q Loss:  0.0003443566965870559\n",
      "Policy Loss:  -0.0006221948424354196\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00010430542170070112\n",
      "Q Loss:  0.0002600615262053907\n",
      "Policy Loss:  0.0034616710618138313\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00016060906636994332\n",
      "Q Loss:  0.00017886630666907877\n",
      "Policy Loss:  0.001652129110880196\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005102157592773\n",
      "Value Loss:  3.1277621019398794e-05\n",
      "Q Loss:  0.00019486456585582346\n",
      "Policy Loss:  0.005445065908133984\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.035262446850538254\n",
      "Q Loss:  0.004230184946209192\n",
      "Policy Loss:  0.03540895879268646\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.10408841818571091\n",
      "Q Loss:  0.018243415281176567\n",
      "Policy Loss:  -0.016685767099261284\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.09993624687194824\n",
      "Q Loss:  0.01730547845363617\n",
      "Policy Loss:  -0.009898211807012558\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.4292336702346802\n",
      "Q Loss:  0.00784861110150814\n",
      "Policy Loss:  0.20247387886047363\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107986 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001863436191342771\n",
      "Q Loss:  0.0004618693783413619\n",
      "Policy Loss:  0.0666697546839714\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.11589391529560089\n",
      "Q Loss:  0.0048029436729848385\n",
      "Policy Loss:  -0.062044963240623474\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.05410412326455116\n",
      "Q Loss:  0.03490700572729111\n",
      "Policy Loss:  -0.017376959323883057\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 107998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  1.5876463651657104\n",
      "Q Loss:  0.002351950854063034\n",
      "Policy Loss:  0.24601495265960693\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108054 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0032625077292323112\n",
      "Q Loss:  0.0053734988905489445\n",
      "Policy Loss:  0.015045550651848316\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.0004205502336844802\n",
      "Q Loss:  0.005408911500126123\n",
      "Policy Loss:  0.021444685757160187\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0002582929446361959\n",
      "Q Loss:  0.0029335757717490196\n",
      "Policy Loss:  -0.007327181287109852\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.001213066396303475\n",
      "Q Loss:  0.0006039037834852934\n",
      "Policy Loss:  0.009846758097410202\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0005414593033492565\n",
      "Q Loss:  0.0007576023344881833\n",
      "Policy Loss:  0.003129437565803528\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.0001017029135255143\n",
      "Q Loss:  0.000865945708937943\n",
      "Policy Loss:  0.011342152953147888\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.783977131708525e-05\n",
      "Q Loss:  0.0016842642799019814\n",
      "Policy Loss:  0.01679719239473343\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108082 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.7315705665387213e-05\n",
      "Q Loss:  0.002036073012277484\n",
      "Policy Loss:  0.021371591836214066\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.242824772722088e-05\n",
      "Q Loss:  0.0017765261000022292\n",
      "Policy Loss:  0.0591229610145092\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.735637366771698\n",
      "Q Loss:  0.004874847363680601\n",
      "Policy Loss:  0.11764420568943024\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108213 length: 123 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.03629204258322716\n",
      "Q Loss:  0.018086068332195282\n",
      "Policy Loss:  -0.009594663977622986\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015934360271785408\n",
      "Q Loss:  0.00070237519685179\n",
      "Policy Loss:  0.03636197745800018\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  10423.2099609375\n",
      "Q Loss:  9916.1005859375\n",
      "Policy Loss:  -22.049875259399414\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108301 length: 80 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.006157874129712582\n",
      "Q Loss:  0.0038376199081540108\n",
      "Policy Loss:  -0.03146933764219284\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108305 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02400517463684082\n",
      "Value Loss:  9.44175772019662e-05\n",
      "Q Loss:  0.0007009551045484841\n",
      "Policy Loss:  -0.017415495589375496\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06501483917236328\n",
      "Value Loss:  0.03491240739822388\n",
      "Q Loss:  0.019222944974899292\n",
      "Policy Loss:  -0.027645662426948547\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108313 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.06855378299951553\n",
      "Q Loss:  0.011365065351128578\n",
      "Policy Loss:  -0.034769993275403976\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108317 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.016254877671599388\n",
      "Q Loss:  0.0253315232694149\n",
      "Policy Loss:  -0.010293075814843178\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016868114471435547\n",
      "Value Loss:  0.0002954124065581709\n",
      "Q Loss:  0.0002676510775927454\n",
      "Policy Loss:  0.01592877320945263\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.0003832644724752754\n",
      "Q Loss:  0.001180106308311224\n",
      "Policy Loss:  0.059758346527814865\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  0.05536544695496559\n",
      "Q Loss:  0.0008134713280014694\n",
      "Policy Loss:  -0.038623910397291183\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.9375863671302795\n",
      "Q Loss:  0.004377796780318022\n",
      "Policy Loss:  0.14984779059886932\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108432 length: 99 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0015271053416654468\n",
      "Q Loss:  0.0035683345049619675\n",
      "Policy Loss:  0.03630547225475311\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300048828125\n",
      "Value Loss:  0.0012727997964248061\n",
      "Q Loss:  0.001724616507999599\n",
      "Policy Loss:  0.02657088078558445\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.021843355149030685\n",
      "Q Loss:  0.007754341699182987\n",
      "Policy Loss:  0.029279209673404694\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  2.884939567593392e-05\n",
      "Q Loss:  0.0014892760664224625\n",
      "Policy Loss:  0.0052888342179358006\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.020167297217995e-05\n",
      "Q Loss:  0.0003039608709514141\n",
      "Policy Loss:  -0.0006042302120476961\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00038994534406811\n",
      "Q Loss:  0.0009865638567134738\n",
      "Policy Loss:  -0.006515234708786011\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.0595556497573853\n",
      "Q Loss:  0.0026038780342787504\n",
      "Policy Loss:  0.14988943934440613\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108544 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  14220.71875\n",
      "Q Loss:  13327.142578125\n",
      "Policy Loss:  -16.197803497314453\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108602 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0001189858594443649\n",
      "Q Loss:  0.0013850448885932565\n",
      "Policy Loss:  -0.013427605852484703\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.00020194397075101733\n",
      "Q Loss:  0.000810887198895216\n",
      "Policy Loss:  -0.014406083151698112\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012077093124389648\n",
      "Value Loss:  0.00015689543215557933\n",
      "Q Loss:  0.00019359958241693676\n",
      "Policy Loss:  -0.011458790861070156\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.4266406297683716\n",
      "Q Loss:  0.00330620096065104\n",
      "Policy Loss:  0.19228994846343994\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108679 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0001473944867029786\n",
      "Q Loss:  2.6006549887824804e-05\n",
      "Policy Loss:  0.002050140406936407\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  116.17324829101562\n",
      "Q Loss:  252.03721618652344\n",
      "Policy Loss:  -12.199193954467773\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108757 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2127.653564453125\n",
      "Q Loss:  4662.14794921875\n",
      "Policy Loss:  -119.25511169433594\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 108761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.852589573711157e-05\n",
      "Q Loss:  486.6617431640625\n",
      "Policy Loss:  13.176532745361328\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00024284556275233626\n",
      "Q Loss:  0.0021792545448988676\n",
      "Policy Loss:  0.002412262139841914\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00025302337598986924\n",
      "Q Loss:  0.0004134472692385316\n",
      "Policy Loss:  0.011404745280742645\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0006793900392949581\n",
      "Q Loss:  0.0003065809141844511\n",
      "Policy Loss:  -0.012247839942574501\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108777 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.530083631630987e-05\n",
      "Q Loss:  0.00013408571248874068\n",
      "Policy Loss:  0.005366731900721788\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108781 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.0002669927489478141\n",
      "Q Loss:  0.0011476343497633934\n",
      "Policy Loss:  0.018276944756507874\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.05251558870077133\n",
      "Q Loss:  0.04094687104225159\n",
      "Policy Loss:  -0.09919621050357819\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.07024042308330536\n",
      "Q Loss:  0.02394452504813671\n",
      "Policy Loss:  -0.10033790022134781\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.016993558034300804\n",
      "Q Loss:  0.0037271573673933744\n",
      "Policy Loss:  -0.007563041523098946\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0009333224734291434\n",
      "Q Loss:  0.0024166260845959187\n",
      "Policy Loss:  0.031037140637636185\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108801 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.045009613037109375\n",
      "Value Loss:  0.0003992549900431186\n",
      "Q Loss:  0.0011263086926192045\n",
      "Policy Loss:  0.019454948604106903\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108805 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  171.02957153320312\n",
      "Q Loss:  354.81365966796875\n",
      "Policy Loss:  -18.087461471557617\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108953 length: 148 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.015071329660713673\n",
      "Q Loss:  0.007246046792715788\n",
      "Policy Loss:  0.014410397037863731\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.04420960694551468\n",
      "Q Loss:  0.015395480208098888\n",
      "Policy Loss:  0.014560991898179054\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00014332686259876937\n",
      "Q Loss:  0.0033378559164702892\n",
      "Policy Loss:  0.04217538610100746\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012013673782348633\n",
      "Value Loss:  0.0005949964979663491\n",
      "Q Loss:  0.002916801255196333\n",
      "Policy Loss:  -0.008727201260626316\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0004918688209727407\n",
      "Q Loss:  0.0016064482042565942\n",
      "Policy Loss:  -0.02546711638569832\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02400493621826172\n",
      "Value Loss:  0.0001283106830669567\n",
      "Q Loss:  0.0015054342802613974\n",
      "Policy Loss:  0.007066867779940367\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.2911894373246469e-05\n",
      "Q Loss:  0.00014450284652411938\n",
      "Policy Loss:  -0.002319873543456197\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.011590266600251198\n",
      "Q Loss:  0.0030304687097668648\n",
      "Policy Loss:  0.06321583688259125\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  0.04449158534407616\n",
      "Q Loss:  0.005413792096078396\n",
      "Policy Loss:  0.030096586793661118\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.010514313355088234\n",
      "Q Loss:  0.016535496339201927\n",
      "Policy Loss:  0.017042022198438644\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  8.625943337392528e-07\n",
      "Q Loss:  0.0010309882927685976\n",
      "Policy Loss:  -0.0013488954864442348\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 108997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0008228662190958858\n",
      "Q Loss:  0.0017955147195607424\n",
      "Policy Loss:  0.017385948449373245\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0010751778027042747\n",
      "Q Loss:  0.001868216902948916\n",
      "Policy Loss:  0.02189185842871666\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.01570919156074524\n",
      "Q Loss:  0.0016601227689534426\n",
      "Policy Loss:  0.03430716693401337\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2.227731704711914\n",
      "Q Loss:  0.0025753590743988752\n",
      "Policy Loss:  0.31968146562576294\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109051 length: 42 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  5.6098306231433526e-05\n",
      "Q Loss:  0.0011669035302475095\n",
      "Policy Loss:  -0.0178691353648901\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109055 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  1.4899413585662842\n",
      "Q Loss:  0.0027631043922156096\n",
      "Policy Loss:  0.1977345049381256\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109118 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.00845110509544611\n",
      "Q Loss:  0.004940999671816826\n",
      "Policy Loss:  -0.008554613217711449\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.7251453995704651\n",
      "Q Loss:  4.837957382202148\n",
      "Policy Loss:  0.21192501485347748\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109251 length: 129 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.027652395889163017\n",
      "Q Loss:  0.023186370730400085\n",
      "Policy Loss:  -0.05624726042151451\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.009530497714877129\n",
      "Q Loss:  0.006465950049459934\n",
      "Policy Loss:  -0.008299486711621284\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.009718422777950764\n",
      "Q Loss:  0.01702376827597618\n",
      "Policy Loss:  -0.027379240840673447\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.017971515655518\n",
      "Q Loss:  0.004977099131792784\n",
      "Policy Loss:  0.5538128018379211\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109286 length: 23 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.012057457119226456\n",
      "Q Loss:  0.0027149664238095284\n",
      "Policy Loss:  0.0026136841624975204\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109290 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  9277.734375\n",
      "Q Loss:  8748.1796875\n",
      "Policy Loss:  -10.139861106872559\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109379 length: 89 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  122.67996215820312\n",
      "Q Loss:  270.333251953125\n",
      "Policy Loss:  -13.092069625854492\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109584 length: 205 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  11964.947265625\n",
      "Q Loss:  11225.541015625\n",
      "Policy Loss:  -13.59701156616211\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109653 length: 69 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01259469985961914\n",
      "Value Loss:  2093.689208984375\n",
      "Q Loss:  4575.6396484375\n",
      "Policy Loss:  -118.96206665039062\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  4184.97607421875\n",
      "Q Loss:  8821.1728515625\n",
      "Policy Loss:  -83.67952728271484\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2081.721923828125\n",
      "Q Loss:  4695.18359375\n",
      "Policy Loss:  -96.10072326660156\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109665 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  2067.302734375\n",
      "Q Loss:  4659.775390625\n",
      "Policy Loss:  -95.0960922241211\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2049.7080078125\n",
      "Q Loss:  4616.57275390625\n",
      "Policy Loss:  -94.00757598876953\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109673 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.001617259462364018\n",
      "Q Loss:  653.5316772460938\n",
      "Policy Loss:  17.72445297241211\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109677 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.0007360689342021942\n",
      "Q Loss:  326.4637145996094\n",
      "Policy Loss:  8.886293411254883\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109681 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  7.986307900864631e-05\n",
      "Q Loss:  324.78155517578125\n",
      "Policy Loss:  8.787935256958008\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109685 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0005098923575133085\n",
      "Q Loss:  0.00016443702043034136\n",
      "Policy Loss:  -0.002064872533082962\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109689 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.001031376188620925\n",
      "Q Loss:  0.0013020196929574013\n",
      "Policy Loss:  0.016749462112784386\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109693 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0006781520787626505\n",
      "Q Loss:  0.0024765986017882824\n",
      "Policy Loss:  0.008675667457282543\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109697 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0005163666792213917\n",
      "Q Loss:  0.023040803149342537\n",
      "Policy Loss:  0.07175859808921814\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109701 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014122247695922852\n",
      "Value Loss:  0.0003870067303068936\n",
      "Q Loss:  0.0027081756852567196\n",
      "Policy Loss:  0.013762068003416061\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109705 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  0.06735778599977493\n",
      "Q Loss:  0.022499315440654755\n",
      "Policy Loss:  -0.04297743737697601\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 109709 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.03377590700984001\n",
      "Q Loss:  0.04026332497596741\n",
      "Policy Loss:  0.05894443392753601\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109713 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  7.41466210456565e-05\n",
      "Q Loss:  0.01771482825279236\n",
      "Policy Loss:  0.04343067854642868\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0003029399085789919\n",
      "Q Loss:  0.0006769569590687752\n",
      "Policy Loss:  -0.01875605806708336\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  5.014454654883593e-05\n",
      "Q Loss:  0.0029536914080381393\n",
      "Policy Loss:  -0.005677946377545595\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 109725 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00018747597641777247\n",
      "Q Loss:  0.000854229205287993\n",
      "Policy Loss:  -0.014723336324095726\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  2.087694883812219e-05\n",
      "Q Loss:  0.0028545698150992393\n",
      "Policy Loss:  0.036823153495788574\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  30882.771484375\n",
      "Q Loss:  29234.337890625\n",
      "Policy Loss:  -29.932106018066406\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109760 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.13450437784194946\n",
      "Q Loss:  0.05092748999595642\n",
      "Policy Loss:  -0.1905982792377472\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109764 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  9781.2509765625\n",
      "Q Loss:  9362.26953125\n",
      "Policy Loss:  -18.807865142822266\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109850 length: 86 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0671495720744133\n",
      "Q Loss:  0.016483725979924202\n",
      "Policy Loss:  -0.03571224957704544\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.252750039100647\n",
      "Q Loss:  0.010212414897978306\n",
      "Policy Loss:  0.17134591937065125\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109924 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0001008698163786903\n",
      "Q Loss:  0.0008442235412076116\n",
      "Policy Loss:  0.07827463746070862\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.06734038144350052\n",
      "Q Loss:  0.01723555475473404\n",
      "Policy Loss:  -0.08717341721057892\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  0.09994153678417206\n",
      "Q Loss:  0.01867733709514141\n",
      "Policy Loss:  -0.00973431020975113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.603337245294824e-05\n",
      "Q Loss:  0.0028782133013010025\n",
      "Policy Loss:  -0.015213078819215298\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.06231938302516937\n",
      "Q Loss:  0.016491707414388657\n",
      "Policy Loss:  0.035317711532115936\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012823104858398438\n",
      "Value Loss:  0.05947354435920715\n",
      "Q Loss:  0.019571619108319283\n",
      "Policy Loss:  0.10076342523097992\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.11197086423635483\n",
      "Q Loss:  0.016396494582295418\n",
      "Policy Loss:  -0.049962982535362244\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 109952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.147986650466919\n",
      "Q Loss:  0.007402306888252497\n",
      "Policy Loss:  0.17504124343395233\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110029 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0004207391175441444\n",
      "Q Loss:  0.0007666010642424226\n",
      "Policy Loss:  -0.004404917359352112\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0023788632825016975\n",
      "Q Loss:  0.002464752644300461\n",
      "Policy Loss:  -0.010088020004332066\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0001893695880426094\n",
      "Q Loss:  0.0004817045119125396\n",
      "Policy Loss:  -0.0058992961421608925\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  3.099263267358765e-05\n",
      "Q Loss:  0.0006404066225513816\n",
      "Policy Loss:  -0.011396493762731552\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  4.36509481005487e-06\n",
      "Q Loss:  0.018649019300937653\n",
      "Policy Loss:  -0.006017085164785385\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.03758247196674347\n",
      "Q Loss:  0.01705380156636238\n",
      "Policy Loss:  0.04577596113085747\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.05330469831824303\n",
      "Q Loss:  0.01657753996551037\n",
      "Policy Loss:  0.037080660462379456\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004613876342773\n",
      "Value Loss:  0.04924796521663666\n",
      "Q Loss:  0.02873816341161728\n",
      "Policy Loss:  0.02623850479722023\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.02965037152171135\n",
      "Q Loss:  0.023362552747130394\n",
      "Policy Loss:  0.06190131977200508\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011081457138061523\n",
      "Value Loss:  14366.169921875\n",
      "Q Loss:  13915.517578125\n",
      "Policy Loss:  -39.246238708496094\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110124 length: 59 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1929.7747802734375\n",
      "Q Loss:  3998.234619140625\n",
      "Policy Loss:  -135.21351623535156\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0004028698895126581\n",
      "Q Loss:  0.001509529771283269\n",
      "Policy Loss:  0.007705316413193941\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 110132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0002304691879544407\n",
      "Q Loss:  0.015849167481064796\n",
      "Policy Loss:  -0.03553151339292526\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  4.7574703785358e-06\n",
      "Q Loss:  152.28558349609375\n",
      "Policy Loss:  4.259156227111816\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  7.276613905560225e-05\n",
      "Q Loss:  0.0011161663569509983\n",
      "Policy Loss:  -0.024378333240747452\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.003351627616211772\n",
      "Q Loss:  0.0018144125351682305\n",
      "Policy Loss:  0.00954472552984953\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.003560153301805258\n",
      "Q Loss:  0.0012332361657172441\n",
      "Policy Loss:  -0.02316729724407196\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0008167343912646174\n",
      "Q Loss:  0.0003592040447983891\n",
      "Policy Loss:  0.004226568154990673\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110156 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.023535076528787613\n",
      "Q Loss:  0.023573163896799088\n",
      "Policy Loss:  -0.05486058443784714\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.02197052538394928\n",
      "Q Loss:  0.013492762111127377\n",
      "Policy Loss:  -0.074811190366745\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110164 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.01339783426374197\n",
      "Q Loss:  0.012111935764551163\n",
      "Policy Loss:  0.0035264752805233\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.2554128170013428\n",
      "Q Loss:  0.0038240656722337008\n",
      "Policy Loss:  0.17544707655906677\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110243 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  8.560525020584464e-05\n",
      "Q Loss:  0.0025925259105861187\n",
      "Policy Loss:  0.02324649877846241\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.022126169875264168\n",
      "Q Loss:  0.004750533495098352\n",
      "Policy Loss:  -0.040125928819179535\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0290071964263916\n",
      "Value Loss:  14005.37109375\n",
      "Q Loss:  13430.75390625\n",
      "Policy Loss:  -27.59821319580078\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110311 length: 60 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.1539630889892578\n",
      "Q Loss:  7.4430928230285645\n",
      "Policy Loss:  0.4025007486343384\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110393 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.021306663751602173\n",
      "Q Loss:  6.318046871456318e-06\n",
      "Policy Loss:  0.000783476629294455\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.01608150266110897\n",
      "Q Loss:  0.010042012669146061\n",
      "Policy Loss:  0.031854283064603806\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.01051412895321846\n",
      "Q Loss:  0.011279215104877949\n",
      "Policy Loss:  0.05214934051036835\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01855635643005371\n",
      "Value Loss:  1.2151122093200684\n",
      "Q Loss:  0.004788546357303858\n",
      "Policy Loss:  0.19997704029083252\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110483 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.004013328347355127\n",
      "Q Loss:  0.003941896837204695\n",
      "Policy Loss:  -0.01430590357631445\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0030421933624893427\n",
      "Q Loss:  0.0037762452848255634\n",
      "Policy Loss:  0.013259290717542171\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.012790916487574577\n",
      "Q Loss:  0.008710810914635658\n",
      "Policy Loss:  0.06319783627986908\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.005379997193813324\n",
      "Q Loss:  0.002359589794650674\n",
      "Policy Loss:  0.027194693684577942\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029653310775756836\n",
      "Value Loss:  0.00019147564307786524\n",
      "Q Loss:  0.0017139033880084753\n",
      "Policy Loss:  -0.0182005874812603\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00021119392476975918\n",
      "Q Loss:  0.00046128861140459776\n",
      "Policy Loss:  -0.005048162303864956\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049010515213012695\n",
      "Value Loss:  0.0001864030200522393\n",
      "Q Loss:  0.0031440372113138437\n",
      "Policy Loss:  0.002526020398363471\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.017288897186517715\n",
      "Q Loss:  0.006763932760804892\n",
      "Policy Loss:  -0.015071088448166847\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.8145397664047778e-05\n",
      "Q Loss:  0.00045291907736100256\n",
      "Policy Loss:  0.008715848438441753\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.011167068965733051\n",
      "Q Loss:  0.0019670529291033745\n",
      "Policy Loss:  -0.006169002503156662\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  1.2267943620681763\n",
      "Q Loss:  0.0028103403747081757\n",
      "Policy Loss:  0.1757626086473465\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110600 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.018395118415355682\n",
      "Q Loss:  0.011522321961820126\n",
      "Policy Loss:  -0.001454320503398776\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110604 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.4792962074279785\n",
      "Q Loss:  0.006930311676114798\n",
      "Policy Loss:  0.19938629865646362\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110668 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  8.635478297946975e-05\n",
      "Q Loss:  0.0007936337497085333\n",
      "Policy Loss:  -0.006038648076355457\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.014700506813824177\n",
      "Q Loss:  0.019740328192710876\n",
      "Policy Loss:  -0.06840195506811142\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.014412444084882736\n",
      "Q Loss:  0.00365040497854352\n",
      "Policy Loss:  -0.013054415583610535\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110680 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.007460589520633221\n",
      "Q Loss:  0.0025778445415198803\n",
      "Policy Loss:  0.0029475484043359756\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110684 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  0.01535465382039547\n",
      "Q Loss:  0.0034740841947495937\n",
      "Policy Loss:  -0.03290378302335739\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110688 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.00020494301861617714\n",
      "Q Loss:  0.0003819787234533578\n",
      "Policy Loss:  0.03777562081813812\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110692 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.015364928171038628\n",
      "Q Loss:  0.0031460230238735676\n",
      "Policy Loss:  -0.007600901648402214\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110696 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.015127654187381268\n",
      "Q Loss:  0.0027620787732303143\n",
      "Policy Loss:  -0.006529925391077995\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014005184173583984\n",
      "Value Loss:  0.0002152942179236561\n",
      "Q Loss:  0.0005718178581446409\n",
      "Policy Loss:  0.011838426813483238\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  4.900024941889569e-05\n",
      "Q Loss:  0.006754211615771055\n",
      "Policy Loss:  0.010883794166147709\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110708 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.027704821899533272\n",
      "Q Loss:  0.005830745212733746\n",
      "Policy Loss:  -0.0573342964053154\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.026042453944683075\n",
      "Q Loss:  0.004238978959619999\n",
      "Policy Loss:  -0.04374285787343979\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110716 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.01773982308804989\n",
      "Q Loss:  0.00445016473531723\n",
      "Policy Loss:  -0.01441056840121746\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  1.2661799192428589\n",
      "Q Loss:  0.00663773575797677\n",
      "Policy Loss:  0.21960730850696564\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110795 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.00896713137626648\n",
      "Q Loss:  0.012710805982351303\n",
      "Policy Loss:  0.060128070414066315\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.004469756968319416\n",
      "Q Loss:  0.00032650475623086095\n",
      "Policy Loss:  0.008892878890037537\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0003892477252520621\n",
      "Q Loss:  0.0017110381741076708\n",
      "Policy Loss:  0.01857174001634121\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  20044.369140625\n",
      "Q Loss:  18960.330078125\n",
      "Policy Loss:  -21.35350799560547\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110890 length: 83 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0037407472264021635\n",
      "Q Loss:  0.0025176506023854017\n",
      "Policy Loss:  -0.0037748953327536583\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110894 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.001873423927463591\n",
      "Q Loss:  0.013543681241571903\n",
      "Policy Loss:  0.02593052014708519\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 110898 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0013006479712203145\n",
      "Q Loss:  0.001874683890491724\n",
      "Policy Loss:  -0.021824916824698448\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0031093484722077847\n",
      "Q Loss:  0.0015390939079225063\n",
      "Policy Loss:  -0.01990867406129837\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05401277542114258\n",
      "Value Loss:  0.0016722730360925198\n",
      "Q Loss:  0.0020068809390068054\n",
      "Policy Loss:  -0.029384039342403412\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.000853010336868465\n",
      "Q Loss:  0.0009689031867310405\n",
      "Policy Loss:  -0.0046243309043347836\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.160731554031372\n",
      "Q Loss:  0.004538434557616711\n",
      "Policy Loss:  0.3348179757595062\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110958 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.01851610653102398\n",
      "Q Loss:  0.0038792809937149286\n",
      "Policy Loss:  0.02838786691427231\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 110962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  9660.505859375\n",
      "Q Loss:  9191.3505859375\n",
      "Policy Loss:  -9.200651168823242\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111048 length: 86 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.05401182174682617\n",
      "Value Loss:  0.007401499431580305\n",
      "Q Loss:  0.009976784698665142\n",
      "Policy Loss:  0.03292513266205788\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111052 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.004247170872986317\n",
      "Q Loss:  0.004704909399151802\n",
      "Policy Loss:  -0.0011638253927230835\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111056 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0043179127387702465\n",
      "Q Loss:  0.0023955139331519604\n",
      "Policy Loss:  -0.022999467328190804\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111060 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.9774222892010584e-05\n",
      "Q Loss:  0.0002869002055376768\n",
      "Policy Loss:  0.010093294084072113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111064 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05062508583068848\n",
      "Value Loss:  0.006894424557685852\n",
      "Q Loss:  0.005054325331002474\n",
      "Policy Loss:  0.021497221663594246\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111068 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.9106690160697326e-05\n",
      "Q Loss:  0.002613178687170148\n",
      "Policy Loss:  0.02210828848183155\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111072 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  3.418189589865506e-05\n",
      "Q Loss:  0.000446400634245947\n",
      "Policy Loss:  0.005672604776918888\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  20946.34375\n",
      "Q Loss:  20010.291015625\n",
      "Policy Loss:  -42.256805419921875\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111116 length: 40 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  4.6513259803759865e-06\n",
      "Q Loss:  0.000276684935670346\n",
      "Policy Loss:  0.005084563512355089\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.008926662616431713\n",
      "Q Loss:  0.002009511226788163\n",
      "Policy Loss:  0.008748914115130901\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.009479116648435593\n",
      "Q Loss:  0.0020471273455768824\n",
      "Policy Loss:  -0.02770616114139557\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.987048785347724e-06\n",
      "Q Loss:  0.00039813402690924704\n",
      "Policy Loss:  -0.009264970198273659\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  6.077687430661172e-06\n",
      "Q Loss:  0.0004678285913541913\n",
      "Policy Loss:  -0.01274140551686287\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.10206939704949e-06\n",
      "Q Loss:  0.0005325467209331691\n",
      "Policy Loss:  -0.010316260159015656\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.297832785799983e-07\n",
      "Q Loss:  0.013252570293843746\n",
      "Policy Loss:  -0.013724029064178467\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.011246600188314915\n",
      "Q Loss:  0.0015271538868546486\n",
      "Policy Loss:  0.0008798111230134964\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.03422681242227554\n",
      "Q Loss:  0.00896418560296297\n",
      "Policy Loss:  -0.04320934787392616\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.022476745769381523\n",
      "Q Loss:  0.004699844401329756\n",
      "Policy Loss:  -0.011204265058040619\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111156 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.043514661490917206\n",
      "Q Loss:  0.009727556258440018\n",
      "Policy Loss:  -0.07779917865991592\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.02032797783613205\n",
      "Q Loss:  0.004159397911280394\n",
      "Policy Loss:  0.008968397974967957\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111164 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  0.01871444284915924\n",
      "Q Loss:  0.006387413013726473\n",
      "Policy Loss:  -0.0030620507895946503\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  16892.4453125\n",
      "Q Loss:  16186.1298828125\n",
      "Policy Loss:  -33.36405563354492\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111267 length: 99 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  22376.3359375\n",
      "Q Loss:  21126.779296875\n",
      "Policy Loss:  -24.585655212402344\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111304 length: 37 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.007937490940093994\n",
      "Q Loss:  0.008532389998435974\n",
      "Policy Loss:  0.05450514331459999\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.023681551218032837\n",
      "Q Loss:  0.005415768828243017\n",
      "Policy Loss:  0.013559294864535332\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111312 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.015318097546696663\n",
      "Q Loss:  0.007135280407965183\n",
      "Policy Loss:  0.0023524872958660126\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.032006263732910156\n",
      "Value Loss:  0.014529977925121784\n",
      "Q Loss:  0.006078669335693121\n",
      "Policy Loss:  0.024866858497262\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.013609258458018303\n",
      "Q Loss:  0.0027447498869150877\n",
      "Policy Loss:  0.0041442811489105225\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.006317950319498777\n",
      "Q Loss:  0.005190055817365646\n",
      "Policy Loss:  0.00547362957149744\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.01728806644678116\n",
      "Q Loss:  0.003166912356391549\n",
      "Policy Loss:  -0.0023303963243961334\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0154773173853755\n",
      "Q Loss:  0.0006565719959326088\n",
      "Policy Loss:  -0.0033533191308379173\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.10302305221557617\n",
      "Value Loss:  0.00454311165958643\n",
      "Q Loss:  0.002051654038950801\n",
      "Policy Loss:  -0.009479198604822159\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  7.602389814564958e-05\n",
      "Q Loss:  0.0006272508762776852\n",
      "Policy Loss:  0.023847755044698715\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.8103039264678955\n",
      "Q Loss:  0.0044749584048986435\n",
      "Policy Loss:  0.3969171643257141\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111378 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  145.62388610839844\n",
      "Q Loss:  363.6202087402344\n",
      "Policy Loss:  -13.45335578918457\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111494 length: 116 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.795584754901938e-05\n",
      "Q Loss:  0.002736030612140894\n",
      "Policy Loss:  -0.015466454438865185\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111498 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.002815519692376256\n",
      "Q Loss:  0.0025792215019464493\n",
      "Policy Loss:  -0.014876614324748516\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111502 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0013594187330454588\n",
      "Q Loss:  0.0031070103868842125\n",
      "Policy Loss:  0.011718343943357468\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06601428985595703\n",
      "Value Loss:  0.0007172116311267018\n",
      "Q Loss:  0.0013896184973418713\n",
      "Policy Loss:  -0.00539430370554328\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005102157592773\n",
      "Value Loss:  0.010879691690206528\n",
      "Q Loss:  0.0008436570060439408\n",
      "Policy Loss:  -0.017507079988718033\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111514 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00034095352748408914\n",
      "Q Loss:  0.003195416647940874\n",
      "Policy Loss:  -0.027570711448788643\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111518 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0003333742206450552\n",
      "Q Loss:  0.0014910376630723476\n",
      "Policy Loss:  -0.015270663425326347\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.918923903256655e-05\n",
      "Q Loss:  0.0026770620606839657\n",
      "Policy Loss:  -0.026033755391836166\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012010574340820312\n",
      "Value Loss:  0.006019015330821276\n",
      "Q Loss:  0.0011140847345814109\n",
      "Policy Loss:  -0.01451790053397417\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0060756816528737545\n",
      "Q Loss:  0.0004277457483112812\n",
      "Policy Loss:  -0.006000706925988197\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00034339074045419693\n",
      "Q Loss:  0.001100028632208705\n",
      "Policy Loss:  0.02014991268515587\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0004926433321088552\n",
      "Q Loss:  0.000501601432915777\n",
      "Policy Loss:  0.010051948949694633\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0004689838970080018\n",
      "Q Loss:  0.0007386036450043321\n",
      "Policy Loss:  0.011275086551904678\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111546 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00024243234656751156\n",
      "Q Loss:  0.00010048497642856091\n",
      "Policy Loss:  -0.0034189478028565645\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111550 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.363220745697618e-05\n",
      "Q Loss:  0.000738357484806329\n",
      "Policy Loss:  0.001335481065325439\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  96990.46875\n",
      "Q Loss:  91865.6640625\n",
      "Policy Loss:  -88.28730010986328\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 111571 length: 17 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2140.58837890625\n",
      "Q Loss:  4358.63525390625\n",
      "Policy Loss:  -145.24205017089844\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  15239.8349609375\n",
      "Q Loss:  14456.2744140625\n",
      "Policy Loss:  -17.26114845275879\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111629 length: 54 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4348.2744140625\n",
      "Q Loss:  4406.1455078125\n",
      "Policy Loss:  -317.9532165527344\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 111633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05601382255554199\n",
      "Value Loss:  0.001109390053898096\n",
      "Q Loss:  154.54147338867188\n",
      "Policy Loss:  4.33657169342041\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 111637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2185.462158203125\n",
      "Q Loss:  1186.748046875\n",
      "Policy Loss:  -205.2442169189453\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 111641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00028864858904853463\n",
      "Q Loss:  156.3482208251953\n",
      "Policy Loss:  4.31345796585083\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 111645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.02165273018181324\n",
      "Q Loss:  0.05452921614050865\n",
      "Policy Loss:  0.0455649271607399\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 111649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.03356286138296127\n",
      "Q Loss:  0.010222276672720909\n",
      "Policy Loss:  0.018526429310441017\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.010789536871016026\n",
      "Q Loss:  0.00801123958081007\n",
      "Policy Loss:  -0.0375855453312397\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.007498444058001041\n",
      "Q Loss:  0.005697142332792282\n",
      "Policy Loss:  -0.0412851944565773\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004966735839844\n",
      "Value Loss:  0.03376685827970505\n",
      "Q Loss:  0.019611530005931854\n",
      "Policy Loss:  -0.06207350268959999\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111665 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.04955199360847473\n",
      "Q Loss:  0.010091361589729786\n",
      "Policy Loss:  -0.033212728798389435\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111669 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.06513995677232742\n",
      "Q Loss:  0.010345811024308205\n",
      "Policy Loss:  -0.06747949868440628\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111673 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02500462532043457\n",
      "Value Loss:  0.8716084361076355\n",
      "Q Loss:  0.021591518074274063\n",
      "Policy Loss:  0.14559589326381683\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111778 length: 105 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.006726789753884077\n",
      "Q Loss:  0.039083316922187805\n",
      "Policy Loss:  -0.009635248221457005\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.06234415993094444\n",
      "Q Loss:  0.016939576715230942\n",
      "Policy Loss:  -0.08781412988901138\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.004438821692019701\n",
      "Q Loss:  0.007582268677651882\n",
      "Policy Loss:  0.05132107436656952\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0009467292111366987\n",
      "Q Loss:  0.025838274508714676\n",
      "Policy Loss:  0.11364683508872986\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.1157854795455933\n",
      "Q Loss:  0.019244303926825523\n",
      "Policy Loss:  0.21888524293899536\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111876 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0025499765761196613\n",
      "Q Loss:  0.01913370192050934\n",
      "Policy Loss:  0.023816991597414017\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0079532191157341\n",
      "Q Loss:  0.007445893716067076\n",
      "Policy Loss:  0.046766314655542374\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111884 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.004654929507523775\n",
      "Q Loss:  0.0021917482372373343\n",
      "Policy Loss:  0.025245683267712593\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0024252315051853657\n",
      "Q Loss:  0.0026605946477502584\n",
      "Policy Loss:  0.007219265680760145\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.001077423570677638\n",
      "Q Loss:  0.0012114220298826694\n",
      "Policy Loss:  0.0016396206337958574\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 111896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.6612804532051086\n",
      "Q Loss:  0.013310055248439312\n",
      "Policy Loss:  0.11318189650774002\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112034 length: 138 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.014000612311065197\n",
      "Q Loss:  0.03752286732196808\n",
      "Policy Loss:  0.10332345962524414\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.005986964330077171\n",
      "Q Loss:  162.63009643554688\n",
      "Policy Loss:  4.44603157043457\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0027137030847370625\n",
      "Q Loss:  0.0017697964794933796\n",
      "Policy Loss:  -0.00891503132879734\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0018068343633785844\n",
      "Q Loss:  0.0024996954016387463\n",
      "Policy Loss:  -0.03426898270845413\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.012058963067829609\n",
      "Q Loss:  0.0184332262724638\n",
      "Policy Loss:  -0.07228464633226395\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  9.035472612595186e-05\n",
      "Q Loss:  0.019649090245366096\n",
      "Policy Loss:  -0.021102897822856903\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003557205200195\n",
      "Value Loss:  1.9803450107574463\n",
      "Q Loss:  0.01779632456600666\n",
      "Policy Loss:  0.23057140409946442\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112104 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0063092815689742565\n",
      "Q Loss:  0.016437919810414314\n",
      "Policy Loss:  -0.06290235370397568\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112108 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052011966705322266\n",
      "Value Loss:  0.028948381543159485\n",
      "Q Loss:  0.00608086958527565\n",
      "Policy Loss:  -0.020590536296367645\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 112112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  6574.876953125\n",
      "Q Loss:  6471.4912109375\n",
      "Policy Loss:  -27.427200317382812\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112241 length: 129 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.006781093776226044\n",
      "Q Loss:  0.0017953352071344852\n",
      "Policy Loss:  -0.0034212851896882057\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700662612915039\n",
      "Value Loss:  0.004211101680994034\n",
      "Q Loss:  0.005307634361088276\n",
      "Policy Loss:  -0.0016991626471281052\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00045259148464538157\n",
      "Q Loss:  0.0017455563647672534\n",
      "Policy Loss:  -0.0037483475171029568\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0001269236672669649\n",
      "Q Loss:  0.0024613775312900543\n",
      "Policy Loss:  0.033310651779174805\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0008285071235150099\n",
      "Q Loss:  0.0017774018924683332\n",
      "Policy Loss:  0.022685958072543144\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200103759765625\n",
      "Value Loss:  0.0016273286892101169\n",
      "Q Loss:  0.002700424287468195\n",
      "Policy Loss:  0.03890414908528328\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.0022586449049413204\n",
      "Q Loss:  0.0030412180349230766\n",
      "Policy Loss:  0.036767370998859406\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.004275192506611347\n",
      "Q Loss:  0.0012161240447312593\n",
      "Policy Loss:  0.012892624363303185\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0031204083934426308\n",
      "Q Loss:  0.0015429145423695445\n",
      "Policy Loss:  0.014027305878698826\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.0008909856551326811\n",
      "Q Loss:  0.004978935234248638\n",
      "Policy Loss:  0.014665056020021439\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.746241756947711e-05\n",
      "Q Loss:  0.0015170688275247812\n",
      "Policy Loss:  -0.012475069612264633\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112285 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  0.0018949771765619516\n",
      "Q Loss:  0.004370176233351231\n",
      "Policy Loss:  0.018458928912878036\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112289 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.0015488447388634086\n",
      "Q Loss:  0.0012910476652905345\n",
      "Policy Loss:  0.005638737231492996\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112293 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0012326108990237117\n",
      "Q Loss:  0.0012707059504464269\n",
      "Policy Loss:  -0.010751239955425262\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03400826454162598\n",
      "Value Loss:  0.0013296219985932112\n",
      "Q Loss:  0.0028988260310143232\n",
      "Policy Loss:  -0.01872754469513893\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112301 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  9.209108611685224e-06\n",
      "Q Loss:  0.0002234485582448542\n",
      "Policy Loss:  0.041426755487918854\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112305 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.027928872033953667\n",
      "Q Loss:  0.01313664112240076\n",
      "Policy Loss:  -0.029037170112133026\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112309 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.0336895684304181e-05\n",
      "Q Loss:  0.00012393706128932536\n",
      "Policy Loss:  0.01512003131210804\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112313 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014005661010742188\n",
      "Value Loss:  0.05549873039126396\n",
      "Q Loss:  0.003499324433505535\n",
      "Policy Loss:  0.005966894328594208\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112317 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.081480011343956\n",
      "Q Loss:  0.03780481964349747\n",
      "Policy Loss:  -0.05617793649435043\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013190746307373047\n",
      "Value Loss:  0.8461503386497498\n",
      "Q Loss:  0.009617985226213932\n",
      "Policy Loss:  0.14154939353466034\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112426 length: 105 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006184630910865963\n",
      "Q Loss:  0.004115941468626261\n",
      "Policy Loss:  0.019378317520022392\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00023324822541326284\n",
      "Q Loss:  0.0025608136784285307\n",
      "Policy Loss:  0.00676727294921875\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.024090062826871872\n",
      "Q Loss:  0.012328491546213627\n",
      "Policy Loss:  0.044476523995399475\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012552261352539062\n",
      "Value Loss:  10381.0166015625\n",
      "Q Loss:  9865.1826171875\n",
      "Policy Loss:  -23.27043914794922\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112518 length: 80 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0002441449323669076\n",
      "Q Loss:  0.014757512137293816\n",
      "Policy Loss:  0.05548851937055588\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005594942485913634\n",
      "Q Loss:  0.000816615647636354\n",
      "Policy Loss:  0.011457077227532864\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00033785958657972515\n",
      "Q Loss:  0.0027843776624649763\n",
      "Policy Loss:  0.019871536642313004\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0890200138092041\n",
      "Value Loss:  0.02242237515747547\n",
      "Q Loss:  0.009777987375855446\n",
      "Policy Loss:  0.040643978863954544\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.057411949062953e-06\n",
      "Q Loss:  0.0008112565265037119\n",
      "Policy Loss:  0.011682288721203804\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.398426770218066e-06\n",
      "Q Loss:  0.00021699884382542223\n",
      "Policy Loss:  0.001358333509415388\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  3.7678544231312117e-06\n",
      "Q Loss:  0.016916073858737946\n",
      "Policy Loss:  -0.00026700430316850543\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112546 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.08447697758674622\n",
      "Q Loss:  0.013075320981442928\n",
      "Policy Loss:  -0.09292557090520859\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112550 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.08037283271551132\n",
      "Q Loss:  0.00904549565166235\n",
      "Policy Loss:  -0.07032382488250732\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01593184471130371\n",
      "Value Loss:  2.490554094314575\n",
      "Q Loss:  0.003977261949330568\n",
      "Policy Loss:  0.3599318265914917\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112590 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.002799944719299674\n",
      "Q Loss:  0.006217368878424168\n",
      "Policy Loss:  0.0032496359199285507\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.0016621118411421776\n",
      "Q Loss:  0.005810542963445187\n",
      "Policy Loss:  0.0025003571063280106\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 112598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018002748489379883\n",
      "Value Loss:  2.0579464035108685e-05\n",
      "Q Loss:  158.51889038085938\n",
      "Policy Loss:  4.291210651397705\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0006484190816991031\n",
      "Q Loss:  0.004390200600028038\n",
      "Policy Loss:  -0.009600167162716389\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0010079416679218411\n",
      "Q Loss:  0.0027822423726320267\n",
      "Policy Loss:  -0.014573242515325546\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0006863452144898474\n",
      "Q Loss:  0.007837732322514057\n",
      "Policy Loss:  -0.03257254138588905\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012600898742675781\n",
      "Value Loss:  0.01771458052098751\n",
      "Q Loss:  0.010344949550926685\n",
      "Policy Loss:  0.019825249910354614\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.16204237937927246\n",
      "Value Loss:  0.01747383549809456\n",
      "Q Loss:  0.01843257062137127\n",
      "Policy Loss:  0.02274099364876747\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.18704748153686523\n",
      "Value Loss:  6.489003681053873e-06\n",
      "Q Loss:  0.0017776956083253026\n",
      "Policy Loss:  0.012487122789025307\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.3580811023712158\n",
      "Value Loss:  1.3851192306901794e-05\n",
      "Q Loss:  0.001435423269867897\n",
      "Policy Loss:  0.0035569211468100548\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.36586928367614746\n",
      "Value Loss:  0.0164574533700943\n",
      "Q Loss:  0.018250126391649246\n",
      "Policy Loss:  0.06022397428750992\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031006813049316406\n",
      "Value Loss:  93.83121490478516\n",
      "Q Loss:  197.8950958251953\n",
      "Policy Loss:  -9.755915641784668\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112729 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02600550651550293\n",
      "Value Loss:  0.032094184309244156\n",
      "Q Loss:  0.0262589193880558\n",
      "Policy Loss:  0.03708012402057648\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  29855.912109375\n",
      "Q Loss:  28223.244140625\n",
      "Policy Loss:  -31.462121963500977\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112788 length: 55 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.018250226974487305\n",
      "Value Loss:  0.012415396980941296\n",
      "Q Loss:  0.019169175997376442\n",
      "Policy Loss:  -0.04721428453922272\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112792 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008568958728574216\n",
      "Q Loss:  0.00032729003578424454\n",
      "Policy Loss:  0.010790443047881126\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112796 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0001654293155297637\n",
      "Q Loss:  0.00025626650312915444\n",
      "Policy Loss:  0.0030259587801992893\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08801937103271484\n",
      "Value Loss:  6.7099595071340445e-06\n",
      "Q Loss:  0.00018821362755261362\n",
      "Policy Loss:  -0.0006520183524116874\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112804 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.000560123473405838\n",
      "Q Loss:  0.0010734964162111282\n",
      "Policy Loss:  0.011957834474742413\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112808 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014632701873779297\n",
      "Value Loss:  0.0003880320582538843\n",
      "Q Loss:  0.005479180254042149\n",
      "Policy Loss:  -0.02533023990690708\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0007565811974927783\n",
      "Q Loss:  0.0011676752474159002\n",
      "Policy Loss:  -0.013489984907209873\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006929318187758327\n",
      "Q Loss:  0.0007889980915933847\n",
      "Policy Loss:  0.0005616234266199172\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112820 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  1.6672372566972626e-06\n",
      "Q Loss:  0.0002143088640877977\n",
      "Policy Loss:  0.009213930927217007\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  1.3483328075380996e-05\n",
      "Q Loss:  0.00019630714086815715\n",
      "Policy Loss:  0.003648998448625207\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  2.82926885120105e-05\n",
      "Q Loss:  7.171963079599664e-05\n",
      "Policy Loss:  0.005676350090652704\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  2.3211345251183957e-05\n",
      "Q Loss:  0.00011941234697587788\n",
      "Policy Loss:  0.00418227631598711\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  8.282771887024865e-06\n",
      "Q Loss:  0.00010957724589388818\n",
      "Policy Loss:  -0.0049092452973127365\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0005356050096452236\n",
      "Q Loss:  0.0008380642393603921\n",
      "Policy Loss:  0.013360505923628807\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  1.1584810977183224e-07\n",
      "Q Loss:  0.00016371236415579915\n",
      "Policy Loss:  0.001687850570306182\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.01649329997599125\n",
      "Q Loss:  0.004228154197335243\n",
      "Policy Loss:  0.02527644671499729\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.06540758907794952\n",
      "Q Loss:  0.012890463694930077\n",
      "Policy Loss:  -0.08441320806741714\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030007362365722656\n",
      "Value Loss:  0.04680982977151871\n",
      "Q Loss:  0.019348304718732834\n",
      "Policy Loss:  -0.04408371448516846\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03400826454162598\n",
      "Value Loss:  15446.400390625\n",
      "Q Loss:  14701.005859375\n",
      "Policy Loss:  -14.567395210266113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112913 length: 53 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.028173070400953293\n",
      "Q Loss:  0.02324354089796543\n",
      "Policy Loss:  0.0018292441964149475\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 112917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.053722821176052094\n",
      "Q Loss:  0.0006257165223360062\n",
      "Policy Loss:  -0.022141199558973312\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024006128311157227\n",
      "Value Loss:  1.4344689846038818\n",
      "Q Loss:  0.0038069405127316713\n",
      "Policy Loss:  0.2342253029346466\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 112985 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  7154.52197265625\n",
      "Q Loss:  7299.61572265625\n",
      "Policy Loss:  -48.611900329589844\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113107 length: 122 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  3.6217425076756626e-05\n",
      "Q Loss:  0.0014116916572675109\n",
      "Policy Loss:  0.008198203518986702\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012792110443115234\n",
      "Value Loss:  1.3192254304885864\n",
      "Q Loss:  0.008609524928033352\n",
      "Policy Loss:  0.22746407985687256\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113181 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.015162438154220581\n",
      "Q Loss:  0.014816759154200554\n",
      "Policy Loss:  0.04749052971601486\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  2.1693189410143532e-05\n",
      "Q Loss:  0.000658347737044096\n",
      "Policy Loss:  0.042695701122283936\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  125.55301666259766\n",
      "Q Loss:  212.30136108398438\n",
      "Policy Loss:  -13.012834548950195\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113263 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.004137584939599037\n",
      "Q Loss:  0.001323257340118289\n",
      "Policy Loss:  0.024222357198596\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113267 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0004184012650512159\n",
      "Q Loss:  0.00023657070414628834\n",
      "Policy Loss:  -0.013895604759454727\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113271 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00019097139011137187\n",
      "Q Loss:  0.002396094147115946\n",
      "Policy Loss:  -0.018029693514108658\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00023457102361135185\n",
      "Q Loss:  0.004685035441070795\n",
      "Policy Loss:  0.012080978602170944\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.00019069785776082426\n",
      "Q Loss:  0.00895839836448431\n",
      "Policy Loss:  0.026497190818190575\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.017227590084075928\n",
      "Q Loss:  0.004700217861682177\n",
      "Policy Loss:  0.031512584537267685\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113287 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0196075439453125\n",
      "Value Loss:  0.052553966641426086\n",
      "Q Loss:  0.015978902578353882\n",
      "Policy Loss:  -0.016212545335292816\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113291 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0519539937376976\n",
      "Q Loss:  0.012939689680933952\n",
      "Policy Loss:  -0.02313082292675972\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113295 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.03328659385442734\n",
      "Q Loss:  0.016604293137788773\n",
      "Policy Loss:  0.015811525285243988\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113299 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.047193992882966995\n",
      "Q Loss:  0.009562642313539982\n",
      "Policy Loss:  -0.01105472631752491\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113303 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  11732.1865234375\n",
      "Q Loss:  11514.185546875\n",
      "Policy Loss:  -48.887943267822266\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113375 length: 72 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2314.951416015625\n",
      "Q Loss:  4745.365234375\n",
      "Policy Loss:  -151.14364624023438\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.011538054794073105\n",
      "Q Loss:  0.011869191192090511\n",
      "Policy Loss:  -0.023176860064268112\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300666809082031\n",
      "Value Loss:  0.00019883288769051433\n",
      "Q Loss:  0.0009141150512732565\n",
      "Policy Loss:  0.0032273749820888042\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.0126242870464921\n",
      "Q Loss:  0.005603827070444822\n",
      "Policy Loss:  0.027627738192677498\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00019507254182826728\n",
      "Q Loss:  0.0017075772630050778\n",
      "Policy Loss:  0.022045552730560303\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113395 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00016584161494392902\n",
      "Q Loss:  0.000993410125374794\n",
      "Policy Loss:  0.007146954536437988\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113399 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.011198545806109905\n",
      "Q Loss:  0.0032842489890754223\n",
      "Policy Loss:  0.014288349077105522\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113403 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  6.5025442381738685e-06\n",
      "Q Loss:  0.00010660536645445973\n",
      "Policy Loss:  -0.002698249649256468\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113407 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.010385924018919468\n",
      "Q Loss:  0.002015454927459359\n",
      "Policy Loss:  0.007954582571983337\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003080368041992\n",
      "Value Loss:  7.733702659606934e-05\n",
      "Q Loss:  0.00031573022715747356\n",
      "Policy Loss:  -0.012835083529353142\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113415 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00015714969777036458\n",
      "Q Loss:  0.00030135802808217704\n",
      "Policy Loss:  -0.011240430176258087\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113419 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00010533486783970147\n",
      "Q Loss:  0.0008900176617316902\n",
      "Policy Loss:  0.0032782196067273617\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113423 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  3.320461109979078e-05\n",
      "Q Loss:  0.009958965703845024\n",
      "Policy Loss:  -0.010451520793139935\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.025799915194511414\n",
      "Q Loss:  0.0070066386833786964\n",
      "Policy Loss:  -0.03270742669701576\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.024302178993821144\n",
      "Q Loss:  0.012604115530848503\n",
      "Policy Loss:  -0.05444720759987831\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0222875215113163\n",
      "Q Loss:  0.004708448424935341\n",
      "Policy Loss:  -0.04014039784669876\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.036008358001708984\n",
      "Value Loss:  3.0764313123654574e-05\n",
      "Q Loss:  0.0003407295444048941\n",
      "Policy Loss:  0.006928682327270508\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033006906509399414\n",
      "Value Loss:  0.0003857423143927008\n",
      "Q Loss:  0.0005524186417460442\n",
      "Policy Loss:  -0.0017770000267773867\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.249624129850417e-05\n",
      "Q Loss:  0.00024256711185444146\n",
      "Policy Loss:  0.00523881521075964\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.009796482510864735\n",
      "Q Loss:  0.002706131199374795\n",
      "Policy Loss:  0.039296943694353104\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.013090459629893303\n",
      "Q Loss:  0.004913977812975645\n",
      "Policy Loss:  0.007804374676197767\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004634857177734\n",
      "Value Loss:  8.257391164079309e-05\n",
      "Q Loss:  0.00487116165459156\n",
      "Policy Loss:  0.03573024272918701\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.2679031796287745e-05\n",
      "Q Loss:  5.9311612858437e-05\n",
      "Policy Loss:  -0.0026568197645246983\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  3.593263681977987e-05\n",
      "Q Loss:  0.0020202239975333214\n",
      "Policy Loss:  0.02076701447367668\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  2.4333289729838725e-06\n",
      "Q Loss:  0.0011361766373738647\n",
      "Policy Loss:  0.008373810909688473\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.2502510546473786e-05\n",
      "Q Loss:  0.0001666311436565593\n",
      "Policy Loss:  -0.00406847707927227\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.9668912500492297e-05\n",
      "Q Loss:  3.0130704544717446e-05\n",
      "Policy Loss:  -0.009802497923374176\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.3328497516340576e-05\n",
      "Q Loss:  0.0005268489476293325\n",
      "Policy Loss:  -0.021286435425281525\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300501823425293\n",
      "Value Loss:  4.5867282096878625e-06\n",
      "Q Loss:  0.00042959960410371423\n",
      "Policy Loss:  -0.010162096470594406\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.9515009522438049\n",
      "Q Loss:  0.004468637052923441\n",
      "Policy Loss:  0.11953838169574738\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113593 length: 102 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  54548.671875\n",
      "Q Loss:  51404.0703125\n",
      "Policy Loss:  -60.58881759643555\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113608 length: 15 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.004163380246609449\n",
      "Q Loss:  0.023641031235456467\n",
      "Policy Loss:  -0.0860084593296051\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113612 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.008130289614200592\n",
      "Q Loss:  160.18772888183594\n",
      "Policy Loss:  4.35258674621582\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113616 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004779815673828\n",
      "Value Loss:  0.0011600714642554522\n",
      "Q Loss:  0.002266125287860632\n",
      "Policy Loss:  -0.019761746749281883\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00011503649147925898\n",
      "Q Loss:  0.0011058792006224394\n",
      "Policy Loss:  0.0015109134837985039\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 113624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.00020057019719388336\n",
      "Q Loss:  0.0005527230096049607\n",
      "Policy Loss:  0.01620243489742279\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.000717111979611218\n",
      "Q Loss:  0.0018803906859830022\n",
      "Policy Loss:  -0.017357610166072845\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00861354824155569\n",
      "Q Loss:  0.005863789469003677\n",
      "Policy Loss:  0.005734847858548164\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046927690505981445\n",
      "Value Loss:  0.0260109044611454\n",
      "Q Loss:  0.006912599317729473\n",
      "Policy Loss:  -0.014672585763037205\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00011183370224898681\n",
      "Q Loss:  0.0038741417229175568\n",
      "Policy Loss:  0.009234094992280006\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.4523591995239258\n",
      "Q Loss:  0.005021991208195686\n",
      "Policy Loss:  0.19686757028102875\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113708 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.01033263560384512\n",
      "Q Loss:  0.003596749622374773\n",
      "Policy Loss:  0.006557016633450985\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.0989158153533936\n",
      "Q Loss:  0.004190058447420597\n",
      "Policy Loss:  0.2968049943447113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113756 length: 44 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.024866901338100433\n",
      "Q Loss:  159.16357421875\n",
      "Policy Loss:  4.477959632873535\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113760 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  10964.3408203125\n",
      "Q Loss:  10603.8818359375\n",
      "Policy Loss:  -37.97028732299805\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113836 length: 76 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00029049505246803164\n",
      "Q Loss:  0.00030198224703781307\n",
      "Policy Loss:  -0.004474308341741562\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00017416905029676855\n",
      "Q Loss:  0.0016904438380151987\n",
      "Policy Loss:  0.018816625699400902\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.9656654078280553e-05\n",
      "Q Loss:  0.00021774397464469075\n",
      "Policy Loss:  0.006112344563007355\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0005126548348926008\n",
      "Q Loss:  0.000874740129802376\n",
      "Policy Loss:  0.002429415937513113\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0010167915606871247\n",
      "Q Loss:  0.001740570180118084\n",
      "Policy Loss:  0.0055302842520177364\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003579685289878398\n",
      "Q Loss:  0.00014777856995351613\n",
      "Policy Loss:  0.003802515333518386\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490114688873291\n",
      "Value Loss:  0.00048516871174797416\n",
      "Q Loss:  0.0026688219513744116\n",
      "Policy Loss:  0.04125247895717621\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  195.19903564453125\n",
      "Q Loss:  12.55164909362793\n",
      "Policy Loss:  -21.830711364746094\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113914 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.10709872841835022\n",
      "Q Loss:  0.03495296835899353\n",
      "Policy Loss:  -0.15476258099079132\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 113918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  91.35897827148438\n",
      "Q Loss:  189.22744750976562\n",
      "Policy Loss:  -9.177790641784668\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114025 length: 107 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.003611191175878048\n",
      "Q Loss:  155.8926544189453\n",
      "Policy Loss:  4.35243558883667\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011525869369506836\n",
      "Value Loss:  0.0024105836637318134\n",
      "Q Loss:  0.01419876515865326\n",
      "Policy Loss:  0.04673583433032036\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.001000232296064496\n",
      "Q Loss:  0.0024019700940698385\n",
      "Policy Loss:  -0.013663580641150475\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0006204888923093677\n",
      "Q Loss:  0.004752137698233128\n",
      "Policy Loss:  -0.023185234516859055\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.0003874546673614532\n",
      "Q Loss:  0.001910477178171277\n",
      "Policy Loss:  0.005139767192304134\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  8.009366865735501e-05\n",
      "Q Loss:  0.00016271253116428852\n",
      "Policy Loss:  -0.006244930438697338\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0012903690803796053\n",
      "Q Loss:  0.003974837251007557\n",
      "Policy Loss:  0.02068827673792839\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.03822175785899162\n",
      "Q Loss:  0.012844380922615528\n",
      "Policy Loss:  0.04230264574289322\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01869940757751465\n",
      "Value Loss:  1.6515600681304932\n",
      "Q Loss:  0.011569586582481861\n",
      "Policy Loss:  0.22912928462028503\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114110 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0007191576296463609\n",
      "Q Loss:  0.006785622797906399\n",
      "Policy Loss:  0.048692841082811356\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.0007784435292705894\n",
      "Q Loss:  0.006084843538701534\n",
      "Policy Loss:  0.01759810373187065\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0006160331540741026\n",
      "Q Loss:  0.0006736600189469755\n",
      "Policy Loss:  -0.003723988076671958\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00010207964078290388\n",
      "Q Loss:  0.034686096012592316\n",
      "Policy Loss:  -0.00195589242503047\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.15735454857349396\n",
      "Q Loss:  0.016880949959158897\n",
      "Policy Loss:  -0.09697750955820084\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.1543823927640915\n",
      "Q Loss:  0.02106119878590107\n",
      "Policy Loss:  -0.07050735503435135\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114134 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  115.56828308105469\n",
      "Q Loss:  255.16473388671875\n",
      "Policy Loss:  -11.227075576782227\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114303 length: 169 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  5.44884787814226e-05\n",
      "Q Loss:  0.0009060159791260958\n",
      "Policy Loss:  -0.008208638057112694\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114307 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.00020882626995444298\n",
      "Q Loss:  0.001336210872977972\n",
      "Policy Loss:  0.002178862923756242\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114311 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.00022110734425950795\n",
      "Q Loss:  0.001412404584698379\n",
      "Policy Loss:  0.019170191138982773\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114315 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002923965454102\n",
      "Value Loss:  0.03149585798382759\n",
      "Q Loss:  0.0033024391159415245\n",
      "Policy Loss:  0.06418164074420929\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114319 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.029980989173054695\n",
      "Q Loss:  0.03611235320568085\n",
      "Policy Loss:  0.01934606395661831\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114323 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.056921616196632385\n",
      "Q Loss:  0.0478937104344368\n",
      "Policy Loss:  0.02804342657327652\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114327 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.826041042804718\n",
      "Q Loss:  16.91832160949707\n",
      "Policy Loss:  0.552596390247345\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114435 length: 108 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0005284243961796165\n",
      "Q Loss:  0.013992419466376305\n",
      "Policy Loss:  0.013164263218641281\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.024457676336169243\n",
      "Q Loss:  0.03104506991803646\n",
      "Policy Loss:  0.005577908828854561\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0002168481587432325\n",
      "Q Loss:  0.015495727770030499\n",
      "Policy Loss:  -0.04495804011821747\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.884179775719531e-05\n",
      "Q Loss:  0.0037460867315530777\n",
      "Policy Loss:  0.07537810504436493\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.04285823553800583\n",
      "Q Loss:  0.03988444060087204\n",
      "Policy Loss:  0.04208111763000488\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.04049808531999588\n",
      "Q Loss:  0.02549116685986519\n",
      "Policy Loss:  -0.0184658020734787\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011000871658325195\n",
      "Value Loss:  0.018906965851783752\n",
      "Q Loss:  0.010737319476902485\n",
      "Policy Loss:  0.036399587988853455\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.0003496638673823327\n",
      "Q Loss:  0.0028255674988031387\n",
      "Policy Loss:  0.02060037851333618\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.0007755591068416834\n",
      "Q Loss:  0.00368026876822114\n",
      "Policy Loss:  0.02471514232456684\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001016616821289\n",
      "Value Loss:  3.866166662191972e-05\n",
      "Q Loss:  0.00010928641131613404\n",
      "Policy Loss:  -0.008712396025657654\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.014217189513146877\n",
      "Q Loss:  0.0015492140082642436\n",
      "Policy Loss:  -0.0030304603278636932\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.4711927835596725e-05\n",
      "Q Loss:  0.0011602045269683003\n",
      "Policy Loss:  -0.016283832490444183\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00011705160432029516\n",
      "Q Loss:  0.005567200016230345\n",
      "Policy Loss:  0.0013725047465413809\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0433049201965332\n",
      "Value Loss:  0.0013141634408384562\n",
      "Q Loss:  0.016659323126077652\n",
      "Policy Loss:  -0.049213480204343796\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004294153186492622\n",
      "Q Loss:  151.24842834472656\n",
      "Policy Loss:  4.246550559997559\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  6450.26416015625\n",
      "Q Loss:  6110.03662109375\n",
      "Policy Loss:  -8.044028282165527\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114621 length: 126 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.0193147659301758\n",
      "Q Loss:  0.012385566718876362\n",
      "Policy Loss:  0.11815568804740906\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114712 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.3232933282852173\n",
      "Q Loss:  0.01381022296845913\n",
      "Policy Loss:  0.15836048126220703\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114782 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.00029184113373048604\n",
      "Q Loss:  0.00017062567349057645\n",
      "Policy Loss:  0.007186966948211193\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 114786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00014683551853522658\n",
      "Q Loss:  0.0013773299288004637\n",
      "Policy Loss:  0.011054517701268196\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  5.514684380614199e-05\n",
      "Q Loss:  0.002588269067928195\n",
      "Policy Loss:  0.009538920596241951\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.0003512335242703557\n",
      "Q Loss:  0.00035492831375449896\n",
      "Policy Loss:  -0.005202252417802811\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.00023320189211517572\n",
      "Q Loss:  0.00025392993120476604\n",
      "Policy Loss:  0.0011338931508362293\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.00015507228090427816\n",
      "Q Loss:  0.00031041388865560293\n",
      "Policy Loss:  0.008182574063539505\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020076990127563477\n",
      "Value Loss:  1.6096233593998477e-05\n",
      "Q Loss:  0.00012006971519440413\n",
      "Policy Loss:  0.006556130014359951\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  8.161559526342899e-05\n",
      "Q Loss:  0.0005092328647151589\n",
      "Policy Loss:  0.03671814501285553\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  302.5195617675781\n",
      "Q Loss:  624.9989624023438\n",
      "Policy Loss:  -29.646804809570312\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114911 length: 97 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  0.014193493872880936\n",
      "Q Loss:  0.0018658176995813847\n",
      "Policy Loss:  -0.011167125776410103\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.04368707537651062\n",
      "Q Loss:  0.054943207651376724\n",
      "Policy Loss:  -0.10482634603977203\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.05814851075410843\n",
      "Q Loss:  0.042031120508909225\n",
      "Policy Loss:  -0.1459379494190216\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009596824645996094\n",
      "Value Loss:  0.0003122571506537497\n",
      "Q Loss:  0.00322145177051425\n",
      "Policy Loss:  0.033033594489097595\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000356674194336\n",
      "Value Loss:  0.0004247962206136435\n",
      "Q Loss:  0.0001891563879325986\n",
      "Policy Loss:  0.007582732476294041\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00019681626872625202\n",
      "Q Loss:  0.0012841655407100916\n",
      "Policy Loss:  -0.012628749012947083\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0018994745332747698\n",
      "Q Loss:  0.0020739352330565453\n",
      "Policy Loss:  0.02572885900735855\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 114939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.000835341343190521\n",
      "Q Loss:  0.0006361256819218397\n",
      "Policy Loss:  0.014015067368745804\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 114943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  6.307035073405132e-05\n",
      "Q Loss:  0.00017301850311923772\n",
      "Policy Loss:  -0.006545497570186853\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 114947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  8.381724910577759e-05\n",
      "Q Loss:  0.0005000795936211944\n",
      "Policy Loss:  -0.014668823219835758\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 114951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  48.43184280395508\n",
      "Q Loss:  132.5251922607422\n",
      "Policy Loss:  -3.8687849044799805\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115154 length: 203 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03400707244873047\n",
      "Value Loss:  0.02280869521200657\n",
      "Q Loss:  0.02333826571702957\n",
      "Policy Loss:  0.0752185806632042\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  103.45891571044922\n",
      "Q Loss:  189.4259490966797\n",
      "Policy Loss:  -9.872014045715332\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115253 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0001084805335267447\n",
      "Q Loss:  0.0003285367856733501\n",
      "Policy Loss:  -0.0036163125187158585\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0001594131754245609\n",
      "Q Loss:  0.0014216072158887982\n",
      "Policy Loss:  0.016012350097298622\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  7.654365617781878e-05\n",
      "Q Loss:  0.0010892110876739025\n",
      "Policy Loss:  0.01214209571480751\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.03426320478320122\n",
      "Q Loss:  0.0034071109257638454\n",
      "Policy Loss:  0.05432254821062088\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 115269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  28018.962890625\n",
      "Q Loss:  26423.931640625\n",
      "Policy Loss:  -33.15979766845703\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115298 length: 29 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014571666717529297\n",
      "Value Loss:  2.246795156679582e-05\n",
      "Q Loss:  0.00012266018893569708\n",
      "Policy Loss:  -0.006217507645487785\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115302 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.502914309501648\n",
      "Q Loss:  0.0034550917334854603\n",
      "Policy Loss:  0.2221517413854599\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115363 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02300572395324707\n",
      "Value Loss:  2452.528564453125\n",
      "Q Loss:  5126.77392578125\n",
      "Policy Loss:  -137.25079345703125\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  1.1551678653631825e-05\n",
      "Q Loss:  0.022356288507580757\n",
      "Policy Loss:  0.045438237488269806\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0005956105887889862\n",
      "Q Loss:  0.0014784714439883828\n",
      "Policy Loss:  -0.01498334389179945\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00042432063492015004\n",
      "Q Loss:  0.0011504334397614002\n",
      "Policy Loss:  -0.02089632675051689\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.0123736501554959e-05\n",
      "Q Loss:  8.229588274843991e-05\n",
      "Policy Loss:  0.0058837151154875755\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  0.03884196653962135\n",
      "Q Loss:  0.005090096965432167\n",
      "Policy Loss:  -0.017177384346723557\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.8581125736236572\n",
      "Q Loss:  0.0027686289977282286\n",
      "Policy Loss:  0.11314897984266281\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115492 length: 105 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0010021348716691136\n",
      "Q Loss:  0.0019473491702228785\n",
      "Policy Loss:  -0.02502831257879734\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115496 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005796432495117\n",
      "Value Loss:  0.0002829144650604576\n",
      "Q Loss:  0.026502808555960655\n",
      "Policy Loss:  -0.07083017379045486\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115500 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0005783111555501819\n",
      "Q Loss:  301.01556396484375\n",
      "Policy Loss:  8.401509284973145\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115504 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  6.73474496579729e-05\n",
      "Q Loss:  0.01864362508058548\n",
      "Policy Loss:  -0.022614315152168274\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115508 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  6.494603439932689e-05\n",
      "Q Loss:  0.00046652162563987076\n",
      "Policy Loss:  -0.004690036177635193\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115512 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00013483353541232646\n",
      "Q Loss:  0.00014628414646722376\n",
      "Policy Loss:  0.005119796842336655\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115516 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0004299851134419441\n",
      "Q Loss:  0.0007011648267507553\n",
      "Policy Loss:  0.016072005033493042\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115520 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.7692707842797972e-05\n",
      "Q Loss:  1.8174325305153616e-05\n",
      "Policy Loss:  0.00854625552892685\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115524 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00012936824350617826\n",
      "Q Loss:  0.0012380479602143168\n",
      "Policy Loss:  0.02002490684390068\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00011271916446276009\n",
      "Q Loss:  0.000322664127452299\n",
      "Policy Loss:  0.0059188841842114925\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.9168466329574585\n",
      "Q Loss:  0.0060860756784677505\n",
      "Policy Loss:  0.28746500611305237\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115578 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008348251576535404\n",
      "Q Loss:  0.0017156433314085007\n",
      "Policy Loss:  0.02891010046005249\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  2.007933653658256e-05\n",
      "Q Loss:  0.0001851477863965556\n",
      "Policy Loss:  -0.001524324994534254\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.399887231760658e-05\n",
      "Q Loss:  4.9719612434273586e-05\n",
      "Policy Loss:  -0.006888741161674261\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115590 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.8998259191866964e-05\n",
      "Q Loss:  6.632372969761491e-05\n",
      "Policy Loss:  -0.0016687910538166761\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.06422307342290878\n",
      "Q Loss:  0.006543146912008524\n",
      "Policy Loss:  -0.006988495588302612\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.09719677269458771\n",
      "Q Loss:  0.05728597939014435\n",
      "Policy Loss:  -0.06620541960000992\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.031778231263160706\n",
      "Q Loss:  0.013828298076987267\n",
      "Policy Loss:  0.02541661262512207\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.446915333275683e-07\n",
      "Q Loss:  6.036215381755028e-06\n",
      "Policy Loss:  0.0008348016417585313\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  3.3525651815580204e-05\n",
      "Q Loss:  0.00015931754023768008\n",
      "Policy Loss:  0.007606382481753826\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115614 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005558013916016\n",
      "Value Loss:  2.3212902306113392e-05\n",
      "Q Loss:  0.000539708707947284\n",
      "Policy Loss:  0.014853637665510178\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115618 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.9696180718019605e-05\n",
      "Q Loss:  0.000686554005369544\n",
      "Policy Loss:  0.012295307591557503\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  2.6461875677341595e-05\n",
      "Q Loss:  4.7378413000842556e-05\n",
      "Policy Loss:  0.00011948661995120347\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  8.163667189364787e-06\n",
      "Q Loss:  0.00010392895637778565\n",
      "Policy Loss:  -9.890570072457194e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.02738369256258011\n",
      "Q Loss:  0.01093739178031683\n",
      "Policy Loss:  0.09555308520793915\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.1879137754440308\n",
      "Q Loss:  0.009719090536236763\n",
      "Policy Loss:  0.1959882229566574\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115708 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0003011900989804417\n",
      "Q Loss:  0.00013168525765649974\n",
      "Policy Loss:  0.0027073535602539778\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.02702314406633377\n",
      "Q Loss:  0.0050005014054477215\n",
      "Policy Loss:  0.019134249538183212\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115716 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  1.3177645206451416\n",
      "Q Loss:  0.007455128710716963\n",
      "Policy Loss:  0.19585081934928894\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115783 length: 67 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  5.049340325058438e-05\n",
      "Q Loss:  0.0014506563311442733\n",
      "Policy Loss:  0.02128424122929573\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.67061103740707e-05\n",
      "Q Loss:  0.0006294712657108903\n",
      "Policy Loss:  7.95281957834959e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.08573375642299652\n",
      "Q Loss:  0.018511410802602768\n",
      "Policy Loss:  -0.05205842852592468\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115795 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.028219373896718025\n",
      "Q Loss:  0.0068997470661997795\n",
      "Policy Loss:  0.021794047206640244\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.05522909015417099\n",
      "Q Loss:  0.01088419184088707\n",
      "Policy Loss:  -0.055603377521038055\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010422229766845703\n",
      "Value Loss:  0.026553427800536156\n",
      "Q Loss:  0.00506396172568202\n",
      "Policy Loss:  0.02751445583999157\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.8606842756271362\n",
      "Q Loss:  0.006836287211626768\n",
      "Policy Loss:  0.130793496966362\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115911 length: 104 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4877.8623046875\n",
      "Q Loss:  8955.966796875\n",
      "Policy Loss:  -113.97567749023438\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00043445726623758674\n",
      "Q Loss:  145.88475036621094\n",
      "Policy Loss:  4.273457050323486\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0008235533023253083\n",
      "Q Loss:  0.002125113969668746\n",
      "Policy Loss:  0.018848543986678123\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.0007903046789579093\n",
      "Q Loss:  0.00025521343923173845\n",
      "Policy Loss:  0.007056525908410549\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0001192524068756029\n",
      "Q Loss:  0.00017594672681298107\n",
      "Policy Loss:  -0.0071913269348442554\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.022632908076047897\n",
      "Q Loss:  0.00919438898563385\n",
      "Policy Loss:  0.02234458364546299\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 115935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.0927940607070923\n",
      "Q Loss:  14.297786712646484\n",
      "Policy Loss:  0.5684565305709839\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116017 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  7.678712427150458e-05\n",
      "Q Loss:  0.0002793149324133992\n",
      "Policy Loss:  -0.01085388008505106\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  4.514303873293102e-05\n",
      "Q Loss:  0.00027489333297125995\n",
      "Policy Loss:  -0.008560283109545708\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.06711482256650925\n",
      "Q Loss:  0.011727266944944859\n",
      "Policy Loss:  -0.014882508665323257\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04357641190290451\n",
      "Q Loss:  0.009773781523108482\n",
      "Policy Loss:  0.0010827593505382538\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.02085288055241108\n",
      "Q Loss:  0.0020178586710244417\n",
      "Policy Loss:  0.020662417635321617\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900909423828125\n",
      "Value Loss:  0.019834524020552635\n",
      "Q Loss:  0.007693078834563494\n",
      "Policy Loss:  -0.02585652843117714\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00012075101403752342\n",
      "Q Loss:  0.0023857024498283863\n",
      "Policy Loss:  -0.02800559438765049\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  7.931602885946631e-05\n",
      "Q Loss:  0.0007294424576684833\n",
      "Policy Loss:  -0.013697946444153786\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  1.0798158655234147e-05\n",
      "Q Loss:  0.0001182538690045476\n",
      "Policy Loss:  -0.004965800791978836\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  1.948388307937421e-05\n",
      "Q Loss:  0.00027311797020956874\n",
      "Policy Loss:  -0.006850197911262512\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003732681274414\n",
      "Value Loss:  0.031009318307042122\n",
      "Q Loss:  0.021089540794491768\n",
      "Policy Loss:  0.01099427416920662\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.7144455909729004\n",
      "Q Loss:  0.0028511600103229284\n",
      "Policy Loss:  0.250429630279541\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116114 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  10886.0380859375\n",
      "Q Loss:  10302.0126953125\n",
      "Policy Loss:  -12.738863945007324\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116189 length: 75 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.036008596420288086\n",
      "Value Loss:  14744.9462890625\n",
      "Q Loss:  14131.48828125\n",
      "Policy Loss:  -33.33253860473633\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116245 length: 56 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.03144383430480957\n",
      "Q Loss:  0.006908948067575693\n",
      "Policy Loss:  -0.03371444344520569\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  8.722917300474364e-06\n",
      "Q Loss:  0.0002749496779870242\n",
      "Policy Loss:  0.007636974100023508\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  8.376870027859695e-06\n",
      "Q Loss:  1.741019332257565e-05\n",
      "Policy Loss:  7.38279486540705e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.162159580620937e-05\n",
      "Q Loss:  0.0019469023682177067\n",
      "Policy Loss:  0.024670450016856194\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  2.071250492008403e-06\n",
      "Q Loss:  2.6436523512529675e-06\n",
      "Policy Loss:  -0.0003982746275141835\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  2.4737228159210645e-05\n",
      "Q Loss:  0.0011161810252815485\n",
      "Policy Loss:  0.052581317722797394\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.07068829983472824\n",
      "Q Loss:  0.01346434187144041\n",
      "Policy Loss:  -0.09569409489631653\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116273 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.03440779447555542\n",
      "Q Loss:  0.0074984231032431126\n",
      "Policy Loss:  0.030533380806446075\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.016447674483060837\n",
      "Q Loss:  0.003942514304071665\n",
      "Policy Loss:  0.05926971882581711\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  105.78900909423828\n",
      "Q Loss:  216.8571014404297\n",
      "Policy Loss:  -10.722480773925781\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116371 length: 90 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.000611334980931133\n",
      "Q Loss:  0.01499570719897747\n",
      "Policy Loss:  -0.0606267973780632\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.001114340266212821\n",
      "Q Loss:  0.0035194475203752518\n",
      "Policy Loss:  -0.03171034902334213\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0008735337760299444\n",
      "Q Loss:  0.0012958229053765535\n",
      "Policy Loss:  -0.015415336936712265\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01106119155883789\n",
      "Value Loss:  3.670923979370855e-05\n",
      "Q Loss:  293.5357360839844\n",
      "Policy Loss:  8.371405601501465\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5724.1298828125\n",
      "Q Loss:  5718.78515625\n",
      "Policy Loss:  -30.727670669555664\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116536 length: 149 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4728.3310546875\n",
      "Q Loss:  8623.939453125\n",
      "Policy Loss:  -112.56954193115234\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  2353.29443359375\n",
      "Q Loss:  5001.572265625\n",
      "Policy Loss:  -113.50444793701172\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.0012899247230961919\n",
      "Q Loss:  0.0066331857815384865\n",
      "Policy Loss:  0.03976917266845703\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0020051421597599983\n",
      "Q Loss:  0.003275357186794281\n",
      "Policy Loss:  0.038029491901397705\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0013310533249750733\n",
      "Q Loss:  0.006147199310362339\n",
      "Policy Loss:  0.04210968688130379\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.037007808685302734\n",
      "Value Loss:  0.0021977631840854883\n",
      "Q Loss:  0.002024890622124076\n",
      "Policy Loss:  0.021469511091709137\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  0.0009206065442413092\n",
      "Q Loss:  0.0010207443265244365\n",
      "Policy Loss:  0.013077184557914734\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.00016666976443957537\n",
      "Q Loss:  0.0004327368806116283\n",
      "Policy Loss:  -0.004751172848045826\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116568 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0003621123032644391\n",
      "Q Loss:  0.0011028838343918324\n",
      "Policy Loss:  -0.030127596110105515\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0004066799592692405\n",
      "Q Loss:  0.0010438587050884962\n",
      "Policy Loss:  -0.017639756202697754\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116576 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0009414894739165902\n",
      "Q Loss:  0.0009042060701176524\n",
      "Policy Loss:  -0.01972603239119053\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116580 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0011199724394828081\n",
      "Q Loss:  0.0011413244064897299\n",
      "Policy Loss:  -0.025729715824127197\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116584 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00032891982118599117\n",
      "Q Loss:  0.0007119523361325264\n",
      "Policy Loss:  -0.00201857415959239\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  8.215860725613311e-05\n",
      "Q Loss:  0.013987617567181587\n",
      "Policy Loss:  -0.002132306806743145\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.029912205412983894\n",
      "Q Loss:  0.006159291602671146\n",
      "Policy Loss:  -0.041533127427101135\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  179.52713012695312\n",
      "Q Loss:  220.42691040039062\n",
      "Policy Loss:  -19.817350387573242\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116696 length: 100 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.701944140426349e-05\n",
      "Q Loss:  0.00023549329489469528\n",
      "Policy Loss:  0.01007487066090107\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116700 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.0811007743759546e-06\n",
      "Q Loss:  7.637705857632682e-05\n",
      "Policy Loss:  0.0007870174013078213\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116704 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.045331910252571106\n",
      "Q Loss:  0.00696445070207119\n",
      "Policy Loss:  -0.016784895211458206\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116708 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.029572805389761925\n",
      "Q Loss:  0.007418299559503794\n",
      "Policy Loss:  -0.014385920017957687\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200556755065918\n",
      "Value Loss:  1.7036871910095215\n",
      "Q Loss:  0.004370787180960178\n",
      "Policy Loss:  0.2446097731590271\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116766 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0571475587785244\n",
      "Q Loss:  0.008465235121548176\n",
      "Policy Loss:  -0.04902994632720947\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  25141.083984375\n",
      "Q Loss:  24118.3046875\n",
      "Policy Loss:  -53.36101531982422\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116803 length: 33 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2215.257080078125\n",
      "Q Loss:  4549.8212890625\n",
      "Policy Loss:  -129.0987091064453\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116807 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05601239204406738\n",
      "Value Loss:  0.0007505756802856922\n",
      "Q Loss:  0.00185362808406353\n",
      "Policy Loss:  -0.004653747659176588\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116811 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0008313829894177616\n",
      "Q Loss:  0.00044310660450719297\n",
      "Policy Loss:  0.01479215919971466\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116815 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.0102523901878158e-06\n",
      "Q Loss:  0.005108988843858242\n",
      "Policy Loss:  0.042751044034957886\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116819 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.031217500567436218\n",
      "Q Loss:  0.001044829492457211\n",
      "Policy Loss:  0.03569025918841362\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116823 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  0.06231188774108887\n",
      "Q Loss:  1.8994994661625242e-06\n",
      "Policy Loss:  -0.014312946237623692\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116827 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5824.26806640625\n",
      "Q Loss:  5677.21337890625\n",
      "Policy Loss:  -19.542325973510742\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116971 length: 144 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0003536621807143092\n",
      "Q Loss:  0.00037969276309013367\n",
      "Policy Loss:  0.002912275493144989\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 116975 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.368202442288748e-06\n",
      "Q Loss:  0.0003152199205942452\n",
      "Policy Loss:  0.0045586093328893185\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116979 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.027916308492422104\n",
      "Q Loss:  0.02820579521358013\n",
      "Policy Loss:  0.07088901102542877\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 116983 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  165.02615356445312\n",
      "Q Loss:  290.1858215332031\n",
      "Policy Loss:  -16.509553909301758\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117037 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00048595244879834354\n",
      "Q Loss:  0.00021637922327499837\n",
      "Policy Loss:  0.0026002100203186274\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  4.091463051736355e-05\n",
      "Q Loss:  0.0003526476211845875\n",
      "Policy Loss:  -0.0022112932056188583\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.4999819288495928e-05\n",
      "Q Loss:  2.203275653300807e-05\n",
      "Policy Loss:  -0.0032056844793260098\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600503921508789\n",
      "Value Loss:  0.01432601548731327\n",
      "Q Loss:  0.007848949171602726\n",
      "Policy Loss:  0.007708696648478508\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  271.8388977050781\n",
      "Q Loss:  553.9407348632812\n",
      "Policy Loss:  -27.831594467163086\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117183 length: 130 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011998171976301819\n",
      "Q Loss:  0.00035754070268012583\n",
      "Policy Loss:  -0.008331019431352615\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  6.0993852457613684e-06\n",
      "Q Loss:  0.0017191251972690225\n",
      "Policy Loss:  -0.018741440027952194\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117191 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301237106323242\n",
      "Value Loss:  1.0652077435224783e-05\n",
      "Q Loss:  0.004037212580442429\n",
      "Policy Loss:  -0.03281807526946068\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  5.315201633493416e-06\n",
      "Q Loss:  0.0018957880092784762\n",
      "Policy Loss:  -0.016417628154158592\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.031303055584430695\n",
      "Q Loss:  0.024849869310855865\n",
      "Policy Loss:  -0.048815660178661346\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117203 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.031063981354236603\n",
      "Q Loss:  0.006309495307505131\n",
      "Policy Loss:  0.0006536580622196198\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117207 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.01512526348233223\n",
      "Q Loss:  0.014477171003818512\n",
      "Policy Loss:  0.0003533046692609787\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.014618977904319763\n",
      "Q Loss:  0.005426076706498861\n",
      "Policy Loss:  -0.0009658001363277435\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00015774212079122663\n",
      "Q Loss:  8.66732734721154e-05\n",
      "Policy Loss:  -0.0018357890658080578\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  1.2063393342032214e-06\n",
      "Q Loss:  8.929141040425748e-05\n",
      "Policy Loss:  0.006939403712749481\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.053011417388916016\n",
      "Value Loss:  3.877310155075975e-05\n",
      "Q Loss:  0.007918870076537132\n",
      "Policy Loss:  0.04908567667007446\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  281.20892333984375\n",
      "Q Loss:  572.8091430664062\n",
      "Policy Loss:  -27.286659240722656\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117321 length: 94 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.3479720766772516e-05\n",
      "Q Loss:  8.972188516054302e-05\n",
      "Policy Loss:  -5.172839155420661e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.4636124433309305e-05\n",
      "Q Loss:  0.004580439534038305\n",
      "Policy Loss:  0.024925116449594498\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.947496785869589e-06\n",
      "Q Loss:  4.188181628705934e-05\n",
      "Policy Loss:  0.0021133541595190763\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  9.23220613913145e-06\n",
      "Q Loss:  0.00010075850877910852\n",
      "Policy Loss:  0.00038735810085199773\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117337 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.418518079139176e-06\n",
      "Q Loss:  1.222887476615142e-05\n",
      "Policy Loss:  -0.002946964930742979\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117341 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.012606398202478886\n",
      "Q Loss:  0.0029874129686504602\n",
      "Policy Loss:  0.015329372137784958\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.5157599449157715\n",
      "Q Loss:  0.005954614840447903\n",
      "Policy Loss:  0.20218579471111298\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117406 length: 61 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.281427025794983\n",
      "Q Loss:  0.007580990437418222\n",
      "Policy Loss:  0.1973215788602829\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117478 length: 72 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.0488858222961426\n",
      "Q Loss:  0.0029921415261924267\n",
      "Policy Loss:  0.16411477327346802\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117565 length: 87 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014005422592163086\n",
      "Value Loss:  11157.654296875\n",
      "Q Loss:  10924.4130859375\n",
      "Policy Loss:  -46.21611785888672\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117641 length: 76 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2189.116455078125\n",
      "Q Loss:  3423.791259765625\n",
      "Policy Loss:  -169.770263671875\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.00011492783232824877\n",
      "Q Loss:  0.0003347737656440586\n",
      "Policy Loss:  -0.006012003868818283\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.044010162353515625\n",
      "Value Loss:  4.606269794749096e-05\n",
      "Q Loss:  0.00020907602447550744\n",
      "Policy Loss:  -0.00033924938179552555\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00028982883668504655\n",
      "Q Loss:  0.0018280649092048407\n",
      "Policy Loss:  0.038452982902526855\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  148.9529266357422\n",
      "Q Loss:  240.72152709960938\n",
      "Policy Loss:  -15.818862915039062\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 117716 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.848434840212576e-05\n",
      "Q Loss:  0.00011460237146820873\n",
      "Policy Loss:  -0.00503246346488595\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.226367258932441e-05\n",
      "Q Loss:  2.2377222194336355e-05\n",
      "Policy Loss:  -4.624796565622091e-05\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  8.270157559309155e-05\n",
      "Q Loss:  0.000977938063442707\n",
      "Policy Loss:  0.013317221775650978\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.0003167517425027e-05\n",
      "Q Loss:  0.00010747813939815387\n",
      "Policy Loss:  0.0010400810278952122\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117732 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  1.2197347132314462e-06\n",
      "Q Loss:  4.380383325042203e-05\n",
      "Policy Loss:  0.0017227045027539134\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  2.1719573851441965e-05\n",
      "Q Loss:  0.0023116767406463623\n",
      "Policy Loss:  0.050438009202480316\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117740 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.09707430005073547\n",
      "Q Loss:  0.045058682560920715\n",
      "Policy Loss:  -0.10322693735361099\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117744 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019016027450561523\n",
      "Value Loss:  0.12993822991847992\n",
      "Q Loss:  0.027986692264676094\n",
      "Policy Loss:  -0.11717414110898972\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.872236967086792\n",
      "Q Loss:  6.104243755340576\n",
      "Policy Loss:  0.3201049268245697\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117848 length: 100 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002290469128638506\n",
      "Q Loss:  0.0005921800038777292\n",
      "Policy Loss:  0.016558540984988213\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005625380435958505\n",
      "Q Loss:  0.0007270856876857579\n",
      "Policy Loss:  0.012214908376336098\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00026390963466838\n",
      "Q Loss:  0.00014320971968118101\n",
      "Policy Loss:  0.002238444285467267\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  0.08992310613393784\n",
      "Q Loss:  0.0004202892305329442\n",
      "Policy Loss:  0.03501136973500252\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  367.7696533203125\n",
      "Q Loss:  696.2601318359375\n",
      "Policy Loss:  -36.16200637817383\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117911 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  0.00023597509425599128\n",
      "Q Loss:  0.0001578211085870862\n",
      "Policy Loss:  0.003442479996010661\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 117915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020005464553833008\n",
      "Value Loss:  1.10846394818509e-05\n",
      "Q Loss:  0.0002694657596293837\n",
      "Policy Loss:  0.010171454399824142\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.8647741626409697e-06\n",
      "Q Loss:  0.0001494001189712435\n",
      "Policy Loss:  0.006304292939603329\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1490114047774114e-05\n",
      "Q Loss:  5.832528040627949e-05\n",
      "Policy Loss:  0.003044955199584365\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.6638852432370186e-05\n",
      "Q Loss:  2.4989882149384357e-05\n",
      "Policy Loss:  0.0005609124782495201\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.175571171392221e-05\n",
      "Q Loss:  4.6770560402364936e-06\n",
      "Policy Loss:  -0.0012245504185557365\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  5.2169314585626125e-05\n",
      "Q Loss:  4.467480903258547e-05\n",
      "Policy Loss:  -0.00017294572899118066\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013080835342407227\n",
      "Value Loss:  4.9100806791102514e-05\n",
      "Q Loss:  2.387606946285814e-05\n",
      "Policy Loss:  0.0004138863296248019\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0014521373668685555\n",
      "Q Loss:  0.011467786505818367\n",
      "Policy Loss:  0.026545656844973564\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.002513315062969923\n",
      "Q Loss:  0.010800227522850037\n",
      "Policy Loss:  0.022936400026082993\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0013982761884108186\n",
      "Q Loss:  0.008027629926800728\n",
      "Policy Loss:  0.023065410554409027\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117955 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.02966022863984108\n",
      "Q Loss:  0.04542161896824837\n",
      "Policy Loss:  0.07155227661132812\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 117959 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  143.86395263671875\n",
      "Q Loss:  279.2401428222656\n",
      "Policy Loss:  -15.373730659484863\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118019 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.994705022909329e-07\n",
      "Q Loss:  0.0005066712619736791\n",
      "Policy Loss:  0.04893375188112259\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118023 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.09089983999729156\n",
      "Q Loss:  0.06351696699857712\n",
      "Policy Loss:  0.03805328905582428\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118027 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400920867919922\n",
      "Value Loss:  0.02994425594806671\n",
      "Q Loss:  0.025737009942531586\n",
      "Policy Loss:  0.011868845671415329\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  228.6851348876953\n",
      "Q Loss:  440.9853210449219\n",
      "Policy Loss:  -23.127201080322266\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118106 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011579513549804688\n",
      "Value Loss:  0.0026656733825802803\n",
      "Q Loss:  0.0021261393558233976\n",
      "Policy Loss:  0.024994580075144768\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118110 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.03166917711496353\n",
      "Q Loss:  0.009777886793017387\n",
      "Policy Loss:  0.028006156906485558\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.7205987609922886e-05\n",
      "Q Loss:  0.025240551680326462\n",
      "Policy Loss:  -0.10511733591556549\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  194.02078247070312\n",
      "Q Loss:  322.44488525390625\n",
      "Policy Loss:  -20.36849594116211\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118294 length: 176 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00043489891686476767\n",
      "Q Loss:  0.0007643219432793558\n",
      "Policy Loss:  -0.00925079733133316\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118298 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004904646193608642\n",
      "Q Loss:  0.0033217177260667086\n",
      "Policy Loss:  -0.03088708221912384\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118302 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0004760035080835223\n",
      "Q Loss:  0.003828322049230337\n",
      "Policy Loss:  -0.022219963371753693\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118306 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2.6465444564819336\n",
      "Q Loss:  0.018421312794089317\n",
      "Policy Loss:  0.36945587396621704\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118339 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.7812813136260957e-05\n",
      "Q Loss:  0.002746282145380974\n",
      "Policy Loss:  -0.019426805898547173\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118343 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.03364439308643341\n",
      "Q Loss:  0.02434227056801319\n",
      "Policy Loss:  -0.012247707694768906\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118347 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  14759.302734375\n",
      "Q Loss:  14456.7919921875\n",
      "Policy Loss:  -42.444000244140625\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118404 length: 57 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.667656660079956e-05\n",
      "Q Loss:  0.0016829570522531867\n",
      "Policy Loss:  -0.014014968648552895\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0003092465049121529\n",
      "Q Loss:  0.0010068612173199654\n",
      "Policy Loss:  -0.013728405348956585\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0006137267337180674\n",
      "Q Loss:  0.0024755680933594704\n",
      "Policy Loss:  0.01366510521620512\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0011976535897701979\n",
      "Q Loss:  0.0011996169341728091\n",
      "Policy Loss:  0.05724699795246124\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.12656041979789734\n",
      "Q Loss:  0.046963032335042953\n",
      "Policy Loss:  -0.10698605328798294\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013005256652832031\n",
      "Value Loss:  0.12631213665008545\n",
      "Q Loss:  0.041003406047821045\n",
      "Policy Loss:  -0.12746299803256989\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0003378958208486438\n",
      "Q Loss:  0.0024708276614546776\n",
      "Policy Loss:  0.028836935758590698\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013009309768676758\n",
      "Value Loss:  0.0795283243060112\n",
      "Q Loss:  0.04474399611353874\n",
      "Policy Loss:  -0.018124926835298538\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  19356.17578125\n",
      "Q Loss:  18685.59765625\n",
      "Policy Loss:  -40.601463317871094\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118479 length: 43 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015001058578491211\n",
      "Value Loss:  6.677851342828944e-05\n",
      "Q Loss:  5.467413575388491e-05\n",
      "Policy Loss:  0.005395690910518169\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490107536315918\n",
      "Value Loss:  0.00028657010989263654\n",
      "Q Loss:  0.0006203657831065357\n",
      "Policy Loss:  0.015414094552397728\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0001224884472321719\n",
      "Q Loss:  0.0012960409512743354\n",
      "Policy Loss:  0.01881972700357437\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00049039744772017\n",
      "Q Loss:  0.01815883442759514\n",
      "Policy Loss:  0.06881162524223328\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.9826338291168213\n",
      "Q Loss:  0.03500896319746971\n",
      "Policy Loss:  0.5457401275634766\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118524 length: 29 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0006067489739507437\n",
      "Q Loss:  0.0010427935048937798\n",
      "Policy Loss:  0.01690247468650341\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 118528 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00033138261642307043\n",
      "Q Loss:  0.031005367636680603\n",
      "Policy Loss:  0.08330069482326508\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 118532 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.0003591104468796402\n",
      "Q Loss:  0.02677076682448387\n",
      "Policy Loss:  0.06466004252433777\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118536 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100396156311035\n",
      "Value Loss:  0.0002055788500001654\n",
      "Q Loss:  0.0010575799969956279\n",
      "Policy Loss:  -0.0009519921150058508\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00033018607064150274\n",
      "Q Loss:  0.00026522588450461626\n",
      "Policy Loss:  -0.008021981455385685\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.00023074900673236698\n",
      "Q Loss:  0.000581108033657074\n",
      "Policy Loss:  -0.01356225460767746\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05601334571838379\n",
      "Value Loss:  0.09155155718326569\n",
      "Q Loss:  0.052479274570941925\n",
      "Policy Loss:  0.027480438351631165\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.42978450655937195\n",
      "Q Loss:  8.821135520935059\n",
      "Policy Loss:  0.31483471393585205\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118759 length: 207 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.988098276546225e-05\n",
      "Q Loss:  0.0005598943680524826\n",
      "Policy Loss:  -0.01289926003664732\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.000597909209318459\n",
      "Q Loss:  0.0022106110118329525\n",
      "Policy Loss:  -0.024039309471845627\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.09267649799585342\n",
      "Q Loss:  0.06069468706846237\n",
      "Policy Loss:  0.012371368706226349\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.04560915380716324\n",
      "Q Loss:  0.02017478086054325\n",
      "Policy Loss:  -0.027512090280652046\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  56991.59765625\n",
      "Q Loss:  54604.3125\n",
      "Policy Loss:  -84.42076873779297\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118804 length: 29 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.395528129767627e-05\n",
      "Q Loss:  304.4907531738281\n",
      "Policy Loss:  8.564003944396973\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118808 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2206.958740234375\n",
      "Q Loss:  4309.06640625\n",
      "Policy Loss:  -150.51434326171875\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06401371955871582\n",
      "Value Loss:  2213.308349609375\n",
      "Q Loss:  4313.9658203125\n",
      "Policy Loss:  -150.5402374267578\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.161053948337212e-05\n",
      "Q Loss:  0.0016326692420989275\n",
      "Policy Loss:  0.0010400027967989445\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118820 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  0.0003557107411324978\n",
      "Q Loss:  0.002073496114462614\n",
      "Policy Loss:  -0.021826282143592834\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0003882028686348349\n",
      "Q Loss:  0.001374383457005024\n",
      "Policy Loss:  -0.01807020604610443\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001311766100116074\n",
      "Q Loss:  0.000513171951752156\n",
      "Policy Loss:  -0.0033471467904746532\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00022815176635049284\n",
      "Q Loss:  0.003790855873376131\n",
      "Policy Loss:  0.03591778129339218\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0003080126771237701\n",
      "Q Loss:  0.0020534927025437355\n",
      "Policy Loss:  0.024497665464878082\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.41972544346936e-05\n",
      "Q Loss:  0.0010958041530102491\n",
      "Policy Loss:  -0.007385041564702988\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.198851118213497e-05\n",
      "Q Loss:  0.00035543268313631415\n",
      "Policy Loss:  0.009525296278297901\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  9.678029528004117e-06\n",
      "Q Loss:  0.0015579862520098686\n",
      "Policy Loss:  0.02076786756515503\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.1321348249912262\n",
      "Q Loss:  0.016077186912298203\n",
      "Policy Loss:  -0.02736186608672142\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.042908210307359695\n",
      "Q Loss:  0.015118065290153027\n",
      "Policy Loss:  -0.016857832670211792\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.12384940683841705\n",
      "Q Loss:  0.010124560445547104\n",
      "Policy Loss:  -0.010071564465761185\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.07762669771909714\n",
      "Q Loss:  0.03230243921279907\n",
      "Policy Loss:  0.017438605427742004\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0012800201075151563\n",
      "Q Loss:  0.00435358053073287\n",
      "Policy Loss:  0.019446462392807007\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118872 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0016986147966235876\n",
      "Q Loss:  0.001753377728164196\n",
      "Policy Loss:  0.025288056582212448\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118876 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012543439865112305\n",
      "Value Loss:  0.0011436358327046037\n",
      "Q Loss:  0.03044591099023819\n",
      "Policy Loss:  -0.059681203216314316\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0012455637333914638\n",
      "Q Loss:  1201.1796875\n",
      "Policy Loss:  13.196428298950195\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 118884 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  58622.44140625\n",
      "Q Loss:  55784.015625\n",
      "Policy Loss:  -64.89314270019531\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118912 length: 28 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00048689727555029094\n",
      "Q Loss:  0.030229587107896805\n",
      "Policy Loss:  -0.044181980192661285\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002321087958989665\n",
      "Q Loss:  0.015251345932483673\n",
      "Policy Loss:  -0.0050495220348238945\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 118920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2253.816162109375\n",
      "Q Loss:  4327.71728515625\n",
      "Policy Loss:  -152.21250915527344\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 118924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011601448059082031\n",
      "Value Loss:  8.050996257225052e-05\n",
      "Q Loss:  0.01953069679439068\n",
      "Policy Loss:  0.13001945614814758\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 118928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00022154461476020515\n",
      "Q Loss:  0.017626643180847168\n",
      "Policy Loss:  0.08036090433597565\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 118932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0014175496762618423\n",
      "Q Loss:  0.0005619944422505796\n",
      "Policy Loss:  -0.0044412557035684586\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 118936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.0006086945068091154\n",
      "Q Loss:  0.000645965279545635\n",
      "Policy Loss:  -0.000417245551943779\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 118940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0004160853277426213\n",
      "Q Loss:  0.010102640837430954\n",
      "Policy Loss:  0.05504179000854492\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 118944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02500462532043457\n",
      "Value Loss:  7.412179547827691e-05\n",
      "Q Loss:  0.0016731778159737587\n",
      "Policy Loss:  0.06472993642091751\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 118948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.024690866470337\n",
      "Q Loss:  0.009761374443769455\n",
      "Policy Loss:  0.16950570046901703\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119036 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  5.356029942049645e-05\n",
      "Q Loss:  0.0002037755912169814\n",
      "Policy Loss:  -0.005356155335903168\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119040 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  8.41439759824425e-05\n",
      "Q Loss:  0.00037832732778042555\n",
      "Policy Loss:  -0.00672456668689847\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119044 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300975799560547\n",
      "Value Loss:  0.07310213893651962\n",
      "Q Loss:  0.017208917066454887\n",
      "Policy Loss:  0.014486061409115791\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119048 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  14099.69921875\n",
      "Q Loss:  13424.7685546875\n",
      "Policy Loss:  -16.984113693237305\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119106 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  0.000267259863903746\n",
      "Q Loss:  0.0001932661107275635\n",
      "Policy Loss:  -0.005197750870138407\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119110 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.2797670364379883\n",
      "Q Loss:  0.010404982604086399\n",
      "Policy Loss:  0.1891847848892212\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119180 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0015959169249981642\n",
      "Q Loss:  0.011090070009231567\n",
      "Policy Loss:  0.0172470323741436\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119184 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0020644592586904764\n",
      "Q Loss:  0.003275221912190318\n",
      "Policy Loss:  -0.039005909115076065\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119188 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.0003380109847057611\n",
      "Q Loss:  0.00017423907411284745\n",
      "Policy Loss:  -0.0009722608374431729\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119192 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00027427065651863813\n",
      "Q Loss:  0.0004903583903796971\n",
      "Policy Loss:  0.004181782715022564\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119196 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.319993968238123e-05\n",
      "Q Loss:  0.0005453056655824184\n",
      "Policy Loss:  0.01710490882396698\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119200 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  1.2590438018378336e-05\n",
      "Q Loss:  0.0021193893626332283\n",
      "Policy Loss:  0.02262062020599842\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119204 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  56.8766975402832\n",
      "Q Loss:  84.59696960449219\n",
      "Policy Loss:  -6.075617790222168\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119369 length: 165 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2325.854248046875\n",
      "Q Loss:  3664.595703125\n",
      "Policy Loss:  -154.6383819580078\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119373 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0019069737754762173\n",
      "Q Loss:  0.00262632267549634\n",
      "Policy Loss:  0.028239376842975616\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.484541932470165e-05\n",
      "Q Loss:  0.014690084382891655\n",
      "Policy Loss:  0.016475379467010498\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119381 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.9665366411209106\n",
      "Q Loss:  0.00674434844404459\n",
      "Policy Loss:  0.14932748675346375\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 119473 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.030007362365722656\n",
      "Value Loss:  6.5874569372681435e-06\n",
      "Q Loss:  0.0017466297140344977\n",
      "Policy Loss:  0.06587424874305725\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 119477 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049628496170043945\n",
      "Value Loss:  0.12415578961372375\n",
      "Q Loss:  0.018843960016965866\n",
      "Policy Loss:  -0.08564674109220505\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033006906509399414\n",
      "Value Loss:  5.048314051236957e-06\n",
      "Q Loss:  0.001641058479435742\n",
      "Policy Loss:  0.007535670883953571\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  5.171139491721988e-06\n",
      "Q Loss:  0.0014965070877224207\n",
      "Policy Loss:  0.006951610557734966\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119489 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  9.497910468780901e-06\n",
      "Q Loss:  0.00321382749825716\n",
      "Policy Loss:  0.025354284793138504\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119493 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  2.730275582507602e-06\n",
      "Q Loss:  0.000702529912814498\n",
      "Policy Loss:  -0.0011623528553172946\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119497 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.585435246757697e-06\n",
      "Q Loss:  0.0007954469183459878\n",
      "Policy Loss:  -0.0006388833280652761\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119501 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.0183859962562565e-06\n",
      "Q Loss:  0.00021332736650947481\n",
      "Policy Loss:  -0.007463496644049883\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119505 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.028584327548742294\n",
      "Q Loss:  0.009421784430742264\n",
      "Policy Loss:  0.014948965981602669\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119509 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.05616716295480728\n",
      "Q Loss:  0.011740599758923054\n",
      "Policy Loss:  0.039693742990493774\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  72686.9453125\n",
      "Q Loss:  69947.8515625\n",
      "Policy Loss:  -112.37115478515625\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119547 length: 34 #teleports:0\n",
      "Got not null reward 3005.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  2.80255744655733e-06\n",
      "Q Loss:  0.00011937379895243794\n",
      "Policy Loss:  -0.004919634200632572\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.0461562851560302e-06\n",
      "Q Loss:  0.000739477516617626\n",
      "Policy Loss:  -0.00990014523267746\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800537109375\n",
      "Value Loss:  1.537949287921947e-06\n",
      "Q Loss:  0.0009968243539333344\n",
      "Policy Loss:  -0.009662494994699955\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.5209374143742025e-05\n",
      "Q Loss:  0.0009627888794057071\n",
      "Policy Loss:  -0.010950194671750069\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119563 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  6.298349944700021e-06\n",
      "Q Loss:  0.002947819884866476\n",
      "Policy Loss:  -0.02814250811934471\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119567 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.7063619452528656e-05\n",
      "Q Loss:  3.7576657632598653e-05\n",
      "Policy Loss:  0.003302011638879776\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119571 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  1.1193411410204135e-05\n",
      "Q Loss:  8.213118417188525e-05\n",
      "Policy Loss:  0.005808659829199314\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.3629519344249275e-06\n",
      "Q Loss:  0.0003451858356129378\n",
      "Policy Loss:  -0.0017587002366781235\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119579 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.897917395079276e-06\n",
      "Q Loss:  0.02292788401246071\n",
      "Policy Loss:  -0.00044738134602084756\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.06941354274749756\n",
      "Q Loss:  0.013461990281939507\n",
      "Policy Loss:  -0.02309328317642212\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005268096923828\n",
      "Value Loss:  2.6958436965942383\n",
      "Q Loss:  0.004943445790559053\n",
      "Policy Loss:  0.3962540328502655\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119620 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2413.013671875\n",
      "Q Loss:  4888.328125\n",
      "Policy Loss:  -114.37921142578125\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05401158332824707\n",
      "Value Loss:  13410.818359375\n",
      "Q Loss:  12894.896484375\n",
      "Policy Loss:  -24.284814834594727\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 119746 length: 122 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00037277446244843304\n",
      "Q Loss:  0.0008713671704754233\n",
      "Policy Loss:  -0.013001253828406334\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0007983194082044065\n",
      "Q Loss:  0.00032830165582709014\n",
      "Policy Loss:  0.006920430343598127\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0004663796571549028\n",
      "Q Loss:  0.0013313457602635026\n",
      "Policy Loss:  -0.015521649271249771\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0001279424614040181\n",
      "Q Loss:  0.00032723514596000314\n",
      "Policy Loss:  -0.006187868770211935\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  0.0001857635215856135\n",
      "Q Loss:  9.937297727447003e-05\n",
      "Policy Loss:  -0.00470450334250927\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00011531238124007359\n",
      "Q Loss:  0.012393041513860226\n",
      "Policy Loss:  0.10662077367305756\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.3613947629928589\n",
      "Q Loss:  0.009641192853450775\n",
      "Policy Loss:  0.22083614766597748\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119835 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  252.99111938476562\n",
      "Q Loss:  457.29351806640625\n",
      "Policy Loss:  -24.493101119995117\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119912 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2424.33203125\n",
      "Q Loss:  3916.435791015625\n",
      "Policy Loss:  -137.07191467285156\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0006062944303266704\n",
      "Q Loss:  0.001331258099526167\n",
      "Policy Loss:  0.023345082998275757\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 119920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00031466371729038656\n",
      "Q Loss:  0.0005539730191230774\n",
      "Policy Loss:  0.013931050896644592\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 119924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.0016412409022450447\n",
      "Q Loss:  0.0010546781122684479\n",
      "Policy Loss:  -0.015723533928394318\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 119928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0010821043979376554\n",
      "Q Loss:  0.0004330028314143419\n",
      "Policy Loss:  -0.003885649610310793\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 119932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101132392883301\n",
      "Value Loss:  0.00024049708736129105\n",
      "Q Loss:  0.00011022273247363046\n",
      "Policy Loss:  0.0027832710184156895\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 119936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.4178189076119452e-06\n",
      "Q Loss:  0.0001605265715625137\n",
      "Policy Loss:  0.00902371946722269\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 119940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0001843129430199042\n",
      "Q Loss:  0.00034913819399662316\n",
      "Policy Loss:  0.005614470224827528\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 119944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.602165699005127\n",
      "Q Loss:  0.015043793246150017\n",
      "Policy Loss:  0.07492417842149734\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 120096 length: 152 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0008214194094762206\n",
      "Q Loss:  0.0005256976000964642\n",
      "Policy Loss:  0.015299303457140923\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 120100 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00016551889711990952\n",
      "Q Loss:  0.00035885925171896815\n",
      "Policy Loss:  0.007859949953854084\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 120104 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  3.4951488487422466e-05\n",
      "Q Loss:  0.00027494021924212575\n",
      "Policy Loss:  -0.005161179229617119\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 120108 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.6800694942940027e-05\n",
      "Q Loss:  0.0002625312772579491\n",
      "Policy Loss:  -0.008438789285719395\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 120112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.08899573236703873\n",
      "Q Loss:  0.057074423879384995\n",
      "Policy Loss:  -0.09053264558315277\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 120116 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04414299130439758\n",
      "Q Loss:  0.04206474497914314\n",
      "Policy Loss:  -0.02964784763753414\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04341622814536095\n",
      "Q Loss:  0.039992351084947586\n",
      "Policy Loss:  -0.019843902438879013\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.1269480288028717\n",
      "Q Loss:  0.024473143741488457\n",
      "Policy Loss:  -0.049333132803440094\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.12040755152702332\n",
      "Q Loss:  0.023527875542640686\n",
      "Policy Loss:  -0.0639571100473404\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600883483886719\n",
      "Value Loss:  0.07415787875652313\n",
      "Q Loss:  0.015474369749426842\n",
      "Policy Loss:  -0.013515651226043701\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.9300211668014526\n",
      "Q Loss:  0.009918740950524807\n",
      "Policy Loss:  0.3113037347793579\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120181 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016000986099243164\n",
      "Value Loss:  0.005349360406398773\n",
      "Q Loss:  0.0017509560566395521\n",
      "Policy Loss:  0.041917555034160614\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012345314025878906\n",
      "Value Loss:  0.00030563678592443466\n",
      "Q Loss:  0.0012563893105834723\n",
      "Policy Loss:  0.0030614761635661125\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0033261668868362904\n",
      "Q Loss:  0.0020078010857105255\n",
      "Policy Loss:  -0.007143928669393063\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0028927288949489594\n",
      "Q Loss:  0.00045108702033758163\n",
      "Policy Loss:  0.0010366113856434822\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0017740856856107712\n",
      "Q Loss:  0.0004935378674417734\n",
      "Policy Loss:  0.01414194144308567\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  7.149516022764146e-05\n",
      "Q Loss:  0.0010501615470275283\n",
      "Policy Loss:  0.025560779497027397\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 120205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.003861199365928769\n",
      "Q Loss:  956.010009765625\n",
      "Policy Loss:  4.604370594024658\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 120209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2365.4111328125\n",
      "Q Loss:  3480.358154296875\n",
      "Policy Loss:  -179.24917602539062\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 120213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00029310915851965547\n",
      "Q Loss:  0.0011213134275749326\n",
      "Policy Loss:  -0.007432304788380861\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 120217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.000507635239046067\n",
      "Q Loss:  0.004573032725602388\n",
      "Policy Loss:  0.0022184657864272594\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 120221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05430412292480469\n",
      "Value Loss:  0.00357155897654593\n",
      "Q Loss:  0.0009416755638085306\n",
      "Policy Loss:  0.009447147138416767\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 120225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.04746435210108757\n",
      "Q Loss:  0.09145232290029526\n",
      "Policy Loss:  0.16268938779830933\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  99.41864776611328\n",
      "Q Loss:  198.03565979003906\n",
      "Policy Loss:  -9.803177833557129\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120324 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.006962815765291452\n",
      "Q Loss:  0.002952001290395856\n",
      "Policy Loss:  0.03161204233765602\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0029221363365650177\n",
      "Q Loss:  0.0037298782262951136\n",
      "Policy Loss:  -0.019695516675710678\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700519561767578\n",
      "Value Loss:  0.003904311917722225\n",
      "Q Loss:  0.002321147359907627\n",
      "Policy Loss:  -0.03106669709086418\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002585290349088609\n",
      "Q Loss:  0.0014857705682516098\n",
      "Policy Loss:  -0.028327496722340584\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0012515851994976401\n",
      "Q Loss:  0.0004048171977046877\n",
      "Policy Loss:  -0.015682794153690338\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00016044528456404805\n",
      "Q Loss:  0.0016076850006356835\n",
      "Policy Loss:  -0.0004768073558807373\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.051011085510253906\n",
      "Value Loss:  4.3259271478746086e-05\n",
      "Q Loss:  0.0018782379338517785\n",
      "Policy Loss:  0.010713759809732437\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.02088562771677971\n",
      "Q Loss:  0.0453229658305645\n",
      "Policy Loss:  0.09938296675682068\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.787219636957161e-05\n",
      "Q Loss:  0.0002415054477751255\n",
      "Policy Loss:  -0.001122234738431871\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0017186077311635017\n",
      "Q Loss:  0.0025632460601627827\n",
      "Policy Loss:  0.022784831002354622\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120364 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.01986752636730671\n",
      "Q Loss:  0.011874724179506302\n",
      "Policy Loss:  0.07624906301498413\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120368 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  195.72238159179688\n",
      "Q Loss:  376.9150085449219\n",
      "Policy Loss:  -19.924259185791016\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120510 length: 142 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  2306.712890625\n",
      "Q Loss:  3899.40380859375\n",
      "Policy Loss:  -109.80442810058594\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120514 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.009020871482789516\n",
      "Q Loss:  171.29306030273438\n",
      "Policy Loss:  4.583420753479004\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120518 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.009987961500883102\n",
      "Q Loss:  0.01935185119509697\n",
      "Policy Loss:  -0.10367266088724136\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 120522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.00040050456300377846\n",
      "Q Loss:  170.20558166503906\n",
      "Policy Loss:  4.5261454582214355\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 120526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2281.183349609375\n",
      "Q Loss:  4594.2919921875\n",
      "Policy Loss:  -110.11602020263672\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 120530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05101156234741211\n",
      "Value Loss:  2270.61962890625\n",
      "Q Loss:  4570.4052734375\n",
      "Policy Loss:  -109.65843200683594\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 120534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.0114701883867383\n",
      "Q Loss:  665.4783935546875\n",
      "Policy Loss:  17.85317039489746\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 120538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0038051558658480644\n",
      "Q Loss:  327.0074768066406\n",
      "Policy Loss:  8.841312408447266\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 120542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00048587238416075706\n",
      "Q Loss:  640.7305908203125\n",
      "Policy Loss:  17.343942642211914\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 120546 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5821.34912109375\n",
      "Q Loss:  5751.005859375\n",
      "Policy Loss:  -18.119361877441406\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120690 length: 144 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04701089859008789\n",
      "Value Loss:  159.48123168945312\n",
      "Q Loss:  317.0836486816406\n",
      "Policy Loss:  -16.081371307373047\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120746 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013831138610839844\n",
      "Value Loss:  0.0029290362726897\n",
      "Q Loss:  0.0024263327941298485\n",
      "Policy Loss:  0.04617244005203247\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.004099156241863966\n",
      "Q Loss:  0.0015649578999727964\n",
      "Policy Loss:  0.006128902547061443\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00012968649389222264\n",
      "Q Loss:  0.05217282474040985\n",
      "Policy Loss:  -0.12241854518651962\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  7630.88232421875\n",
      "Q Loss:  7514.81396484375\n",
      "Policy Loss:  -24.033966064453125\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120868 length: 110 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0005604195175692439\n",
      "Q Loss:  0.0019263264257460833\n",
      "Policy Loss:  0.005248657427728176\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120872 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010989665985107422\n",
      "Value Loss:  0.00031332351500168443\n",
      "Q Loss:  0.02933553233742714\n",
      "Policy Loss:  -0.08459549397230148\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120876 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00019130877626594156\n",
      "Q Loss:  0.07481798529624939\n",
      "Policy Loss:  -0.04956764727830887\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120880 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  29373.423828125\n",
      "Q Loss:  28106.7109375\n",
      "Policy Loss:  -33.50437927246094\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120908 length: 28 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  6.663537351414561e-05\n",
      "Q Loss:  0.00036378088407218456\n",
      "Policy Loss:  -0.002567766699939966\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120912 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.09314417093992233\n",
      "Q Loss:  0.14973679184913635\n",
      "Policy Loss:  -0.17755743861198425\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 120916 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.893432080745697\n",
      "Q Loss:  10.748360633850098\n",
      "Policy Loss:  0.44888758659362793\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121014 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0019545406103134155\n",
      "Q Loss:  0.004136179573833942\n",
      "Policy Loss:  0.012656635604798794\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121018 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004779815673828\n",
      "Value Loss:  0.0015258457278832793\n",
      "Q Loss:  0.007449300028383732\n",
      "Policy Loss:  0.02029699832201004\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121022 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.03605866804718971\n",
      "Q Loss:  0.019228603690862656\n",
      "Policy Loss:  0.01738465391099453\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121026 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.8930100202560425\n",
      "Q Loss:  0.014801710844039917\n",
      "Policy Loss:  0.16437213122844696\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121124 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006612080615013838\n",
      "Q Loss:  0.052771054208278656\n",
      "Policy Loss:  0.07954713702201843\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0011715091532096267\n",
      "Q Loss:  0.00018502416787669063\n",
      "Policy Loss:  -0.004998377058655024\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0010252025676891208\n",
      "Q Loss:  0.0002725653466768563\n",
      "Policy Loss:  -0.004252547398209572\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0003573670401237905\n",
      "Q Loss:  0.008402857929468155\n",
      "Policy Loss:  0.034749433398246765\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  5.949631304247305e-05\n",
      "Q Loss:  0.0007800021558068693\n",
      "Policy Loss:  0.010249705985188484\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0001541835517855361\n",
      "Q Loss:  0.017262060195207596\n",
      "Policy Loss:  0.05807541310787201\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  11812.572265625\n",
      "Q Loss:  11595.3232421875\n",
      "Policy Loss:  -36.11659240722656\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121219 length: 71 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0011645194608718157\n",
      "Q Loss:  0.004766923375427723\n",
      "Policy Loss:  0.03570782393217087\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0002178362919948995\n",
      "Q Loss:  0.04662104323506355\n",
      "Policy Loss:  0.1171794980764389\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00014290773833636194\n",
      "Q Loss:  0.022680828347802162\n",
      "Policy Loss:  0.06649356335401535\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046010494232177734\n",
      "Value Loss:  0.00024333829060196877\n",
      "Q Loss:  0.013883926905691624\n",
      "Policy Loss:  0.03752683103084564\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.035007476806640625\n",
      "Value Loss:  0.00021515751723200083\n",
      "Q Loss:  0.002971283858641982\n",
      "Policy Loss:  0.007047557737678289\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  9.66583174886182e-05\n",
      "Q Loss:  0.002337409881874919\n",
      "Policy Loss:  -0.004003436770290136\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  5.9402100305305794e-05\n",
      "Q Loss:  0.0011661191238090396\n",
      "Policy Loss:  -0.02298027276992798\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0011653649853542447\n",
      "Q Loss:  0.002561825094744563\n",
      "Policy Loss:  -0.03194807842373848\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  0.002105286344885826\n",
      "Q Loss:  0.004190809093415737\n",
      "Policy Loss:  0.0010774319525808096\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  4.131375317228958e-05\n",
      "Q Loss:  0.0037567708641290665\n",
      "Policy Loss:  -0.03376978635787964\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  6.395460513886064e-05\n",
      "Q Loss:  0.010914556682109833\n",
      "Policy Loss:  0.004431929439306259\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  81.09844970703125\n",
      "Q Loss:  139.15386962890625\n",
      "Policy Loss:  -8.060691833496094\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121374 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00010564588592387736\n",
      "Q Loss:  0.017831847071647644\n",
      "Policy Loss:  -0.06468787044286728\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121378 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020005226135253906\n",
      "Value Loss:  0.0001437713799532503\n",
      "Q Loss:  0.02772090584039688\n",
      "Policy Loss:  -0.09241649508476257\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121382 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.000280609296169132\n",
      "Q Loss:  0.0009190115379169583\n",
      "Policy Loss:  -0.01464513223618269\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  38086.59375\n",
      "Q Loss:  37291.43359375\n",
      "Policy Loss:  -101.98272705078125\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121408 length: 22 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0009279075311496854\n",
      "Q Loss:  0.0023221042938530445\n",
      "Policy Loss:  -0.029231537133455276\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0006305132992565632\n",
      "Q Loss:  0.0005221121245995164\n",
      "Policy Loss:  -0.006465267855674028\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.0003507551737129688\n",
      "Q Loss:  0.0005701495683752\n",
      "Policy Loss:  0.0007698971312493086\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6.567871878360165e-06\n",
      "Q Loss:  0.06517131626605988\n",
      "Policy Loss:  -0.0014651959063485265\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  0.19741126894950867\n",
      "Q Loss:  0.051181282848119736\n",
      "Policy Loss:  0.03161279112100601\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.06562284380197525\n",
      "Q Loss:  0.0501682423055172\n",
      "Policy Loss:  0.011294424533843994\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.051011085510253906\n",
      "Value Loss:  4.813529085367918e-05\n",
      "Q Loss:  0.0027342515531927347\n",
      "Policy Loss:  0.03196357935667038\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  5.737832179875113e-05\n",
      "Q Loss:  0.005424372851848602\n",
      "Policy Loss:  0.053843822330236435\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.06352566927671432\n",
      "Q Loss:  0.03929908573627472\n",
      "Policy Loss:  0.06314912438392639\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121444 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.943950625602156e-05\n",
      "Q Loss:  0.0057194894179701805\n",
      "Policy Loss:  0.04600035026669502\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121448 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0002174465189455077\n",
      "Q Loss:  0.006864742375910282\n",
      "Policy Loss:  0.03844793885946274\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121452 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0001239461125805974\n",
      "Q Loss:  0.002099445788189769\n",
      "Policy Loss:  0.007940895855426788\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121456 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.3605750811839243e-06\n",
      "Q Loss:  0.0003802059800364077\n",
      "Policy Loss:  -0.001065350603312254\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121460 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  1.6638667148072273e-05\n",
      "Q Loss:  0.00017947008018381894\n",
      "Policy Loss:  0.000586795445997268\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  0.1747012734413147\n",
      "Q Loss:  0.02994292974472046\n",
      "Policy Loss:  -0.04839656502008438\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0560082346200943\n",
      "Q Loss:  0.01435380894690752\n",
      "Policy Loss:  -0.025527793914079666\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121472 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.6931384127237834e-06\n",
      "Q Loss:  0.0009242650703527033\n",
      "Policy Loss:  0.07712927460670471\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121476 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  7397.03271484375\n",
      "Q Loss:  7253.27490234375\n",
      "Policy Loss:  -24.999698638916016\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121589 length: 113 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.008899886161088943\n",
      "Q Loss:  0.009962119162082672\n",
      "Policy Loss:  0.058239519596099854\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121593 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700282096862793\n",
      "Value Loss:  0.005115916021168232\n",
      "Q Loss:  0.0019271282944828272\n",
      "Policy Loss:  0.017061695456504822\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121597 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0010780394077301025\n",
      "Q Loss:  0.013363328762352467\n",
      "Policy Loss:  -0.05851287022233009\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121601 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0004090867005288601\n",
      "Q Loss:  0.0011426624841988087\n",
      "Policy Loss:  -0.015261368826031685\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121605 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.044245485216379166\n",
      "Q Loss:  0.007693983148783445\n",
      "Policy Loss:  0.03539464622735977\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121609 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.08566560596227646\n",
      "Q Loss:  0.017526449635624886\n",
      "Policy Loss:  0.0020782947540283203\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.12226618081331253\n",
      "Q Loss:  0.021680939942598343\n",
      "Policy Loss:  -0.022751951590180397\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121617 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  13113.7138671875\n",
      "Q Loss:  12704.12890625\n",
      "Policy Loss:  -30.446422576904297\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121680 length: 63 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.10724088549613953\n",
      "Q Loss:  0.009509921073913574\n",
      "Policy Loss:  -0.0014756713062524796\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121684 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.1317933201789856\n",
      "Q Loss:  0.005096570588648319\n",
      "Policy Loss:  -0.055082157254219055\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121688 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  72.2353515625\n",
      "Q Loss:  106.91759490966797\n",
      "Policy Loss:  -7.615683555603027\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121818 length: 130 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.040317751467227936\n",
      "Q Loss:  0.02037450298666954\n",
      "Policy Loss:  -0.08165799826383591\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.01335942279547453\n",
      "Q Loss:  0.0033626900985836983\n",
      "Policy Loss:  -0.01269612554460764\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  0.0013286927714943886\n",
      "Q Loss:  0.00015269273717422038\n",
      "Policy Loss:  0.0020867439452558756\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.0004232568317092955\n",
      "Q Loss:  0.0008562898146919906\n",
      "Policy Loss:  0.01178764645010233\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600170135498047\n",
      "Value Loss:  0.0006269589648582041\n",
      "Q Loss:  0.000620667589828372\n",
      "Policy Loss:  -0.008332636207342148\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.652855073392857e-05\n",
      "Q Loss:  0.0004855302977375686\n",
      "Policy Loss:  -0.012000872753560543\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  191.97911071777344\n",
      "Q Loss:  365.066650390625\n",
      "Policy Loss:  -19.718355178833008\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121940 length: 98 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0036082749720662832\n",
      "Q Loss:  127.38188934326172\n",
      "Policy Loss:  3.968552589416504\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  2341.94580078125\n",
      "Q Loss:  4532.58447265625\n",
      "Policy Loss:  -141.38829040527344\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 121948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9597.7998046875\n",
      "Q Loss:  9360.216796875\n",
      "Policy Loss:  -21.8719539642334\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122034 length: 86 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.01875147968530655\n",
      "Q Loss:  0.023760635405778885\n",
      "Policy Loss:  0.07803903520107269\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.020634371787309647\n",
      "Q Loss:  0.005043639335781336\n",
      "Policy Loss:  0.0431821309030056\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.0026371008716523647\n",
      "Q Loss:  0.0013175765052437782\n",
      "Policy Loss:  -0.006698449142277241\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 122046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0004841710615437478\n",
      "Q Loss:  0.002850233344361186\n",
      "Policy Loss:  -0.03280596435070038\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 122050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.004136241972446442\n",
      "Q Loss:  0.02138134092092514\n",
      "Policy Loss:  -0.08904899656772614\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 122054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.005042162258177996\n",
      "Q Loss:  0.0057836235500872135\n",
      "Policy Loss:  -0.04444095864892006\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 122058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047010183334350586\n",
      "Value Loss:  0.010149157606065273\n",
      "Q Loss:  0.010934572666883469\n",
      "Policy Loss:  -0.05803389847278595\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 122062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.006206689868122339\n",
      "Q Loss:  0.004690151661634445\n",
      "Policy Loss:  -0.029469484463334084\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 122066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.006940548773854971\n",
      "Q Loss:  0.0010382251348346472\n",
      "Policy Loss:  -0.004663233645260334\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 122070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.005526207387447357\n",
      "Q Loss:  0.0005193178076297045\n",
      "Policy Loss:  0.008480970747768879\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 122074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005340576171875\n",
      "Value Loss:  0.0015252443263307214\n",
      "Q Loss:  0.0011904551647603512\n",
      "Policy Loss:  0.011220654472708702\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 122078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.0002720122574828565\n",
      "Q Loss:  0.0037731290794909\n",
      "Policy Loss:  0.047950293868780136\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 122082 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0019758748821914196\n",
      "Q Loss:  0.008898711763322353\n",
      "Policy Loss:  0.058377236127853394\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 122086 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.006244720425456762\n",
      "Q Loss:  0.01891506277024746\n",
      "Policy Loss:  -0.02772965095937252\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 122090 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.006573594640940428\n",
      "Q Loss:  0.006967739202082157\n",
      "Policy Loss:  0.033406250178813934\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 122094 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0015734133776277304\n",
      "Q Loss:  0.009079065173864365\n",
      "Policy Loss:  0.03585650771856308\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 122098 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00632092822343111\n",
      "Q Loss:  0.004419304896146059\n",
      "Policy Loss:  0.023586034774780273\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 122102 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0035038599744439125\n",
      "Q Loss:  0.001822374644689262\n",
      "Policy Loss:  0.013259254395961761\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 122106 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  7.361843017861247e-05\n",
      "Q Loss:  0.0003918766451533884\n",
      "Policy Loss:  0.007178077474236488\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 122110 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0003282634716015309\n",
      "Q Loss:  0.0071623316034674644\n",
      "Policy Loss:  -0.04100998491048813\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 122114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00044795667054131627\n",
      "Q Loss:  0.0038666550535708666\n",
      "Policy Loss:  -0.03806071728467941\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.974926769733429\n",
      "Q Loss:  0.023852530866861343\n",
      "Policy Loss:  0.16579829156398773\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122212 length: 94 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.011956388130784035\n",
      "Q Loss:  0.009639224968850613\n",
      "Policy Loss:  0.004717256873846054\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122216 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.006372305564582348\n",
      "Q Loss:  0.006393169052898884\n",
      "Policy Loss:  0.0369352325797081\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122220 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.003231881884858012\n",
      "Q Loss:  0.00205499236471951\n",
      "Policy Loss:  -0.016109375283122063\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.003637505229562521\n",
      "Q Loss:  0.007665886078029871\n",
      "Policy Loss:  -0.020499683916568756\n",
      "[(0.00011, 0), (0.00011, 0.0)]\n",
      "Alpha*: 0.00011 tau*: 0 Episode: 122228 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0035313761327415705\n",
      "Q Loss:  0.011167031712830067\n",
      "Policy Loss:  -0.050038471817970276\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 122232 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0009994034189730883\n",
      "Q Loss:  0.006672175135463476\n",
      "Policy Loss:  -0.004376560915261507\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 122236 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.004587906878441572\n",
      "Q Loss:  0.0025423881597816944\n",
      "Policy Loss:  -0.053358159959316254\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 122240 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013593435287475586\n",
      "Value Loss:  9.126451914198697e-06\n",
      "Q Loss:  0.0024905786849558353\n",
      "Policy Loss:  0.02190915122628212\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 122244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.7868096232414246\n",
      "Q Loss:  36.13107681274414\n",
      "Policy Loss:  1.2290513515472412\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 122359 length: 115 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2308.944091796875\n",
      "Q Loss:  4581.388671875\n",
      "Policy Loss:  -119.9171142578125\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 122363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.003903181292116642\n",
      "Q Loss:  0.0069941384717822075\n",
      "Policy Loss:  0.0028266748413443565\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 122367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.011347095482051373\n",
      "Q Loss:  0.02142285741865635\n",
      "Policy Loss:  0.04322175309062004\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 122371 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.006829367950558662\n",
      "Q Loss:  0.003113423241302371\n",
      "Policy Loss:  -0.025943972170352936\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122375 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.00870606955140829\n",
      "Q Loss:  0.014980853535234928\n",
      "Policy Loss:  0.0573301762342453\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00237668608315289\n",
      "Q Loss:  0.017917072400450706\n",
      "Policy Loss:  0.030239755287766457\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.042009592056274414\n",
      "Value Loss:  0.06152056157588959\n",
      "Q Loss:  0.03796739876270294\n",
      "Policy Loss:  0.03685586899518967\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122387 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.020200079306960106\n",
      "Q Loss:  0.03210368752479553\n",
      "Policy Loss:  0.061070360243320465\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122391 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01660442352294922\n",
      "Value Loss:  0.005212570074945688\n",
      "Q Loss:  0.00838126614689827\n",
      "Policy Loss:  0.05519489198923111\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122395 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.9828833341598511\n",
      "Q Loss:  0.010780985467135906\n",
      "Policy Loss:  0.16770435869693756\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122487 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0019140237709507346\n",
      "Q Loss:  0.0021813958883285522\n",
      "Policy Loss:  -0.03919001668691635\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0009823294822126627\n",
      "Q Loss:  0.011763663031160831\n",
      "Policy Loss:  0.02891293726861477\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0003944188356399536\n",
      "Q Loss:  0.006823559291660786\n",
      "Policy Loss:  0.039555713534355164\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014988899230957031\n",
      "Value Loss:  0.00038302302709780633\n",
      "Q Loss:  0.0034423540346324444\n",
      "Policy Loss:  0.006834335625171661\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500985145568848\n",
      "Value Loss:  0.0032419608905911446\n",
      "Q Loss:  0.008821058087050915\n",
      "Policy Loss:  0.008235071785748005\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  4.3173273297725245e-05\n",
      "Q Loss:  8.903007255867124e-06\n",
      "Policy Loss:  -0.004563441500067711\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122511 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.003115343162789941\n",
      "Q Loss:  0.0005738318432122469\n",
      "Policy Loss:  0.05545952171087265\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122515 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7446.30615234375\n",
      "Q Loss:  7141.2861328125\n",
      "Policy Loss:  -9.048995018005371\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122625 length: 110 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0021053478121757507\n",
      "Q Loss:  0.0016867942176759243\n",
      "Policy Loss:  -0.004945305176079273\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  61.232337951660156\n",
      "Q Loss:  86.83740234375\n",
      "Policy Loss:  -6.694522380828857\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122778 length: 149 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.00678491685539484\n",
      "Q Loss:  0.05898936092853546\n",
      "Policy Loss:  -0.13940398395061493\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0007048276020213962\n",
      "Q Loss:  0.0038401195779442787\n",
      "Policy Loss:  -0.015795130282640457\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.02189488708972931\n",
      "Q Loss:  0.00797106884419918\n",
      "Policy Loss:  0.0012306421995162964\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.06513775140047073\n",
      "Q Loss:  0.01590728387236595\n",
      "Policy Loss:  -0.08827119320631027\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.0017998766852542758\n",
      "Q Loss:  0.0027288554701954126\n",
      "Policy Loss:  -0.018874775618314743\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.9780101180076599\n",
      "Q Loss:  11.468643188476562\n",
      "Policy Loss:  0.49107903242111206\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122889 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.001691923476755619\n",
      "Q Loss:  0.0012468077475205064\n",
      "Policy Loss:  -0.01594705507159233\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122893 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  0.021285375580191612\n",
      "Q Loss:  0.021195771172642708\n",
      "Policy Loss:  -0.019893813878297806\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.021153494715690613\n",
      "Q Loss:  0.01462473813444376\n",
      "Policy Loss:  -0.019557693973183632\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  0.08125792443752289\n",
      "Q Loss:  0.005968893878161907\n",
      "Policy Loss:  -0.05856192111968994\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.07667601853609085\n",
      "Q Loss:  0.0020173457451164722\n",
      "Policy Loss:  -0.03248610720038414\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 122909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.9654451608657837\n",
      "Q Loss:  0.008285483345389366\n",
      "Policy Loss:  0.18839749693870544\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123003 length: 94 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.0023183883167803288\n",
      "Q Loss:  0.012285185046494007\n",
      "Policy Loss:  0.06655754894018173\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123007 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0015418080147355795\n",
      "Q Loss:  0.0018343569245189428\n",
      "Policy Loss:  0.028837256133556366\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123011 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  219.048583984375\n",
      "Q Loss:  318.272705078125\n",
      "Policy Loss:  -23.191692352294922\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123094 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  81.56013488769531\n",
      "Q Loss:  115.56599426269531\n",
      "Policy Loss:  -8.783541679382324\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123206 length: 112 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016001462936401367\n",
      "Value Loss:  0.0011797032784670591\n",
      "Q Loss:  0.0011838185600936413\n",
      "Policy Loss:  0.013454612344503403\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123210 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.014971761964261532\n",
      "Q Loss:  0.029073353856801987\n",
      "Policy Loss:  0.08375303447246552\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9.42583501455374e-05\n",
      "Q Loss:  0.014136316254734993\n",
      "Policy Loss:  0.05111517384648323\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123218 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000352268572896719\n",
      "Q Loss:  0.00017388307605870068\n",
      "Policy Loss:  -0.017602844163775444\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123222 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.02967173419892788\n",
      "Q Loss:  0.022273268550634384\n",
      "Policy Loss:  0.060786809772253036\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123226 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.014539948664605618\n",
      "Q Loss:  0.019309908151626587\n",
      "Policy Loss:  0.061195917427539825\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  79.29166412353516\n",
      "Q Loss:  125.92604064941406\n",
      "Policy Loss:  -8.138055801391602\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123345 length: 115 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04263114929199219\n",
      "Value Loss:  0.001806657062843442\n",
      "Q Loss:  0.0014760477934032679\n",
      "Policy Loss:  -0.02850157767534256\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.000294785771984607\n",
      "Q Loss:  0.00036329712020233274\n",
      "Policy Loss:  -0.014440091326832771\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00020045523706357926\n",
      "Q Loss:  0.00022918242029845715\n",
      "Policy Loss:  -0.018908347934484482\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.9331294298171997\n",
      "Q Loss:  0.006087540183216333\n",
      "Policy Loss:  0.10412540286779404\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123456 length: 99 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0002987475018016994\n",
      "Q Loss:  0.0007206835434772074\n",
      "Policy Loss:  -0.016985565423965454\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123460 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.028497889637947083\n",
      "Q Loss:  0.00739362882450223\n",
      "Policy Loss:  -0.025648031383752823\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123464 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  183.31271362304688\n",
      "Q Loss:  204.30052185058594\n",
      "Policy Loss:  -20.366056442260742\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123612 length: 148 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.001817263662815094\n",
      "Q Loss:  0.0028492410201579332\n",
      "Policy Loss:  -0.02981596440076828\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123616 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  8.621484084869735e-06\n",
      "Q Loss:  0.0022119537461549044\n",
      "Policy Loss:  -0.02539103664457798\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0009050170192494988\n",
      "Q Loss:  0.00048759218771010637\n",
      "Policy Loss:  -0.0013671084307134151\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.001804940402507782\n",
      "Q Loss:  0.002808501711115241\n",
      "Policy Loss:  -0.01952243596315384\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0011739965993911028\n",
      "Q Loss:  0.0034444881603121758\n",
      "Policy Loss:  0.012528383173048496\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.014926116913557053\n",
      "Q Loss:  0.0030930456705391407\n",
      "Policy Loss:  0.0031883474439382553\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00047076973714865744\n",
      "Q Loss:  0.0025984402745962143\n",
      "Policy Loss:  -0.013629438355565071\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00011034082126570866\n",
      "Q Loss:  0.0031871628016233444\n",
      "Policy Loss:  -0.02350982278585434\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.028796715661883354\n",
      "Q Loss:  0.02423934079706669\n",
      "Policy Loss:  -0.05551261827349663\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  2.1084990748931887e-06\n",
      "Q Loss:  0.0005262285703793168\n",
      "Policy Loss:  -0.0005262412596493959\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.9206780052627437e-05\n",
      "Q Loss:  4.378214362077415e-05\n",
      "Policy Loss:  0.005412187427282333\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.040377430617809296\n",
      "Q Loss:  0.006143306382000446\n",
      "Policy Loss:  -0.012013837695121765\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.05115381255745888\n",
      "Q Loss:  0.004463518038392067\n",
      "Policy Loss:  -0.0465390682220459\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0350174754858017\n",
      "Q Loss:  0.012143980711698532\n",
      "Policy Loss:  0.016133733093738556\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017005205154418945\n",
      "Value Loss:  1.1218725442886353\n",
      "Q Loss:  0.0062134298495948315\n",
      "Policy Loss:  0.19599473476409912\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123751 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5730.88623046875\n",
      "Q Loss:  5497.45947265625\n",
      "Policy Loss:  -6.918298244476318\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123894 length: 143 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00013523611414711922\n",
      "Q Loss:  0.0075945197604596615\n",
      "Policy Loss:  0.03626371547579765\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123898 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.326614362071268e-05\n",
      "Q Loss:  0.0012978303711861372\n",
      "Policy Loss:  0.02020406350493431\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0021221493370831013\n",
      "Q Loss:  0.0014453792246058583\n",
      "Policy Loss:  0.014111725613474846\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0006973168929107487\n",
      "Q Loss:  0.0009102760232053697\n",
      "Policy Loss:  0.010818390175700188\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0005242128390818834\n",
      "Q Loss:  0.0007584665436297655\n",
      "Policy Loss:  0.0009685801342129707\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.0005438285297714174\n",
      "Q Loss:  0.009420357644557953\n",
      "Policy Loss:  0.035901907831430435\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.01397436112165451\n",
      "Q Loss:  0.006010487675666809\n",
      "Policy Loss:  0.057102274149656296\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.01343206875026226\n",
      "Q Loss:  0.010986986570060253\n",
      "Policy Loss:  0.0125749371945858\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.006278329063206911\n",
      "Q Loss:  0.009853501804172993\n",
      "Policy Loss:  0.03964458405971527\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123930 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.7124499082565308\n",
      "Q Loss:  9.447113990783691\n",
      "Policy Loss:  0.5439596772193909\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123985 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011006593704223633\n",
      "Value Loss:  0.0006026229821145535\n",
      "Q Loss:  0.00045715755550190806\n",
      "Policy Loss:  -0.015857486054301262\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0003174554731231183\n",
      "Q Loss:  0.0023086450528353453\n",
      "Policy Loss:  -0.029340527951717377\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100966453552246\n",
      "Value Loss:  5.305194008542458e-06\n",
      "Q Loss:  0.0004856346931774169\n",
      "Policy Loss:  -0.0031604196410626173\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 123997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.3231834600446746e-05\n",
      "Q Loss:  0.00012112606782466173\n",
      "Policy Loss:  0.02055833861231804\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  89.34642791748047\n",
      "Q Loss:  136.6072540283203\n",
      "Policy Loss:  -9.332049369812012\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124103 length: 102 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00012421802966855466\n",
      "Q Loss:  1.8263939637108706e-05\n",
      "Policy Loss:  -6.361730629578233e-05\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.00012246338883414865\n",
      "Q Loss:  5.761948341387324e-05\n",
      "Policy Loss:  0.0034061893820762634\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.811849844874814e-05\n",
      "Q Loss:  0.0008683294290676713\n",
      "Policy Loss:  -0.022054465487599373\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124115 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6.8793042373727076e-06\n",
      "Q Loss:  0.0016393400728702545\n",
      "Policy Loss:  -0.026892203837633133\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124119 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.02368832379579544\n",
      "Q Loss:  0.011388178914785385\n",
      "Policy Loss:  -0.04510192573070526\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100918769836426\n",
      "Value Loss:  154.42092895507812\n",
      "Q Loss:  218.51856994628906\n",
      "Policy Loss:  -16.562498092651367\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124182 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  46808.05078125\n",
      "Q Loss:  45019.6796875\n",
      "Policy Loss:  -52.87601852416992\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124217 length: 35 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.390302976593375e-05\n",
      "Q Loss:  0.000893626653123647\n",
      "Policy Loss:  0.010796945542097092\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  3.5643111914396286e-05\n",
      "Q Loss:  4.5207063521957025e-05\n",
      "Policy Loss:  1.1833326425403357e-05\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600788116455078\n",
      "Value Loss:  3.7487665395019576e-05\n",
      "Q Loss:  6.999459401413333e-06\n",
      "Policy Loss:  0.0014109208714216948\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.012083807960152626\n",
      "Q Loss:  0.01153434719890356\n",
      "Policy Loss:  -0.011078482493758202\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  2.3434741497039795\n",
      "Q Loss:  0.0025410957168787718\n",
      "Policy Loss:  0.3348854184150696\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124272 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.180167449405417e-05\n",
      "Q Loss:  0.00026928132865577936\n",
      "Policy Loss:  0.009761229157447815\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  6.895944534335285e-05\n",
      "Q Loss:  6.393763032974675e-05\n",
      "Policy Loss:  0.004497421905398369\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.3562948626931757e-05\n",
      "Q Loss:  0.0006768653984181583\n",
      "Policy Loss:  0.016526415944099426\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00011159075074829161\n",
      "Q Loss:  0.001178670092485845\n",
      "Policy Loss:  -0.00016001681797206402\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.84506555646658e-05\n",
      "Q Loss:  0.0012605695519596338\n",
      "Policy Loss:  0.0034788474440574646\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.8048354831989855e-05\n",
      "Q Loss:  0.0002325927489437163\n",
      "Policy Loss:  0.008120506070554256\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  1.1798894774983637e-05\n",
      "Q Loss:  0.009425862692296505\n",
      "Policy Loss:  0.021443886682391167\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.07220955938100815\n",
      "Q Loss:  0.016000818461179733\n",
      "Policy Loss:  -0.04806705191731453\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0510096549987793\n",
      "Value Loss:  139.58480834960938\n",
      "Q Loss:  257.2377014160156\n",
      "Policy Loss:  -14.435690879821777\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124372 length: 68 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  3.873603418469429e-05\n",
      "Q Loss:  0.012145398184657097\n",
      "Policy Loss:  0.0657925009727478\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124376 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.728398587554693e-05\n",
      "Q Loss:  0.004231559112668037\n",
      "Policy Loss:  0.020968925207853317\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.6506479978561401\n",
      "Q Loss:  0.005088914651423693\n",
      "Policy Loss:  0.09888415038585663\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124517 length: 137 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  2359.16748046875\n",
      "Q Loss:  3470.161376953125\n",
      "Policy Loss:  -160.2386016845703\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.021340818231693e-07\n",
      "Q Loss:  1.8811701011145487e-05\n",
      "Policy Loss:  -0.001905019162222743\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.944651194207836e-05\n",
      "Q Loss:  0.0006168177933432162\n",
      "Policy Loss:  0.008385974913835526\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  3.8295584090519696e-05\n",
      "Q Loss:  387.4176025390625\n",
      "Policy Loss:  12.136524200439453\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  6.928005859663244e-06\n",
      "Q Loss:  0.00038905616383999586\n",
      "Policy Loss:  -0.0016914482694119215\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.4136696790956194e-06\n",
      "Q Loss:  0.00019842061738017946\n",
      "Policy Loss:  -0.0010616544168442488\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 124541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0005062517593614757\n",
      "Q Loss:  0.0007161446264944971\n",
      "Policy Loss:  0.01085451990365982\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124545 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  5.650991170114139e-06\n",
      "Q Loss:  0.0002709515392780304\n",
      "Policy Loss:  -0.010855235159397125\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 124549 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  10332.2587890625\n",
      "Q Loss:  9969.6201171875\n",
      "Policy Loss:  -12.502601623535156\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 124628 length: 79 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  0.00020854116883128881\n",
      "Q Loss:  0.0008734804578125477\n",
      "Policy Loss:  -0.012923330068588257\n",
      "[(9e-05, 0), (9e-05, 0.0)]\n",
      "Alpha*: 9e-05 tau*: 0 Episode: 124632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00013032389688305557\n",
      "Q Loss:  0.0014396661426872015\n",
      "Policy Loss:  -0.019175447523593903\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 124636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  9.728304576128721e-06\n",
      "Q Loss:  5.218688784225378e-06\n",
      "Policy Loss:  0.0015045555774122477\n",
      "[(0.00014, 0), (0.00014, 0.0)]\n",
      "Alpha*: 0.00014 tau*: 0 Episode: 124640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  8.67754079081351e-06\n",
      "Q Loss:  0.0005678299348801374\n",
      "Policy Loss:  -0.005038565956056118\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 124644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  1.1510468311826116e-06\n",
      "Q Loss:  1172.1138916015625\n",
      "Policy Loss:  8.102144241333008\n",
      "[(0.00016, 0), (0.00016, 0.0)]\n",
      "Alpha*: 0.00016 tau*: 0 Episode: 124648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2335.28759765625\n",
      "Q Loss:  3300.201171875\n",
      "Policy Loss:  -179.39801025390625\n",
      "[(0.00012, 0), (0.00012, 0.0)]\n",
      "Alpha*: 0.00012 tau*: 0 Episode: 124652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.661238565655367e-07\n",
      "Q Loss:  0.00024071321240626276\n",
      "Policy Loss:  -0.00026055146008729935\n",
      "[(0.0001, 0), (0.0001, 0.0)]\n",
      "Alpha*: 0.0001 tau*: 0 Episode: 124656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01661229133605957\n",
      "Value Loss:  0.00038544516428373754\n",
      "Q Loss:  0.0003714713384397328\n",
      "Policy Loss:  -0.010162442922592163\n",
      "[(8e-05, 0), (8e-05, 0.0)]\n",
      "Alpha*: 8e-05 tau*: 0 Episode: 124660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  2.018889063037932e-05\n",
      "Q Loss:  0.00043615119648166\n",
      "Policy Loss:  -0.004060927778482437\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 124664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.04138514772057533\n",
      "Q Loss:  0.012971853837370872\n",
      "Policy Loss:  0.04952554777264595\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 124668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  1.158534049987793\n",
      "Q Loss:  0.0056635551154613495\n",
      "Policy Loss:  0.16282136738300323\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 124742 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  0.0001567859435454011\n",
      "Q Loss:  0.00022790677030570805\n",
      "Policy Loss:  0.006448659114539623\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 124746 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.2874346793978475e-05\n",
      "Q Loss:  0.0006575736915692687\n",
      "Policy Loss:  0.01519243884831667\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 124750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  5.835056981595699e-06\n",
      "Q Loss:  0.0006951674004085362\n",
      "Policy Loss:  0.016462353989481926\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 124754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  3.340480907354504e-05\n",
      "Q Loss:  0.0003414772218093276\n",
      "Policy Loss:  0.011991582810878754\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 124758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.04486650228500366\n",
      "Q Loss:  0.014591659419238567\n",
      "Policy Loss:  0.012832041829824448\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 124762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  7560.662109375\n",
      "Q Loss:  7606.3876953125\n",
      "Policy Loss:  -40.64278030395508\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124875 length: 113 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  8.677326695760712e-05\n",
      "Q Loss:  0.0012648936826735735\n",
      "Policy Loss:  0.02105160616338253\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0001313944230787456\n",
      "Q Loss:  0.0008158288546837866\n",
      "Policy Loss:  0.013556389138102531\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.00012566911755129695\n",
      "Q Loss:  0.00041442259680479765\n",
      "Policy Loss:  0.009942199103534222\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124887 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.392665141494945e-05\n",
      "Q Loss:  0.00022757952683605254\n",
      "Policy Loss:  -0.0031064252834767103\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124891 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  4.310999429435469e-06\n",
      "Q Loss:  124.97216796875\n",
      "Policy Loss:  3.913609027862549\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124895 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  4.215698481857544e-06\n",
      "Q Loss:  124.80133819580078\n",
      "Policy Loss:  3.898381233215332\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124899 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.9852479454129934e-05\n",
      "Q Loss:  0.00019075098680332303\n",
      "Policy Loss:  -0.009924801997840405\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124903 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.049010515213012695\n",
      "Value Loss:  5.729153417632915e-05\n",
      "Q Loss:  5.181136657483876e-05\n",
      "Policy Loss:  -0.0030926670879125595\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124907 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200697898864746\n",
      "Value Loss:  3.455622209003195e-05\n",
      "Q Loss:  3.804248626693152e-05\n",
      "Policy Loss:  -0.0005614581750705838\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.107693969970569e-05\n",
      "Q Loss:  9.725542622618377e-05\n",
      "Policy Loss:  0.06533297896385193\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  30630.140625\n",
      "Q Loss:  29801.8515625\n",
      "Policy Loss:  -62.11874771118164\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124942 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014088630676269531\n",
      "Value Loss:  6.563528586411849e-06\n",
      "Q Loss:  0.0003942284965887666\n",
      "Policy Loss:  -0.009991558268666267\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.5984391211532056e-05\n",
      "Q Loss:  0.001112253055907786\n",
      "Policy Loss:  -0.014484580606222153\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.539571167086251e-05\n",
      "Q Loss:  0.0009072281536646187\n",
      "Policy Loss:  0.059846363961696625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.16431279480457306\n",
      "Q Loss:  0.03291842341423035\n",
      "Policy Loss:  -0.05783319100737572\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.21801432967185974\n",
      "Q Loss:  0.034054044634103775\n",
      "Policy Loss:  -0.13288229703903198\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.15635636448860168\n",
      "Q Loss:  0.026752041652798653\n",
      "Policy Loss:  -0.06920959055423737\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 124966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.09700557589530945\n",
      "Q Loss:  0.0034431160893291235\n",
      "Policy Loss:  0.047860026359558105\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 124970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.4360707998275757\n",
      "Q Loss:  0.01644190028309822\n",
      "Policy Loss:  0.24540747702121735\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125030 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04801034927368164\n",
      "Value Loss:  9.969128586817533e-05\n",
      "Q Loss:  0.002248168922960758\n",
      "Policy Loss:  0.03321947902441025\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125034 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  5.9013455029344186e-05\n",
      "Q Loss:  3.991031553596258e-05\n",
      "Policy Loss:  0.004043755121529102\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125038 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  9.626792598282918e-05\n",
      "Q Loss:  0.00010878795728785917\n",
      "Policy Loss:  -0.0031181706581264734\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125042 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00016326730838045478\n",
      "Q Loss:  0.00020941969705745578\n",
      "Policy Loss:  -0.0047010923735797405\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125046 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00016905531811062247\n",
      "Q Loss:  9.554452117299661e-05\n",
      "Policy Loss:  -0.0055955396965146065\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  4.492755397222936e-05\n",
      "Q Loss:  0.00030018604593351483\n",
      "Policy Loss:  0.00034701067488640547\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.452462988207117e-05\n",
      "Q Loss:  0.0001918128109537065\n",
      "Policy Loss:  8.770998101681471e-05\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.03050941973924637\n",
      "Q Loss:  0.07681451737880707\n",
      "Policy Loss:  0.04652796685695648\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  9.654384484747425e-05\n",
      "Q Loss:  0.00460215425118804\n",
      "Policy Loss:  0.04000586271286011\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.028008470311760902\n",
      "Q Loss:  0.0752880796790123\n",
      "Policy Loss:  0.11543359607458115\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 125070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.053468842059373856\n",
      "Q Loss:  0.061768557876348495\n",
      "Policy Loss:  0.04679551720619202\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125074 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.2755433494457975e-05\n",
      "Q Loss:  0.000116868490295019\n",
      "Policy Loss:  0.0011739428155124187\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125078 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  8073.6201171875\n",
      "Q Loss:  7762.53759765625\n",
      "Policy Loss:  -9.813878059387207\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125179 length: 101 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.0005259814788587391\n",
      "Q Loss:  0.001053918618708849\n",
      "Policy Loss:  0.012468471191823483\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125183 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0004349224327597767\n",
      "Q Loss:  0.00021857557294424623\n",
      "Policy Loss:  0.0029124205466359854\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0002793477033264935\n",
      "Q Loss:  0.000513328704982996\n",
      "Policy Loss:  -0.010433562099933624\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125191 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  4.781378811458126e-05\n",
      "Q Loss:  0.00015906750923022628\n",
      "Policy Loss:  -0.01064460538327694\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500913619995117\n",
      "Value Loss:  0.019101673737168312\n",
      "Q Loss:  0.01128378976136446\n",
      "Policy Loss:  0.030937081202864647\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.036517515778541565\n",
      "Q Loss:  0.009894422255456448\n",
      "Policy Loss:  0.004071876406669617\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125203 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.01714469864964485\n",
      "Q Loss:  0.006252281367778778\n",
      "Policy Loss:  0.013180669397115707\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125207 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  2.4614864742034115e-05\n",
      "Q Loss:  0.0005588586209341884\n",
      "Policy Loss:  -0.018144454807043076\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04701066017150879\n",
      "Value Loss:  1.8178294340032153e-05\n",
      "Q Loss:  0.0006179604097269475\n",
      "Policy Loss:  -0.01435307040810585\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300951957702637\n",
      "Value Loss:  4.532217644737102e-05\n",
      "Q Loss:  0.002627576468512416\n",
      "Policy Loss:  -0.030576961115002632\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  6.027886411175132e-05\n",
      "Q Loss:  0.0005287743406370282\n",
      "Policy Loss:  -0.015503598377108574\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.305645466549322e-05\n",
      "Q Loss:  0.00037533717113547027\n",
      "Policy Loss:  -0.011615719646215439\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  2.274042708449997e-05\n",
      "Q Loss:  0.00032651075161993504\n",
      "Policy Loss:  -0.00741614168509841\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.011552104726433754\n",
      "Q Loss:  0.012166505679488182\n",
      "Policy Loss:  -0.011665983125567436\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.912806510925293\n",
      "Q Loss:  9.571474075317383\n",
      "Policy Loss:  0.4039827287197113\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125336 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0010773867834359407\n",
      "Q Loss:  0.004920191131532192\n",
      "Policy Loss:  -0.015566578134894371\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0003624996170401573\n",
      "Q Loss:  0.004836347885429859\n",
      "Policy Loss:  -0.030300535261631012\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  1.0933646990451962e-05\n",
      "Q Loss:  0.00010178105731029063\n",
      "Policy Loss:  -0.001246193191036582\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.036008596420288086\n",
      "Value Loss:  0.010568139143288136\n",
      "Q Loss:  0.0007056249887682498\n",
      "Policy Loss:  -0.009420791640877724\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.010387301445007324\n",
      "Q Loss:  0.0007656233501620591\n",
      "Policy Loss:  -0.006777619011700153\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  58.24728012084961\n",
      "Q Loss:  127.32042694091797\n",
      "Policy Loss:  -5.395909309387207\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125521 length: 165 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  6.689141173410462e-06\n",
      "Q Loss:  2.257523374282755e-05\n",
      "Policy Loss:  0.003314619418233633\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.994586328801233e-06\n",
      "Q Loss:  2.6935533242067322e-05\n",
      "Policy Loss:  0.003919178619980812\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.810457615647465e-05\n",
      "Q Loss:  0.0005315160378813744\n",
      "Policy Loss:  0.012347746640443802\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.3569782822742127e-05\n",
      "Q Loss:  1.3316540389496367e-05\n",
      "Policy Loss:  0.003017900511622429\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.5045514373923652e-05\n",
      "Q Loss:  0.0001935992913786322\n",
      "Policy Loss:  0.008609522134065628\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125541 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  2.096834396070335e-05\n",
      "Q Loss:  0.000425897043896839\n",
      "Policy Loss:  0.013019535690546036\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125545 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.009961704723536968\n",
      "Q Loss:  0.0006316830404102802\n",
      "Policy Loss:  7.940828800201416e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125549 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00982910767197609\n",
      "Q Loss:  0.01077322382479906\n",
      "Policy Loss:  0.0033294642344117165\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125553 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  15367.3125\n",
      "Q Loss:  14803.6083984375\n",
      "Policy Loss:  -17.515169143676758\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125606 length: 53 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.02991056814789772\n",
      "Q Loss:  0.024812858551740646\n",
      "Policy Loss:  -0.09402856230735779\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125610 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1181926727294922\n",
      "Q Loss:  0.005924521945416927\n",
      "Policy Loss:  0.15139071643352509\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125693 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  13344.388671875\n",
      "Q Loss:  12895.7841796875\n",
      "Policy Loss:  -16.318864822387695\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125754 length: 61 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  4.5315617171581835e-05\n",
      "Q Loss:  0.00041352363768965006\n",
      "Policy Loss:  0.0015254792524501681\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  4.817774606635794e-05\n",
      "Q Loss:  5.0956303311977535e-05\n",
      "Policy Loss:  -0.0016656303778290749\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  3.6175508284941316e-05\n",
      "Q Loss:  0.001319613540545106\n",
      "Policy Loss:  0.011509024538099766\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  529.1025390625\n",
      "Q Loss:  913.3206176757812\n",
      "Policy Loss:  -51.134334564208984\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125821 length: 55 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.064959815266775e-05\n",
      "Q Loss:  0.004656409844756126\n",
      "Policy Loss:  0.03664068877696991\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.048150308430194855\n",
      "Q Loss:  0.006836208514869213\n",
      "Policy Loss:  -0.017719034105539322\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125829 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.03351520001888275\n",
      "Q Loss:  0.009869241155683994\n",
      "Policy Loss:  0.015359394252300262\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.223167061805725\n",
      "Q Loss:  0.004409369081258774\n",
      "Policy Loss:  0.19237659871578217\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125907 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  6.743165431544185e-05\n",
      "Q Loss:  0.0011064187856391072\n",
      "Policy Loss:  0.012875395826995373\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 125911 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.1054896933492273e-05\n",
      "Q Loss:  0.0006334905629046261\n",
      "Policy Loss:  0.037511587142944336\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  2.293739080429077\n",
      "Q Loss:  0.002108937129378319\n",
      "Policy Loss:  0.35128551721572876\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125954 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.2896436601295136e-05\n",
      "Q Loss:  0.0006158449104987085\n",
      "Policy Loss:  0.010569402948021889\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.13992274843622e-05\n",
      "Q Loss:  5.115586463944055e-05\n",
      "Policy Loss:  0.00195494806393981\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 125962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  1.2459828853607178\n",
      "Q Loss:  0.0038985228165984154\n",
      "Policy Loss:  0.1891370415687561\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126033 length: 71 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.025005817413330078\n",
      "Value Loss:  0.027997132390737534\n",
      "Q Loss:  0.0025918802712112665\n",
      "Policy Loss:  0.0323249027132988\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.03006438910961151\n",
      "Q Loss:  0.0165181215852499\n",
      "Policy Loss:  0.030563775449991226\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.1353633403778076\n",
      "Q Loss:  0.0066849300637841225\n",
      "Policy Loss:  0.1665031462907791\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126119 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  1.679947854427155e-05\n",
      "Q Loss:  0.00024093507090583444\n",
      "Policy Loss:  0.008331431075930595\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  1.7146954633062705e-05\n",
      "Q Loss:  2.029766983469017e-05\n",
      "Policy Loss:  -0.0024881139397621155\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126127 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.8623170035425574e-05\n",
      "Q Loss:  1.2739352314383723e-05\n",
      "Policy Loss:  -0.0014388775452971458\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.4455115888267756e-05\n",
      "Q Loss:  0.00011138574336655438\n",
      "Policy Loss:  0.003389955498278141\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  9.104317541641649e-06\n",
      "Q Loss:  0.00012166372471256182\n",
      "Policy Loss:  0.0024899491108953953\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.041794657707214355\n",
      "Q Loss:  0.015198316425085068\n",
      "Policy Loss:  0.023916903883218765\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.841838538646698\n",
      "Q Loss:  0.004937897901982069\n",
      "Policy Loss:  0.1335275024175644\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 126244 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.035007476806640625\n",
      "Value Loss:  0.044011835008859634\n",
      "Q Loss:  0.05245283618569374\n",
      "Policy Loss:  -0.03536558896303177\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126248 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03100728988647461\n",
      "Value Loss:  2.926636443589814e-05\n",
      "Q Loss:  0.00010005942749558017\n",
      "Policy Loss:  0.0056024398654699326\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126252 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.0002300768974237e-05\n",
      "Q Loss:  0.0003289850428700447\n",
      "Policy Loss:  0.07599033415317535\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126256 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.046309951692819595\n",
      "Q Loss:  0.010532518848776817\n",
      "Policy Loss:  -0.030232688412070274\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009999513626098633\n",
      "Value Loss:  1.997277286136523e-05\n",
      "Q Loss:  0.0002610056253615767\n",
      "Policy Loss:  0.009560536593198776\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  5.4120760069054086e-06\n",
      "Q Loss:  0.0005955767119303346\n",
      "Policy Loss:  0.01602611131966114\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  2.2714564238413004e-06\n",
      "Q Loss:  0.00042227376252412796\n",
      "Policy Loss:  0.010085044428706169\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  1.8449783965479583e-05\n",
      "Q Loss:  0.00019473020802251995\n",
      "Policy Loss:  0.004267343319952488\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.09391648322343826\n",
      "Q Loss:  0.054677221924066544\n",
      "Policy Loss:  -0.028537306934595108\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0921749472618103\n",
      "Q Loss:  0.019817249849438667\n",
      "Policy Loss:  -0.02270939201116562\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  163.85809326171875\n",
      "Q Loss:  309.2762145996094\n",
      "Policy Loss:  -16.489110946655273\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126404 length: 120 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.0021903105080127716\n",
      "Q Loss:  359.08538818359375\n",
      "Policy Loss:  11.378091812133789\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0014839792856946588\n",
      "Q Loss:  476.7121276855469\n",
      "Policy Loss:  15.040874481201172\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 126412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  7.375244604190812e-05\n",
      "Q Loss:  235.8233184814453\n",
      "Policy Loss:  7.495460510253906\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 126416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.9407375879818574e-05\n",
      "Q Loss:  0.0012666909024119377\n",
      "Policy Loss:  0.014582893811166286\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 126420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.000177571433596313\n",
      "Q Loss:  0.000761727336794138\n",
      "Policy Loss:  0.0037366929464042187\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 126424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00012391971540637314\n",
      "Q Loss:  0.0005740577471442521\n",
      "Policy Loss:  -0.01157134585082531\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00015589460963383317\n",
      "Q Loss:  2.1399800971266814e-05\n",
      "Policy Loss:  -0.004062756430357695\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.03792044520378113\n",
      "Q Loss:  0.000496752851177007\n",
      "Policy Loss:  -0.0034858547151088715\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.0702565908432007\n",
      "Q Loss:  0.011869365349411964\n",
      "Policy Loss:  0.13042673468589783\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126517 length: 81 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  9.964031960407738e-06\n",
      "Q Loss:  0.0012843781150877476\n",
      "Policy Loss:  -0.02255801111459732\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  8.055496891756775e-08\n",
      "Q Loss:  0.0017442376120015979\n",
      "Policy Loss:  -0.02381718158721924\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  6.49911817163229e-06\n",
      "Q Loss:  0.0016849938547238708\n",
      "Policy Loss:  -0.023544616997241974\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  2.4936627596616745e-05\n",
      "Q Loss:  0.0015915348194539547\n",
      "Policy Loss:  -0.02407357469201088\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.1105484664440155\n",
      "Q Loss:  0.10151821374893188\n",
      "Policy Loss:  -0.13535505533218384\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126537 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  11107.1455078125\n",
      "Q Loss:  10802.8359375\n",
      "Policy Loss:  -26.945363998413086\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126611 length: 74 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  4.205348886898719e-05\n",
      "Q Loss:  0.00022889729007147253\n",
      "Policy Loss:  -0.0024440744891762733\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010003328323364258\n",
      "Value Loss:  0.03475206717848778\n",
      "Q Loss:  0.0010538770584389567\n",
      "Policy Loss:  0.018740154802799225\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.06789039820432663\n",
      "Q Loss:  0.01591339521110058\n",
      "Policy Loss:  -0.01947706937789917\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 126623 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0325416624546051\n",
      "Q Loss:  0.02320905774831772\n",
      "Policy Loss:  -0.005613630637526512\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126627 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800607681274414\n",
      "Value Loss:  2.9827351681888103e-06\n",
      "Q Loss:  0.002235842403024435\n",
      "Policy Loss:  0.030742108821868896\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126631 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.5372253983514383e-05\n",
      "Q Loss:  0.0034811673685908318\n",
      "Policy Loss:  0.03995993733406067\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.028369152918457985\n",
      "Q Loss:  0.00998837873339653\n",
      "Policy Loss:  0.04538002610206604\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.08092346787452698\n",
      "Q Loss:  0.008436654694378376\n",
      "Policy Loss:  -0.004318730905652046\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.8606770038604736\n",
      "Q Loss:  0.0067872763611376286\n",
      "Policy Loss:  0.1457373946905136\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126747 length: 104 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.010088833048939705\n",
      "Q Loss:  0.034496065229177475\n",
      "Policy Loss:  0.06253672391176224\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126751 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.008715861476957798\n",
      "Q Loss:  0.0022586598061025143\n",
      "Policy Loss:  0.02634822390973568\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  9.144669661509397e-07\n",
      "Q Loss:  0.002517883200198412\n",
      "Policy Loss:  -0.04264383763074875\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.000640856334939599\n",
      "Q Loss:  0.002558445790782571\n",
      "Policy Loss:  -0.027847982943058014\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00030966917984187603\n",
      "Q Loss:  0.002592019271105528\n",
      "Policy Loss:  -0.025621678680181503\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126767 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00010411916446173564\n",
      "Q Loss:  0.0003498565638437867\n",
      "Policy Loss:  -0.001497942954301834\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126771 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.004242712631821632\n",
      "Q Loss:  204.8195343017578\n",
      "Policy Loss:  7.023784637451172\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126775 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0005452761542983353\n",
      "Q Loss:  0.00974154844880104\n",
      "Policy Loss:  -0.03519517183303833\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126779 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.1064690119819716e-05\n",
      "Q Loss:  0.00024451903300359845\n",
      "Policy Loss:  0.009411687031388283\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126783 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001016616821289\n",
      "Value Loss:  0.0004932775627821684\n",
      "Q Loss:  0.014827247709035873\n",
      "Policy Loss:  -0.0499204620718956\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126787 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0003163596265949309\n",
      "Q Loss:  0.0007268573390319943\n",
      "Policy Loss:  -0.000953000970184803\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00011713462299667299\n",
      "Q Loss:  0.0008275839500129223\n",
      "Policy Loss:  0.03846299648284912\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126795 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.06487807631492615\n",
      "Q Loss:  0.0023878789506852627\n",
      "Policy Loss:  0.014169689267873764\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.030719269067049026\n",
      "Q Loss:  0.01730702817440033\n",
      "Policy Loss:  0.04871639609336853\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  13750.1123046875\n",
      "Q Loss:  13314.2978515625\n",
      "Policy Loss:  -16.524839401245117\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126862 length: 59 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0004939104546792805\n",
      "Q Loss:  0.0010692585492506623\n",
      "Policy Loss:  0.015426606871187687\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126866 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  0.0010265606688335538\n",
      "Q Loss:  0.0008368383278138936\n",
      "Policy Loss:  0.0131562864407897\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.067467671120539e-06\n",
      "Q Loss:  0.00011638220166787505\n",
      "Policy Loss:  -0.003263869322836399\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126874 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.747289949591504e-06\n",
      "Q Loss:  0.00019499537302181125\n",
      "Policy Loss:  0.0006657431949861348\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126878 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  5.935540684731677e-06\n",
      "Q Loss:  9.199244232149795e-05\n",
      "Policy Loss:  0.00012222639634273946\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126882 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001110076904297\n",
      "Value Loss:  1.5819400687178131e-06\n",
      "Q Loss:  5.601353768724948e-05\n",
      "Policy Loss:  -0.0022983760572969913\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126886 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  2.043072981905425e-07\n",
      "Q Loss:  6.0376049077603966e-05\n",
      "Policy Loss:  -0.005764451809227467\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126890 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.011066781356930733\n",
      "Q Loss:  0.00045961179421283305\n",
      "Policy Loss:  0.026182785630226135\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126894 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.042909182608127594\n",
      "Q Loss:  0.000610330025665462\n",
      "Policy Loss:  -0.03220397233963013\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126898 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.02988624945282936\n",
      "Q Loss:  0.020872443914413452\n",
      "Policy Loss:  -0.02476191520690918\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126902 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  3.6525023460853845e-05\n",
      "Q Loss:  5.967350716673536e-06\n",
      "Policy Loss:  0.0021751916501671076\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126906 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  3.548351378412917e-05\n",
      "Q Loss:  0.0005255784490145743\n",
      "Policy Loss:  0.014209818094968796\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126910 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003795623779297\n",
      "Value Loss:  0.0002129950444214046\n",
      "Q Loss:  0.000190913793630898\n",
      "Policy Loss:  0.0012713810428977013\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126914 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010000228881835938\n",
      "Value Loss:  0.00041449262062087655\n",
      "Q Loss:  0.0003972631529904902\n",
      "Policy Loss:  -0.002376250922679901\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.0444449799251743e-05\n",
      "Q Loss:  0.00043170139542780817\n",
      "Policy Loss:  0.010795142501592636\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.747830174281262e-05\n",
      "Q Loss:  0.00016232291818596423\n",
      "Policy Loss:  0.005685671232640743\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00012867925397586077\n",
      "Q Loss:  9.179786502500065e-06\n",
      "Policy Loss:  -0.0026638873387128115\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126930 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  7.530266157118604e-05\n",
      "Q Loss:  0.0035831923596560955\n",
      "Policy Loss:  0.012527493759989738\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  0.010367661714553833\n",
      "Q Loss:  0.0027093873359262943\n",
      "Policy Loss:  -0.015526846051216125\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  6.67911626806017e-06\n",
      "Q Loss:  0.00022277957759797573\n",
      "Policy Loss:  -0.00907924771308899\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  7.108070349204354e-06\n",
      "Q Loss:  0.0004062247462570667\n",
      "Policy Loss:  -0.01167747750878334\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.00853890273720026\n",
      "Q Loss:  0.002037688158452511\n",
      "Policy Loss:  0.011504817754030228\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0039638192392885685\n",
      "Q Loss:  0.002840588102117181\n",
      "Policy Loss:  0.02360006794333458\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 126954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  1.3824752569198608\n",
      "Q Loss:  0.0019060997292399406\n",
      "Policy Loss:  0.1973477602005005\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127023 length: 69 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.003709993790835142\n",
      "Q Loss:  0.0013767691561952233\n",
      "Policy Loss:  0.016549205407500267\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127027 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.007390084210783243\n",
      "Q Loss:  0.0017812565201893449\n",
      "Policy Loss:  -0.012713777832686901\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.040484585246304e-05\n",
      "Q Loss:  0.002057085745036602\n",
      "Policy Loss:  0.014753852970898151\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0035659840796142817\n",
      "Q Loss:  0.0011441673850640655\n",
      "Policy Loss:  0.014852059073746204\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.9565539956092834\n",
      "Q Loss:  0.002482579555362463\n",
      "Policy Loss:  0.1266023963689804\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127139 length: 100 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6.358679092954844e-05\n",
      "Q Loss:  0.00019367030472494662\n",
      "Policy Loss:  -0.0050862981006503105\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  4.85259952256456e-05\n",
      "Q Loss:  1.912134393933229e-05\n",
      "Policy Loss:  0.0009096089052036405\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  6.203734665177763e-05\n",
      "Q Loss:  0.0005721324123442173\n",
      "Policy Loss:  -0.014239148236811161\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  6.762846851415816e-07\n",
      "Q Loss:  0.0006589824333786964\n",
      "Policy Loss:  -0.012216753326356411\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127155 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.4262002423492959e-06\n",
      "Q Loss:  0.00016103162488434464\n",
      "Policy Loss:  -0.0034540186170488596\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127159 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003971099853516\n",
      "Value Loss:  2.488688153334806e-07\n",
      "Q Loss:  8.229615923482925e-05\n",
      "Policy Loss:  -0.0035641356371343136\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.3034038543701172\n",
      "Q Loss:  0.0029922157991677523\n",
      "Policy Loss:  0.17211033403873444\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127236 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.4303186535835266\n",
      "Q Loss:  0.002358400961384177\n",
      "Policy Loss:  0.04797959700226784\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127458 length: 222 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  4.309278665459715e-05\n",
      "Q Loss:  8.828037971397862e-05\n",
      "Policy Loss:  0.0026996410451829433\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3.6243443901184946e-05\n",
      "Q Loss:  0.0010815516579896212\n",
      "Policy Loss:  -0.013207750394940376\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127466 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01190185546875\n",
      "Value Loss:  3.044931509066373e-05\n",
      "Q Loss:  0.002254452323541045\n",
      "Policy Loss:  -0.02245713397860527\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127470 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.622174931981135e-05\n",
      "Q Loss:  0.0003056861169170588\n",
      "Policy Loss:  -0.004278986714780331\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127474 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  3.088495577685535e-05\n",
      "Q Loss:  7.964096585055813e-05\n",
      "Policy Loss:  -0.0002759082708507776\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.006720159202814102\n",
      "Q Loss:  0.006302313879132271\n",
      "Policy Loss:  -0.01976773515343666\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  3.0889502795616863e-06\n",
      "Q Loss:  0.005525633227080107\n",
      "Policy Loss:  0.006674893666058779\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.02138087898492813\n",
      "Q Loss:  0.005818693432956934\n",
      "Policy Loss:  -0.05288339778780937\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  8.256317869381746e-07\n",
      "Q Loss:  0.00024338522052858025\n",
      "Policy Loss:  0.011298433877527714\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127494 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  0.00012634816812351346\n",
      "Q Loss:  0.002108235377818346\n",
      "Policy Loss:  0.030100539326667786\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127498 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00016049224359449\n",
      "Q Loss:  0.0008361710933968425\n",
      "Policy Loss:  0.010091608390212059\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127502 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00010889150144066662\n",
      "Q Loss:  0.0031648201402276754\n",
      "Policy Loss:  0.03270997852087021\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03261685371398926\n",
      "Value Loss:  2.502499773981981e-05\n",
      "Q Loss:  0.0015776661457493901\n",
      "Policy Loss:  0.013675257563591003\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046010494232177734\n",
      "Value Loss:  0.00015310844173654914\n",
      "Q Loss:  0.010727430693805218\n",
      "Policy Loss:  0.04005397856235504\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127514 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  4.274448292562738e-05\n",
      "Q Loss:  0.0008028482552617788\n",
      "Policy Loss:  0.012409517541527748\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127518 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.4983026378322393e-05\n",
      "Q Loss:  0.00021177630696911365\n",
      "Policy Loss:  0.0004499709466472268\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  6.134178693173453e-05\n",
      "Q Loss:  0.00018212362192571163\n",
      "Policy Loss:  0.004440094344317913\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.5074221412069164e-05\n",
      "Q Loss:  0.002430608496069908\n",
      "Policy Loss:  0.036947332322597504\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.027620254084467888\n",
      "Q Loss:  0.0044679115526378155\n",
      "Policy Loss:  -0.052167825400829315\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.1183408498764038\n",
      "Q Loss:  0.0031222098041325808\n",
      "Policy Loss:  0.16846613585948944\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 127618 length: 84 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  2506.623291015625\n",
      "Q Loss:  6010.21484375\n",
      "Policy Loss:  -137.3612060546875\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 127622 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2498.800048828125\n",
      "Q Loss:  3737.685546875\n",
      "Policy Loss:  -136.69004821777344\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 127626 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0011373759480193257\n",
      "Q Loss:  99.31463623046875\n",
      "Policy Loss:  3.5736405849456787\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 127630 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0001269747008336708\n",
      "Q Loss:  0.00012038296699756756\n",
      "Policy Loss:  0.006892893463373184\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 127634 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002926536544691771\n",
      "Q Loss:  0.0037754387594759464\n",
      "Policy Loss:  0.028126120567321777\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 127638 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.0002707192616071552\n",
      "Q Loss:  0.0024150596000254154\n",
      "Policy Loss:  0.022565320134162903\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 127642 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.020674919709563255\n",
      "Q Loss:  0.009183819405734539\n",
      "Policy Loss:  0.011645637452602386\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 127646 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.013681452721357346\n",
      "Q Loss:  0.011070329695940018\n",
      "Policy Loss:  0.025063643231987953\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 127650 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0006032655364833772\n",
      "Q Loss:  0.006176489870995283\n",
      "Policy Loss:  0.04086553305387497\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 127654 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.00024047390616033226\n",
      "Q Loss:  0.0021806848235428333\n",
      "Policy Loss:  0.013908620923757553\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 127658 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  1.3260204468679149e-05\n",
      "Q Loss:  8.63806635607034e-05\n",
      "Policy Loss:  -0.012060558423399925\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 127662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.00010309094795957208\n",
      "Q Loss:  0.00046657235361635685\n",
      "Policy Loss:  -0.02413676679134369\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127666 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0002616578422021121\n",
      "Q Loss:  0.0019254867220297456\n",
      "Policy Loss:  -0.03797411173582077\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127670 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900718688964844\n",
      "Value Loss:  0.0002196044661104679\n",
      "Q Loss:  0.0004115819465368986\n",
      "Policy Loss:  0.00894729420542717\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.020901115611195564\n",
      "Q Loss:  0.0017520461697131395\n",
      "Policy Loss:  -0.038574010133743286\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127678 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.019568653777241707\n",
      "Q Loss:  0.001246840343810618\n",
      "Policy Loss:  -0.030010761693120003\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010003089904785156\n",
      "Value Loss:  0.5881272554397583\n",
      "Q Loss:  0.003928643651306629\n",
      "Policy Loss:  0.061821550130844116\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127844 length: 162 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.04400944709777832\n",
      "Value Loss:  0.0005557663389481604\n",
      "Q Loss:  0.004670658614486456\n",
      "Policy Loss:  -0.028789183124899864\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.008082926273345947\n",
      "Q Loss:  0.003681135829538107\n",
      "Policy Loss:  0.00366881862282753\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  58187.23046875\n",
      "Q Loss:  56000.95703125\n",
      "Policy Loss:  -66.84254455566406\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127866 length: 14 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00013755762483924627\n",
      "Q Loss:  0.00042043637949973345\n",
      "Policy Loss:  -0.009062892757356167\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127870 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.660649430363264e-07\n",
      "Q Loss:  0.0004906312096863985\n",
      "Policy Loss:  0.01793219894170761\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127874 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.026587720960378647\n",
      "Q Loss:  0.0014267814112827182\n",
      "Policy Loss:  -0.03240983933210373\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127878 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.9198857545852661\n",
      "Q Loss:  0.0025798010174185038\n",
      "Policy Loss:  0.12935581803321838\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127980 length: 102 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010002851486206055\n",
      "Value Loss:  0.0002032444899668917\n",
      "Q Loss:  0.00036937143886461854\n",
      "Policy Loss:  0.024586573243141174\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 127984 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  108.74613952636719\n",
      "Q Loss:  148.83120727539062\n",
      "Policy Loss:  -11.331384658813477\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128075 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.000310153845930472\n",
      "Q Loss:  0.00021894580277148634\n",
      "Policy Loss:  -0.0014719204045832157\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  0.0002648546069394797\n",
      "Q Loss:  0.00013059095363132656\n",
      "Policy Loss:  0.0004807565128430724\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128083 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00017059998936019838\n",
      "Q Loss:  0.00015658176562283188\n",
      "Policy Loss:  0.006690270267426968\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128087 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.014085749164223671\n",
      "Q Loss:  0.008747441694140434\n",
      "Policy Loss:  0.030477255582809448\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128091 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.014872630126774311\n",
      "Q Loss:  0.007781534921377897\n",
      "Policy Loss:  0.0284455344080925\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128095 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.045980118215084076\n",
      "Q Loss:  0.004654153250157833\n",
      "Policy Loss:  -0.015424579381942749\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128099 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.06137795001268387\n",
      "Q Loss:  0.0051930928602814674\n",
      "Policy Loss:  -0.059293486177921295\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.014753660187125206\n",
      "Q Loss:  0.007437557447701693\n",
      "Policy Loss:  0.003839375451207161\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  0.7519455552101135\n",
      "Q Loss:  10.243417739868164\n",
      "Policy Loss:  0.46735700964927673\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128230 length: 123 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00065403594635427\n",
      "Q Loss:  0.0028178892098367214\n",
      "Policy Loss:  0.031057029962539673\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.1491185432532802e-05\n",
      "Q Loss:  0.0007686160388402641\n",
      "Policy Loss:  0.006710886023938656\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  73.43018341064453\n",
      "Q Loss:  138.68328857421875\n",
      "Policy Loss:  -7.354276657104492\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128376 length: 138 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.05330841988325119\n",
      "Q Loss:  0.007131750229746103\n",
      "Policy Loss:  -0.04389052838087082\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128380 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.012937793508172035\n",
      "Q Loss:  0.006772814318537712\n",
      "Policy Loss:  0.06493402272462845\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128384 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  2.047940492630005\n",
      "Q Loss:  0.0033289315178990364\n",
      "Policy Loss:  0.2998829483985901\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128429 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05001187324523926\n",
      "Value Loss:  0.00037362484727054834\n",
      "Q Loss:  0.0007202719571068883\n",
      "Policy Loss:  -0.012328717857599258\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.134302333928645e-05\n",
      "Q Loss:  0.00018968747463077307\n",
      "Policy Loss:  0.006244190037250519\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128437 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  9.754938946571201e-05\n",
      "Q Loss:  0.00023664423497393727\n",
      "Policy Loss:  -0.006515669170767069\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  6.800943810958415e-05\n",
      "Q Loss:  0.0005038576782681048\n",
      "Policy Loss:  -0.014315169304609299\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.548889460740611e-05\n",
      "Q Loss:  0.00026021714438684285\n",
      "Policy Loss:  0.027176357805728912\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02500605583190918\n",
      "Value Loss:  1.0603355169296265\n",
      "Q Loss:  0.004143127705901861\n",
      "Policy Loss:  0.1317884922027588\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128536 length: 87 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  3.351863779244013e-05\n",
      "Q Loss:  1.5706242265878245e-05\n",
      "Policy Loss:  -0.0009905067272484303\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128540 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019005298614501953\n",
      "Value Loss:  0.0002179979346692562\n",
      "Q Loss:  0.0023354210425168276\n",
      "Policy Loss:  -0.018342798575758934\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128544 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.00024263776140287519\n",
      "Q Loss:  0.0006539315218105912\n",
      "Policy Loss:  -0.013007733970880508\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500985145568848\n",
      "Value Loss:  0.00033300661016255617\n",
      "Q Loss:  0.00018312092288397253\n",
      "Policy Loss:  -0.008692959323525429\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  5.1558588893385604e-05\n",
      "Q Loss:  1.1779291526181623e-05\n",
      "Policy Loss:  0.002588791772723198\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.016042141243815422\n",
      "Q Loss:  0.002689740853384137\n",
      "Policy Loss:  0.016097484156489372\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.03226625174283981\n",
      "Q Loss:  0.007140001747757196\n",
      "Policy Loss:  -0.036007486283779144\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.03172092139720917\n",
      "Q Loss:  0.0072721876204013824\n",
      "Policy Loss:  -0.0005046948790550232\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128568 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  0.00013393571134656668\n",
      "Q Loss:  0.0003650308644864708\n",
      "Policy Loss:  0.009477369487285614\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0003559764882083982\n",
      "Q Loss:  0.0006802667048759758\n",
      "Policy Loss:  0.0199226476252079\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128576 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00025581795489415526\n",
      "Q Loss:  0.001690595061518252\n",
      "Policy Loss:  -0.012174388393759727\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128580 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00011629916116362438\n",
      "Q Loss:  0.0012358671519905329\n",
      "Policy Loss:  -0.012986395508050919\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128584 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.037252187728881836\n",
      "Q Loss:  0.027632730081677437\n",
      "Policy Loss:  0.024589162319898605\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0647052451968193\n",
      "Q Loss:  0.035301633179187775\n",
      "Policy Loss:  0.049481868743896484\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0003622896911110729\n",
      "Q Loss:  0.010859241709113121\n",
      "Policy Loss:  -0.08020750433206558\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.014486740343272686\n",
      "Q Loss:  100.62503051757812\n",
      "Policy Loss:  3.5172276496887207\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0004549752047751099\n",
      "Q Loss:  0.006565445102751255\n",
      "Policy Loss:  -0.044431738555431366\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128604 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.0033626025542616844\n",
      "Q Loss:  0.002869922434911132\n",
      "Policy Loss:  0.03292751684784889\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128608 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0006135045550763607\n",
      "Q Loss:  7.794303382979706e-05\n",
      "Policy Loss:  -0.009271159768104553\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128612 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0013978936476632953\n",
      "Q Loss:  0.0016675584483891726\n",
      "Policy Loss:  0.027400994673371315\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128616 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.038008928298950195\n",
      "Value Loss:  0.039796195924282074\n",
      "Q Loss:  0.004710964858531952\n",
      "Policy Loss:  -0.05987370014190674\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128620 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  6.527730147354305e-05\n",
      "Q Loss:  0.0005682939081452787\n",
      "Policy Loss:  0.011650199070572853\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128624 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.002201044699177146\n",
      "Q Loss:  0.0008346904069185257\n",
      "Policy Loss:  -0.020223697647452354\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128628 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0003404288727324456\n",
      "Q Loss:  0.00014071054465603083\n",
      "Policy Loss:  0.009114759042859077\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128632 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.00023853829770814627\n",
      "Q Loss:  0.0002512423670850694\n",
      "Policy Loss:  0.004791867919266224\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0001555129565531388\n",
      "Q Loss:  0.0007707704789936543\n",
      "Policy Loss:  0.015131998807191849\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00018545164493843913\n",
      "Q Loss:  0.0002387403801549226\n",
      "Policy Loss:  0.010767094790935516\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.051010847091674805\n",
      "Value Loss:  5.0019429181702435e-05\n",
      "Q Loss:  0.0008624589536339045\n",
      "Policy Loss:  0.013768093660473824\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.021437184885144234\n",
      "Q Loss:  0.009290906600654125\n",
      "Policy Loss:  0.06878896802663803\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.04131683334708214\n",
      "Q Loss:  0.0008688707021065056\n",
      "Policy Loss:  -0.032739508897066116\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  124.37762451171875\n",
      "Q Loss:  171.9899139404297\n",
      "Policy Loss:  -12.512073516845703\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128738 length: 82 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.9195780623704195e-05\n",
      "Q Loss:  3.993243080913089e-05\n",
      "Policy Loss:  -0.001843077247031033\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.01848076656460762\n",
      "Q Loss:  0.008030431345105171\n",
      "Policy Loss:  0.02528989687561989\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128746 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.0005794076714664698\n",
      "Q Loss:  0.003581210970878601\n",
      "Policy Loss:  0.03540283441543579\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128750 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0005455162026919425\n",
      "Q Loss:  0.0017203056486323476\n",
      "Policy Loss:  0.05030655115842819\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  82.86192321777344\n",
      "Q Loss:  164.38046264648438\n",
      "Policy Loss:  -7.901642799377441\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128877 length: 123 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00017501701950095594\n",
      "Q Loss:  2.7455382678454043e-07\n",
      "Policy Loss:  -0.0011507635936141014\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0006053748656995595\n",
      "Q Loss:  0.0003899468865711242\n",
      "Policy Loss:  -0.00984429195523262\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00042231695260852575\n",
      "Q Loss:  0.00033232130226679146\n",
      "Policy Loss:  -0.006286812014877796\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00017592794029042125\n",
      "Q Loss:  0.00034646119456738234\n",
      "Policy Loss:  -0.00891111046075821\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128893 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.0719197790604085e-05\n",
      "Q Loss:  0.0004990598536096513\n",
      "Policy Loss:  0.0168741624802351\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400087833404541\n",
      "Value Loss:  2.8220670223236084\n",
      "Q Loss:  0.009865578263998032\n",
      "Policy Loss:  0.3972552418708801\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 128930 length: 33 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.12651152908802032\n",
      "Q Loss:  287.962158203125\n",
      "Policy Loss:  10.293600082397461\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 128934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02800607681274414\n",
      "Value Loss:  0.031408123672008514\n",
      "Q Loss:  0.04406360536813736\n",
      "Policy Loss:  0.061099324375391006\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 128938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00010902829671977088\n",
      "Q Loss:  0.0012119575403630733\n",
      "Policy Loss:  -0.018354570493102074\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 128942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0003937411238439381\n",
      "Q Loss:  0.0017152680084109306\n",
      "Policy Loss:  -0.030147559940814972\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 128946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00019266773597337306\n",
      "Q Loss:  0.001114889164455235\n",
      "Policy Loss:  -0.019293317571282387\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 128950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  6.64011895423755e-05\n",
      "Q Loss:  0.0003315089561510831\n",
      "Policy Loss:  -0.01032863836735487\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 128954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00021732661116402596\n",
      "Q Loss:  0.003360637929290533\n",
      "Policy Loss:  -0.02640560269355774\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 128958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.013894176110625267\n",
      "Q Loss:  0.029052533209323883\n",
      "Policy Loss:  -0.05997263267636299\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 128962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.014447219669818878\n",
      "Q Loss:  0.014643227681517601\n",
      "Policy Loss:  -0.028566116467118263\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 128966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.1382155418395996\n",
      "Q Loss:  9.696041107177734\n",
      "Policy Loss:  0.4988920986652374\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129046 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.0004285277973394841\n",
      "Q Loss:  0.0015067914500832558\n",
      "Policy Loss:  -0.02170928195118904\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129050 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.010614573955535889\n",
      "Q Loss:  1349.0723876953125\n",
      "Policy Loss:  6.8374457359313965\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129054 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8520.3671875\n",
      "Q Loss:  8220.7998046875\n",
      "Policy Loss:  -10.377212524414062\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129149 length: 95 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011621713638305664\n",
      "Value Loss:  0.013244411908090115\n",
      "Q Loss:  97.25050354003906\n",
      "Policy Loss:  3.4260740280151367\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129153 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00037546452949754894\n",
      "Q Loss:  0.0010076765902340412\n",
      "Policy Loss:  0.02048838511109352\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129157 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500795364379883\n",
      "Value Loss:  0.00017287011723965406\n",
      "Q Loss:  0.0004584472335409373\n",
      "Policy Loss:  0.00868681538850069\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129161 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00015172793064266443\n",
      "Q Loss:  2.9614635423058644e-05\n",
      "Policy Loss:  0.0026269827503710985\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129165 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100942611694336\n",
      "Value Loss:  0.039729151874780655\n",
      "Q Loss:  0.021753665059804916\n",
      "Policy Loss:  -0.050648920238018036\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129169 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.07992323487997055\n",
      "Q Loss:  0.020439976826310158\n",
      "Policy Loss:  -0.09298115968704224\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129173 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  0.019321000203490257\n",
      "Q Loss:  0.014297042042016983\n",
      "Policy Loss:  0.04473411664366722\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129177 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0002235438150819391\n",
      "Q Loss:  0.00389675609767437\n",
      "Policy Loss:  0.022859815508127213\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  9.705311094876379e-05\n",
      "Q Loss:  0.00817598681896925\n",
      "Policy Loss:  0.04128630459308624\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  6.216140900505707e-05\n",
      "Q Loss:  0.007452249526977539\n",
      "Policy Loss:  0.03967749699950218\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  7.78416870161891e-05\n",
      "Q Loss:  0.004084338434040546\n",
      "Policy Loss:  0.026942938566207886\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00014806103718001395\n",
      "Q Loss:  0.0006795133231207728\n",
      "Policy Loss:  0.014365013688802719\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00011917558731511235\n",
      "Q Loss:  0.002601460786536336\n",
      "Policy Loss:  0.0160280242562294\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011640787124633789\n",
      "Value Loss:  7.266417378559709e-05\n",
      "Q Loss:  0.0010623468551784754\n",
      "Policy Loss:  -0.0016049352707341313\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06701517105102539\n",
      "Value Loss:  7.427595846820623e-05\n",
      "Q Loss:  0.0001165310968644917\n",
      "Policy Loss:  -0.014979219995439053\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  7.337725401157513e-05\n",
      "Q Loss:  0.00033035132219083607\n",
      "Policy Loss:  -0.015811700373888016\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.028899025171995163\n",
      "Q Loss:  0.031785544008016586\n",
      "Policy Loss:  0.07245348393917084\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.3245728041511029e-05\n",
      "Q Loss:  0.002552819438278675\n",
      "Policy Loss:  -0.037503570318222046\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129221 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.01351485587656498\n",
      "Q Loss:  0.01636996492743492\n",
      "Policy Loss:  0.0017714370042085648\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.013008558191359043\n",
      "Q Loss:  0.015338391065597534\n",
      "Policy Loss:  -0.0014571510255336761\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.813983883243054e-05\n",
      "Q Loss:  0.007158864289522171\n",
      "Policy Loss:  -0.04828055575489998\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.0497715013334528e-05\n",
      "Q Loss:  0.002560587599873543\n",
      "Policy Loss:  -0.022659217938780785\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.1316826203255914e-05\n",
      "Q Loss:  0.000313133088639006\n",
      "Policy Loss:  -0.009293235838413239\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.3663260688190348e-05\n",
      "Q Loss:  0.0003111757687292993\n",
      "Policy Loss:  -0.002095339121297002\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.558225439017406e-06\n",
      "Q Loss:  0.0004801292670890689\n",
      "Policy Loss:  0.007987053133547306\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  0.9736560583114624\n",
      "Q Loss:  0.002914158161729574\n",
      "Policy Loss:  0.14639081060886383\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129344 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  1.8627792087499984e-05\n",
      "Q Loss:  0.0003562820784281939\n",
      "Policy Loss:  0.0024771166499704123\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.6692332792445086e-05\n",
      "Q Loss:  0.00024697359185665846\n",
      "Policy Loss:  0.005562894977629185\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.021166114136576653\n",
      "Q Loss:  0.004082466941326857\n",
      "Policy Loss:  0.001223936676979065\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  89.97200775146484\n",
      "Q Loss:  196.44451904296875\n",
      "Policy Loss:  -7.861568927764893\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129470 length: 114 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  2540.751708984375\n",
      "Q Loss:  4913.89208984375\n",
      "Policy Loss:  -139.93539428710938\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 129474 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05401253700256348\n",
      "Value Loss:  0.0020412409212440252\n",
      "Q Loss:  0.008165816776454449\n",
      "Policy Loss:  -0.01971108466386795\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.0004835435829591006\n",
      "Q Loss:  0.00020193967793602496\n",
      "Policy Loss:  0.006213329266756773\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 129482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  2.3739650714560412e-05\n",
      "Q Loss:  0.0005001213867217302\n",
      "Policy Loss:  0.01211771834641695\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.8786276996252127e-05\n",
      "Q Loss:  0.0007140050875023007\n",
      "Policy Loss:  0.009336724877357483\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.0492268453817815e-05\n",
      "Q Loss:  0.000864062923938036\n",
      "Policy Loss:  0.040204789489507675\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129494 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04654957726597786\n",
      "Q Loss:  0.004163574893027544\n",
      "Policy Loss:  -0.05081549659371376\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129498 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.011398375034332275\n",
      "Q Loss:  0.006566730327904224\n",
      "Policy Loss:  0.043184228241443634\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129502 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.04365316033363342\n",
      "Q Loss:  0.0013562903041020036\n",
      "Policy Loss:  -0.032604679465293884\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.7090069055557251\n",
      "Q Loss:  0.003152107121422887\n",
      "Policy Loss:  0.12292185425758362\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129637 length: 131 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  5.277828313410282e-05\n",
      "Q Loss:  0.0017316758166998625\n",
      "Policy Loss:  0.020773451775312424\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.572566831484437e-05\n",
      "Q Loss:  0.0002602616441436112\n",
      "Policy Loss:  0.007529843598604202\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129645 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  6.901544111315161e-05\n",
      "Q Loss:  0.002870787400752306\n",
      "Policy Loss:  0.023579293861985207\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129649 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.616752605419606e-05\n",
      "Q Loss:  0.0021936807315796614\n",
      "Policy Loss:  0.017993060871958733\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129653 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.008448932319879532\n",
      "Q Loss:  0.00823917705565691\n",
      "Policy Loss:  0.03376682475209236\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129657 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.83520169230178e-05\n",
      "Q Loss:  0.00042003687121905386\n",
      "Policy Loss:  0.031300827860832214\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129661 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  212.41815185546875\n",
      "Q Loss:  286.15875244140625\n",
      "Policy Loss:  -21.672574996948242\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129708 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.533909956691787e-05\n",
      "Q Loss:  0.00034428367507644\n",
      "Policy Loss:  0.003807535395026207\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129712 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  0.00012226414401084185\n",
      "Q Loss:  0.00013955148460809141\n",
      "Policy Loss:  0.00516663258895278\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129716 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03155875205993652\n",
      "Value Loss:  9.807880996959284e-05\n",
      "Q Loss:  0.0002766345569398254\n",
      "Policy Loss:  -0.009746674448251724\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  0.00011480444663902745\n",
      "Q Loss:  0.0007979691727086902\n",
      "Policy Loss:  -0.01574612408876419\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.029026299715042114\n",
      "Q Loss:  0.0006813908694311976\n",
      "Policy Loss:  0.002915414981544018\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  1.272236704826355\n",
      "Q Loss:  0.0034119063057005405\n",
      "Policy Loss:  0.17311857640743256\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129801 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.8523973226547241\n",
      "Q Loss:  7.807462215423584\n",
      "Policy Loss:  0.5300519466400146\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129851 length: 50 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2.5486633603577502e-05\n",
      "Q Loss:  0.0015498735010623932\n",
      "Policy Loss:  -0.02016577497124672\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129855 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5.4303491197060794e-05\n",
      "Q Loss:  0.0008732581045478582\n",
      "Policy Loss:  -0.014291850849986076\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129859 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.00011308708053547889\n",
      "Q Loss:  0.0004313915269449353\n",
      "Policy Loss:  -0.011113581247627735\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129863 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  1.1755504601751454e-05\n",
      "Q Loss:  0.0007721854490227997\n",
      "Policy Loss:  0.026200292631983757\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129867 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.01468074880540371\n",
      "Q Loss:  0.006484868936240673\n",
      "Policy Loss:  -0.02353951707482338\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129871 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00016716592654120177\n",
      "Q Loss:  0.0004527932615019381\n",
      "Policy Loss:  -0.005560651421546936\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129875 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.00012046710617141798\n",
      "Q Loss:  9.112532279687002e-05\n",
      "Policy Loss:  0.005026450380682945\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  4.8787118430482224e-05\n",
      "Q Loss:  0.00019729838822968304\n",
      "Policy Loss:  0.006501578260213137\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.6997220516204834\n",
      "Q Loss:  7.367679119110107\n",
      "Policy Loss:  0.5127089023590088\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129936 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0026623443700373173\n",
      "Q Loss:  0.000588979572057724\n",
      "Policy Loss:  -0.0018267636187374592\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2451.810302734375\n",
      "Q Loss:  4530.2939453125\n",
      "Policy Loss:  -169.6767120361328\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 129944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.005009998567402363\n",
      "Q Loss:  195.61441040039062\n",
      "Policy Loss:  6.8764142990112305\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0030628005042672157\n",
      "Q Loss:  196.3966064453125\n",
      "Policy Loss:  6.878179550170898\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.0006535033462569118\n",
      "Q Loss:  98.62920379638672\n",
      "Policy Loss:  3.447543144226074\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 129956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0005308340769261122\n",
      "Q Loss:  0.0004336272832006216\n",
      "Policy Loss:  0.014099400490522385\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 129960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.5466314554214478\n",
      "Q Loss:  0.003406585892662406\n",
      "Policy Loss:  0.24943728744983673\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 130017 length: 57 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0013474355218932033\n",
      "Q Loss:  0.0015798488166183233\n",
      "Policy Loss:  0.014709491282701492\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 130021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0006581045454367995\n",
      "Q Loss:  97.37053680419922\n",
      "Policy Loss:  3.4129886627197266\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 130025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00017913279589265585\n",
      "Q Loss:  8.954175427788869e-05\n",
      "Policy Loss:  -0.0034536365419626236\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 130029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  3.692931204568595e-05\n",
      "Q Loss:  0.00012806087033823133\n",
      "Policy Loss:  -0.008106784895062447\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 130033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00010604616545606405\n",
      "Q Loss:  0.027927914634346962\n",
      "Policy Loss:  0.008064829744398594\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.1106929779052734\n",
      "Q Loss:  0.017624348402023315\n",
      "Policy Loss:  0.11950928717851639\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130117 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0021976965945214033\n",
      "Q Loss:  0.005571993067860603\n",
      "Policy Loss:  -0.0221096258610487\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130121 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002818311331793666\n",
      "Q Loss:  0.0007459927583113313\n",
      "Policy Loss:  -0.016239255666732788\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130125 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00047777057625353336\n",
      "Q Loss:  0.000759644084610045\n",
      "Policy Loss:  -0.012387685477733612\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130129 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000165298959473148\n",
      "Q Loss:  0.00015466680633835495\n",
      "Policy Loss:  -0.0032089585438370705\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130133 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.04067069664597511\n",
      "Q Loss:  0.00930027011781931\n",
      "Policy Loss:  -0.009036336094141006\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130137 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.08250795304775238\n",
      "Q Loss:  0.024201147258281708\n",
      "Policy Loss:  -0.03740379959344864\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130141 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  72.8577880859375\n",
      "Q Loss:  136.79261779785156\n",
      "Policy Loss:  -7.512768745422363\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130273 length: 132 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  4.236701897752937e-06\n",
      "Q Loss:  0.00018956430722028017\n",
      "Policy Loss:  0.00725074065849185\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400944709777832\n",
      "Value Loss:  2.6847726985579357e-05\n",
      "Q Loss:  0.020329397171735764\n",
      "Policy Loss:  0.02340083010494709\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.0119291543960571\n",
      "Q Loss:  0.01829371228814125\n",
      "Policy Loss:  0.12879732251167297\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130369 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.041398558765649796\n",
      "Q Loss:  0.01417071558535099\n",
      "Policy Loss:  0.04271596297621727\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130373 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04128299281001091\n",
      "Q Loss:  0.019374480471014977\n",
      "Policy Loss:  0.021700255572795868\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.12222734838724136\n",
      "Q Loss:  0.02276112698018551\n",
      "Policy Loss:  -0.03361738473176956\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130381 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.11697196960449219\n",
      "Q Loss:  0.02044125832617283\n",
      "Policy Loss:  -0.012099843472242355\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130385 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0724867582321167\n",
      "Q Loss:  0.019870201125741005\n",
      "Policy Loss:  0.04467481002211571\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130389 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04900693893432617\n",
      "Value Loss:  0.03327365592122078\n",
      "Q Loss:  0.019345227628946304\n",
      "Policy Loss:  0.006036547943949699\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00020548012980725616\n",
      "Q Loss:  0.0012922735186293721\n",
      "Policy Loss:  0.008656383492052555\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.00023703450278844684\n",
      "Q Loss:  0.013669807463884354\n",
      "Policy Loss:  0.040751125663518906\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.07569126784801483\n",
      "Q Loss:  0.03792417794466019\n",
      "Policy Loss:  0.03722872957587242\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.8598209619522095\n",
      "Q Loss:  7.272587776184082\n",
      "Policy Loss:  0.42095857858657837\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130509 length: 104 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  7.00516247889027e-05\n",
      "Q Loss:  0.0038304952904582024\n",
      "Policy Loss:  0.05885833501815796\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130513 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.043767690658569336\n",
      "Value Loss:  1.695999264717102\n",
      "Q Loss:  0.005938468035310507\n",
      "Policy Loss:  0.26406246423721313\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 130566 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2368.6171875\n",
      "Q Loss:  3233.27392578125\n",
      "Policy Loss:  -183.3095245361328\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130570 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.007811531890183687\n",
      "Q Loss:  94.68890380859375\n",
      "Policy Loss:  3.3809258937835693\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 130574 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  2354.01220703125\n",
      "Q Loss:  4358.91943359375\n",
      "Policy Loss:  -166.072998046875\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 130578 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.001869651721790433\n",
      "Q Loss:  93.8398208618164\n",
      "Policy Loss:  3.3878817558288574\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 130582 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  9.138915629591793e-05\n",
      "Q Loss:  0.00020398390188347548\n",
      "Policy Loss:  -0.0008814848843030632\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 130586 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00011295630974927917\n",
      "Q Loss:  0.000653421098832041\n",
      "Policy Loss:  -0.0003757593221962452\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 130590 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00014783798542339355\n",
      "Q Loss:  0.0014514904469251633\n",
      "Policy Loss:  -0.009563751518726349\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 130594 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  0.002056276425719261\n",
      "Q Loss:  0.0062594227492809296\n",
      "Policy Loss:  -0.04874945431947708\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 130598 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00044693780364468694\n",
      "Q Loss:  0.01603221334517002\n",
      "Policy Loss:  -0.0122098159044981\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 130602 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.03486308082938194\n",
      "Q Loss:  0.022849002853035927\n",
      "Policy Loss:  -0.00785883143544197\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 130606 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01802206039428711\n",
      "Value Loss:  0.6658664345741272\n",
      "Q Loss:  0.0038086751010268927\n",
      "Policy Loss:  0.07666179537773132\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 130743 length: 137 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0002534635423216969\n",
      "Q Loss:  0.0015498214634135365\n",
      "Policy Loss:  -0.02750205807387829\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 130747 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013563394546508789\n",
      "Value Loss:  0.0004741066077258438\n",
      "Q Loss:  0.0007696062093600631\n",
      "Policy Loss:  -0.008044542744755745\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 130751 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.053011417388916016\n",
      "Value Loss:  9.079946903511882e-05\n",
      "Q Loss:  0.00306441611610353\n",
      "Policy Loss:  0.06887927651405334\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130755 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.06553217768669128\n",
      "Q Loss:  0.011487871408462524\n",
      "Policy Loss:  -0.08792802691459656\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130759 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.5375193470390514e-05\n",
      "Q Loss:  0.004730734042823315\n",
      "Policy Loss:  0.07546862959861755\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130763 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  46813.2109375\n",
      "Q Loss:  45460.0078125\n",
      "Policy Loss:  -50.2829475402832\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130798 length: 35 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.016607999801635742\n",
      "Value Loss:  5.186885391594842e-05\n",
      "Q Loss:  0.00011259946040809155\n",
      "Policy Loss:  -0.005274309776723385\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0007263430161401629\n",
      "Q Loss:  0.0014860815135762095\n",
      "Policy Loss:  0.02417893335223198\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.014787436462938786\n",
      "Q Loss:  0.012070469558238983\n",
      "Policy Loss:  0.014544916339218616\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.014426828362047672\n",
      "Q Loss:  0.006817148998379707\n",
      "Policy Loss:  0.07598724216222763\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.04230803996324539\n",
      "Q Loss:  0.009836969897150993\n",
      "Policy Loss:  -0.04606088623404503\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 130818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.04039240628480911\n",
      "Q Loss:  0.009740415960550308\n",
      "Policy Loss:  -0.038785170763731\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.037611156702041626\n",
      "Q Loss:  0.007181541062891483\n",
      "Policy Loss:  -0.003974555060267448\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.022904299199581146\n",
      "Q Loss:  0.007668009027838707\n",
      "Policy Loss:  -0.0075433626770973206\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00023792454157955945\n",
      "Q Loss:  0.005153709091246128\n",
      "Policy Loss:  0.03901052474975586\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012004613876342773\n",
      "Value Loss:  0.027588527649641037\n",
      "Q Loss:  0.0019329481292515993\n",
      "Policy Loss:  0.011716696433722973\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  35895.03515625\n",
      "Q Loss:  35005.11328125\n",
      "Policy Loss:  -79.13934326171875\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130884 length: 46 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0001781197206582874\n",
      "Q Loss:  0.0009727386641316116\n",
      "Policy Loss:  0.03833014518022537\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130888 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.006925249006599188\n",
      "Q Loss:  0.008849159814417362\n",
      "Policy Loss:  0.009108767844736576\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130892 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025004863739013672\n",
      "Value Loss:  0.025102324783802032\n",
      "Q Loss:  3.3167118090204895e-05\n",
      "Policy Loss:  -0.01527218148112297\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130896 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.011155026964843273\n",
      "Q Loss:  0.004592892713844776\n",
      "Policy Loss:  -0.0031674522906541824\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130900 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.004885628819465637\n",
      "Q Loss:  0.004813844803720713\n",
      "Policy Loss:  0.025270573794841766\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130904 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  2.61507502727909e-05\n",
      "Q Loss:  2.060458791675046e-05\n",
      "Policy Loss:  -0.008696628734469414\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130908 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  13123.4453125\n",
      "Q Loss:  12752.095703125\n",
      "Policy Loss:  -15.890677452087402\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130970 length: 62 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0009866030886769295\n",
      "Q Loss:  0.000397428433643654\n",
      "Policy Loss:  -0.008914640173316002\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00043943108175881207\n",
      "Q Loss:  6.125178333604708e-05\n",
      "Policy Loss:  0.004384580999612808\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  5.5215146858245134e-05\n",
      "Q Loss:  0.0001651313214097172\n",
      "Policy Loss:  0.0013100295327603817\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00013289169874042273\n",
      "Q Loss:  0.0005117770633660257\n",
      "Policy Loss:  -0.00613024365156889\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00022471186821348965\n",
      "Q Loss:  0.00043008860666304827\n",
      "Policy Loss:  0.010205358266830444\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00017560753622092307\n",
      "Q Loss:  0.0018185678636655211\n",
      "Policy Loss:  0.005085257347673178\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  0.008136637508869171\n",
      "Q Loss:  0.005278729368001223\n",
      "Policy Loss:  -0.028880681842565536\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 130998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.010166692547500134\n",
      "Q Loss:  0.0005511479685083032\n",
      "Policy Loss:  -0.02032472938299179\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  16223.8583984375\n",
      "Q Loss:  15762.6875\n",
      "Policy Loss:  -20.209299087524414\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131052 length: 50 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00020606309408321977\n",
      "Q Loss:  0.001433593686670065\n",
      "Policy Loss:  -0.01989326812326908\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131056 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.004882471170276403\n",
      "Q Loss:  0.00037870329106226563\n",
      "Policy Loss:  0.008550298400223255\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131060 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  0.0024892867077142\n",
      "Q Loss:  0.0015625829109922051\n",
      "Policy Loss:  0.011611128225922585\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131064 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.009472607634961605\n",
      "Q Loss:  3.184665331446013e-08\n",
      "Policy Loss:  -0.004831045400351286\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131068 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  1.459594488143921\n",
      "Q Loss:  0.0025958942715078592\n",
      "Policy Loss:  0.21712790429592133\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131134 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.010003328323364258\n",
      "Value Loss:  0.0012696217745542526\n",
      "Q Loss:  97.5889663696289\n",
      "Policy Loss:  3.453585624694824\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131138 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0012444481253623962\n",
      "Q Loss:  0.00031308282632380724\n",
      "Policy Loss:  -0.0027188509702682495\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131142 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  2.2939609323202603e-07\n",
      "Q Loss:  0.00024245522217825055\n",
      "Policy Loss:  0.0009798419196158648\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  4.391617767396383e-05\n",
      "Q Loss:  0.0007741472218185663\n",
      "Policy Loss:  0.017884910106658936\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009650468826293945\n",
      "Value Loss:  8.290471305372193e-05\n",
      "Q Loss:  0.00047969885054044425\n",
      "Policy Loss:  0.022854473441839218\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 131154 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003971099853516\n",
      "Value Loss:  0.8047926425933838\n",
      "Q Loss:  0.000960401026532054\n",
      "Policy Loss:  0.11402423679828644\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131273 length: 119 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  3.320353425806388e-05\n",
      "Q Loss:  0.00012992712436243892\n",
      "Policy Loss:  -0.0024180705659091473\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131277 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  1.3101735021336935e-05\n",
      "Q Loss:  0.0002862860856112093\n",
      "Policy Loss:  0.0004984037950634956\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131281 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  1.5874520540237427\n",
      "Q Loss:  0.001803859486244619\n",
      "Policy Loss:  0.21403586864471436\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131341 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  5.1843406254192814e-05\n",
      "Q Loss:  2.9911709134466946e-05\n",
      "Policy Loss:  0.0019613895565271378\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131345 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  3.709582961164415e-05\n",
      "Q Loss:  0.00024390970065724105\n",
      "Policy Loss:  -0.0050877854228019714\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 131349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001042390285874717\n",
      "Q Loss:  7.134792394936085e-05\n",
      "Policy Loss:  -0.004417327232658863\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  5.3164967539487407e-05\n",
      "Q Loss:  2.6128986064577475e-05\n",
      "Policy Loss:  0.001721925218589604\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00013547549315262586\n",
      "Q Loss:  1.8380331312073395e-05\n",
      "Policy Loss:  -0.0026165805757045746\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131361 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.479109000181779e-05\n",
      "Q Loss:  9.444598617847078e-06\n",
      "Policy Loss:  0.0007595284841954708\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131365 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  1.521525155112613e-05\n",
      "Q Loss:  0.00010920019849436358\n",
      "Policy Loss:  0.0021796333603560925\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131369 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.0002810005680657923\n",
      "Q Loss:  0.0008572039660066366\n",
      "Policy Loss:  -0.019132714718580246\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131373 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.00019119755597785115\n",
      "Q Loss:  0.00024353805929422379\n",
      "Policy Loss:  -0.006382216699421406\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131377 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  2558.372314453125\n",
      "Q Loss:  4766.19775390625\n",
      "Policy Loss:  -158.25804138183594\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 131381 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0007382425828836858\n",
      "Q Loss:  0.001629596808925271\n",
      "Policy Loss:  -0.019102031365036964\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 131385 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  5.515343582374044e-05\n",
      "Q Loss:  0.0003086646902374923\n",
      "Policy Loss:  0.012699258513748646\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 131389 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00011852357420139015\n",
      "Q Loss:  0.0006289193406701088\n",
      "Policy Loss:  0.012628109194338322\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 131393 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.0004680827842094004\n",
      "Q Loss:  0.001040598494000733\n",
      "Policy Loss:  0.02096659503877163\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 131397 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.020283546298742294\n",
      "Q Loss:  0.0052326396107673645\n",
      "Policy Loss:  -0.011413034051656723\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 131401 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.02013860084116459\n",
      "Q Loss:  0.011022424325346947\n",
      "Policy Loss:  -0.024663839489221573\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 131405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  384.7925720214844\n",
      "Q Loss:  671.040771484375\n",
      "Policy Loss:  -37.20795822143555\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 131510 length: 105 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.00038205349119380116\n",
      "Q Loss:  0.0016037665773183107\n",
      "Policy Loss:  0.023776650428771973\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131514 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00013793446123600006\n",
      "Q Loss:  0.0004935209872201085\n",
      "Policy Loss:  0.011130928993225098\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131518 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010000944137573242\n",
      "Value Loss:  8.622690984338988e-06\n",
      "Q Loss:  0.00013929068518336862\n",
      "Policy Loss:  0.005388162098824978\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131522 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.1098281649756245e-05\n",
      "Q Loss:  4.239696863805875e-05\n",
      "Policy Loss:  -0.0022872802801430225\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131526 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.339517570566386e-05\n",
      "Q Loss:  0.000277690589427948\n",
      "Policy Loss:  0.0015717388596385717\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131530 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  7.011299021542072e-05\n",
      "Q Loss:  0.0003403642913326621\n",
      "Policy Loss:  0.007310272194445133\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131534 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  2.3116590455174446e-05\n",
      "Q Loss:  0.001344493473879993\n",
      "Policy Loss:  0.00969819724559784\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131538 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004676818847656\n",
      "Value Loss:  3.423734597163275e-05\n",
      "Q Loss:  0.004550160840153694\n",
      "Policy Loss:  0.04055715724825859\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131542 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.1372366973082535e-05\n",
      "Q Loss:  4.916489706374705e-05\n",
      "Policy Loss:  0.0006122086197137833\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131546 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.1005677151842974e-05\n",
      "Q Loss:  0.0010779732838273048\n",
      "Policy Loss:  0.010698050260543823\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131550 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  1.2905135918117594e-05\n",
      "Q Loss:  0.0009045825572684407\n",
      "Policy Loss:  0.03731464594602585\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 131554 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  10007.017578125\n",
      "Q Loss:  9777.19140625\n",
      "Policy Loss:  -24.65825653076172\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 131636 length: 82 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0006386353052221239\n",
      "Q Loss:  0.00011288225505268201\n",
      "Policy Loss:  -0.005337178707122803\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 131640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.03445800766348839\n",
      "Q Loss:  0.017075730487704277\n",
      "Policy Loss:  -0.03488221392035484\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 131644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  40524.08984375\n",
      "Q Loss:  39401.625\n",
      "Policy Loss:  -48.3087158203125\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 131664 length: 20 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.009001731872558594\n",
      "Value Loss:  2.7818754460895434e-05\n",
      "Q Loss:  5.270206747809425e-05\n",
      "Policy Loss:  -0.0030663840007036924\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  2.0092902559554204e-05\n",
      "Q Loss:  0.00037859659641981125\n",
      "Policy Loss:  -0.008391065523028374\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  0.045627303421497345\n",
      "Q Loss:  0.00851115770637989\n",
      "Policy Loss:  -0.02186732366681099\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  455.6941223144531\n",
      "Q Loss:  822.9432373046875\n",
      "Policy Loss:  -42.91620635986328\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131810 length: 134 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0007068596314638853\n",
      "Q Loss:  0.0004886403912678361\n",
      "Policy Loss:  -0.0007281738799065351\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0007500565843656659\n",
      "Q Loss:  0.0026193419471383095\n",
      "Policy Loss:  -0.02283354103565216\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  0.00029603467555716634\n",
      "Q Loss:  0.0006895324913784862\n",
      "Policy Loss:  -0.003719731466844678\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  2.6393518055556342e-05\n",
      "Q Loss:  0.00027207029052078724\n",
      "Policy Loss:  0.00825219415128231\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  8.105699816951528e-05\n",
      "Q Loss:  0.0001421004708390683\n",
      "Policy Loss:  0.012029087170958519\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001182556152344\n",
      "Value Loss:  4.20998185290955e-05\n",
      "Q Loss:  0.00020213922834955156\n",
      "Policy Loss:  0.00038915674667805433\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0210588201880455\n",
      "Q Loss:  0.01784532517194748\n",
      "Policy Loss:  -0.01915735751390457\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700662612915039\n",
      "Value Loss:  0.0851096510887146\n",
      "Q Loss:  0.012481281533837318\n",
      "Policy Loss:  -0.0771191269159317\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  8.899437671061605e-05\n",
      "Q Loss:  0.0010095618199557066\n",
      "Policy Loss:  0.017304636538028717\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131846 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002923965454102\n",
      "Value Loss:  9.505022899247706e-05\n",
      "Q Loss:  0.00035681395092979074\n",
      "Policy Loss:  0.044402580708265305\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131850 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.039779383689165115\n",
      "Q Loss:  0.011122425086796284\n",
      "Policy Loss:  -0.007449328899383545\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131854 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.05736878514289856\n",
      "Q Loss:  0.009002036415040493\n",
      "Policy Loss:  -0.02052302286028862\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  15214.34765625\n",
      "Q Loss:  14705.4638671875\n",
      "Policy Loss:  -19.930814743041992\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131911 length: 53 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.017332881689071655\n",
      "Q Loss:  0.010867573320865631\n",
      "Policy Loss:  0.03622962534427643\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.032987236976623535\n",
      "Q Loss:  0.006530009675770998\n",
      "Policy Loss:  0.021333862096071243\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.046542223542928696\n",
      "Q Loss:  0.011032454669475555\n",
      "Policy Loss:  0.021062444895505905\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.028451235964894295\n",
      "Q Loss:  0.026251835748553276\n",
      "Policy Loss:  0.02278195135295391\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131927 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.025699859485030174\n",
      "Q Loss:  0.013678093440830708\n",
      "Policy Loss:  0.018140656873583794\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131931 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00043209700379520655\n",
      "Q Loss:  0.008179279044270515\n",
      "Policy Loss:  0.0448489710688591\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  0.0005018148804083467\n",
      "Q Loss:  0.0004702946753241122\n",
      "Policy Loss:  0.008775399997830391\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131939 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.018490759655833244\n",
      "Q Loss:  0.002678027842193842\n",
      "Policy Loss:  0.01070094108581543\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001659393310547\n",
      "Value Loss:  0.024522200226783752\n",
      "Q Loss:  0.005751315038651228\n",
      "Policy Loss:  -0.03683430328965187\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131947 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001420974731445\n",
      "Value Loss:  0.00010712927905842662\n",
      "Q Loss:  0.003391621634364128\n",
      "Policy Loss:  0.022920362651348114\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 131951 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002613067626953\n",
      "Value Loss:  14487.412109375\n",
      "Q Loss:  14469.2646484375\n",
      "Policy Loss:  -49.39039993286133\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 132008 length: 57 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03300786018371582\n",
      "Value Loss:  0.017058346420526505\n",
      "Q Loss:  0.00393292773514986\n",
      "Policy Loss:  -0.046893101185560226\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 132012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00021400729019660503\n",
      "Q Loss:  0.0007413410930894315\n",
      "Policy Loss:  -0.015781890600919724\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 132016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0006077596917748451\n",
      "Q Loss:  0.0005695309955626726\n",
      "Policy Loss:  -0.01461221743375063\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 132020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.0569562911987305\n",
      "Q Loss:  22.82588005065918\n",
      "Policy Loss:  0.9390084147453308\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 132110 length: 90 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  8.951252675615251e-05\n",
      "Q Loss:  9.320000390289351e-05\n",
      "Policy Loss:  -0.003974989056587219\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.004079281818121672\n",
      "Q Loss:  0.00496984226629138\n",
      "Policy Loss:  0.01040860079228878\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001970291137695\n",
      "Value Loss:  0.015718480572104454\n",
      "Q Loss:  0.008428926579654217\n",
      "Policy Loss:  -0.06561345607042313\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002447128295898\n",
      "Value Loss:  105.50720977783203\n",
      "Q Loss:  204.9771728515625\n",
      "Policy Loss:  -9.741584777832031\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132225 length: 103 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  0.0003156089223921299\n",
      "Q Loss:  0.00011028663720935583\n",
      "Policy Loss:  -0.0004002135246992111\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132229 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00015577816520817578\n",
      "Q Loss:  0.00036374275805428624\n",
      "Policy Loss:  0.0010051331482827663\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132233 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.5217124857590534e-05\n",
      "Q Loss:  0.0003690735320560634\n",
      "Policy Loss:  -0.008071951568126678\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132237 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.00367788621224463\n",
      "Q Loss:  0.0010775303235277534\n",
      "Policy Loss:  0.008355760015547276\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132241 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010002374649047852\n",
      "Value Loss:  0.01429099589586258\n",
      "Q Loss:  0.0013805573107674718\n",
      "Policy Loss:  -0.025240182876586914\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132245 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0034453943371772766\n",
      "Q Loss:  0.0017441418021917343\n",
      "Policy Loss:  0.003963236231356859\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132249 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00011933410132769495\n",
      "Q Loss:  0.00032117433147504926\n",
      "Policy Loss:  -0.0002685090294107795\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132253 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  6.604127702303231e-05\n",
      "Q Loss:  0.0008096677483990788\n",
      "Policy Loss:  -0.0003223817329853773\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132257 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009001493453979492\n",
      "Value Loss:  4.707969128503464e-05\n",
      "Q Loss:  0.0004321556771174073\n",
      "Policy Loss:  0.019595593214035034\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132261 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.008314105682075024\n",
      "Q Loss:  0.002689364366233349\n",
      "Policy Loss:  0.0031824326142668724\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132265 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.009002208709716797\n",
      "Value Loss:  3.39626130880788e-05\n",
      "Q Loss:  0.00015100011660251766\n",
      "Policy Loss:  0.014220955781638622\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132269 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  3915.653564453125\n",
      "Q Loss:  3807.822509765625\n",
      "Policy Loss:  -4.54984188079834\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132474 length: 205 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0006379619590006769\n",
      "Q Loss:  0.0026640398427844048\n",
      "Policy Loss:  -0.0037963385693728924\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132478 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0020691780373454094\n",
      "Q Loss:  0.002615045988932252\n",
      "Policy Loss:  0.00821677315980196\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00046927438233979046\n",
      "Q Loss:  0.0010594697669148445\n",
      "Policy Loss:  0.009751912206411362\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.00018828884640242904\n",
      "Q Loss:  0.0008431710302829742\n",
      "Policy Loss:  -0.007776373066008091\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.0003826386237051338\n",
      "Q Loss:  0.0016227971063926816\n",
      "Policy Loss:  -0.02193306013941765\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 132494 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01000213623046875\n",
      "Value Loss:  0.0007483272347599268\n",
      "Q Loss:  0.0003148251853417605\n",
      "Policy Loss:  -0.01551784947514534\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132498 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.010001897811889648\n",
      "Value Loss:  0.0002515712403692305\n",
      "Q Loss:  0.00030672852881252766\n",
      "Policy Loss:  -0.010265449061989784\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132502 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  5.443496411317028e-05\n",
      "Q Loss:  0.003224689746275544\n",
      "Policy Loss:  0.0018560716416686773\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  93.86918640136719\n",
      "Q Loss:  128.54843139648438\n",
      "Policy Loss:  -9.058797836303711\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132623 length: 117 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.350817132741213e-05\n",
      "Q Loss:  0.0005216022254899144\n",
      "Policy Loss:  0.011570604518055916\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132627 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0020808838307857513\n",
      "Q Loss:  0.00017984096484724432\n",
      "Policy Loss:  0.015599720180034637\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132631 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.004251567646861076\n",
      "Q Loss:  0.0021360055543482304\n",
      "Policy Loss:  -0.000858040526509285\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016608476638793945\n",
      "Value Loss:  0.0021611421834677458\n",
      "Q Loss:  0.00022367932251654565\n",
      "Policy Loss:  0.02046200819313526\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.006373673677444458\n",
      "Q Loss:  0.0018217036267742515\n",
      "Policy Loss:  0.008831430226564407\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.8702393770217896\n",
      "Q Loss:  0.0008796871406957507\n",
      "Policy Loss:  0.12681205570697784\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132754 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0012905981857329607\n",
      "Q Loss:  0.0009659025818109512\n",
      "Policy Loss:  -0.025302544236183167\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015001773834228516\n",
      "Value Loss:  0.0012960138265043497\n",
      "Q Loss:  0.0013265039306133986\n",
      "Policy Loss:  0.008092544972896576\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0008513397187925875\n",
      "Q Loss:  0.00042181910248473287\n",
      "Policy Loss:  0.011147724464535713\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0023828803095966578\n",
      "Q Loss:  0.0002647739020176232\n",
      "Policy Loss:  0.009006510488688946\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132770 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0023913797922432423\n",
      "Q Loss:  0.000775675754994154\n",
      "Policy Loss:  -0.005744767375290394\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.071457631951489e-06\n",
      "Q Loss:  0.00012151848204666749\n",
      "Policy Loss:  -0.005458901636302471\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132778 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.532075061229989e-05\n",
      "Q Loss:  0.00014449736045207828\n",
      "Policy Loss:  -0.005698647350072861\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  2.1671208742191084e-05\n",
      "Q Loss:  1.8575099602458067e-05\n",
      "Policy Loss:  -0.0009001787984743714\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.002465581987053156\n",
      "Q Loss:  0.0005025758873671293\n",
      "Policy Loss:  -0.0010741157457232475\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.5965953682316467e-05\n",
      "Q Loss:  1.0398868653282989e-05\n",
      "Policy Loss:  -0.0009227950940839946\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.00722561776638031\n",
      "Q Loss:  0.002105120336636901\n",
      "Policy Loss:  -0.01872161403298378\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  0.002334771677851677\n",
      "Q Loss:  0.00033608460216782987\n",
      "Policy Loss:  -0.007915431633591652\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  15427.361328125\n",
      "Q Loss:  15030.080078125\n",
      "Policy Loss:  -20.11347007751465\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132854 length: 52 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.028006553649902344\n",
      "Value Loss:  0.004792352672666311\n",
      "Q Loss:  0.001054301974363625\n",
      "Policy Loss:  -0.005714841187000275\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132858 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  141.47573852539062\n",
      "Q Loss:  258.4925842285156\n",
      "Policy Loss:  -13.536465644836426\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 132936 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3594.994384765625\n",
      "Q Loss:  3476.243896484375\n",
      "Policy Loss:  -4.965427875518799\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 133159 length: 223 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  2744.42578125\n",
      "Q Loss:  5152.6689453125\n",
      "Policy Loss:  -148.22117614746094\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 133163 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.1156748769280966e-05\n",
      "Q Loss:  102.08040618896484\n",
      "Policy Loss:  3.5149435997009277\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 133167 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.038008689880371094\n",
      "Value Loss:  0.0008540311246179044\n",
      "Q Loss:  0.000282687833532691\n",
      "Policy Loss:  0.011618067510426044\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 133171 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0003287277650088072\n",
      "Q Loss:  0.0002007294970098883\n",
      "Policy Loss:  -0.0026448972057551146\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 133175 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3.11551739287097e-05\n",
      "Q Loss:  0.00022870241082273424\n",
      "Policy Loss:  0.01751159504055977\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 133179 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.009203264489769936\n",
      "Q Loss:  0.0019922591745853424\n",
      "Policy Loss:  -0.01741647720336914\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 133183 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  171.68215942382812\n",
      "Q Loss:  351.2021789550781\n",
      "Policy Loss:  -14.717179298400879\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 133247 length: 64 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.0391584634780884\n",
      "Q Loss:  0.0013917002361267805\n",
      "Policy Loss:  0.13734745979309082\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 133338 length: 91 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03600740432739258\n",
      "Value Loss:  2.8129215934313834e-05\n",
      "Q Loss:  0.0006957700243219733\n",
      "Policy Loss:  -0.01310513075441122\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 133342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  8.20890927570872e-05\n",
      "Q Loss:  0.0008222286705859005\n",
      "Policy Loss:  -0.013721683993935585\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133346 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  4.184480712865479e-05\n",
      "Q Loss:  0.000182944699190557\n",
      "Policy Loss:  -0.004018895328044891\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133350 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0001278986019315198\n",
      "Q Loss:  0.0002858187071979046\n",
      "Policy Loss:  -0.0021598762832581997\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133354 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00027179866447113454\n",
      "Q Loss:  102.5583724975586\n",
      "Policy Loss:  3.517254590988159\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133358 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.028006315231323242\n",
      "Value Loss:  3.1714120268588886e-05\n",
      "Q Loss:  3.401304638828151e-05\n",
      "Policy Loss:  0.004496545530855656\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133362 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  9.743513510329649e-05\n",
      "Q Loss:  102.45122528076172\n",
      "Policy Loss:  3.512831687927246\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133366 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012656450271606445\n",
      "Value Loss:  0.0003569093532860279\n",
      "Q Loss:  0.0010387487709522247\n",
      "Policy Loss:  0.0020867413841187954\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133370 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0006774917710572481\n",
      "Q Loss:  0.0002329790877411142\n",
      "Policy Loss:  -0.003241795115172863\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133374 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.544405262800865e-05\n",
      "Q Loss:  3.821105565293692e-07\n",
      "Policy Loss:  -0.0021245419047772884\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133378 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.02420450933277607\n",
      "Q Loss:  0.009318589232861996\n",
      "Policy Loss:  -0.02693655714392662\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133382 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.012219282798469067\n",
      "Q Loss:  0.0016176068456843495\n",
      "Policy Loss:  -0.02436681091785431\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133386 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0003233343595638871\n",
      "Q Loss:  0.00028125481912866235\n",
      "Policy Loss:  0.011778430081903934\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133390 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00019155829795636237\n",
      "Q Loss:  0.0015408063773065805\n",
      "Policy Loss:  0.024506907910108566\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133394 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  8.900406101020053e-05\n",
      "Q Loss:  0.001750837778672576\n",
      "Policy Loss:  0.021685626357793808\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133398 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.7731682318262756e-05\n",
      "Q Loss:  0.00045510189374908805\n",
      "Policy Loss:  0.008677045814692974\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  9.161002526525408e-05\n",
      "Q Loss:  0.00018181453924626112\n",
      "Policy Loss:  -0.004377653822302818\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  2.469851096975617e-05\n",
      "Q Loss:  0.00032855162862688303\n",
      "Policy Loss:  0.001510528614744544\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133410 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.6345555195584893e-05\n",
      "Q Loss:  8.138268458424136e-05\n",
      "Policy Loss:  -0.004379065241664648\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133414 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.024320241063833237\n",
      "Q Loss:  0.005742719396948814\n",
      "Policy Loss:  -0.008036360144615173\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133418 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.8008353114128113\n",
      "Q Loss:  0.0031339942943304777\n",
      "Policy Loss:  0.10355956852436066\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133534 length: 116 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  8526.2109375\n",
      "Q Loss:  8486.3134765625\n",
      "Policy Loss:  -41.7400016784668\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133632 length: 98 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00016649841563776135\n",
      "Q Loss:  0.00037563516525551677\n",
      "Policy Loss:  -0.007410836406052113\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133636 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.025082945823669434\n",
      "Q Loss:  0.00301217008382082\n",
      "Policy Loss:  0.004494421184062958\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133640 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.05017281323671341\n",
      "Q Loss:  0.0035281695891171694\n",
      "Policy Loss:  -0.043162740767002106\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133644 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  11638.40625\n",
      "Q Loss:  11345.98046875\n",
      "Policy Loss:  -15.213146209716797\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133713 length: 69 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0015218707267194986\n",
      "Q Loss:  0.0021500936709344387\n",
      "Policy Loss:  -0.006889102980494499\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  6.596057573915459e-06\n",
      "Q Loss:  2.4032386136241257e-05\n",
      "Policy Loss:  0.0034401551820337772\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133721 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  8.481262739223894e-06\n",
      "Q Loss:  0.00010199606913374737\n",
      "Policy Loss:  0.005243541672825813\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133725 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.193381078541279e-06\n",
      "Q Loss:  0.0007481237989850342\n",
      "Policy Loss:  0.01455590222030878\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133729 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  2.4472490622429177e-05\n",
      "Q Loss:  0.00045553460950031877\n",
      "Policy Loss:  0.008697418496012688\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133733 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005817413330078\n",
      "Value Loss:  5.090072363600484e-07\n",
      "Q Loss:  0.00101977470330894\n",
      "Policy Loss:  0.015889374539256096\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133737 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  2.5890598408295773e-05\n",
      "Q Loss:  0.0003269057488068938\n",
      "Policy Loss:  0.0073135062120854855\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133741 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.9122678572312e-05\n",
      "Q Loss:  5.811266601085663e-05\n",
      "Policy Loss:  -0.0005572749068960547\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133745 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  4.417051241034642e-05\n",
      "Q Loss:  9.228619455825537e-05\n",
      "Policy Loss:  0.0047231270000338554\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133749 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00010648109309840947\n",
      "Q Loss:  9.474243415752426e-05\n",
      "Policy Loss:  0.0008516816888004541\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133753 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.476851583807729e-06\n",
      "Q Loss:  1.826604966481682e-05\n",
      "Policy Loss:  -0.0008934042416512966\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133757 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.02304445020854473\n",
      "Q Loss:  0.019929558038711548\n",
      "Policy Loss:  0.08899878710508347\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.03381004557013512\n",
      "Q Loss:  0.03510574996471405\n",
      "Policy Loss:  0.04628705233335495\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.010708460584282875\n",
      "Q Loss:  0.013350266963243484\n",
      "Policy Loss:  0.01958131045103073\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08501911163330078\n",
      "Value Loss:  0.010106381960213184\n",
      "Q Loss:  0.009546373970806599\n",
      "Policy Loss:  0.016937579959630966\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.009478665888309479\n",
      "Q Loss:  0.007114585489034653\n",
      "Policy Loss:  -0.0008342843502759933\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133777 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  9.160602530755568e-06\n",
      "Q Loss:  0.0015990384854376316\n",
      "Policy Loss:  -0.025705257430672646\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133781 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.912120023916941e-05\n",
      "Q Loss:  0.0008917294908314943\n",
      "Policy Loss:  -0.01414448395371437\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.618660674779676e-06\n",
      "Q Loss:  0.0025369569193571806\n",
      "Policy Loss:  -0.027376875281333923\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  6.7060864239465445e-06\n",
      "Q Loss:  0.0013103578239679337\n",
      "Policy Loss:  -0.015980906784534454\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002250671386719\n",
      "Value Loss:  0.013994867913424969\n",
      "Q Loss:  0.0051239305175840855\n",
      "Policy Loss:  -0.03449251502752304\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  8829.9833984375\n",
      "Q Loss:  8709.6455078125\n",
      "Policy Loss:  -23.10295867919922\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133889 length: 92 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  0.0001216401215060614\n",
      "Q Loss:  0.0006515359855256975\n",
      "Policy Loss:  -0.011268500238656998\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133893 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  8.665379573358223e-05\n",
      "Q Loss:  4.776255082106218e-05\n",
      "Policy Loss:  -0.0010056262835860252\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.650192128494382e-05\n",
      "Q Loss:  2.2202417312655598e-05\n",
      "Policy Loss:  0.0033783791586756706\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011995315551757812\n",
      "Value Loss:  6.0698739616782404e-06\n",
      "Q Loss:  9.321075049228966e-05\n",
      "Policy Loss:  0.002403319114819169\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  1.845961570739746\n",
      "Q Loss:  0.004894887562841177\n",
      "Policy Loss:  0.24965694546699524\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133956 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  5.848828732268885e-05\n",
      "Q Loss:  0.00027297294582240283\n",
      "Policy Loss:  9.255862096324563e-05\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133960 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  9.211825090460479e-05\n",
      "Q Loss:  0.0005971742793917656\n",
      "Policy Loss:  -0.004303313791751862\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133964 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.593836714164354e-05\n",
      "Q Loss:  0.0005110103520564735\n",
      "Policy Loss:  -0.0025181074161082506\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133968 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2.8586193366209045e-05\n",
      "Q Loss:  0.0003916543209925294\n",
      "Policy Loss:  -0.010503444820642471\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133972 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.879012981793494e-06\n",
      "Q Loss:  0.00030982220778241754\n",
      "Policy Loss:  -0.006004338152706623\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133976 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.0002599465078674257\n",
      "Q Loss:  0.00015725960838608444\n",
      "Policy Loss:  0.0031786118634045124\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133980 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011596918106079102\n",
      "Value Loss:  0.008674719370901585\n",
      "Q Loss:  0.006370374001562595\n",
      "Policy Loss:  -0.004633230157196522\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133984 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.5509125407552347e-05\n",
      "Q Loss:  0.004608707502484322\n",
      "Policy Loss:  0.03374343365430832\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133988 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.4035236492636614e-05\n",
      "Q Loss:  0.0025186920538544655\n",
      "Policy Loss:  0.01963619515299797\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133992 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400090217590332\n",
      "Value Loss:  0.009179129265248775\n",
      "Q Loss:  0.003618723014369607\n",
      "Policy Loss:  -0.011672981083393097\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 133996 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  8.491196012982982e-07\n",
      "Q Loss:  0.00018449206254445016\n",
      "Policy Loss:  0.007752789184451103\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134000 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05801272392272949\n",
      "Value Loss:  2.4902437871787697e-06\n",
      "Q Loss:  0.0004244993324391544\n",
      "Policy Loss:  0.0029417830519378185\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134004 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.027850303798913956\n",
      "Q Loss:  0.05498136579990387\n",
      "Policy Loss:  -0.12719129025936127\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134008 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.03610622137784958\n",
      "Q Loss:  0.04918697103857994\n",
      "Policy Loss:  -0.12952569127082825\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134012 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.008434654213488102\n",
      "Q Loss:  0.0003888517676386982\n",
      "Policy Loss:  -0.009686233475804329\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134016 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.01571015641093254\n",
      "Q Loss:  0.005901388358324766\n",
      "Policy Loss:  0.003732386976480484\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134020 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.007163779344409704\n",
      "Q Loss:  0.003379897214472294\n",
      "Policy Loss:  0.014612260274589062\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134024 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00011437393550295383\n",
      "Q Loss:  0.0013257147511467338\n",
      "Policy Loss:  0.02157146856188774\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134028 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00020297477021813393\n",
      "Q Loss:  0.0007520184153690934\n",
      "Policy Loss:  0.014790024608373642\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134032 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.010974526405334473\n",
      "Q Loss:  0.011910281144082546\n",
      "Policy Loss:  0.0787249282002449\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 134036 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  10815.1630859375\n",
      "Q Loss:  10543.9130859375\n",
      "Policy Loss:  -14.636188507080078\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 134110 length: 74 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00012364456779323518\n",
      "Q Loss:  0.01025568600744009\n",
      "Policy Loss:  0.045839861035346985\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 134114 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  3.767537054955028e-05\n",
      "Q Loss:  0.007228655740618706\n",
      "Policy Loss:  0.021077895537018776\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 134118 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.000279232335742563\n",
      "Q Loss:  0.0023345511872321367\n",
      "Policy Loss:  0.011317721568048\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134122 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00024024100275710225\n",
      "Q Loss:  0.0017750479746609926\n",
      "Policy Loss:  -0.021309714764356613\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134126 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  8.403408719459549e-05\n",
      "Q Loss:  0.00014364210073836148\n",
      "Policy Loss:  -0.005457459483295679\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134130 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.7814604640007019\n",
      "Q Loss:  0.006472792010754347\n",
      "Policy Loss:  0.12911909818649292\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134252 length: 122 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  6.663754902547225e-05\n",
      "Q Loss:  0.0009351189946755767\n",
      "Policy Loss:  -0.0068758768029510975\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134256 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.012615842744708061\n",
      "Q Loss:  0.014939093962311745\n",
      "Policy Loss:  0.08326046913862228\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.016544928774237633\n",
      "Q Loss:  0.01662091724574566\n",
      "Policy Loss:  0.0598275326192379\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.6821267008781433\n",
      "Q Loss:  0.008250639773905277\n",
      "Policy Loss:  0.09240787476301193\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134404 length: 140 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.000556916231289506\n",
      "Q Loss:  0.0003829365596175194\n",
      "Policy Loss:  0.01550009660422802\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134408 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.4397891037515365e-06\n",
      "Q Loss:  0.004825027659535408\n",
      "Policy Loss:  -0.03370743244886398\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134412 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0037839156575500965\n",
      "Q Loss:  0.004452916793525219\n",
      "Policy Loss:  0.01992017962038517\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134416 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.003712916048243642\n",
      "Q Loss:  0.007319149561226368\n",
      "Policy Loss:  -0.013324296101927757\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134420 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  4.343442014942411e-06\n",
      "Q Loss:  0.0032509362790733576\n",
      "Policy Loss:  -0.022312263026833534\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134424 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.731278527789982e-06\n",
      "Q Loss:  0.004288536962121725\n",
      "Policy Loss:  -0.02613705024123192\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134428 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05901288986206055\n",
      "Value Loss:  0.0034491366241127253\n",
      "Q Loss:  0.0010071848519146442\n",
      "Policy Loss:  0.004957146011292934\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.010033859871327877\n",
      "Q Loss:  0.005488430615514517\n",
      "Policy Loss:  -0.039593566209077835\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014005184173583984\n",
      "Value Loss:  40973.54296875\n",
      "Q Loss:  39832.0\n",
      "Policy Loss:  -53.03286361694336\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134475 length: 39 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  69425.546875\n",
      "Q Loss:  67480.453125\n",
      "Policy Loss:  -86.5431137084961\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134498 length: 23 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  14438.0576171875\n",
      "Q Loss:  14148.43359375\n",
      "Policy Loss:  -39.03455352783203\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134554 length: 56 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.6207355858787196e-06\n",
      "Q Loss:  0.0062445541843771935\n",
      "Policy Loss:  0.043557703495025635\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134558 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1.3419317838270217e-05\n",
      "Q Loss:  0.007991963997483253\n",
      "Policy Loss:  0.061269812285900116\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134562 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  20335.599609375\n",
      "Q Loss:  19698.2109375\n",
      "Policy Loss:  -28.592498779296875\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134601 length: 39 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  5.556536780204624e-05\n",
      "Q Loss:  0.0025121201761066914\n",
      "Policy Loss:  -0.012519464828073978\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134605 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200578689575195\n",
      "Value Loss:  0.0015534486155956984\n",
      "Q Loss:  0.0011095879599452019\n",
      "Policy Loss:  -0.013750624842941761\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134609 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0010633516358211637\n",
      "Q Loss:  0.00012271291052456945\n",
      "Policy Loss:  -0.003723808331415057\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0001281928998650983\n",
      "Q Loss:  0.008500698953866959\n",
      "Policy Loss:  0.041386015713214874\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134617 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0002868223818950355\n",
      "Q Loss:  9.940065501723439e-05\n",
      "Policy Loss:  0.0049948072992265224\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134621 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301426887512207\n",
      "Value Loss:  0.012524997815489769\n",
      "Q Loss:  0.0086215166375041\n",
      "Policy Loss:  0.011053891852498055\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134625 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.026420125737786293\n",
      "Q Loss:  0.010299140587449074\n",
      "Policy Loss:  -0.045041680335998535\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.013697144575417042\n",
      "Q Loss:  0.0068104625679552555\n",
      "Policy Loss:  0.014739417470991611\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.01406027376651764\n",
      "Q Loss:  0.0028785220347344875\n",
      "Policy Loss:  -0.015360042452812195\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.014195299707353115\n",
      "Q Loss:  0.010496050119400024\n",
      "Policy Loss:  0.010950034484267235\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.0731931924819946\n",
      "Q Loss:  0.007085307966917753\n",
      "Policy Loss:  0.17461881041526794\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134726 length: 85 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.001047806697897613\n",
      "Q Loss:  0.009109074249863625\n",
      "Policy Loss:  0.05076345056295395\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134730 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0010200757533311844\n",
      "Q Loss:  0.005478960461914539\n",
      "Policy Loss:  0.03136488050222397\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134734 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0001470748393330723\n",
      "Q Loss:  0.00036649484536610544\n",
      "Policy Loss:  -0.00029611086938530207\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.03144597262144089\n",
      "Q Loss:  0.015681259334087372\n",
      "Policy Loss:  -0.026084639132022858\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  1.3801822662353516\n",
      "Q Loss:  0.008946291171014309\n",
      "Policy Loss:  0.17368948459625244\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134808 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03300809860229492\n",
      "Value Loss:  7229.4638671875\n",
      "Q Loss:  7036.89111328125\n",
      "Policy Loss:  -22.064937591552734\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134918 length: 110 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00040968245593830943\n",
      "Q Loss:  0.006303833331912756\n",
      "Policy Loss:  -0.008693573996424675\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.000483298470498994\n",
      "Q Loss:  0.0003422571753617376\n",
      "Policy Loss:  -0.008662794716656208\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 134926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  93.28292083740234\n",
      "Q Loss:  173.6793670654297\n",
      "Policy Loss:  -7.965208053588867\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 135072 length: 146 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.4129383998806588e-05\n",
      "Q Loss:  406.0198059082031\n",
      "Policy Loss:  13.947010040283203\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.001076545100659132\n",
      "Q Loss:  100.75464630126953\n",
      "Policy Loss:  3.4952025413513184\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0400083065032959\n",
      "Value Loss:  0.0006158275646157563\n",
      "Q Loss:  0.0050977482460439205\n",
      "Policy Loss:  -0.032723113894462585\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.0002969370980281383\n",
      "Q Loss:  0.003837196622043848\n",
      "Policy Loss:  -0.0282922200858593\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135088 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.04366852343082428\n",
      "Q Loss:  0.009552720002830029\n",
      "Policy Loss:  -0.026846732944250107\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135092 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.021947167813777924\n",
      "Q Loss:  0.0048118047416210175\n",
      "Policy Loss:  -0.009107524529099464\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135096 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  5.479847118294856e-07\n",
      "Q Loss:  0.0020325765945017338\n",
      "Policy Loss:  -0.0266508087515831\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135100 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.021825319156050682\n",
      "Q Loss:  0.006430721376091242\n",
      "Policy Loss:  0.006848976016044617\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135104 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.021588195115327835\n",
      "Q Loss:  0.003777710720896721\n",
      "Policy Loss:  -0.04078204557299614\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135108 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  11839.80078125\n",
      "Q Loss:  11648.08203125\n",
      "Policy Loss:  -35.187313079833984\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135175 length: 67 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011599540710449219\n",
      "Value Loss:  0.000165250850841403\n",
      "Q Loss:  9.066689381143078e-05\n",
      "Policy Loss:  0.0036086076870560646\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135179 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  8.844593685353175e-05\n",
      "Q Loss:  0.00040130698471330106\n",
      "Policy Loss:  -0.00666822912171483\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135183 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0018377357628196478\n",
      "Q Loss:  0.009378381073474884\n",
      "Policy Loss:  0.04381592944264412\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135187 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0005186381749808788\n",
      "Q Loss:  3.7444671761477366e-05\n",
      "Policy Loss:  -0.0008862955728545785\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135191 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03700852394104004\n",
      "Value Loss:  1.0921463399427012e-05\n",
      "Q Loss:  0.0007784388726577163\n",
      "Policy Loss:  0.017261818051338196\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135195 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.02148856222629547\n",
      "Q Loss:  0.0050924355164170265\n",
      "Policy Loss:  0.014406668022274971\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135199 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.042708247900009155\n",
      "Q Loss:  0.009154518134891987\n",
      "Policy Loss:  -0.04283895343542099\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135203 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.06261120736598969\n",
      "Q Loss:  0.011707638390362263\n",
      "Policy Loss:  -0.024175358936190605\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135207 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.07964304834604263\n",
      "Q Loss:  0.01016197819262743\n",
      "Policy Loss:  -0.07227440178394318\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135211 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.018421951681375504\n",
      "Q Loss:  0.008399917744100094\n",
      "Policy Loss:  0.0008376315236091614\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135215 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.1877207220532e-05\n",
      "Q Loss:  0.001107553020119667\n",
      "Policy Loss:  0.013903871178627014\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135219 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.3415084797306918e-05\n",
      "Q Loss:  0.002114963484928012\n",
      "Policy Loss:  0.02233893610537052\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.014567346312105656\n",
      "Q Loss:  0.0016713140066713095\n",
      "Policy Loss:  0.05006786808371544\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135227 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.026928111910820007\n",
      "Q Loss:  0.011914975941181183\n",
      "Policy Loss:  -0.0035145990550518036\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135231 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.012303744442760944\n",
      "Q Loss:  0.023016314953565598\n",
      "Policy Loss:  0.04111884906888008\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.022346246987581253\n",
      "Q Loss:  0.011685522273182869\n",
      "Policy Loss:  -0.007023360580205917\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  7.623716373927891e-05\n",
      "Q Loss:  0.0001714238605927676\n",
      "Policy Loss:  -0.008256387896835804\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.009038670919835567\n",
      "Q Loss:  0.011243429034948349\n",
      "Policy Loss:  0.028036126866936684\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  5.080963092041202e-05\n",
      "Q Loss:  0.0005984755698591471\n",
      "Policy Loss:  -0.018056388944387436\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.00012725661508738995\n",
      "Q Loss:  0.008202146738767624\n",
      "Policy Loss:  -0.0033710808493196964\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.009115464985370636\n",
      "Q Loss:  0.00048533425433561206\n",
      "Policy Loss:  -0.03565220907330513\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135259 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  7.4893023338518105e-06\n",
      "Q Loss:  0.0014509372413158417\n",
      "Policy Loss:  0.020165501162409782\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135263 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  1.0170550346374512\n",
      "Q Loss:  12.025184631347656\n",
      "Policy Loss:  0.576444685459137\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135356 length: 93 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.010754785500466824\n",
      "Q Loss:  0.005322674755007029\n",
      "Policy Loss:  -0.008704569190740585\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.5027471780776978\n",
      "Q Loss:  0.0040067341178655624\n",
      "Policy Loss:  0.20785242319107056\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135423 length: 63 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00048568026977591217\n",
      "Q Loss:  92.94020080566406\n",
      "Policy Loss:  3.3423357009887695\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3496.540283203125\n",
      "Q Loss:  6255.591796875\n",
      "Policy Loss:  -211.06585693359375\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.118099579703994e-05\n",
      "Q Loss:  0.0017401345539838076\n",
      "Policy Loss:  -0.0013471010606735945\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04300975799560547\n",
      "Value Loss:  3.477392965578474e-05\n",
      "Q Loss:  0.0011872403556481004\n",
      "Policy Loss:  -0.0005965838208794594\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0001921404036693275\n",
      "Q Loss:  8.719085599295795e-05\n",
      "Policy Loss:  -0.00775404367595911\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0010992633178830147\n",
      "Q Loss:  0.006213366985321045\n",
      "Policy Loss:  0.001716364175081253\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.000804371724370867\n",
      "Q Loss:  0.0020058974623680115\n",
      "Policy Loss:  0.02641611360013485\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.006123619619756937\n",
      "Q Loss:  0.0031162030063569546\n",
      "Policy Loss:  0.044125981628894806\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.012078595347702503\n",
      "Q Loss:  0.0051306807436048985\n",
      "Policy Loss:  0.004042400047183037\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.7156390792224556e-05\n",
      "Q Loss:  0.00258351000957191\n",
      "Policy Loss:  0.025742467492818832\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.017397593706846237\n",
      "Q Loss:  0.003932556137442589\n",
      "Policy Loss:  -0.01650342531502247\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.01664748601615429\n",
      "Q Loss:  0.0010543366661295295\n",
      "Policy Loss:  0.0031496798619627953\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.005292094312608242\n",
      "Q Loss:  0.004951938055455685\n",
      "Policy Loss:  0.01746627502143383\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.004985629580914974\n",
      "Q Loss:  0.0040952833369374275\n",
      "Policy Loss:  0.03360547870397568\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  152.11196899414062\n",
      "Q Loss:  286.4054870605469\n",
      "Policy Loss:  -12.654047012329102\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135569 length: 90 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0003992580168414861\n",
      "Q Loss:  0.0004885541857220232\n",
      "Policy Loss:  0.009360255673527718\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135573 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  320.2865905761719\n",
      "Q Loss:  506.3219299316406\n",
      "Policy Loss:  -27.093509674072266\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135658 length: 85 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0003559429314918816\n",
      "Q Loss:  387.4989013671875\n",
      "Policy Loss:  13.65644645690918\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 135662 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0001687248732196167\n",
      "Q Loss:  96.34363555908203\n",
      "Policy Loss:  3.3767528533935547\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135666 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  8.881381654646248e-05\n",
      "Q Loss:  0.03239861875772476\n",
      "Policy Loss:  -0.07794472575187683\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135670 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3.925482087652199e-05\n",
      "Q Loss:  95.0754623413086\n",
      "Policy Loss:  3.3522157669067383\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 135674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0800178050994873\n",
      "Value Loss:  4.625611609299085e-07\n",
      "Q Loss:  0.0016853937413543463\n",
      "Policy Loss:  0.0033790890593081713\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135678 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03500676155090332\n",
      "Value Loss:  0.0004194578796159476\n",
      "Q Loss:  0.0012506109196692705\n",
      "Policy Loss:  0.04090823978185654\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0005775270401500165\n",
      "Q Loss:  0.0034986590035259724\n",
      "Policy Loss:  0.025987733155488968\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00038556550862267613\n",
      "Q Loss:  0.00305199739523232\n",
      "Policy Loss:  -0.020678497850894928\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0058866702020168304\n",
      "Q Loss:  0.020311133936047554\n",
      "Policy Loss:  -0.04347623139619827\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004770278930664\n",
      "Value Loss:  1.0706474781036377\n",
      "Q Loss:  16.695871353149414\n",
      "Policy Loss:  0.7428109645843506\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135782 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016598939895629883\n",
      "Value Loss:  0.00015060993609949946\n",
      "Q Loss:  0.0027252621948719025\n",
      "Policy Loss:  -0.017318246886134148\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.012684333138167858\n",
      "Q Loss:  0.008702571503818035\n",
      "Policy Loss:  -0.05166070908308029\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024004220962524414\n",
      "Value Loss:  8.969192276708782e-05\n",
      "Q Loss:  0.012069575488567352\n",
      "Policy Loss:  -0.052277885377407074\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052011966705322266\n",
      "Value Loss:  2.9994114811415784e-05\n",
      "Q Loss:  0.0031560645438730717\n",
      "Policy Loss:  -0.015624204650521278\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00023101318220142275\n",
      "Q Loss:  0.0011761037167161703\n",
      "Policy Loss:  -0.008288802579045296\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.8793314666254446e-05\n",
      "Q Loss:  0.0017345610540360212\n",
      "Policy Loss:  0.01252908818423748\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.006975030060857534\n",
      "Q Loss:  0.0055786678567528725\n",
      "Policy Loss:  -0.001779668964445591\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.013942649587988853\n",
      "Q Loss:  0.000749391270801425\n",
      "Policy Loss:  -0.015801770612597466\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.013744882307946682\n",
      "Q Loss:  0.0037418422289192677\n",
      "Policy Loss:  0.005445249378681183\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  16231.8193359375\n",
      "Q Loss:  16130.4921875\n",
      "Policy Loss:  -45.89332580566406\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135867 length: 49 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.00039789819857105613\n",
      "Q Loss:  0.0014140649000182748\n",
      "Policy Loss:  0.027239251881837845\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135871 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.021025484427809715\n",
      "Q Loss:  0.003738827770575881\n",
      "Policy Loss:  -0.01897854171693325\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135875 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.02091081254184246\n",
      "Q Loss:  0.004002821631729603\n",
      "Policy Loss:  -0.010985637083649635\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135879 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.006756233051419258\n",
      "Q Loss:  0.010140420868992805\n",
      "Policy Loss:  0.06535367667675018\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135883 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.012972177006304264\n",
      "Q Loss:  0.0077761574648320675\n",
      "Policy Loss:  0.007490463554859161\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135887 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0061388565227389336\n",
      "Q Loss:  0.00048756340402178466\n",
      "Policy Loss:  0.007825114764273167\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135891 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  2.416379928588867\n",
      "Q Loss:  0.0029338495805859566\n",
      "Policy Loss:  0.3580245077610016\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 135930 length: 39 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  3384.417236328125\n",
      "Q Loss:  6057.84912109375\n",
      "Policy Loss:  -208.1648406982422\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00020607185433618724\n",
      "Q Loss:  0.03450922667980194\n",
      "Policy Loss:  -0.016475845128297806\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014093637466430664\n",
      "Value Loss:  0.00015092040121089667\n",
      "Q Loss:  179.78933715820312\n",
      "Policy Loss:  6.585675239562988\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.2022654118482023e-05\n",
      "Q Loss:  0.08081313222646713\n",
      "Policy Loss:  0.10513854026794434\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0012774713104590774\n",
      "Q Loss:  0.0012834458611905575\n",
      "Policy Loss:  0.013462577015161514\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 135950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900861740112305\n",
      "Value Loss:  2.261352346977219e-05\n",
      "Q Loss:  0.002756258472800255\n",
      "Policy Loss:  0.000828940887004137\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.676368189393543e-05\n",
      "Q Loss:  0.0010769411455839872\n",
      "Policy Loss:  0.01456032320857048\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  8.956998499343172e-05\n",
      "Q Loss:  0.0022695153020322323\n",
      "Policy Loss:  0.03272728994488716\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.000558033469133079\n",
      "Q Loss:  0.0024183974601328373\n",
      "Policy Loss:  0.01347874291241169\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.008328581228852272\n",
      "Q Loss:  0.010121622122824192\n",
      "Policy Loss:  0.08611779659986496\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 135970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  1.0580945014953613\n",
      "Q Loss:  0.005870181135833263\n",
      "Policy Loss:  0.16864487528800964\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136058 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0001789203961379826\n",
      "Q Loss:  0.0008412102470174432\n",
      "Policy Loss:  -0.0031583625823259354\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03881430625915527\n",
      "Value Loss:  0.00014257831207942218\n",
      "Q Loss:  0.001487337751314044\n",
      "Policy Loss:  -0.008458935655653477\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136066 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.018967172130942345\n",
      "Q Loss:  0.004306385293602943\n",
      "Policy Loss:  0.0020011551678180695\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136070 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  0.908919632434845\n",
      "Q Loss:  0.004105746280401945\n",
      "Policy Loss:  0.12504830956459045\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136173 length: 103 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03464388847351074\n",
      "Value Loss:  0.0007578402291983366\n",
      "Q Loss:  0.04179883748292923\n",
      "Policy Loss:  -0.04468214511871338\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136177 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0005257555167190731\n",
      "Q Loss:  0.0007134857587516308\n",
      "Policy Loss:  -0.0023528756573796272\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  1.8383474525762722e-05\n",
      "Q Loss:  0.00031082372879609466\n",
      "Policy Loss:  0.025549329817295074\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.7060385346412659\n",
      "Q Loss:  0.0035179818514734507\n",
      "Policy Loss:  0.08866798877716064\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136317 length: 132 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00041121902177110314\n",
      "Q Loss:  0.005087646655738354\n",
      "Policy Loss:  -0.037580907344818115\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136321 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0003171796561218798\n",
      "Q Loss:  0.0029946668073534966\n",
      "Policy Loss:  -0.03185703605413437\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136325 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.8822770370170474e-05\n",
      "Q Loss:  0.0008283438510261476\n",
      "Policy Loss:  0.01876462996006012\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136329 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.0915143977617845e-05\n",
      "Q Loss:  0.0010726579930633307\n",
      "Policy Loss:  -0.003699295222759247\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136333 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.012613292783498764\n",
      "Q Loss:  0.013324749656021595\n",
      "Policy Loss:  -0.011586589738726616\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136337 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.0050818920135498\n",
      "Q Loss:  3.986236095428467\n",
      "Policy Loss:  0.27801838517189026\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 136429 length: 92 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.821391560952179e-05\n",
      "Q Loss:  0.00021179653413128108\n",
      "Policy Loss:  0.011257851496338844\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 136433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  219.85105895996094\n",
      "Q Loss:  399.61492919921875\n",
      "Policy Loss:  -19.27529525756836\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 136553 length: 120 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  3284.695556640625\n",
      "Q Loss:  4183.087890625\n",
      "Policy Loss:  -204.48268127441406\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 136557 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600764274597168\n",
      "Value Loss:  0.0008945051813498139\n",
      "Q Loss:  0.00253518158569932\n",
      "Policy Loss:  -0.004537923727184534\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136561 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0004616994992829859\n",
      "Q Loss:  0.0009442122536711395\n",
      "Policy Loss:  -0.00068614911288023\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136565 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.0002306139504071325\n",
      "Q Loss:  0.000861585489474237\n",
      "Policy Loss:  0.0062959035858511925\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136569 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00022981861548032612\n",
      "Q Loss:  0.00031327601755037904\n",
      "Policy Loss:  -0.005839892663061619\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136573 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0248105525970459\n",
      "Value Loss:  0.05052155256271362\n",
      "Q Loss:  0.008027192205190659\n",
      "Policy Loss:  -0.028156258165836334\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136577 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.033614687621593475\n",
      "Q Loss:  0.008355296216905117\n",
      "Policy Loss:  -0.026365086436271667\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136581 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  3.085454227402806e-05\n",
      "Q Loss:  0.0008600179571658373\n",
      "Policy Loss:  -0.005242431536316872\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136585 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.57087641954422\n",
      "Q Loss:  0.0029110682662576437\n",
      "Policy Loss:  0.09459104388952255\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136745 length: 160 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03400731086730957\n",
      "Value Loss:  0.00043729133903980255\n",
      "Q Loss:  0.0024822959676384926\n",
      "Policy Loss:  0.012293502688407898\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136749 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03300738334655762\n",
      "Value Loss:  6.865238538011909e-05\n",
      "Q Loss:  0.0010139456717297435\n",
      "Policy Loss:  0.011267511174082756\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136753 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  6.189432315295562e-05\n",
      "Q Loss:  0.0025812331587076187\n",
      "Policy Loss:  0.02486974373459816\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136757 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  7.195452781161293e-05\n",
      "Q Loss:  0.0007460541091859341\n",
      "Policy Loss:  0.007715115323662758\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136761 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  2.1639656551997177e-05\n",
      "Q Loss:  0.002886628732085228\n",
      "Policy Loss:  0.024895217269659042\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136765 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.45906155416742e-05\n",
      "Q Loss:  0.000986457453109324\n",
      "Policy Loss:  0.008825762197375298\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136769 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  4.50679290224798e-05\n",
      "Q Loss:  4.96167667733971e-05\n",
      "Policy Loss:  -0.001416954561136663\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136773 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  36656.2109375\n",
      "Q Loss:  36441.59765625\n",
      "Policy Loss:  -115.39832305908203\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136817 length: 44 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  6367.3203125\n",
      "Q Loss:  9717.4970703125\n",
      "Policy Loss:  -206.22674560546875\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  82891.6484375\n",
      "Q Loss:  80839.1171875\n",
      "Policy Loss:  -107.9626235961914\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136840 length: 19 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0001559434604132548\n",
      "Q Loss:  0.10401409864425659\n",
      "Policy Loss:  0.07633057236671448\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 136844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00013453146675601602\n",
      "Q Loss:  0.0018955748528242111\n",
      "Policy Loss:  0.011326737701892853\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004531860351562\n",
      "Value Loss:  0.02065039984881878\n",
      "Q Loss:  0.003919008653610945\n",
      "Policy Loss:  -0.0019088834524154663\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.021557798609137535\n",
      "Q Loss:  0.014865903183817863\n",
      "Policy Loss:  -0.025885935872793198\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 136856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  0.04429767280817032\n",
      "Q Loss:  0.0036296546459198\n",
      "Policy Loss:  0.0026448704302310944\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.06696367263793945\n",
      "Q Loss:  0.015501294285058975\n",
      "Policy Loss:  -0.025290600955486298\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.02197396196424961\n",
      "Q Loss:  0.01971759833395481\n",
      "Policy Loss:  0.05421391874551773\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  1.3223129510879517\n",
      "Q Loss:  0.006111451890319586\n",
      "Policy Loss:  0.19968515634536743\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136936 length: 68 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  3.033232133020647e-05\n",
      "Q Loss:  192.6473846435547\n",
      "Policy Loss:  6.843829154968262\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136940 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  3.963752533309162e-05\n",
      "Q Loss:  0.007645498961210251\n",
      "Policy Loss:  0.03584197908639908\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136944 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.0008528553880751133\n",
      "Q Loss:  0.002168833278119564\n",
      "Policy Loss:  -0.0007202033884823322\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136948 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003898620605469\n",
      "Value Loss:  4.935189281241037e-05\n",
      "Q Loss:  0.0018720971420407295\n",
      "Policy Loss:  0.021684713661670685\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136952 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.021797558292746544\n",
      "Q Loss:  0.024575160816311836\n",
      "Policy Loss:  -0.02713235840201378\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 136956 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012011289596557617\n",
      "Value Loss:  1.648440957069397\n",
      "Q Loss:  0.003887922503054142\n",
      "Policy Loss:  0.2395908683538437\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137010 length: 54 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  12814.892578125\n",
      "Q Loss:  12451.3447265625\n",
      "Policy Loss:  -19.841697692871094\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137071 length: 61 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.04501008987426758\n",
      "Value Loss:  1.72356485563796e-05\n",
      "Q Loss:  0.0001711115473881364\n",
      "Policy Loss:  0.0036988675128668547\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.526435517007485e-05\n",
      "Q Loss:  3.858056879835203e-05\n",
      "Policy Loss:  0.0028214436024427414\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  19044.859375\n",
      "Q Loss:  18506.205078125\n",
      "Policy Loss:  -29.38524627685547\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137120 length: 41 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00017048203153535724\n",
      "Q Loss:  192.103515625\n",
      "Policy Loss:  6.766268730163574\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  6.50093425065279e-05\n",
      "Q Loss:  95.65994262695312\n",
      "Policy Loss:  3.3773272037506104\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301070213317871\n",
      "Value Loss:  8.017590153031051e-05\n",
      "Q Loss:  0.0019396593561396003\n",
      "Policy Loss:  -0.01831967756152153\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00024059964925982058\n",
      "Q Loss:  0.00033773749601095915\n",
      "Policy Loss:  -0.0014629607321694493\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0001210553600685671\n",
      "Q Loss:  0.0009813331998884678\n",
      "Policy Loss:  -0.012721851468086243\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  4.080157304997556e-05\n",
      "Q Loss:  0.005241665057837963\n",
      "Policy Loss:  -0.03358307108283043\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0004168115265201777\n",
      "Q Loss:  0.0012854684609919786\n",
      "Policy Loss:  -0.017828984186053276\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137148 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0358145646750927\n",
      "Q Loss:  0.005172421224415302\n",
      "Policy Loss:  -0.004744231700897217\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137152 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00011910257308045402\n",
      "Q Loss:  0.003006660146638751\n",
      "Policy Loss:  0.023589540272951126\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137156 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.518292239983566e-05\n",
      "Q Loss:  0.0013607772998511791\n",
      "Policy Loss:  0.01574837416410446\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.03678027167916298\n",
      "Q Loss:  0.003474203869700432\n",
      "Policy Loss:  0.0633189007639885\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137164 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.14678166806697845\n",
      "Q Loss:  0.05571646988391876\n",
      "Policy Loss:  -0.17688821256160736\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  13004.5908203125\n",
      "Q Loss:  13193.7470703125\n",
      "Policy Loss:  -71.64742279052734\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137231 length: 63 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0012342182453721762\n",
      "Q Loss:  0.0009184886002913117\n",
      "Policy Loss:  0.016089655458927155\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137235 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0008033221820369363\n",
      "Q Loss:  0.0010467409156262875\n",
      "Policy Loss:  0.018657438457012177\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137239 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0002338849299121648\n",
      "Q Loss:  0.002736788708716631\n",
      "Policy Loss:  0.02639431320130825\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137243 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0001072067825589329\n",
      "Q Loss:  0.0001232732756761834\n",
      "Policy Loss:  0.009417327120900154\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137247 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022005319595336914\n",
      "Value Loss:  0.00010185127757722512\n",
      "Q Loss:  0.005196975544095039\n",
      "Policy Loss:  0.024328358471393585\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137251 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0007588464068248868\n",
      "Q Loss:  0.0021398088429123163\n",
      "Policy Loss:  0.020983058959245682\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137255 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.6993488073349\n",
      "Q Loss:  0.0075160968117415905\n",
      "Policy Loss:  0.27485644817352295\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137306 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  3550.033935546875\n",
      "Q Loss:  2116.639404296875\n",
      "Policy Loss:  -293.499755859375\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137310 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  3540.827392578125\n",
      "Q Loss:  6428.94580078125\n",
      "Policy Loss:  -180.74588012695312\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137314 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.1369798560044728e-05\n",
      "Q Loss:  93.14282989501953\n",
      "Policy Loss:  3.4054484367370605\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137318 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07337737083435059\n",
      "Value Loss:  0.004982625599950552\n",
      "Q Loss:  0.006740559823811054\n",
      "Policy Loss:  -0.012052775360643864\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00104421132709831\n",
      "Q Loss:  0.01772649958729744\n",
      "Policy Loss:  -0.057299669831991196\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137326 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0017458652146160603\n",
      "Q Loss:  0.003401403548195958\n",
      "Policy Loss:  -0.006417672615498304\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137330 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.3988435461651534e-05\n",
      "Q Loss:  5.628807775792666e-05\n",
      "Policy Loss:  -0.0054552811197936535\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00010727710468927398\n",
      "Q Loss:  0.0008746411185711622\n",
      "Policy Loss:  0.00845254585146904\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137338 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.8250305301044136e-05\n",
      "Q Loss:  0.0016612231265753508\n",
      "Policy Loss:  0.025788769125938416\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00020372538710944355\n",
      "Q Loss:  0.005848131608217955\n",
      "Policy Loss:  0.022680286318063736\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137346 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  11640.6591796875\n",
      "Q Loss:  11285.5087890625\n",
      "Policy Loss:  -18.177242279052734\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 137413 length: 67 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.031006336212158203\n",
      "Value Loss:  0.0021642190404236317\n",
      "Q Loss:  0.0010578699875622988\n",
      "Policy Loss:  -0.01246829517185688\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0006928760558366776\n",
      "Q Loss:  0.0010618353262543678\n",
      "Policy Loss:  -0.015393368899822235\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02400493621826172\n",
      "Value Loss:  0.0006272658356465399\n",
      "Q Loss:  0.0024643216747790575\n",
      "Policy Loss:  0.004344466608017683\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.08426923304796219\n",
      "Q Loss:  0.0321187824010849\n",
      "Policy Loss:  0.037763260304927826\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 137429 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.12536941468715668\n",
      "Q Loss:  0.0002828120195772499\n",
      "Policy Loss:  0.029458584263920784\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 137433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011314630508422852\n",
      "Value Loss:  0.6145532131195068\n",
      "Q Loss:  0.00967880804091692\n",
      "Policy Loss:  0.13011758029460907\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 137575 length: 142 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.0009654848836362362\n",
      "Q Loss:  0.003897382877767086\n",
      "Policy Loss:  -0.009217996150255203\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 137579 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0005552706425078213\n",
      "Q Loss:  0.0015050687361508608\n",
      "Policy Loss:  0.019277403131127357\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 137583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  3.235149779357016e-05\n",
      "Q Loss:  0.002291030716150999\n",
      "Policy Loss:  0.02450977824628353\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011601686477661133\n",
      "Value Loss:  0.03670002147555351\n",
      "Q Loss:  0.027273355051875114\n",
      "Policy Loss:  0.06322450935840607\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.0522936463530641e-05\n",
      "Q Loss:  0.0008745522936806083\n",
      "Policy Loss:  0.011283675208687782\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003494262695312\n",
      "Value Loss:  1.1388772691134363e-05\n",
      "Q Loss:  0.00039225543150678277\n",
      "Policy Loss:  0.058546025305986404\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.036008596420288086\n",
      "Value Loss:  0.03408326581120491\n",
      "Q Loss:  0.01823786087334156\n",
      "Policy Loss:  -0.03666835278272629\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  3.979171742685139e-05\n",
      "Q Loss:  0.00024254852905869484\n",
      "Policy Loss:  -0.0037664754781872034\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  4.0896458813222125e-05\n",
      "Q Loss:  0.0007363609038293362\n",
      "Policy Loss:  -0.008521702140569687\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  3.442301385803148e-05\n",
      "Q Loss:  0.006914804223924875\n",
      "Policy Loss:  0.009541618637740612\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004770278930664\n",
      "Value Loss:  8.653874829178676e-06\n",
      "Q Loss:  0.004052651114761829\n",
      "Policy Loss:  -0.03566921502351761\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  6.041550022928277e-06\n",
      "Q Loss:  0.0026429402641952038\n",
      "Policy Loss:  -0.027677450329065323\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137623 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  1.1317375538055785e-05\n",
      "Q Loss:  0.002811379497870803\n",
      "Policy Loss:  -0.02485490031540394\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137627 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.029481083154678345\n",
      "Q Loss:  0.037862930446863174\n",
      "Policy Loss:  -0.03320423141121864\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137631 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0008899125386960804\n",
      "Q Loss:  0.001601206255145371\n",
      "Policy Loss:  0.012266147881746292\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137635 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0018170801922678947\n",
      "Q Loss:  0.0006982274353504181\n",
      "Policy Loss:  0.007427789270877838\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137639 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.00016862705524545163\n",
      "Q Loss:  0.0015233177691698074\n",
      "Policy Loss:  -0.010512487962841988\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137643 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.346583227743395e-05\n",
      "Q Loss:  0.0004084449028596282\n",
      "Policy Loss:  -0.0007344457553699613\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137647 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00011851514864247292\n",
      "Q Loss:  0.00046412472147494555\n",
      "Policy Loss:  -0.008817619644105434\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137651 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.039008378982543945\n",
      "Value Loss:  0.00010121583909494802\n",
      "Q Loss:  0.0031585185788571835\n",
      "Policy Loss:  -0.007911852560937405\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137655 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014001846313476562\n",
      "Value Loss:  0.0035731447860598564\n",
      "Q Loss:  0.0028184871189296246\n",
      "Policy Loss:  -0.025897826999425888\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.004350753966718912\n",
      "Q Loss:  0.0008343535009771585\n",
      "Policy Loss:  -0.01145973801612854\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200413703918457\n",
      "Value Loss:  0.0003736685903277248\n",
      "Q Loss:  0.001380931120365858\n",
      "Policy Loss:  0.0035107573494315147\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0006883047753944993\n",
      "Q Loss:  0.0024925395846366882\n",
      "Policy Loss:  0.03521202504634857\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00026654909015633166\n",
      "Q Loss:  196.4822235107422\n",
      "Policy Loss:  6.8739800453186035\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.000226493866648525\n",
      "Q Loss:  0.0005405102856457233\n",
      "Policy Loss:  -0.0032633268274366856\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137679 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.003707587718963623\n",
      "Q Loss:  0.00916423462331295\n",
      "Policy Loss:  0.01458815298974514\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0017462058458477259\n",
      "Q Loss:  0.002246810356155038\n",
      "Policy Loss:  0.005962559022009373\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  6.683339597657323e-05\n",
      "Q Loss:  0.013269948773086071\n",
      "Policy Loss:  0.038100309669971466\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  7.456304501829436e-06\n",
      "Q Loss:  0.03473100811243057\n",
      "Policy Loss:  0.09222090244293213\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137695 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  2.8346103135845624e-06\n",
      "Q Loss:  0.015381993725895882\n",
      "Policy Loss:  0.042336367070674896\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137699 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02700638771057129\n",
      "Value Loss:  0.04834083840250969\n",
      "Q Loss:  0.015403187833726406\n",
      "Policy Loss:  -0.005984872579574585\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137703 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0110015869140625\n",
      "Value Loss:  236.25877380371094\n",
      "Q Loss:  362.3797302246094\n",
      "Policy Loss:  -20.858840942382812\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137818 length: 115 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400136947631836\n",
      "Value Loss:  0.0006686666165478528\n",
      "Q Loss:  0.006436455063521862\n",
      "Policy Loss:  -0.030653124675154686\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0014225146733224392\n",
      "Q Loss:  0.0006145870429463685\n",
      "Policy Loss:  -0.00890800915658474\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.09153389930725098\n",
      "Value Loss:  3.610159910749644e-05\n",
      "Q Loss:  9.136043809121475e-05\n",
      "Policy Loss:  0.0057098232209682465\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  3.765057772397995e-05\n",
      "Q Loss:  4.534942127065733e-05\n",
      "Policy Loss:  -0.004249135963618755\n",
      "[(7e-05, 0), (7e-05, 0.0)]\n",
      "Alpha*: 7e-05 tau*: 0 Episode: 137834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  4.9200430112250615e-06\n",
      "Q Loss:  0.044774651527404785\n",
      "Policy Loss:  -0.048435863107442856\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137838 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.02296619303524494\n",
      "Q Loss:  0.013076474890112877\n",
      "Policy Loss:  -0.10156629234552383\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137842 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  43392.20703125\n",
      "Q Loss:  42013.7109375\n",
      "Policy Loss:  -64.1301040649414\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137860 length: 18 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00013119123468641192\n",
      "Q Loss:  0.00015005521709099412\n",
      "Policy Loss:  0.0027044881135225296\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0001034911401802674\n",
      "Q Loss:  0.03689903765916824\n",
      "Policy Loss:  0.02368292771279812\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  1.1829843521118164\n",
      "Q Loss:  0.01068486925214529\n",
      "Policy Loss:  0.15467111766338348\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 137943 length: 75 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  5410.5263671875\n",
      "Q Loss:  5290.32373046875\n",
      "Policy Loss:  -8.504335403442383\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 138087 length: 144 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  8284.5380859375\n",
      "Q Loss:  8390.978515625\n",
      "Policy Loss:  -46.614906311035156\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138186 length: 99 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  7.686205208301544e-05\n",
      "Q Loss:  0.0020778393372893333\n",
      "Policy Loss:  0.011357193812727928\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.06922789663076401\n",
      "Q Loss:  0.02999163791537285\n",
      "Policy Loss:  -0.03065246343612671\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004106521606445\n",
      "Value Loss:  0.00011883860133821145\n",
      "Q Loss:  0.005126398988068104\n",
      "Policy Loss:  0.023882292211055756\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.902900764136575e-05\n",
      "Q Loss:  0.01377616822719574\n",
      "Policy Loss:  0.056741729378700256\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011694908142089844\n",
      "Value Loss:  3.2459058729727985e-06\n",
      "Q Loss:  1.7399792341166176e-05\n",
      "Policy Loss:  0.0026393134612590075\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138206 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.0385700985789299\n",
      "Q Loss:  0.022044876590371132\n",
      "Policy Loss:  0.06563590466976166\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138210 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012015104293823242\n",
      "Value Loss:  0.7561808824539185\n",
      "Q Loss:  13.006617546081543\n",
      "Policy Loss:  0.5645838379859924\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138327 length: 117 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.07933768630027771\n",
      "Q Loss:  0.03291187435388565\n",
      "Policy Loss:  -0.03536843881011009\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138331 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.11883777379989624\n",
      "Q Loss:  0.02997829020023346\n",
      "Policy Loss:  -0.09411226212978363\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138335 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0002942283172160387\n",
      "Q Loss:  0.006990905851125717\n",
      "Policy Loss:  0.04216817021369934\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138339 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0004070380819030106\n",
      "Q Loss:  0.003486305708065629\n",
      "Policy Loss:  0.015168815851211548\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138343 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00031870167003944516\n",
      "Q Loss:  0.002313526114448905\n",
      "Policy Loss:  0.019498048350214958\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138347 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015350361354649067\n",
      "Q Loss:  0.0011171444784849882\n",
      "Policy Loss:  0.011446870863437653\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138351 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.03561469912528992\n",
      "Q Loss:  0.03396420180797577\n",
      "Policy Loss:  -0.031100867316126823\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05201268196105957\n",
      "Value Loss:  1.701334834098816\n",
      "Q Loss:  0.004895156715065241\n",
      "Policy Loss:  0.2594970166683197\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138406 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  13360.4658203125\n",
      "Q Loss:  12936.341796875\n",
      "Policy Loss:  -21.555936813354492\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138464 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012784242630004883\n",
      "Value Loss:  0.0005585661856457591\n",
      "Q Loss:  9.812371717998758e-05\n",
      "Policy Loss:  0.005098698660731316\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138468 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200484275817871\n",
      "Value Loss:  0.00017063415725715458\n",
      "Q Loss:  4.41515730926767e-05\n",
      "Policy Loss:  -0.008257973939180374\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138472 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  3.487067442620173e-05\n",
      "Q Loss:  0.00043474469566717744\n",
      "Policy Loss:  -0.0020921651739627123\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138476 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00038380789919756353\n",
      "Q Loss:  0.0008039684034883976\n",
      "Policy Loss:  -0.009091565385460854\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138480 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04400944709777832\n",
      "Value Loss:  18873.251953125\n",
      "Q Loss:  18476.8828125\n",
      "Policy Loss:  -29.476728439331055\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138521 length: 41 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012119054794311523\n",
      "Value Loss:  0.000368770444765687\n",
      "Q Loss:  0.0006193146109580994\n",
      "Policy Loss:  0.04467250779271126\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  209.8104705810547\n",
      "Q Loss:  379.3125\n",
      "Policy Loss:  -17.570940017700195\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138595 length: 70 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0006388669717125595\n",
      "Q Loss:  0.03834741935133934\n",
      "Policy Loss:  -0.003920648712664843\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.04412366822361946\n",
      "Q Loss:  0.01693246327340603\n",
      "Policy Loss:  -0.019481249153614044\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  1.846132545324508e-05\n",
      "Q Loss:  0.031742386519908905\n",
      "Policy Loss:  0.035390835255384445\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  1.2043710947036743\n",
      "Q Loss:  0.010164759121835232\n",
      "Policy Loss:  0.1857723742723465\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138679 length: 72 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00027107427013106644\n",
      "Q Loss:  0.0013375300914049149\n",
      "Policy Loss:  0.007920688949525356\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.00039266099338419735\n",
      "Q Loss:  0.009224801324307919\n",
      "Policy Loss:  0.05665374547243118\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.000574385398067534\n",
      "Q Loss:  0.006104642059653997\n",
      "Policy Loss:  0.03612547367811203\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  1.0603762865066528\n",
      "Q Loss:  9.665980339050293\n",
      "Policy Loss:  0.5124003887176514\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138770 length: 79 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.00011053054186049849\n",
      "Q Loss:  0.0018319523660466075\n",
      "Policy Loss:  0.011833976954221725\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.3752055565419141e-06\n",
      "Q Loss:  0.005260458216071129\n",
      "Policy Loss:  0.027717694640159607\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138778 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0003431122750043869\n",
      "Q Loss:  0.0030071299988776445\n",
      "Policy Loss:  0.0186160895973444\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  2.2431815523304977e-05\n",
      "Q Loss:  0.0006313822814263403\n",
      "Policy Loss:  -0.004312978126108646\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015005111694335938\n",
      "Value Loss:  0.0018137942533940077\n",
      "Q Loss:  0.001441862783394754\n",
      "Policy Loss:  -0.02272828109562397\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.0005943076102994382\n",
      "Q Loss:  0.0015079723671078682\n",
      "Policy Loss:  -0.024087440222501755\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046010494232177734\n",
      "Value Loss:  0.00017084661521948874\n",
      "Q Loss:  0.0012728299479931593\n",
      "Policy Loss:  0.0700431764125824\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.25257351994514465\n",
      "Q Loss:  0.03421935439109802\n",
      "Policy Loss:  -0.14912506937980652\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.2456463724374771\n",
      "Q Loss:  0.022718727588653564\n",
      "Policy Loss:  -0.11350197345018387\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.11478647589683533\n",
      "Q Loss:  0.05147719383239746\n",
      "Policy Loss:  0.017950870096683502\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.10615948587656021\n",
      "Q Loss:  0.038533393293619156\n",
      "Policy Loss:  0.07260534167289734\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  216.217041015625\n",
      "Q Loss:  348.7720947265625\n",
      "Policy Loss:  -17.38043212890625\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138953 length: 139 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  0.0002840885135810822\n",
      "Q Loss:  0.01839575730264187\n",
      "Policy Loss:  0.07131622731685638\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02200460433959961\n",
      "Value Loss:  0.16944798827171326\n",
      "Q Loss:  0.0004932007868774235\n",
      "Policy Loss:  -0.007427619770169258\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.11533036828041077\n",
      "Q Loss:  0.08487922698259354\n",
      "Policy Loss:  0.028101254254579544\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0009374261717312038\n",
      "Q Loss:  0.009296314790844917\n",
      "Policy Loss:  0.03981025889515877\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.06111396476626396\n",
      "Q Loss:  0.04517541825771332\n",
      "Policy Loss:  0.049378328025341034\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 138973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  45302.34765625\n",
      "Q Loss:  44124.71484375\n",
      "Policy Loss:  -70.48382568359375\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139007 length: 34 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.00993539672344923\n",
      "Q Loss:  0.006258876528590918\n",
      "Policy Loss:  0.04173815995454788\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139011 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005889892578125\n",
      "Value Loss:  0.0055245403200387955\n",
      "Q Loss:  9.272367606172338e-05\n",
      "Policy Loss:  0.008357726037502289\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139015 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.020856449380517006\n",
      "Q Loss:  0.027653314173221588\n",
      "Policy Loss:  0.031244419515132904\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139019 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014035701751708984\n",
      "Value Loss:  2.7427466193330474e-05\n",
      "Q Loss:  0.003001145087182522\n",
      "Policy Loss:  0.004803593270480633\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139023 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00020660832524299622\n",
      "Q Loss:  0.0018056161934509873\n",
      "Policy Loss:  -0.022987384349107742\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139027 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0006107048830017447\n",
      "Q Loss:  0.0018626577220857143\n",
      "Policy Loss:  -0.025780927389860153\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 139031 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00013846802175976336\n",
      "Q Loss:  0.0001409679389325902\n",
      "Policy Loss:  -0.006879119202494621\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 139035 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.9772679378511384e-05\n",
      "Q Loss:  0.000266082352027297\n",
      "Policy Loss:  -0.018021173775196075\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 139039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.026993403211236\n",
      "Q Loss:  0.011964228935539722\n",
      "Policy Loss:  0.019807271659374237\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 139043 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.03753092139959335\n",
      "Q Loss:  0.014313954859972\n",
      "Policy Loss:  0.003870973363518715\n",
      "[(6e-05, 0), (6e-05, 0.0)]\n",
      "Alpha*: 6e-05 tau*: 0 Episode: 139047 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  6029.388671875\n",
      "Q Loss:  5906.50537109375\n",
      "Policy Loss:  -10.305360794067383\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139174 length: 127 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00037542227073572576\n",
      "Q Loss:  0.0023218935821205378\n",
      "Policy Loss:  0.025027375668287277\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139178 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0011419187067076564\n",
      "Q Loss:  0.0005903305718675256\n",
      "Policy Loss:  -0.0009302191901952028\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139182 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2.4910552383516915e-05\n",
      "Q Loss:  0.002088054781779647\n",
      "Policy Loss:  -0.029116231948137283\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139186 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.017035065218806267\n",
      "Q Loss:  0.005458470433950424\n",
      "Policy Loss:  0.00568104162812233\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139190 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.051011085510253906\n",
      "Value Loss:  0.007880344986915588\n",
      "Q Loss:  0.0029940898530185223\n",
      "Policy Loss:  -0.02734747901558876\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139194 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.7971450090408325\n",
      "Q Loss:  0.02254278026521206\n",
      "Policy Loss:  0.05022571235895157\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139314 length: 120 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.05394473671913147\n",
      "Q Loss:  0.02248864620923996\n",
      "Policy Loss:  -0.11928483098745346\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139318 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0287652425467968\n",
      "Q Loss:  0.017494140192866325\n",
      "Policy Loss:  -0.05073684826493263\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139322 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.013251915574073792\n",
      "Q Loss:  0.0008153297239914536\n",
      "Policy Loss:  0.01722746714949608\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139326 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0008690858376212418\n",
      "Q Loss:  0.007664423901587725\n",
      "Policy Loss:  0.06481429934501648\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139330 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.010242382064461708\n",
      "Q Loss:  0.027745850384235382\n",
      "Policy Loss:  0.113613560795784\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139334 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0035936955828219652\n",
      "Q Loss:  0.0064954496920108795\n",
      "Policy Loss:  0.04431164637207985\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139338 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0011415914632380009\n",
      "Q Loss:  0.0031419352162629366\n",
      "Policy Loss:  0.030249856412410736\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139342 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0008847585413604975\n",
      "Q Loss:  0.002801788505166769\n",
      "Policy Loss:  0.019690735265612602\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139346 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031015634536743164\n",
      "Value Loss:  0.0001947164419107139\n",
      "Q Loss:  0.0003585012163966894\n",
      "Policy Loss:  -0.013655931688845158\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139350 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052011728286743164\n",
      "Value Loss:  0.0003105069336015731\n",
      "Q Loss:  0.0006067542126402259\n",
      "Policy Loss:  0.00679998891428113\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139354 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600740432739258\n",
      "Value Loss:  0.005082001909613609\n",
      "Q Loss:  0.0038132970221340656\n",
      "Policy Loss:  -0.007444428279995918\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139358 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.004594380501657724\n",
      "Q Loss:  0.003574306843802333\n",
      "Policy Loss:  0.004049153998494148\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139362 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  17316.54296875\n",
      "Q Loss:  17291.48046875\n",
      "Policy Loss:  -53.95796585083008\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139407 length: 45 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013306140899658203\n",
      "Value Loss:  0.0041594975627958775\n",
      "Q Loss:  0.005289915949106216\n",
      "Policy Loss:  -0.022749783471226692\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139411 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000664710998535\n",
      "Value Loss:  0.0022940237540751696\n",
      "Q Loss:  96.77320861816406\n",
      "Policy Loss:  3.367675304412842\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139415 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.015353091061115265\n",
      "Q Loss:  0.00792200118303299\n",
      "Policy Loss:  -0.020550871267914772\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139419 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.08964425325393677\n",
      "Q Loss:  0.0843489021062851\n",
      "Policy Loss:  0.07434132695198059\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139423 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.07536086440086365\n",
      "Q Loss:  0.038154251873493195\n",
      "Policy Loss:  0.026755336672067642\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139427 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.004256389103829861\n",
      "Q Loss:  0.0017531409393996\n",
      "Policy Loss:  -0.007452868390828371\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139431 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.017958279699087143\n",
      "Q Loss:  0.0028786086477339268\n",
      "Policy Loss:  -0.03256641700863838\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139435 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04501008987426758\n",
      "Value Loss:  0.006350228562951088\n",
      "Q Loss:  0.0028228007722646\n",
      "Policy Loss:  -0.03604469448328018\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139439 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.029006242752075195\n",
      "Value Loss:  0.06403178721666336\n",
      "Q Loss:  0.04085443168878555\n",
      "Policy Loss:  -0.1027715802192688\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139443 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.009066672064363956\n",
      "Q Loss:  0.027629027143120766\n",
      "Policy Loss:  -0.02784106507897377\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.034153155982494354\n",
      "Q Loss:  0.0077374167740345\n",
      "Policy Loss:  0.01796584390103817\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.001208400703035295\n",
      "Q Loss:  0.003948442172259092\n",
      "Policy Loss:  0.022737251594662666\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.001888343715108931\n",
      "Q Loss:  0.0035617281682789326\n",
      "Policy Loss:  0.03246535733342171\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0006275808555074036\n",
      "Q Loss:  0.0010270703351125121\n",
      "Policy Loss:  0.009305055253207684\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.006275152787566185\n",
      "Q Loss:  0.0027295013424009085\n",
      "Policy Loss:  0.013202294707298279\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.002418462885543704\n",
      "Q Loss:  0.004498176276683807\n",
      "Policy Loss:  0.02559470385313034\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.0031514025758951902\n",
      "Q Loss:  0.06803596019744873\n",
      "Policy Loss:  -0.026749510318040848\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.006555495318025351\n",
      "Q Loss:  0.025473972782492638\n",
      "Policy Loss:  -0.03759508207440376\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139479 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.006241345778107643\n",
      "Q Loss:  0.0033000335097312927\n",
      "Policy Loss:  -0.031240373849868774\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139483 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.019882598891854286\n",
      "Q Loss:  0.042051270604133606\n",
      "Policy Loss:  -0.0652831420302391\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139487 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  0.0002292233402840793\n",
      "Q Loss:  0.0006768218008801341\n",
      "Policy Loss:  -0.012533199042081833\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139491 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0006653632735833526\n",
      "Q Loss:  0.004737616516649723\n",
      "Policy Loss:  -0.02155335061252117\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139495 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0008489267202094197\n",
      "Q Loss:  0.0027407926972955465\n",
      "Policy Loss:  -0.01831342652440071\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139499 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.0008514373330399394\n",
      "Q Loss:  0.00176775804720819\n",
      "Policy Loss:  -0.012921231798827648\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139503 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.011675389483571053\n",
      "Q Loss:  0.0027357027865946293\n",
      "Policy Loss:  0.0006004534661769867\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139507 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  454.17828369140625\n",
      "Q Loss:  693.0772094726562\n",
      "Policy Loss:  -35.7852668762207\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139579 length: 72 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.005319429561495781\n",
      "Q Loss:  0.0014124172739684582\n",
      "Policy Loss:  -0.012541515752673149\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01698589324951172\n",
      "Value Loss:  0.00018855617963708937\n",
      "Q Loss:  0.0002266413066536188\n",
      "Policy Loss:  0.012195387855172157\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9.236032929038629e-05\n",
      "Q Loss:  0.0035970876924693584\n",
      "Policy Loss:  0.003701492678374052\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021003246307373047\n",
      "Value Loss:  0.018520545214414597\n",
      "Q Loss:  0.003371828468516469\n",
      "Policy Loss:  -0.010238884948194027\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.2965292930603027\n",
      "Q Loss:  0.022023597732186317\n",
      "Policy Loss:  0.36273378133773804\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139636 length: 41 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016021013259887695\n",
      "Value Loss:  4.929668426513672\n",
      "Q Loss:  0.008400438353419304\n",
      "Policy Loss:  0.7081001400947571\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139655 length: 19 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.014263182878494263\n",
      "Q Loss:  0.023407474160194397\n",
      "Policy Loss:  0.012029696255922318\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139659 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05801272392272949\n",
      "Value Loss:  0.0009810840710997581\n",
      "Q Loss:  0.00127188500482589\n",
      "Policy Loss:  0.009197317063808441\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.00011944461584789678\n",
      "Q Loss:  0.0015524461632594466\n",
      "Policy Loss:  0.012426381930708885\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.8847134709358215\n",
      "Q Loss:  0.017614487558603287\n",
      "Policy Loss:  0.15762777626514435\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139770 length: 103 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.0038316510617733\n",
      "Q Loss:  189.9840545654297\n",
      "Policy Loss:  6.736396789550781\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139774 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0021283882670104504\n",
      "Q Loss:  94.98194885253906\n",
      "Policy Loss:  3.3890600204467773\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139778 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015007972717285156\n",
      "Value Loss:  0.0010092180455103517\n",
      "Q Loss:  0.05024554207921028\n",
      "Policy Loss:  0.07440449297428131\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139782 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00042902849963866174\n",
      "Q Loss:  0.0011870595626533031\n",
      "Policy Loss:  0.011756437830626965\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139786 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.026878247037529945\n",
      "Q Loss:  0.005075038410723209\n",
      "Policy Loss:  -0.005997827276587486\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139790 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00019013305427506566\n",
      "Q Loss:  0.0003538694581948221\n",
      "Policy Loss:  -0.0016551017761230469\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139794 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024006128311157227\n",
      "Value Loss:  0.00015959360462147743\n",
      "Q Loss:  0.00037483853520825505\n",
      "Policy Loss:  -0.0046320268884301186\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  4.940044891554862e-05\n",
      "Q Loss:  0.0010402121115475893\n",
      "Policy Loss:  -0.01424816157668829\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  1.8547059880802408e-05\n",
      "Q Loss:  0.0005948699545115232\n",
      "Policy Loss:  -0.007682564668357372\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.06556043028831482\n",
      "Q Loss:  0.02238030917942524\n",
      "Policy Loss:  -0.06944175809621811\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  2.0003006284241565e-05\n",
      "Q Loss:  0.0003053206892218441\n",
      "Policy Loss:  -0.012244980782270432\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  7.243875734275207e-05\n",
      "Q Loss:  0.023939387872815132\n",
      "Policy Loss:  0.05915173888206482\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014506101608276367\n",
      "Value Loss:  0.007281181402504444\n",
      "Q Loss:  0.018774889409542084\n",
      "Policy Loss:  0.00012099836021661758\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0020480446983128786\n",
      "Q Loss:  0.0010329250944778323\n",
      "Policy Loss:  0.01704421453177929\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.03475698456168175\n",
      "Q Loss:  0.019804103299975395\n",
      "Policy Loss:  0.009425673633813858\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.7172178626060486\n",
      "Q Loss:  0.012254017405211926\n",
      "Policy Loss:  0.08535792678594589\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139953 length: 123 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.004786078818142414\n",
      "Q Loss:  0.006677261088043451\n",
      "Policy Loss:  -0.007130867801606655\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139957 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0019684857688844204\n",
      "Q Loss:  0.003965409472584724\n",
      "Policy Loss:  -0.0031343060545623302\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139961 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.004480765201151371\n",
      "Q Loss:  0.027088355273008347\n",
      "Policy Loss:  0.06309953331947327\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139965 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00010834070417331532\n",
      "Q Loss:  0.0008552988874725997\n",
      "Policy Loss:  0.018089964985847473\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139969 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003736660582944751\n",
      "Q Loss:  0.0011467344593256712\n",
      "Policy Loss:  -0.0048455167561769485\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03000640869140625\n",
      "Value Loss:  0.001420145621523261\n",
      "Q Loss:  0.0011211605742573738\n",
      "Policy Loss:  0.00391007587313652\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0003139770124107599\n",
      "Q Loss:  0.09276044368743896\n",
      "Policy Loss:  -0.14007747173309326\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00016951349971350282\n",
      "Q Loss:  0.00042050701449625194\n",
      "Policy Loss:  -0.004968428052961826\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021005630493164062\n",
      "Value Loss:  0.0002326775575056672\n",
      "Q Loss:  0.00031101773492991924\n",
      "Policy Loss:  0.005593877751380205\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600811958312988\n",
      "Value Loss:  6.418894190574065e-05\n",
      "Q Loss:  0.02158823236823082\n",
      "Policy Loss:  -0.03649844229221344\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 139993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00013934343587607145\n",
      "Q Loss:  0.014024456962943077\n",
      "Policy Loss:  -0.029670290648937225\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 139997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  7.729075878160074e-05\n",
      "Q Loss:  0.000657893717288971\n",
      "Policy Loss:  0.009189431555569172\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  3.924082557205111e-05\n",
      "Q Loss:  0.0006524299969896674\n",
      "Policy Loss:  0.008962152525782585\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06501483917236328\n",
      "Value Loss:  2.3122545826481655e-05\n",
      "Q Loss:  0.00021709657448809594\n",
      "Policy Loss:  0.010077964514493942\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.026005983352661133\n",
      "Value Loss:  7.645719051652122e-06\n",
      "Q Loss:  0.00014323435607366264\n",
      "Policy Loss:  0.00736524723470211\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.037450868636369705\n",
      "Q Loss:  0.006693860050290823\n",
      "Policy Loss:  0.018435189500451088\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140017 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  1.872891516541131e-05\n",
      "Q Loss:  1.389751287206309e-05\n",
      "Policy Loss:  -0.000911451003048569\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140021 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  2.9656428523594514e-05\n",
      "Q Loss:  8.966992027126253e-05\n",
      "Policy Loss:  -0.0031317677348852158\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140025 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  5.4645610362058505e-05\n",
      "Q Loss:  0.00011671434185700491\n",
      "Policy Loss:  2.3647909983992577e-05\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140029 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  5.666065408149734e-05\n",
      "Q Loss:  5.1482107664924115e-05\n",
      "Policy Loss:  -0.003723591798916459\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140033 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  3.003926030942239e-05\n",
      "Q Loss:  0.00030600634636357427\n",
      "Policy Loss:  -0.00969007983803749\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140037 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.706302075239364e-05\n",
      "Q Loss:  0.0001795464922906831\n",
      "Policy Loss:  -0.008007251657545567\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140041 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.8982335506007075e-06\n",
      "Q Loss:  0.00016610490274615586\n",
      "Policy Loss:  -0.004560595378279686\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140045 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012897968292236328\n",
      "Value Loss:  3.7741763662779704e-05\n",
      "Q Loss:  0.00019998906645923853\n",
      "Policy Loss:  -0.005819115322083235\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.07206614315509796\n",
      "Q Loss:  0.05118229240179062\n",
      "Policy Loss:  -0.07455512136220932\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.1059899851679802\n",
      "Q Loss:  0.02162601798772812\n",
      "Policy Loss:  -0.09535647928714752\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  1.8124881535186432e-05\n",
      "Q Loss:  0.000682168232742697\n",
      "Policy Loss:  0.020474335178732872\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140061 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  9.006206710182596e-06\n",
      "Q Loss:  0.00021186306548770517\n",
      "Policy Loss:  0.01070349756628275\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140065 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  2.754593333520461e-05\n",
      "Q Loss:  0.02457617036998272\n",
      "Policy Loss:  0.06944923102855682\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140069 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  2.3023734684102237e-05\n",
      "Q Loss:  0.0002645273052621633\n",
      "Policy Loss:  0.009205049835145473\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140073 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031007051467895508\n",
      "Value Loss:  2.423596743028611e-05\n",
      "Q Loss:  0.00017957386444322765\n",
      "Policy Loss:  0.006123124621808529\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140077 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  0.05707589164376259\n",
      "Q Loss:  0.019589703530073166\n",
      "Policy Loss:  0.04925120994448662\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140081 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.039008140563964844\n",
      "Value Loss:  574.3172607421875\n",
      "Q Loss:  963.4595947265625\n",
      "Policy Loss:  -44.76912307739258\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140194 length: 113 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.009553192183375359\n",
      "Q Loss:  0.004569429904222488\n",
      "Policy Loss:  0.030672134831547737\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140198 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.01084996573626995\n",
      "Q Loss:  0.00016967742703855038\n",
      "Policy Loss:  -0.006187372840940952\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140202 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0009693835163488984\n",
      "Q Loss:  0.005127839744091034\n",
      "Policy Loss:  -0.05012396723031998\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140206 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0060396743938326836\n",
      "Q Loss:  0.009037303738296032\n",
      "Policy Loss:  -0.02287374809384346\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140210 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.010221069678664207\n",
      "Q Loss:  0.007410133257508278\n",
      "Policy Loss:  -0.05507716163992882\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140214 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.006361764390021563\n",
      "Q Loss:  0.00547364167869091\n",
      "Policy Loss:  0.022339802235364914\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140218 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00010069433483295143\n",
      "Q Loss:  1.4947609997761901e-05\n",
      "Policy Loss:  0.0005133118247613311\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140222 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.00010233113425783813\n",
      "Q Loss:  0.007920973934233189\n",
      "Policy Loss:  0.046571873128414154\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140226 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.022653205320239067\n",
      "Q Loss:  0.01877788081765175\n",
      "Policy Loss:  0.05996894836425781\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06301474571228027\n",
      "Value Loss:  0.022101832553744316\n",
      "Q Loss:  0.027001745998859406\n",
      "Policy Loss:  0.008194683119654655\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00011493034980958328\n",
      "Q Loss:  0.0007296652183867991\n",
      "Policy Loss:  0.0008392346207983792\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  7.638910028617829e-05\n",
      "Q Loss:  0.008427013643085957\n",
      "Policy Loss:  0.02477378025650978\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  3.0767278076382354e-05\n",
      "Q Loss:  2.63008496403927e-06\n",
      "Policy Loss:  -0.004923978820443153\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140246 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.05964288488030434\n",
      "Q Loss:  0.0057007623836398125\n",
      "Policy Loss:  -0.0022839847952127457\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140250 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.03792614862322807\n",
      "Q Loss:  0.00865615252405405\n",
      "Policy Loss:  -0.04449312761425972\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140254 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  1.827998858061619e-06\n",
      "Q Loss:  0.004279155284166336\n",
      "Policy Loss:  0.0064581409096717834\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140258 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.216050784743857e-07\n",
      "Q Loss:  0.0006732924375683069\n",
      "Policy Loss:  -0.014764228835701942\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140262 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.01595199480652809\n",
      "Q Loss:  0.007763525936752558\n",
      "Policy Loss:  0.02062617614865303\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140266 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.015042195096611977\n",
      "Q Loss:  0.007149704732000828\n",
      "Policy Loss:  0.017162641510367393\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140270 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.486493468284607\n",
      "Q Loss:  0.01335599273443222\n",
      "Policy Loss:  0.19853663444519043\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140332 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  7.2828161137294956e-06\n",
      "Q Loss:  0.0009736611391417682\n",
      "Policy Loss:  -0.01675126701593399\n",
      "[(5e-05, 0), (5e-05, 0.0)]\n",
      "Alpha*: 5e-05 tau*: 0 Episode: 140336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015001058578491211\n",
      "Value Loss:  6.882025900267763e-06\n",
      "Q Loss:  0.017723215743899345\n",
      "Policy Loss:  -0.016879118978977203\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.013423720374703407\n",
      "Q Loss:  0.0033755451440811157\n",
      "Policy Loss:  -0.02185068279504776\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  49185.78125\n",
      "Q Loss:  47941.83984375\n",
      "Policy Loss:  -80.61032104492188\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140375 length: 31 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  0.0402994304895401\n",
      "Q Loss:  0.016615621745586395\n",
      "Policy Loss:  -0.05561332404613495\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140379 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0510106086730957\n",
      "Value Loss:  1.596170295670163e-05\n",
      "Q Loss:  0.0019326505716890097\n",
      "Policy Loss:  0.0719301849603653\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140383 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  1.9421108961105347\n",
      "Q Loss:  0.003254367271438241\n",
      "Policy Loss:  0.2967788577079773\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140430 length: 47 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.03063989244401455\n",
      "Q Loss:  0.02277117222547531\n",
      "Policy Loss:  0.009047523140907288\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.02732158452272415\n",
      "Q Loss:  0.007195293437689543\n",
      "Policy Loss:  0.019919313490390778\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.009424184449017048\n",
      "Q Loss:  0.00418210681527853\n",
      "Policy Loss:  0.008089279755949974\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004728317260742\n",
      "Value Loss:  0.002324726665392518\n",
      "Q Loss:  0.002068826463073492\n",
      "Policy Loss:  -0.03098723292350769\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.004884637892246246\n",
      "Q Loss:  0.007061270996928215\n",
      "Policy Loss:  0.04895983263850212\n",
      "[(4e-05, 0), (4e-05, 0.0)]\n",
      "Alpha*: 4e-05 tau*: 0 Episode: 140450 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.002985684433951974\n",
      "Q Loss:  0.01982302963733673\n",
      "Policy Loss:  0.05063094571232796\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140454 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.017961744219064713\n",
      "Q Loss:  0.023439185693860054\n",
      "Policy Loss:  -0.08662784844636917\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140458 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0065339007414877415\n",
      "Q Loss:  0.008317851461470127\n",
      "Policy Loss:  -0.02882044017314911\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.7665051221847534\n",
      "Q Loss:  0.01150275394320488\n",
      "Policy Loss:  0.23917807638645172\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140513 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0014900045935064554\n",
      "Q Loss:  2585.872802734375\n",
      "Policy Loss:  9.997856140136719\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140517 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.032006263732910156\n",
      "Value Loss:  4236.04541015625\n",
      "Q Loss:  5268.6865234375\n",
      "Policy Loss:  -235.92462158203125\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140521 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.014116907492280006\n",
      "Q Loss:  0.01766578108072281\n",
      "Policy Loss:  -0.004630986601114273\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140525 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.02386866882443428\n",
      "Q Loss:  0.013909831643104553\n",
      "Policy Loss:  -0.01992139220237732\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140529 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  0.024464251473546028\n",
      "Q Loss:  0.012776520103216171\n",
      "Policy Loss:  0.010418826714158058\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140533 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  639.0811767578125\n",
      "Q Loss:  1022.7546997070312\n",
      "Policy Loss:  -49.498050689697266\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140612 length: 79 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  9333.22265625\n",
      "Q Loss:  9207.875\n",
      "Policy Loss:  -32.2091178894043\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140695 length: 83 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.06401491165161133\n",
      "Value Loss:  0.0057065049186348915\n",
      "Q Loss:  0.0006965325446799397\n",
      "Policy Loss:  0.019966647028923035\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140699 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.051647186279296875\n",
      "Value Loss:  0.0008453376940451562\n",
      "Q Loss:  2445.118408203125\n",
      "Policy Loss:  6.731225967407227\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140703 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  16843.021484375\n",
      "Q Loss:  16275.2109375\n",
      "Policy Loss:  -85.08094024658203\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140750 length: 47 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.00011614469258347526\n",
      "Q Loss:  0.002585571026429534\n",
      "Policy Loss:  0.02185455895960331\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140754 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00014986559108365327\n",
      "Q Loss:  0.003997009247541428\n",
      "Policy Loss:  0.02100764960050583\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140758 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00013024707732256502\n",
      "Q Loss:  0.011428460478782654\n",
      "Policy Loss:  0.059958238154649734\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140762 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  9.159493492916226e-05\n",
      "Q Loss:  0.0090594831854105\n",
      "Policy Loss:  0.04871585592627525\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140766 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.2634780406951904\n",
      "Q Loss:  0.012545879930257797\n",
      "Policy Loss:  0.3948640525341034\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140804 length: 38 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0003466797643341124\n",
      "Q Loss:  0.0003690026933327317\n",
      "Policy Loss:  0.009236115962266922\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140808 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0008031130419112742\n",
      "Q Loss:  0.004198747221380472\n",
      "Policy Loss:  -0.009941349737346172\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.01080726832151413\n",
      "Q Loss:  0.08143249899148941\n",
      "Policy Loss:  0.1313687264919281\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.7275073332712054e-05\n",
      "Q Loss:  0.0008661938481964171\n",
      "Policy Loss:  0.008296119049191475\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140820 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.3156585888937116e-05\n",
      "Q Loss:  0.0012986973160877824\n",
      "Policy Loss:  0.061559952795505524\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.18596738576889038\n",
      "Q Loss:  0.030459420755505562\n",
      "Policy Loss:  -0.13646899163722992\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.04639389365911484\n",
      "Q Loss:  0.015879174694418907\n",
      "Policy Loss:  -0.05309115722775459\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.04589169844985008\n",
      "Q Loss:  0.017348699271678925\n",
      "Policy Loss:  0.03859439119696617\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  6.082613253965974e-05\n",
      "Q Loss:  0.002236606553196907\n",
      "Policy Loss:  -0.013491261750459671\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.04435562342405319\n",
      "Q Loss:  0.01798820309340954\n",
      "Policy Loss:  0.027416637167334557\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  6.749240856152028e-05\n",
      "Q Loss:  0.0014178634155541658\n",
      "Policy Loss:  -0.008733794093132019\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04501032829284668\n",
      "Value Loss:  0.12713941931724548\n",
      "Q Loss:  0.009757746942341328\n",
      "Policy Loss:  -0.0063605643808841705\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003992080688477\n",
      "Value Loss:  0.16209514439105988\n",
      "Q Loss:  0.00808254349976778\n",
      "Policy Loss:  -0.07523971050977707\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.11271458119153976\n",
      "Q Loss:  0.021632913500070572\n",
      "Policy Loss:  -0.039081208407878876\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0008449083543382585\n",
      "Q Loss:  0.0001280251017306\n",
      "Policy Loss:  0.0023264787159860134\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.359306812286377\n",
      "Q Loss:  0.015659019351005554\n",
      "Policy Loss:  0.3746831715106964\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 140901 length: 37 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  330.7441711425781\n",
      "Q Loss:  548.2478637695312\n",
      "Policy Loss:  -25.28091812133789\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141054 length: 153 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0001337705907644704\n",
      "Q Loss:  0.0005028899176977575\n",
      "Policy Loss:  -0.011825231835246086\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141058 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  4.236710992699955e-06\n",
      "Q Loss:  0.0020851725712418556\n",
      "Policy Loss:  0.03329464793205261\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141062 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  9801.18359375\n",
      "Q Loss:  9674.6142578125\n",
      "Policy Loss:  -33.58940887451172\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141141 length: 79 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00014039869711268693\n",
      "Q Loss:  0.0024594797287136316\n",
      "Policy Loss:  -0.004844498820602894\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141145 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.08072422444820404\n",
      "Q Loss:  0.015874594449996948\n",
      "Policy Loss:  0.01117861457169056\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141149 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.07792747020721436\n",
      "Q Loss:  0.027910016477108\n",
      "Policy Loss:  0.0084291473031044\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141153 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05001115798950195\n",
      "Value Loss:  0.0004895079764537513\n",
      "Q Loss:  0.0012245273683220148\n",
      "Policy Loss:  0.010626433417201042\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141157 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.02337651327252388\n",
      "Q Loss:  0.012453533709049225\n",
      "Policy Loss:  0.008233711123466492\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141161 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  1.3898245096206665\n",
      "Q Loss:  0.0078056007623672485\n",
      "Policy Loss:  0.20675744116306305\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141226 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  4226.3984375\n",
      "Q Loss:  7679.259765625\n",
      "Policy Loss:  -199.7190704345703\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  4211.41259765625\n",
      "Q Loss:  5129.30419921875\n",
      "Policy Loss:  -251.0146484375\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4181.6767578125\n",
      "Q Loss:  7573.296875\n",
      "Policy Loss:  -197.1643829345703\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  16154.7998046875\n",
      "Q Loss:  15863.1533203125\n",
      "Policy Loss:  -27.47830581665039\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141285 length: 47 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  2.4320064767380245e-05\n",
      "Q Loss:  0.009117589332163334\n",
      "Policy Loss:  0.04759997874498367\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141289 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  1.4593570085708052e-05\n",
      "Q Loss:  0.00862117949873209\n",
      "Policy Loss:  0.03879832476377487\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141293 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03600907325744629\n",
      "Value Loss:  0.019925113767385483\n",
      "Q Loss:  0.004970774054527283\n",
      "Policy Loss:  0.07210979610681534\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141297 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  247.47560119628906\n",
      "Q Loss:  376.6368713378906\n",
      "Policy Loss:  -19.76531982421875\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141428 length: 131 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.020044760778546333\n",
      "Q Loss:  0.017277628183364868\n",
      "Policy Loss:  0.03457215428352356\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141432 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.0612586013157852e-05\n",
      "Q Loss:  0.0015324146952480078\n",
      "Policy Loss:  0.004335800651460886\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141436 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.03999985381960869\n",
      "Q Loss:  0.030754586681723595\n",
      "Policy Loss:  0.020998399704694748\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141440 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.1136317253112793\n",
      "Value Loss:  125.88114929199219\n",
      "Q Loss:  222.54061889648438\n",
      "Policy Loss:  -10.18535041809082\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141567 length: 127 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.006946524605154991\n",
      "Q Loss:  0.0036625980865210295\n",
      "Policy Loss:  0.001329805701971054\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141571 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  3.149654367007315e-05\n",
      "Q Loss:  0.0009763368288986385\n",
      "Policy Loss:  0.008685488253831863\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141575 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.039361290633678436\n",
      "Q Loss:  0.009381184354424477\n",
      "Policy Loss:  0.0022550709545612335\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141579 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  243.16029357910156\n",
      "Q Loss:  321.90203857421875\n",
      "Policy Loss:  -19.001216888427734\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141644 length: 65 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.05501270294189453\n",
      "Value Loss:  3919.084716796875\n",
      "Q Loss:  4762.80029296875\n",
      "Policy Loss:  -242.53717041015625\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141648 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00033674013684503734\n",
      "Q Loss:  0.011006146669387817\n",
      "Policy Loss:  -0.04768335446715355\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 141652 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00018523950711824\n",
      "Q Loss:  0.005526630207896233\n",
      "Policy Loss:  -0.023713964968919754\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141656 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.1086438209749758e-05\n",
      "Q Loss:  0.002360766986384988\n",
      "Policy Loss:  -0.006344162859022617\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141660 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.8697342713712715e-05\n",
      "Q Loss:  0.0011454597115516663\n",
      "Policy Loss:  -0.007621458265930414\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141664 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3.416619438212365e-05\n",
      "Q Loss:  0.0001651578349992633\n",
      "Policy Loss:  -0.001728109666146338\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141668 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.04121857136487961\n",
      "Q Loss:  0.006104898173362017\n",
      "Policy Loss:  -0.0036685578525066376\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141672 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.06104288250207901\n",
      "Q Loss:  0.014475765638053417\n",
      "Policy Loss:  -0.023028859868645668\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141676 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  200.61976623535156\n",
      "Q Loss:  359.0140075683594\n",
      "Policy Loss:  -16.20281410217285\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141752 length: 76 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.018004655838012695\n",
      "Value Loss:  1.5611850023269653\n",
      "Q Loss:  0.006869798991829157\n",
      "Policy Loss:  0.21929942071437836\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141810 length: 58 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.0002258379536215216\n",
      "Q Loss:  0.011530849151313305\n",
      "Policy Loss:  0.022696180269122124\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.4003946489538066e-05\n",
      "Q Loss:  0.0012602197239175439\n",
      "Policy Loss:  0.0007693410152569413\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.1475728570076171e-05\n",
      "Q Loss:  2.8561216822708957e-05\n",
      "Policy Loss:  0.0010762058664113283\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.965278200572357e-06\n",
      "Q Loss:  0.0008750144625082612\n",
      "Policy Loss:  0.04697955399751663\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  312.6054382324219\n",
      "Q Loss:  388.15576171875\n",
      "Policy Loss:  -26.12108039855957\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141922 length: 96 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.043009042739868164\n",
      "Value Loss:  0.0015137880109250546\n",
      "Q Loss:  116.40128326416016\n",
      "Policy Loss:  3.8011837005615234\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0004263679147697985\n",
      "Q Loss:  0.0015841408167034388\n",
      "Policy Loss:  -0.0028582382947206497\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141930 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  2.1368663510656916e-05\n",
      "Q Loss:  0.022359253838658333\n",
      "Policy Loss:  0.05678115785121918\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001348495483398\n",
      "Value Loss:  3716.77734375\n",
      "Q Loss:  6563.60595703125\n",
      "Policy Loss:  -199.68186950683594\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141938 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  3699.1474609375\n",
      "Q Loss:  6521.8271484375\n",
      "Policy Loss:  -198.6082763671875\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141942 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7.111654849722981e-05\n",
      "Q Loss:  234.52415466308594\n",
      "Policy Loss:  7.519126892089844\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141946 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  7.346920756390318e-05\n",
      "Q Loss:  0.01204055268317461\n",
      "Policy Loss:  -0.0361776128411293\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141950 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00048210774548351765\n",
      "Q Loss:  0.00114241405390203\n",
      "Policy Loss:  -0.0015584173379465938\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141954 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.0007677726680412889\n",
      "Q Loss:  0.0008086251327767968\n",
      "Policy Loss:  -0.008547734469175339\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141958 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  2.1998137526679784e-05\n",
      "Q Loss:  0.00012493117537815124\n",
      "Policy Loss:  0.0073332274332642555\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141962 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00018728207214735448\n",
      "Q Loss:  0.0005235890275798738\n",
      "Policy Loss:  -0.0024463103618472815\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141966 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.0003575067385099828\n",
      "Q Loss:  8.099747356027365e-05\n",
      "Policy Loss:  -0.0013757236301898956\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141970 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  8.836415872792713e-06\n",
      "Q Loss:  0.0012591903796419501\n",
      "Policy Loss:  0.01757112704217434\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141974 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.05467705801129341\n",
      "Q Loss:  0.014972101897001266\n",
      "Policy Loss:  0.015722915530204773\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141978 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.048010826110839844\n",
      "Value Loss:  0.05410785228013992\n",
      "Q Loss:  0.02657449245452881\n",
      "Policy Loss:  0.0182906836271286\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 141982 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.028005361557006836\n",
      "Value Loss:  8890.9296875\n",
      "Q Loss:  8771.97265625\n",
      "Policy Loss:  -27.238265991210938\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142071 length: 89 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00016655214130878448\n",
      "Q Loss:  0.000368262582924217\n",
      "Policy Loss:  0.009044405072927475\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142075 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00016691074415575713\n",
      "Q Loss:  0.0018809224711731076\n",
      "Policy Loss:  0.019988596439361572\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142079 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  3.9630696846870705e-05\n",
      "Q Loss:  0.002121566329151392\n",
      "Policy Loss:  0.021413829177618027\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142083 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  0.05110548809170723\n",
      "Q Loss:  0.024074018001556396\n",
      "Policy Loss:  -0.013950124382972717\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142087 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  1.0890022167586721e-05\n",
      "Q Loss:  0.005367625504732132\n",
      "Policy Loss:  0.04013915732502937\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142091 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.07344385981559753\n",
      "Q Loss:  0.012960711494088173\n",
      "Policy Loss:  -0.020732590928673744\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142095 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.04686209186911583\n",
      "Q Loss:  0.010128477588295937\n",
      "Policy Loss:  0.049810413271188736\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142099 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.04424026980996132\n",
      "Q Loss:  0.025769809260964394\n",
      "Policy Loss:  -0.03212406486272812\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.044008731842041016\n",
      "Value Loss:  0.04121910035610199\n",
      "Q Loss:  0.00903946440666914\n",
      "Policy Loss:  0.0036559700965881348\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  5.0172489864053205e-05\n",
      "Q Loss:  0.001404175884090364\n",
      "Policy Loss:  0.015755094587802887\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142111 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  5.818781573907472e-05\n",
      "Q Loss:  0.0003729156160261482\n",
      "Policy Loss:  0.002201508730649948\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142115 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003795623779297\n",
      "Value Loss:  0.04883652180433273\n",
      "Q Loss:  0.023707404732704163\n",
      "Policy Loss:  -0.07718374580144882\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142119 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.04438208043575287\n",
      "Q Loss:  0.009150570258498192\n",
      "Policy Loss:  -0.06719106435775757\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142123 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.00016757039702497423\n",
      "Q Loss:  0.0013790774391964078\n",
      "Policy Loss:  0.04726231470704079\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142127 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.035256609320640564\n",
      "Q Loss:  0.00871502235531807\n",
      "Policy Loss:  -0.009693978354334831\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.00019097296171821654\n",
      "Q Loss:  0.0002570317010395229\n",
      "Policy Loss:  0.0033315210603177547\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00022680932306684554\n",
      "Q Loss:  7.372918480541557e-05\n",
      "Policy Loss:  -0.0012216513277962804\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.015961917117238045\n",
      "Q Loss:  0.00625411095097661\n",
      "Policy Loss:  -0.018873274326324463\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004302978515625\n",
      "Value Loss:  0.027739476412534714\n",
      "Q Loss:  0.0012859493726864457\n",
      "Policy Loss:  -0.02916286513209343\n",
      "[(3e-05, 0), (3e-05, 0.0)]\n",
      "Alpha*: 3e-05 tau*: 0 Episode: 142147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  190.65847778320312\n",
      "Q Loss:  243.49925231933594\n",
      "Policy Loss:  -16.320249557495117\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142220 length: 73 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.005273830611258745\n",
      "Q Loss:  0.004266031552106142\n",
      "Policy Loss:  0.007765987887978554\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142224 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  6.194882735144347e-05\n",
      "Q Loss:  0.0007400584872812033\n",
      "Policy Loss:  -0.012251943349838257\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142228 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0001354195992462337\n",
      "Q Loss:  0.0003336165100336075\n",
      "Policy Loss:  -0.002404536120593548\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142232 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  4.11817200074438e-05\n",
      "Q Loss:  0.0011950928019359708\n",
      "Policy Loss:  0.013253750279545784\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142236 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.006952366791665554\n",
      "Q Loss:  0.007715869229286909\n",
      "Policy Loss:  0.04136795178055763\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142240 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.009335769340395927\n",
      "Q Loss:  0.006319105159491301\n",
      "Policy Loss:  0.033888742327690125\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142244 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  25634.83984375\n",
      "Q Loss:  26091.8203125\n",
      "Policy Loss:  -124.35908508300781\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142308 length: 64 #teleports:0\n",
      "Got not null reward 2010.0!\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  0.0050561991520226\n",
      "Q Loss:  0.0067555722780525684\n",
      "Policy Loss:  0.0062391990795731544\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142312 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003225326538086\n",
      "Value Loss:  1.6282748447338236e-06\n",
      "Q Loss:  0.00238204188644886\n",
      "Policy Loss:  0.008052602410316467\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.004178310744464397\n",
      "Q Loss:  0.0010465768864378333\n",
      "Policy Loss:  0.02156788296997547\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.028810947900638e-05\n",
      "Q Loss:  0.00030625969520770013\n",
      "Policy Loss:  -1.4224089682102203e-05\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700448989868164\n",
      "Value Loss:  1.237100332218688e-05\n",
      "Q Loss:  0.0002229932724731043\n",
      "Policy Loss:  -0.0020952834747731686\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0017563827568665147\n",
      "Q Loss:  0.0011679542949423194\n",
      "Policy Loss:  0.011712195351719856\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 142332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0008058754610829055\n",
      "Q Loss:  0.0004896993050351739\n",
      "Policy Loss:  -0.005250880029052496\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.1233928489673417e-05\n",
      "Q Loss:  0.0003988599346484989\n",
      "Policy Loss:  -0.012706136330962181\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07901787757873535\n",
      "Value Loss:  2.8296508389757946e-05\n",
      "Q Loss:  0.00015871759387664497\n",
      "Policy Loss:  -0.00945802591741085\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.08301854133605957\n",
      "Value Loss:  0.004117782227694988\n",
      "Q Loss:  0.0008816996123641729\n",
      "Policy Loss:  -0.011535821482539177\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  1.2885444448329508e-05\n",
      "Q Loss:  0.0013429310638457537\n",
      "Policy Loss:  -0.0042618499137461185\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001203536987305\n",
      "Value Loss:  1.986942172050476\n",
      "Q Loss:  0.002484857104718685\n",
      "Policy Loss:  0.25873297452926636\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142401 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  0.0004156308132223785\n",
      "Q Loss:  0.00966432224959135\n",
      "Policy Loss:  -0.041713736951351166\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142405 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  0.001164977322332561\n",
      "Q Loss:  0.002753563690930605\n",
      "Policy Loss:  -0.02715148776769638\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142409 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.526342541386839e-06\n",
      "Q Loss:  0.00045036530354991555\n",
      "Policy Loss:  -0.01055905781686306\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142413 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  8.2276230386924e-05\n",
      "Q Loss:  0.00031462262268178165\n",
      "Policy Loss:  0.0047989701852202415\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142417 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00048290324048139155\n",
      "Q Loss:  0.00068232836201787\n",
      "Policy Loss:  -0.013993061147630215\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142421 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01201176643371582\n",
      "Value Loss:  0.0007258031982928514\n",
      "Q Loss:  0.0006174287991598248\n",
      "Policy Loss:  -0.008043785579502583\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142425 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  8.901359251467511e-05\n",
      "Q Loss:  0.00017220865993294865\n",
      "Policy Loss:  0.0031217639334499836\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142429 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  5.824065738124773e-05\n",
      "Q Loss:  0.00026283564511686563\n",
      "Policy Loss:  0.0019872647244483232\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142433 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.028006315231323242\n",
      "Value Loss:  3.304720303276554e-05\n",
      "Q Loss:  0.0001711839868221432\n",
      "Policy Loss:  0.003481537103652954\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142437 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.000954022107180208\n",
      "Q Loss:  0.002119773766025901\n",
      "Policy Loss:  0.025492534041404724\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142441 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  7.006195119174663e-06\n",
      "Q Loss:  0.0003171245916746557\n",
      "Policy Loss:  0.02425023913383484\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142445 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0440068244934082\n",
      "Value Loss:  0.008101319894194603\n",
      "Q Loss:  0.0027047903276979923\n",
      "Policy Loss:  -0.02449852228164673\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142449 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  5.5478609283454716e-05\n",
      "Q Loss:  0.000782032439019531\n",
      "Policy Loss:  0.016969924792647362\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142453 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.005379394628107548\n",
      "Q Loss:  0.0017031263560056686\n",
      "Policy Loss:  0.00235091894865036\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142457 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  2.4832819690345787e-05\n",
      "Q Loss:  0.0015936080599203706\n",
      "Policy Loss:  0.019346699118614197\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142461 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  1.457404613494873\n",
      "Q Loss:  0.002721393248066306\n",
      "Policy Loss:  0.20981602370738983\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142527 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0016690657939761877\n",
      "Q Loss:  126.7227554321289\n",
      "Policy Loss:  3.9407758712768555\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.001196487108245492\n",
      "Q Loss:  0.004375148564577103\n",
      "Policy Loss:  -0.004284880124032497\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  3500.276611328125\n",
      "Q Loss:  7874.666015625\n",
      "Policy Loss:  -172.14093017578125\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  3488.171630859375\n",
      "Q Loss:  4598.357421875\n",
      "Policy Loss:  -171.2737274169922\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004945755004883\n",
      "Value Loss:  0.0005192910903133452\n",
      "Q Loss:  127.74787902832031\n",
      "Policy Loss:  3.8523640632629395\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.000516361731570214\n",
      "Q Loss:  1839.402587890625\n",
      "Policy Loss:  7.837300777435303\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001514434814453\n",
      "Value Loss:  3426.718017578125\n",
      "Q Loss:  4271.51171875\n",
      "Policy Loss:  -207.4468994140625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.11102509498596191\n",
      "Value Loss:  0.0012697699712589383\n",
      "Q Loss:  0.011816062033176422\n",
      "Policy Loss:  -0.030270010232925415\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0025541093200445175\n",
      "Q Loss:  0.0004248202021699399\n",
      "Policy Loss:  0.019919604063034058\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142563 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.417983291205019e-05\n",
      "Q Loss:  0.0005170273943804204\n",
      "Policy Loss:  -0.0052313911728560925\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142567 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  131.5838623046875\n",
      "Q Loss:  173.34971618652344\n",
      "Policy Loss:  -11.307415008544922\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142669 length: 102 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  6991.798828125\n",
      "Q Loss:  6811.12841796875\n",
      "Policy Loss:  -10.812808990478516\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142781 length: 112 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.0005339111085049808\n",
      "Q Loss:  0.0004421934427227825\n",
      "Policy Loss:  0.0073622106574475765\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142785 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00020779864280484617\n",
      "Q Loss:  0.0006564807845279574\n",
      "Policy Loss:  0.00409915205091238\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142789 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.687183066678699e-05\n",
      "Q Loss:  8.977997640613467e-05\n",
      "Policy Loss:  -0.004768346436321735\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142793 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004199981689453\n",
      "Value Loss:  0.00038603859138675034\n",
      "Q Loss:  0.0006757219089195132\n",
      "Policy Loss:  0.010709671303629875\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142797 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  8.912365592550486e-05\n",
      "Q Loss:  9.847026376519352e-05\n",
      "Policy Loss:  0.001182522508315742\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142801 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016321897506713867\n",
      "Value Loss:  8.936230733525008e-05\n",
      "Q Loss:  5.827553104609251e-05\n",
      "Policy Loss:  0.002733497880399227\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142805 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.9511224309098907e-05\n",
      "Q Loss:  0.0009593382710590959\n",
      "Policy Loss:  0.017930995672941208\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142809 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003732681274414\n",
      "Value Loss:  2.538857006584294e-05\n",
      "Q Loss:  0.001231450354680419\n",
      "Policy Loss:  0.024917244911193848\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142813 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.015084094367921352\n",
      "Q Loss:  0.004973400384187698\n",
      "Policy Loss:  -0.01017024740576744\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142817 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  1.6818339645396918e-06\n",
      "Q Loss:  0.00015375280054286122\n",
      "Policy Loss:  0.0030144467018544674\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142821 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.479111445718445e-07\n",
      "Q Loss:  2.1295683836797252e-05\n",
      "Policy Loss:  -0.0025353317614644766\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142825 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.007675176952034235\n",
      "Q Loss:  0.0044724601320922375\n",
      "Policy Loss:  0.0058259377256035805\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142829 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.007645533420145512\n",
      "Q Loss:  0.003947109449654818\n",
      "Policy Loss:  0.002635907381772995\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 142833 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023004770278930664\n",
      "Value Loss:  2.5823264877544716e-05\n",
      "Q Loss:  2.2610067389905453e-05\n",
      "Policy Loss:  -0.001410976517945528\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142837 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  0.0015990504762157798\n",
      "Q Loss:  0.0009200627682730556\n",
      "Policy Loss:  -0.012715822085738182\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142841 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06101369857788086\n",
      "Value Loss:  0.0005077914102002978\n",
      "Q Loss:  0.02641141042113304\n",
      "Policy Loss:  0.06935125589370728\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142845 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.00039651329279877245\n",
      "Q Loss:  133.35472106933594\n",
      "Policy Loss:  4.031967639923096\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142849 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0012829913757741451\n",
      "Q Loss:  0.002317732432857156\n",
      "Policy Loss:  0.005855408962816\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142853 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  8.023629925446585e-05\n",
      "Q Loss:  0.0021688889246433973\n",
      "Policy Loss:  -0.00775949377566576\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142857 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.0001519137731520459\n",
      "Q Loss:  0.017539232969284058\n",
      "Policy Loss:  -0.020465604960918427\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142861 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.0285472609102726\n",
      "Q Loss:  0.01791047491133213\n",
      "Policy Loss:  -0.09612324088811874\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142865 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.020561905577778816\n",
      "Q Loss:  0.008418737910687923\n",
      "Policy Loss:  -0.06874372065067291\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142869 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.932329127565026e-05\n",
      "Q Loss:  0.001969589851796627\n",
      "Policy Loss:  -0.012725777924060822\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142873 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  4.412188718561083e-05\n",
      "Q Loss:  0.0004499936767388135\n",
      "Policy Loss:  0.0008476544171571732\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142877 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.005725415889173746\n",
      "Q Loss:  0.0019466482335701585\n",
      "Policy Loss:  0.023850275203585625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142881 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01158761978149414\n",
      "Value Loss:  6.439438038796652e-06\n",
      "Q Loss:  0.00026857975171878934\n",
      "Policy Loss:  0.03718452900648117\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142885 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.015261068940162659\n",
      "Q Loss:  0.0032297486905008554\n",
      "Policy Loss:  0.013705091550946236\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  29152.77734375\n",
      "Q Loss:  28419.265625\n",
      "Policy Loss:  -42.538516998291016\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142916 length: 27 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  5.314625377650373e-05\n",
      "Q Loss:  0.0015150692779570818\n",
      "Policy Loss:  -0.017688607797026634\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142920 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.00016018349560908973\n",
      "Q Loss:  0.0007225507870316505\n",
      "Policy Loss:  -0.008837470784783363\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142924 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004894256591797\n",
      "Value Loss:  0.00023147407046053559\n",
      "Q Loss:  0.0006135990843176842\n",
      "Policy Loss:  -0.0045213159173727036\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142928 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.005883449222892523\n",
      "Q Loss:  0.00040998857002705336\n",
      "Policy Loss:  0.00896622147411108\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142932 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011993169784545898\n",
      "Value Loss:  0.01193298026919365\n",
      "Q Loss:  0.006639678031206131\n",
      "Policy Loss:  0.031147629022598267\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 142936 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  523.8898315429688\n",
      "Q Loss:  907.475830078125\n",
      "Policy Loss:  -44.94253921508789\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143035 length: 99 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.012607182376086712\n",
      "Q Loss:  0.007070588879287243\n",
      "Policy Loss:  0.02178122103214264\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143039 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.9122177958488464\n",
      "Q Loss:  0.004609124734997749\n",
      "Policy Loss:  0.13490146398544312\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143142 length: 103 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.03700709342956543\n",
      "Value Loss:  0.000737259048037231\n",
      "Q Loss:  263.0177917480469\n",
      "Policy Loss:  7.8440351486206055\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143146 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.001723868539556861\n",
      "Q Loss:  130.8476104736328\n",
      "Policy Loss:  3.8155789375305176\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143150 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0004552967147901654\n",
      "Q Loss:  0.03045087493956089\n",
      "Policy Loss:  -0.008580641821026802\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143154 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  5.5678254284430295e-05\n",
      "Q Loss:  0.001225167652592063\n",
      "Policy Loss:  0.10541731864213943\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143158 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  5.865899220225401e-05\n",
      "Q Loss:  258.2607116699219\n",
      "Policy Loss:  7.90345573425293\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143162 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  3259.40869140625\n",
      "Q Loss:  7125.12939453125\n",
      "Policy Loss:  -182.94985961914062\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143166 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  3250.4013671875\n",
      "Q Loss:  4043.9189453125\n",
      "Policy Loss:  -201.5137939453125\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143170 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  9738.1630859375\n",
      "Q Loss:  9691.4951171875\n",
      "Policy Loss:  -27.919322967529297\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143252 length: 82 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0003702569811139256\n",
      "Q Loss:  0.0031034296844154596\n",
      "Policy Loss:  0.01619799993932247\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143256 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00020349494297988713\n",
      "Q Loss:  0.0009969969978556037\n",
      "Policy Loss:  0.014091819524765015\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005093503277748823\n",
      "Q Loss:  0.006380582693964243\n",
      "Policy Loss:  0.05060562118887901\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.026532405987382e-05\n",
      "Q Loss:  0.003753304248675704\n",
      "Policy Loss:  0.03209316357970238\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.00043159391498193145\n",
      "Q Loss:  0.003913676366209984\n",
      "Policy Loss:  0.022339332848787308\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0005962451105006039\n",
      "Q Loss:  0.004262840375304222\n",
      "Policy Loss:  0.02673877403140068\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.022004365921020508\n",
      "Value Loss:  0.0002486703742761165\n",
      "Q Loss:  0.0007349407533183694\n",
      "Policy Loss:  0.0020210277289152145\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  2.426321225357242e-05\n",
      "Q Loss:  0.00013775448314845562\n",
      "Policy Loss:  -0.017827335745096207\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  2.5855166313704103e-05\n",
      "Q Loss:  0.000957579119130969\n",
      "Policy Loss:  -0.02463890239596367\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00021759493392892182\n",
      "Q Loss:  0.0006846209871582687\n",
      "Policy Loss:  -0.0009039221331477165\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.00018297930364497006\n",
      "Q Loss:  0.0006331196636892855\n",
      "Policy Loss:  -0.010316303931176662\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00023376545868813992\n",
      "Q Loss:  0.002763471333310008\n",
      "Policy Loss:  -0.02933194860816002\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.5848652512650006e-05\n",
      "Q Loss:  0.0029803612269461155\n",
      "Policy Loss:  -0.029799822717905045\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00042590367957018316\n",
      "Q Loss:  0.002681720070540905\n",
      "Policy Loss:  -0.029215438291430473\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00024934913381002843\n",
      "Q Loss:  0.0018132971599698067\n",
      "Policy Loss:  -8.845189586281776e-05\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143312 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.00010667450987966731\n",
      "Q Loss:  0.000749513041228056\n",
      "Policy Loss:  -0.003830245230346918\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  5.3797052714799065e-06\n",
      "Q Loss:  0.00044708733912557364\n",
      "Policy Loss:  0.009145333431661129\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0008833635947667062\n",
      "Q Loss:  0.0012547443620860577\n",
      "Policy Loss:  0.0176245030015707\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143324 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.03933687135577202\n",
      "Q Loss:  0.0005457442020997405\n",
      "Policy Loss:  0.016553357243537903\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.014315640553832054\n",
      "Q Loss:  0.016797129064798355\n",
      "Policy Loss:  0.02827896922826767\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600193977355957\n",
      "Value Loss:  0.0005588761996477842\n",
      "Q Loss:  0.00040390199865214527\n",
      "Policy Loss:  -0.007485825568437576\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0006238528294488788\n",
      "Q Loss:  0.0031872165855020285\n",
      "Policy Loss:  0.017444351688027382\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.012242026627063751\n",
      "Q Loss:  0.011912843212485313\n",
      "Policy Loss:  0.0028194542974233627\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031005859375\n",
      "Value Loss:  1.1652384273475036e-05\n",
      "Q Loss:  0.0011576790129765868\n",
      "Policy Loss:  -0.00033018295653164387\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143348 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  8.897092629922554e-05\n",
      "Q Loss:  0.0014622502494603395\n",
      "Policy Loss:  0.026277713477611542\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143352 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0112110935151577\n",
      "Q Loss:  0.007513945922255516\n",
      "Policy Loss:  0.00225820392370224\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143356 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.03267605975270271\n",
      "Q Loss:  0.0020877928473055363\n",
      "Policy Loss:  -0.012631986290216446\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143360 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.8511961102485657\n",
      "Q Loss:  0.0034461813047528267\n",
      "Policy Loss:  0.11505626142024994\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143469 length: 109 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0012679994106292725\n",
      "Q Loss:  0.0002586965565569699\n",
      "Policy Loss:  0.00613807886838913\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 143473 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.0017165453173220158\n",
      "Q Loss:  0.0015534517588093877\n",
      "Policy Loss:  0.013393168337643147\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143477 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.03866204619407654\n",
      "Q Loss:  0.0055693043395876884\n",
      "Policy Loss:  -0.061988867819309235\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143481 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.009142501279711723\n",
      "Q Loss:  0.003184759523719549\n",
      "Policy Loss:  0.007043852470815182\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143485 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  1.5744905471801758\n",
      "Q Loss:  0.0029519761446863413\n",
      "Policy Loss:  0.23116178810596466\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143544 length: 59 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3100.034912109375\n",
      "Q Loss:  3861.35986328125\n",
      "Policy Loss:  -196.17311096191406\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143548 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013004064559936523\n",
      "Value Loss:  0.0031737994868308306\n",
      "Q Loss:  0.11207076907157898\n",
      "Policy Loss:  0.11834841221570969\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143552 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00033488281769677997\n",
      "Q Loss:  0.0008475365466438234\n",
      "Policy Loss:  0.007688037119805813\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143556 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7.36751826480031e-05\n",
      "Q Loss:  0.0001905766548588872\n",
      "Policy Loss:  -0.0011696997098624706\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143560 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0001263909216504544\n",
      "Q Loss:  0.002267617266625166\n",
      "Policy Loss:  -0.02025098353624344\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143564 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.01767730340361595\n",
      "Q Loss:  0.004400888457894325\n",
      "Policy Loss:  0.004947993904352188\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143568 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.017410632222890854\n",
      "Q Loss:  0.007426114287227392\n",
      "Policy Loss:  -0.042021434754133224\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.02528074011206627\n",
      "Q Loss:  0.008348070085048676\n",
      "Policy Loss:  -0.04353191703557968\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143576 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.023882243782281876\n",
      "Q Loss:  0.008776460774242878\n",
      "Policy Loss:  -0.07596524804830551\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143580 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  9.620536002330482e-05\n",
      "Q Loss:  0.0017698240699246526\n",
      "Policy Loss:  0.0003083120100200176\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143584 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.0018618762260302901\n",
      "Q Loss:  0.0053679184056818485\n",
      "Policy Loss:  -0.04338543117046356\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00017592110089026392\n",
      "Q Loss:  0.02659647911787033\n",
      "Policy Loss:  -0.08413121849298477\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490107536315918\n",
      "Value Loss:  0.0016938894987106323\n",
      "Q Loss:  0.010653940960764885\n",
      "Policy Loss:  -0.04671658203005791\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.0025329359341412783\n",
      "Q Loss:  0.0034756979439407587\n",
      "Policy Loss:  -0.016992077231407166\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143600 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.0002254732680739835\n",
      "Q Loss:  0.0010514729656279087\n",
      "Policy Loss:  0.001911328872665763\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143604 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  7075.435546875\n",
      "Q Loss:  6982.1923828125\n",
      "Policy Loss:  -9.366507530212402\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143716 length: 112 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.00038028531707823277\n",
      "Q Loss:  0.0008155654650181532\n",
      "Policy Loss:  0.013206647709012032\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143720 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.00028322520665824413\n",
      "Q Loss:  0.00014417491911444813\n",
      "Policy Loss:  0.00632130354642868\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143724 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  3.8887086702743545e-05\n",
      "Q Loss:  0.0002677130978554487\n",
      "Policy Loss:  0.026878047734498978\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143728 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500391960144043\n",
      "Value Loss:  0.009474026039242744\n",
      "Q Loss:  0.009975164197385311\n",
      "Policy Loss:  0.045293375849723816\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143732 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.013813646510243416\n",
      "Q Loss:  0.01055477187037468\n",
      "Policy Loss:  0.021194810047745705\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143736 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04601001739501953\n",
      "Value Loss:  0.013091744855046272\n",
      "Q Loss:  0.0022179947700351477\n",
      "Policy Loss:  0.03510142117738724\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143740 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.0043078516609966755\n",
      "Q Loss:  0.006953598000109196\n",
      "Policy Loss:  -0.014460391364991665\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143744 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.0006363580469042063\n",
      "Q Loss:  0.0012450657086446881\n",
      "Policy Loss:  -0.022080495953559875\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143748 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.0007522107334807515\n",
      "Q Loss:  0.0013845814391970634\n",
      "Policy Loss:  -0.010227702558040619\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143752 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00022647692821919918\n",
      "Q Loss:  5.467187656904571e-05\n",
      "Policy Loss:  -0.005528180859982967\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143756 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  3.062234463868663e-05\n",
      "Q Loss:  1.5455947504960932e-05\n",
      "Policy Loss:  -0.0030424920842051506\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143760 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  10055.455078125\n",
      "Q Loss:  9864.3330078125\n",
      "Policy Loss:  -27.99026870727539\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143840 length: 80 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00017370295245200396\n",
      "Q Loss:  131.8470916748047\n",
      "Policy Loss:  3.835681676864624\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0054521821439266205\n",
      "Q Loss:  0.034608062356710434\n",
      "Policy Loss:  0.011499715968966484\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.000553047051653266\n",
      "Q Loss:  0.0019537145271897316\n",
      "Policy Loss:  0.024834200739860535\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 143852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.0006701188976876438\n",
      "Q Loss:  0.0021526776254177094\n",
      "Policy Loss:  0.026479683816432953\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.00021884699526708573\n",
      "Q Loss:  0.00016318830603267998\n",
      "Policy Loss:  0.004312576726078987\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.405802848050371e-05\n",
      "Q Loss:  2.6279221856384538e-05\n",
      "Policy Loss:  -0.0033144946210086346\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.025005102157592773\n",
      "Value Loss:  0.0055683683604002\n",
      "Q Loss:  0.00216531939804554\n",
      "Policy Loss:  -0.0020022690296173096\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.9513769745826721\n",
      "Q Loss:  0.0010418567107990384\n",
      "Policy Loss:  0.12667900323867798\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143969 length: 101 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00013772599049843848\n",
      "Q Loss:  259.6517639160156\n",
      "Policy Loss:  7.894792556762695\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.0008705017389729619\n",
      "Q Loss:  0.0005060230614617467\n",
      "Policy Loss:  0.002575801219791174\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800537109375\n",
      "Value Loss:  0.0010238469112664461\n",
      "Q Loss:  0.010389675386250019\n",
      "Policy Loss:  0.0516604445874691\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 143981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  12368.529296875\n",
      "Q Loss:  12175.994140625\n",
      "Policy Loss:  -17.44510269165039\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144045 length: 64 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.000774177722632885\n",
      "Q Loss:  127.89665222167969\n",
      "Policy Loss:  3.910198926925659\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144049 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300191879272461\n",
      "Value Loss:  0.001501418766565621\n",
      "Q Loss:  0.0036266588140279055\n",
      "Policy Loss:  -0.030028406530618668\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144053 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.0012542278273031116\n",
      "Q Loss:  0.0028619158547371626\n",
      "Policy Loss:  -0.024658842012286186\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144057 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.4390349388122559\n",
      "Q Loss:  0.0030362948309630156\n",
      "Policy Loss:  0.18897759914398193\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144123 length: 66 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  3066.759521484375\n",
      "Q Loss:  5165.51806640625\n",
      "Policy Loss:  -196.24085998535156\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144127 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.00015633252041880041\n",
      "Q Loss:  0.002019781619310379\n",
      "Policy Loss:  0.02205718867480755\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144131 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  0.0001177422673208639\n",
      "Q Loss:  0.00033296382753178477\n",
      "Policy Loss:  0.00808854028582573\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144135 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.490749830030836e-05\n",
      "Q Loss:  0.000178871865500696\n",
      "Policy Loss:  0.009283553808927536\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144139 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.020673006772994995\n",
      "Q Loss:  0.013403625227510929\n",
      "Policy Loss:  -0.0491546131670475\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144143 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.014227853156626225\n",
      "Q Loss:  0.0044666193425655365\n",
      "Policy Loss:  -0.02747684344649315\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144147 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0004090041620656848\n",
      "Q Loss:  0.0013710898347198963\n",
      "Policy Loss:  0.02594810724258423\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144151 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005342921358533204\n",
      "Q Loss:  0.0012743661645799875\n",
      "Policy Loss:  0.02087973989546299\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144155 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00021772400941699743\n",
      "Q Loss:  0.001173461670987308\n",
      "Policy Loss:  0.03400326147675514\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144159 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004438400268555\n",
      "Value Loss:  1.5104426145553589\n",
      "Q Loss:  0.002688909415155649\n",
      "Policy Loss:  0.22340434789657593\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144221 length: 62 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.340838520671241e-05\n",
      "Q Loss:  0.00012932730896864086\n",
      "Policy Loss:  -0.001901560346595943\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144225 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  101.49085235595703\n",
      "Q Loss:  137.8264617919922\n",
      "Policy Loss:  -9.033474922180176\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144345 length: 120 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00013439287431538105\n",
      "Q Loss:  0.0007524724933318794\n",
      "Policy Loss:  -0.008096223697066307\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144349 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02600836753845215\n",
      "Value Loss:  7.635759538970888e-05\n",
      "Q Loss:  0.0018657208420336246\n",
      "Policy Loss:  0.03497482091188431\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144353 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013993501663208008\n",
      "Value Loss:  0.041332636028528214\n",
      "Q Loss:  0.001669163117185235\n",
      "Policy Loss:  -0.03491969406604767\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144357 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  1.739586591720581\n",
      "Q Loss:  0.0033689523115754128\n",
      "Policy Loss:  0.26158004999160767\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144410 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0003622869844548404\n",
      "Q Loss:  0.0007845767540857196\n",
      "Policy Loss:  -0.010115962475538254\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144414 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.381313429912552e-05\n",
      "Q Loss:  0.0006515167187899351\n",
      "Policy Loss:  0.0071788365021348\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144418 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.0002421688404865563\n",
      "Q Loss:  0.00039429476601071656\n",
      "Policy Loss:  -0.005640969146043062\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.039984576404094696\n",
      "Q Loss:  0.008977069519460201\n",
      "Policy Loss:  0.0028632264584302902\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.050678253173828125\n",
      "Value Loss:  0.04061385989189148\n",
      "Q Loss:  0.00881437212228775\n",
      "Policy Loss:  0.0030936505645513535\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  1.7647768259048462\n",
      "Q Loss:  0.0034672890324145555\n",
      "Policy Loss:  0.24951767921447754\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144482 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  2.0324481738498434e-05\n",
      "Q Loss:  2.9811608328600414e-05\n",
      "Policy Loss:  0.0008283185306936502\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.014278876595199108\n",
      "Q Loss:  0.02071254700422287\n",
      "Policy Loss:  -0.01383661013096571\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600480079650879\n",
      "Value Loss:  0.0001157015940407291\n",
      "Q Loss:  0.00039635878056287766\n",
      "Policy Loss:  0.010524684563279152\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144494 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  11670.6845703125\n",
      "Q Loss:  11752.044921875\n",
      "Policy Loss:  -45.248226165771484\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144564 length: 70 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002084732055664\n",
      "Value Loss:  6007.9072265625\n",
      "Q Loss:  8755.61328125\n",
      "Policy Loss:  -194.6484375\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144568 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013001680374145508\n",
      "Value Loss:  6.814264634158462e-05\n",
      "Q Loss:  129.74098205566406\n",
      "Policy Loss:  3.957188606262207\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144572 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  3.620286406658124e-06\n",
      "Q Loss:  0.0010237585520371795\n",
      "Policy Loss:  0.0006364146247506142\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144576 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00014258130977395922\n",
      "Q Loss:  0.000608398171607405\n",
      "Policy Loss:  0.007329713087528944\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144580 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  0.00036154547706246376\n",
      "Q Loss:  9.469508950132877e-05\n",
      "Policy Loss:  -0.0010975943878293037\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144584 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.032007694244384766\n",
      "Value Loss:  0.000250880402745679\n",
      "Q Loss:  0.00012850435450673103\n",
      "Policy Loss:  0.0035714120604097843\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144588 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  0.00015454605454578996\n",
      "Q Loss:  0.0005588044296018779\n",
      "Policy Loss:  0.004150944761931896\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144592 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.03671741858124733\n",
      "Q Loss:  0.017995135858654976\n",
      "Policy Loss:  0.011381398886442184\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144596 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400446891784668\n",
      "Value Loss:  61223.6640625\n",
      "Q Loss:  60257.140625\n",
      "Policy Loss:  -77.42865753173828\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144609 length: 13 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.00014266396465245634\n",
      "Q Loss:  0.0003751044860109687\n",
      "Policy Loss:  -0.008719302713871002\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144613 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  8437.82421875\n",
      "Q Loss:  8494.34765625\n",
      "Policy Loss:  -33.05332565307617\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144710 length: 97 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  0.0005554481758736074\n",
      "Q Loss:  0.001352511579170823\n",
      "Policy Loss:  -0.01872658170759678\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144714 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047009944915771484\n",
      "Value Loss:  0.0007449163822457194\n",
      "Q Loss:  0.0006473085377365351\n",
      "Policy Loss:  -0.011505440808832645\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144718 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00045800470979884267\n",
      "Q Loss:  0.0026935595087707043\n",
      "Policy Loss:  0.01861254870891571\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144722 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014000415802001953\n",
      "Value Loss:  0.0002804070245474577\n",
      "Q Loss:  0.005581018049269915\n",
      "Policy Loss:  0.060854218900203705\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144726 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.03268180042505264\n",
      "Q Loss:  0.013662692159414291\n",
      "Policy Loss:  0.0018773321062326431\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144730 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  9.21438549994491e-05\n",
      "Q Loss:  0.004579710774123669\n",
      "Policy Loss:  0.06206415593624115\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144734 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.07000135630369186\n",
      "Q Loss:  0.014298252761363983\n",
      "Policy Loss:  -0.026433557271957397\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144738 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  1.9127250197925605e-05\n",
      "Q Loss:  0.0031029856763780117\n",
      "Policy Loss:  0.020966950803995132\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144742 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400136947631836\n",
      "Value Loss:  1.926916241645813\n",
      "Q Loss:  0.01666955091059208\n",
      "Policy Loss:  0.26343080401420593\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144787 length: 45 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002416610717773\n",
      "Value Loss:  0.00020199942809995264\n",
      "Q Loss:  0.00024018694239202887\n",
      "Policy Loss:  0.00843464769423008\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144791 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00024630443658679724\n",
      "Q Loss:  0.0005751322023570538\n",
      "Policy Loss:  0.0093153091147542\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144795 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.03988685458898544\n",
      "Q Loss:  0.0020692190155386925\n",
      "Policy Loss:  -0.0011677853763103485\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144799 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  8.489764877595007e-05\n",
      "Q Loss:  0.00027210210100747645\n",
      "Policy Loss:  0.06482335180044174\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144803 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  9798.27734375\n",
      "Q Loss:  9752.3076171875\n",
      "Policy Loss:  -27.54808235168457\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144885 length: 82 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  0.00010650184412952513\n",
      "Q Loss:  0.0016763792373239994\n",
      "Policy Loss:  0.01661461405456066\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144889 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.00016919212066568434\n",
      "Q Loss:  0.00039853391353972256\n",
      "Policy Loss:  0.002156093018129468\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144893 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  7.398902380373329e-05\n",
      "Q Loss:  0.00038881212822161615\n",
      "Policy Loss:  0.005428575444966555\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144897 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  1.699871791061014e-05\n",
      "Q Loss:  0.0655493214726448\n",
      "Policy Loss:  -0.041757166385650635\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144901 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.1382301300764084\n",
      "Q Loss:  0.058649830520153046\n",
      "Policy Loss:  -0.11838939785957336\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144905 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.13645446300506592\n",
      "Q Loss:  0.02634863369166851\n",
      "Policy Loss:  -0.09820330142974854\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144909 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  2.6822475774679333e-05\n",
      "Q Loss:  0.00017065764404833317\n",
      "Policy Loss:  0.0769830271601677\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 144913 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.12804655730724335\n",
      "Q Loss:  0.03171816095709801\n",
      "Policy Loss:  -0.05558754503726959\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144917 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.08109621703624725\n",
      "Q Loss:  0.015896910801529884\n",
      "Policy Loss:  0.009645432233810425\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.07610494643449783\n",
      "Q Loss:  0.01694132201373577\n",
      "Policy Loss:  0.021731678396463394\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 144925 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.07062411308288574\n",
      "Value Loss:  5.020180833525956e-05\n",
      "Q Loss:  0.008538818918168545\n",
      "Policy Loss:  0.05991942435503006\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144929 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00016560369112994522\n",
      "Q Loss:  6.783801654819399e-05\n",
      "Policy Loss:  0.0032983424607664347\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144933 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.00016165633860509843\n",
      "Q Loss:  0.001884246477857232\n",
      "Policy Loss:  0.015006667003035545\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144937 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.029020002111792564\n",
      "Q Loss:  0.0034451703540980816\n",
      "Policy Loss:  0.0565015971660614\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144941 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.2221200466156006\n",
      "Q Loss:  0.006216175854206085\n",
      "Policy Loss:  0.32754409313201904\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144981 length: 40 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016002655029296875\n",
      "Value Loss:  0.07941458374261856\n",
      "Q Loss:  0.015674401074647903\n",
      "Policy Loss:  -0.022402804344892502\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 144985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.030007123947143555\n",
      "Value Loss:  572.4580078125\n",
      "Q Loss:  820.3108520507812\n",
      "Policy Loss:  -51.103004455566406\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145072 length: 87 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.04929209500551224\n",
      "Q Loss:  0.01947510614991188\n",
      "Policy Loss:  0.05118055269122124\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01100301742553711\n",
      "Value Loss:  0.9226610064506531\n",
      "Q Loss:  0.00658273184671998\n",
      "Policy Loss:  0.15926313400268555\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145173 length: 97 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.049010515213012695\n",
      "Value Loss:  0.0004414266149979085\n",
      "Q Loss:  0.005608597304672003\n",
      "Policy Loss:  0.03775331377983093\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145177 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004987716674805\n",
      "Value Loss:  0.0008568819612264633\n",
      "Q Loss:  0.002866603434085846\n",
      "Policy Loss:  0.02562759630382061\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145181 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.00019618606893345714\n",
      "Q Loss:  0.0006555459694936872\n",
      "Policy Loss:  0.013971207663416862\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145185 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03162217140197754\n",
      "Value Loss:  1.2544195442387718e-06\n",
      "Q Loss:  0.00035154956276528537\n",
      "Policy Loss:  0.003691678401082754\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145189 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.9282902940176427e-05\n",
      "Q Loss:  0.0012789906468242407\n",
      "Policy Loss:  -0.01966266520321369\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145193 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.00010952416778309271\n",
      "Q Loss:  0.0006801859708502889\n",
      "Policy Loss:  -0.021006973460316658\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145197 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001396221196046099\n",
      "Q Loss:  0.0010554986074566841\n",
      "Policy Loss:  -0.015583404339849949\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145201 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00024343062250409275\n",
      "Q Loss:  0.0021701764781028032\n",
      "Policy Loss:  -0.02815370075404644\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145205 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.00030694977613165975\n",
      "Q Loss:  0.00041379244066774845\n",
      "Policy Loss:  -0.002497611101716757\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145209 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.0001046084871632047\n",
      "Q Loss:  0.00014042042312212288\n",
      "Policy Loss:  0.04812926426529884\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145213 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  0.02091520093381405\n",
      "Q Loss:  0.01417556032538414\n",
      "Policy Loss:  0.03560831770300865\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145217 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  18366.638671875\n",
      "Q Loss:  17958.599609375\n",
      "Policy Loss:  -26.860231399536133\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145260 length: 43 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.0911471438012086e-05\n",
      "Q Loss:  0.0014680995373055339\n",
      "Policy Loss:  -0.007178116589784622\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.00047717607230879366\n",
      "Q Loss:  0.001507998676970601\n",
      "Policy Loss:  -0.020843442529439926\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04801058769226074\n",
      "Value Loss:  4.106866072106641e-06\n",
      "Q Loss:  0.0025722007267177105\n",
      "Policy Loss:  -0.027720175683498383\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  1.5733969576103846e-06\n",
      "Q Loss:  0.002190332394093275\n",
      "Policy Loss:  -0.015598745085299015\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.0919205806203536e-07\n",
      "Q Loss:  0.0005181778687983751\n",
      "Policy Loss:  0.0005627972423098981\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00015940961020532995\n",
      "Q Loss:  0.00237283855676651\n",
      "Policy Loss:  -0.0034223978873342276\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001276016235352\n",
      "Value Loss:  0.00038707780186086893\n",
      "Q Loss:  0.0009588809916749597\n",
      "Policy Loss:  -0.013099391013383865\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145288 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.00021048480994068086\n",
      "Q Loss:  0.0006971324328333139\n",
      "Policy Loss:  -0.00839952565729618\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145292 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  6.141058838693425e-05\n",
      "Q Loss:  0.000222424219828099\n",
      "Policy Loss:  0.012491405010223389\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145296 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019003868103027344\n",
      "Value Loss:  9.427808254258707e-05\n",
      "Q Loss:  0.0006779865943826735\n",
      "Policy Loss:  -0.0091641154140234\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145300 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.143760477541946e-05\n",
      "Q Loss:  0.00016656161460559815\n",
      "Policy Loss:  0.0013356968993321061\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145304 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  3.396351166884415e-05\n",
      "Q Loss:  0.00015170060214586556\n",
      "Policy Loss:  0.0021870851051062346\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145308 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  2.6413141313241795e-05\n",
      "Q Loss:  0.0001353967672912404\n",
      "Policy Loss:  -0.00014916504733264446\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145312 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  9.766576840775087e-05\n",
      "Q Loss:  0.0004419166361913085\n",
      "Policy Loss:  -0.009548632428050041\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145316 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  7.37302761990577e-05\n",
      "Q Loss:  0.00021884971647523344\n",
      "Policy Loss:  0.04311901330947876\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145320 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.1368343830108643\n",
      "Q Loss:  0.0035743433982133865\n",
      "Policy Loss:  0.18252220749855042\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145398 length: 78 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00017915053467731923\n",
      "Q Loss:  0.004107442684471607\n",
      "Policy Loss:  -0.003410730976611376\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145402 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0001625160512048751\n",
      "Q Loss:  0.007485125679522753\n",
      "Policy Loss:  0.043499112129211426\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145406 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005651473999023\n",
      "Value Loss:  0.00010136494529433548\n",
      "Q Loss:  0.0009537978330627084\n",
      "Policy Loss:  0.014651592820882797\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145410 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02100515365600586\n",
      "Value Loss:  0.00010235162335447967\n",
      "Q Loss:  0.0006478446302935481\n",
      "Policy Loss:  0.014112165197730064\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145414 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00011845490371342748\n",
      "Q Loss:  0.0006725082639604807\n",
      "Policy Loss:  0.011884821578860283\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145418 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  8.791705477051437e-05\n",
      "Q Loss:  0.0001280335709452629\n",
      "Policy Loss:  0.0046539101749658585\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145422 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.0006711565656587e-05\n",
      "Q Loss:  3.136185114271939e-05\n",
      "Policy Loss:  -0.004586116876453161\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145426 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.031720876693725586\n",
      "Value Loss:  7.308948988793418e-05\n",
      "Q Loss:  0.0005268664099276066\n",
      "Policy Loss:  0.007375848945230246\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  5.447587318485603e-05\n",
      "Q Loss:  0.0003300412790849805\n",
      "Policy Loss:  0.002967286389321089\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  4.707401240011677e-05\n",
      "Q Loss:  4.8240410251310095e-05\n",
      "Policy Loss:  -0.00010215508518740535\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0001864681689767167\n",
      "Q Loss:  0.00010916849714703858\n",
      "Policy Loss:  0.004814929328858852\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001991271972656\n",
      "Value Loss:  2.428478240966797\n",
      "Q Loss:  0.0047098491340875626\n",
      "Policy Loss:  0.35092324018478394\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145478 length: 36 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011612415313720703\n",
      "Value Loss:  0.00024778678198345006\n",
      "Q Loss:  0.00040172459557652473\n",
      "Policy Loss:  -0.013616958633065224\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145482 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.00013172115723136812\n",
      "Q Loss:  0.0002286411909153685\n",
      "Policy Loss:  -0.0013104070676490664\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145486 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.000111402478069067\n",
      "Q Loss:  0.00026015436742454767\n",
      "Policy Loss:  -0.0038417461328208447\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145490 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005247116088867\n",
      "Value Loss:  0.00011533985525602475\n",
      "Q Loss:  0.0007097101770341396\n",
      "Policy Loss:  0.05211193859577179\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145494 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.06983166188001633\n",
      "Q Loss:  0.016644306480884552\n",
      "Policy Loss:  -0.01974702626466751\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145498 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00023074520868249238\n",
      "Q Loss:  0.0006943773478269577\n",
      "Policy Loss:  -0.012901402078568935\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145502 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.03572167828679085\n",
      "Q Loss:  0.0066637624986469746\n",
      "Policy Loss:  0.01542573794722557\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145506 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  3.292856854386628e-05\n",
      "Q Loss:  0.0002850109594874084\n",
      "Policy Loss:  0.05748606100678444\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145510 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.1358152627944946\n",
      "Q Loss:  0.008441940881311893\n",
      "Policy Loss:  0.15516076982021332\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145587 length: 77 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.019003629684448242\n",
      "Value Loss:  1.8920822185464203e-05\n",
      "Q Loss:  0.00018561742035672069\n",
      "Policy Loss:  0.008366025984287262\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.7712806463241577\n",
      "Q Loss:  9.63760757446289\n",
      "Policy Loss:  0.3745924234390259\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145705 length: 114 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0002476449008099735\n",
      "Q Loss:  0.0021826119627803564\n",
      "Policy Loss:  -0.0056791892275214195\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145709 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007956890622153878\n",
      "Q Loss:  0.0011580158025026321\n",
      "Policy Loss:  0.003590972162783146\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145713 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020003795623779297\n",
      "Value Loss:  0.00010976445628330112\n",
      "Q Loss:  0.0008452069014310837\n",
      "Policy Loss:  0.012725844979286194\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145717 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  228.76394653320312\n",
      "Q Loss:  398.38037109375\n",
      "Policy Loss:  -20.125473022460938\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145828 length: 111 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0290069580078125\n",
      "Value Loss:  0.16039958596229553\n",
      "Q Loss:  0.06858844310045242\n",
      "Policy Loss:  -0.17953386902809143\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 145832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002323150634766\n",
      "Value Loss:  0.1184135228395462\n",
      "Q Loss:  0.02825281210243702\n",
      "Policy Loss:  -0.04012887179851532\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.15187478065490723\n",
      "Q Loss:  0.02748052217066288\n",
      "Policy Loss:  -0.09610079973936081\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.07107613980770111\n",
      "Q Loss:  0.03820418193936348\n",
      "Policy Loss:  0.05380447208881378\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.06566186994314194\n",
      "Q Loss:  0.061036400496959686\n",
      "Policy Loss:  0.026025641709566116\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  0.0008848325815051794\n",
      "Q Loss:  0.0006502901669591665\n",
      "Policy Loss:  0.019282212480902672\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03900790214538574\n",
      "Value Loss:  0.0008828744175843894\n",
      "Q Loss:  0.011774033308029175\n",
      "Policy Loss:  0.06492212414741516\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.0002107150066876784\n",
      "Q Loss:  0.02160927653312683\n",
      "Policy Loss:  0.08446629345417023\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145860 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.000806096475571394\n",
      "Q Loss:  0.0006284526898525655\n",
      "Policy Loss:  0.009699160233139992\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145864 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.041008710861206055\n",
      "Value Loss:  0.022017130628228188\n",
      "Q Loss:  0.008552473038434982\n",
      "Policy Loss:  0.09286720305681229\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145868 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002540588378906\n",
      "Value Loss:  0.08168663829565048\n",
      "Q Loss:  0.009659385308623314\n",
      "Policy Loss:  0.03892200067639351\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145872 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  11949.3330078125\n",
      "Q Loss:  11830.345703125\n",
      "Policy Loss:  -33.5909538269043\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145939 length: 67 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  0.0003451767552178353\n",
      "Q Loss:  0.0018509489018470049\n",
      "Policy Loss:  -0.018751777708530426\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145943 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.042009830474853516\n",
      "Value Loss:  28472.708984375\n",
      "Q Loss:  28433.751953125\n",
      "Policy Loss:  -142.8902587890625\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145972 length: 29 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.032653093338012695\n",
      "Value Loss:  3173.349365234375\n",
      "Q Loss:  3890.683837890625\n",
      "Policy Loss:  -200.10841369628906\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 145976 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.0006244859541766346\n",
      "Q Loss:  0.0013298466801643372\n",
      "Policy Loss:  0.01704413816332817\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145980 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.0009017960983328521\n",
      "Q Loss:  0.00030781837995164096\n",
      "Policy Loss:  -0.0035184931475669146\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145984 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0015448597259819508\n",
      "Q Loss:  0.0013891435228288174\n",
      "Policy Loss:  0.005541009828448296\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145988 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00026385264936834574\n",
      "Q Loss:  0.0011511293705552816\n",
      "Policy Loss:  -0.01770787499845028\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145992 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.2522823453764431e-05\n",
      "Q Loss:  0.0010767653584480286\n",
      "Policy Loss:  -0.02442663535475731\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 145996 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0014606566401198506\n",
      "Q Loss:  0.0033404347486793995\n",
      "Policy Loss:  -0.032818179577589035\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146000 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004417419433594\n",
      "Value Loss:  7956.1416015625\n",
      "Q Loss:  7852.3603515625\n",
      "Policy Loss:  -11.439594268798828\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146099 length: 99 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013001441955566406\n",
      "Value Loss:  0.00203127134591341\n",
      "Q Loss:  0.004064528737217188\n",
      "Policy Loss:  -0.03754377365112305\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146103 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.0027074897661805153\n",
      "Q Loss:  0.004100453574210405\n",
      "Policy Loss:  -0.0260166022926569\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146107 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.052011966705322266\n",
      "Value Loss:  1.624238133430481\n",
      "Q Loss:  0.0100783072412014\n",
      "Policy Loss:  0.21030153334140778\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146163 length: 56 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  4969.46337890625\n",
      "Q Loss:  4913.296875\n",
      "Policy Loss:  -14.695903778076172\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146324 length: 161 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0007415834115818143\n",
      "Q Loss:  277.995361328125\n",
      "Policy Loss:  8.129446983337402\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146328 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002178192138672\n",
      "Value Loss:  0.0027027134783566\n",
      "Q Loss:  0.003244727849960327\n",
      "Policy Loss:  -0.0266166552901268\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146332 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200721740722656\n",
      "Value Loss:  0.003893913235515356\n",
      "Q Loss:  0.0009580843616276979\n",
      "Policy Loss:  -0.014353053644299507\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146336 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0007084319368004799\n",
      "Q Loss:  0.0012087873183190823\n",
      "Policy Loss:  0.01296873576939106\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146340 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0030889767222106457\n",
      "Q Loss:  0.006987432949244976\n",
      "Policy Loss:  0.08528344333171844\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146344 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.057905912399292\n",
      "Q Loss:  0.016225600615143776\n",
      "Policy Loss:  0.1357002854347229\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146430 length: 86 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  0.02250666357576847\n",
      "Q Loss:  0.009529922157526016\n",
      "Policy Loss:  0.04515787959098816\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.003964598756283522\n",
      "Q Loss:  0.01521808747202158\n",
      "Policy Loss:  0.03048972226679325\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01206207275390625\n",
      "Value Loss:  0.004030283074826002\n",
      "Q Loss:  0.012285067699849606\n",
      "Policy Loss:  0.050363149493932724\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003826141357422\n",
      "Value Loss:  0.0005432358593679965\n",
      "Q Loss:  0.005073062144219875\n",
      "Policy Loss:  -0.017995785921812057\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  7.562251266790554e-05\n",
      "Q Loss:  0.0022742946166545153\n",
      "Policy Loss:  -0.013419168069958687\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146450 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.6647897362709045\n",
      "Q Loss:  0.009189584292471409\n",
      "Policy Loss:  0.08291857689619064\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146587 length: 137 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.007298653945326805\n",
      "Q Loss:  0.016057394444942474\n",
      "Policy Loss:  0.03871634975075722\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.00813391525298357\n",
      "Q Loss:  0.004560776986181736\n",
      "Policy Loss:  -0.007655523717403412\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.004933718126267195\n",
      "Q Loss:  0.01439199410378933\n",
      "Policy Loss:  -0.07925809174776077\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.02300548553466797\n",
      "Value Loss:  13749.46484375\n",
      "Q Loss:  14006.2431640625\n",
      "Policy Loss:  -71.63935852050781\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146659 length: 60 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.028006553649902344\n",
      "Value Loss:  0.02672331966459751\n",
      "Q Loss:  0.008043794892728329\n",
      "Policy Loss:  0.03501741960644722\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146663 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.002156580099835992\n",
      "Q Loss:  0.0037486995570361614\n",
      "Policy Loss:  -0.004338676575571299\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146667 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  0.000563712150324136\n",
      "Q Loss:  0.001180051127448678\n",
      "Policy Loss:  -0.0018200138583779335\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146671 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  0.02721143513917923\n",
      "Q Loss:  0.01425117813050747\n",
      "Policy Loss:  0.058233488351106644\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146675 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.027349434792995453\n",
      "Q Loss:  0.008868291974067688\n",
      "Policy Loss:  0.08301158249378204\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146679 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.08159539103507996\n",
      "Q Loss:  0.018785936757922173\n",
      "Policy Loss:  -0.058886341750621796\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146683 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002893447875977\n",
      "Value Loss:  0.05345335230231285\n",
      "Q Loss:  0.016004135832190514\n",
      "Policy Loss:  -0.04762230068445206\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146687 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.0008913503843359649\n",
      "Q Loss:  0.007364909164607525\n",
      "Policy Loss:  0.03864400088787079\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146691 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0011495579965412617\n",
      "Q Loss:  0.00942396279424429\n",
      "Policy Loss:  0.032856300473213196\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146695 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  10940.818359375\n",
      "Q Loss:  10936.4970703125\n",
      "Policy Loss:  -30.394590377807617\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146768 length: 73 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  0.024689270183444023\n",
      "Q Loss:  0.010113939642906189\n",
      "Policy Loss:  0.016604093834757805\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146772 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018004179000854492\n",
      "Value Loss:  0.06866749376058578\n",
      "Q Loss:  0.019437719136476517\n",
      "Policy Loss:  -0.05811633914709091\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146776 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  0.06576016545295715\n",
      "Q Loss:  0.016542427241802216\n",
      "Policy Loss:  -0.04501833766698837\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146780 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.041057102382183075\n",
      "Q Loss:  0.009558337740600109\n",
      "Policy Loss:  -0.08501434326171875\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146784 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019004344940185547\n",
      "Value Loss:  88.98722839355469\n",
      "Q Loss:  111.59547424316406\n",
      "Policy Loss:  -7.943929672241211\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146931 length: 147 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.004152144771069288\n",
      "Q Loss:  0.036040257662534714\n",
      "Policy Loss:  0.037029676139354706\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146935 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014218568801879883\n",
      "Value Loss:  2.6569411754608154\n",
      "Q Loss:  0.004133254289627075\n",
      "Policy Loss:  0.39775270223617554\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146969 length: 34 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.0200040340423584\n",
      "Value Loss:  0.0007198969251476228\n",
      "Q Loss:  0.0033750806469470263\n",
      "Policy Loss:  -0.025369584560394287\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 146973 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0005393242463469505\n",
      "Q Loss:  0.000231541387620382\n",
      "Policy Loss:  -0.006710662506520748\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146977 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  0.0001547981664771214\n",
      "Q Loss:  0.0004753685789182782\n",
      "Policy Loss:  -0.011467388831079006\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146981 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.00031965316156856716\n",
      "Q Loss:  0.0007631118642166257\n",
      "Policy Loss:  0.01940406672656536\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146985 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.03652198240160942\n",
      "Q Loss:  0.015418925322592258\n",
      "Policy Loss:  -0.01859160140156746\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146989 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01361083984375\n",
      "Value Loss:  0.05436774343252182\n",
      "Q Loss:  0.015375872142612934\n",
      "Policy Loss:  0.029467593878507614\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146993 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  1.978122782020364e-05\n",
      "Q Loss:  0.0006122903432697058\n",
      "Policy Loss:  -0.011112364940345287\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 146997 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004158020019531\n",
      "Value Loss:  0.0003822299186140299\n",
      "Q Loss:  0.001400971319526434\n",
      "Policy Loss:  -0.008076452650129795\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147001 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.03366951271891594\n",
      "Q Loss:  0.0001035288514685817\n",
      "Policy Loss:  0.026593655347824097\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147005 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018006086349487305\n",
      "Value Loss:  0.031826552003622055\n",
      "Q Loss:  0.025560755282640457\n",
      "Policy Loss:  0.006278105080127716\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147009 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.036008596420288086\n",
      "Value Loss:  0.045108210295438766\n",
      "Q Loss:  0.014002220705151558\n",
      "Policy Loss:  0.027402671054005623\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147013 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.027006149291992188\n",
      "Value Loss:  0.8929350972175598\n",
      "Q Loss:  0.0055414834059774876\n",
      "Policy Loss:  0.11706417053937912\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147116 length: 103 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00012455793330445886\n",
      "Q Loss:  0.0004493808373808861\n",
      "Policy Loss:  0.0021572234109044075\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.009050906635820866\n",
      "Q Loss:  0.001774708623997867\n",
      "Policy Loss:  -0.023553140461444855\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.0007346537313424051\n",
      "Q Loss:  0.0032974134664982557\n",
      "Policy Loss:  -0.03163367509841919\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147128 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.02299107424914837\n",
      "Q Loss:  0.009261459112167358\n",
      "Policy Loss:  0.03142295032739639\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147132 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900506019592285\n",
      "Value Loss:  7.187397568486631e-05\n",
      "Q Loss:  0.005728576332330704\n",
      "Policy Loss:  0.037307389080524445\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147136 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  7.393761916318908e-05\n",
      "Q Loss:  0.004454965703189373\n",
      "Policy Loss:  0.028342533856630325\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147140 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003131866455078\n",
      "Value Loss:  0.009795363061130047\n",
      "Q Loss:  0.008052225224673748\n",
      "Policy Loss:  0.029456067830324173\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147144 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.033006906509399414\n",
      "Value Loss:  8105.71435546875\n",
      "Q Loss:  8128.9677734375\n",
      "Policy Loss:  -34.1263427734375\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147244 length: 100 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0005303058424033225\n",
      "Q Loss:  0.0021825814619660378\n",
      "Policy Loss:  0.023500461131334305\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147248 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  3.915273555321619e-05\n",
      "Q Loss:  0.002348122885450721\n",
      "Policy Loss:  -0.0033259745687246323\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147252 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  6.352644504659111e-06\n",
      "Q Loss:  0.0018272573361173272\n",
      "Policy Loss:  -0.001724599627777934\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147256 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.0066259028390049934\n",
      "Q Loss:  0.006322307512164116\n",
      "Policy Loss:  0.03419875726103783\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147260 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.008786219172179699\n",
      "Q Loss:  0.006077905185520649\n",
      "Policy Loss:  -0.01062687300145626\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147264 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.01657196506857872\n",
      "Q Loss:  0.006345431320369244\n",
      "Policy Loss:  -0.06819046288728714\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147268 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  0.023282434791326523\n",
      "Q Loss:  0.011140942573547363\n",
      "Policy Loss:  -0.05642189085483551\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147272 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011001825332641602\n",
      "Value Loss:  0.007578824181109667\n",
      "Q Loss:  0.0004857056774199009\n",
      "Policy Loss:  -0.01065126620233059\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147276 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06201457977294922\n",
      "Value Loss:  0.00023461846285499632\n",
      "Q Loss:  0.0026855110190808773\n",
      "Policy Loss:  -0.014008009806275368\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147280 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.00023089881869964302\n",
      "Q Loss:  0.0006678607896901667\n",
      "Policy Loss:  0.012605185620486736\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147284 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016003847122192383\n",
      "Value Loss:  0.5959721207618713\n",
      "Q Loss:  6.870075702667236\n",
      "Policy Loss:  0.2843071520328522\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147443 length: 159 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.0005477748345583677\n",
      "Q Loss:  0.004725318402051926\n",
      "Policy Loss:  -0.04633843153715134\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147447 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.003765612607821822\n",
      "Q Loss:  0.001867133192718029\n",
      "Policy Loss:  0.0232562143355608\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147451 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600193977355957\n",
      "Value Loss:  0.0028152335435152054\n",
      "Q Loss:  0.005266326479613781\n",
      "Policy Loss:  0.008368341252207756\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147455 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.0032483255490660667\n",
      "Q Loss:  0.000998399336822331\n",
      "Policy Loss:  0.0041884370148181915\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147459 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03100728988647461\n",
      "Value Loss:  0.0006643715896643698\n",
      "Q Loss:  0.001607329468242824\n",
      "Policy Loss:  0.005704071372747421\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147463 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00022078875917941332\n",
      "Q Loss:  0.000340846658218652\n",
      "Policy Loss:  0.0032123513519763947\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147467 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  0.00019139294454362243\n",
      "Q Loss:  0.00045590399531647563\n",
      "Policy Loss:  0.013635258190333843\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147471 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  0.015148021280765533\n",
      "Q Loss:  0.0004497174813877791\n",
      "Policy Loss:  0.014276049099862576\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147475 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002302169799805\n",
      "Value Loss:  127.50947570800781\n",
      "Q Loss:  226.02598571777344\n",
      "Policy Loss:  -10.888846397399902\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147579 length: 104 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00033648990211077034\n",
      "Q Loss:  0.001167076057754457\n",
      "Policy Loss:  -0.007615955546498299\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147583 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.0003121651243418455\n",
      "Q Loss:  0.0011293357238173485\n",
      "Policy Loss:  -0.0033025378361344337\n",
      "No valid pairs found\n",
      "[(0.0, 0)]\n",
      "No updates performed, episode: 147587 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  7.223691682156641e-06\n",
      "Q Loss:  545.9005126953125\n",
      "Policy Loss:  16.129741668701172\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147591 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.3451233826344833e-05\n",
      "Q Loss:  270.76983642578125\n",
      "Policy Loss:  8.018027305603027\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  6.718571239616722e-05\n",
      "Q Loss:  0.0011971225030720234\n",
      "Policy Loss:  0.010531635023653507\n",
      "[(0.0, 0), (0.0, 0.0)]\n",
      "No updates performed, episode: 147599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  0.012674359604716301\n",
      "Q Loss:  0.018859652802348137\n",
      "Policy Loss:  -0.04954640194773674\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004562377929688\n",
      "Value Loss:  3.1817016861168668e-06\n",
      "Q Loss:  0.0037650628946721554\n",
      "Policy Loss:  -0.01009563822299242\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200045108795166\n",
      "Value Loss:  0.009882218204438686\n",
      "Q Loss:  0.0031625903211534023\n",
      "Policy Loss:  -0.008447326719760895\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.004878334701061249\n",
      "Q Loss:  0.004446924664080143\n",
      "Policy Loss:  0.0075883157551288605\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0094568757340312\n",
      "Q Loss:  0.0035521765239536762\n",
      "Policy Loss:  -0.014101417735219002\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.8605197668075562\n",
      "Q Loss:  40.029136657714844\n",
      "Policy Loss:  1.4752236604690552\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147670 length: 51 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.0005665080971084535\n",
      "Q Loss:  0.005164430942386389\n",
      "Policy Loss:  0.020846448838710785\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147674 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003536224365234\n",
      "Value Loss:  0.000589476665481925\n",
      "Q Loss:  0.0006767605664208531\n",
      "Policy Loss:  -0.00565135246142745\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147678 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0200042724609375\n",
      "Value Loss:  0.0009072368266060948\n",
      "Q Loss:  0.0021832603961229324\n",
      "Policy Loss:  -0.006642327643930912\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147682 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0006054040277376771\n",
      "Q Loss:  0.001650365418754518\n",
      "Policy Loss:  -0.006830513942986727\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147686 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.0004719729768112302\n",
      "Q Loss:  0.0008506615995429456\n",
      "Policy Loss:  -0.01383151113986969\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147690 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700425148010254\n",
      "Value Loss:  3.182586078764871e-05\n",
      "Q Loss:  0.000611539522651583\n",
      "Policy Loss:  -0.015088221058249474\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147694 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0011843034299090505\n",
      "Q Loss:  0.0033738939091563225\n",
      "Policy Loss:  0.025401443243026733\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147698 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04100966453552246\n",
      "Value Loss:  0.00012388364120852202\n",
      "Q Loss:  1.6819589291117154e-05\n",
      "Policy Loss:  0.0027075447142124176\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147702 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  0.006551516707986593\n",
      "Q Loss:  0.004125726874917746\n",
      "Policy Loss:  -0.0080283647403121\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147706 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014004230499267578\n",
      "Value Loss:  1.0980170965194702\n",
      "Q Loss:  0.006000750232487917\n",
      "Policy Loss:  0.12207338958978653\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147792 length: 86 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.0004776724672410637\n",
      "Q Loss:  0.0010041252244263887\n",
      "Policy Loss:  -0.004137841984629631\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147796 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  9.539640450384468e-05\n",
      "Q Loss:  0.0014043773990124464\n",
      "Policy Loss:  -0.004448210820555687\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147800 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.001812007394619286\n",
      "Q Loss:  0.00020586415485013276\n",
      "Policy Loss:  0.01640932820737362\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147804 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0016819473821669817\n",
      "Q Loss:  0.002703922800719738\n",
      "Policy Loss:  -0.001814443152397871\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147808 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.024021126329898834\n",
      "Q Loss:  0.007496979087591171\n",
      "Policy Loss:  -0.032595518976449966\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147812 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.046980857849121094\n",
      "Value Loss:  0.008060025982558727\n",
      "Q Loss:  0.0026246358174830675\n",
      "Policy Loss:  -0.01519069168716669\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147816 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.0014355314197018743\n",
      "Q Loss:  0.0013060190249234438\n",
      "Policy Loss:  0.010350003838539124\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147820 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.021004915237426758\n",
      "Value Loss:  0.00120156432967633\n",
      "Q Loss:  0.0004675672680605203\n",
      "Policy Loss:  -0.009678631089627743\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147824 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  7.253264016071626e-07\n",
      "Q Loss:  0.0017957626841962337\n",
      "Policy Loss:  -0.017297223210334778\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147828 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011003255844116211\n",
      "Value Loss:  0.008024000562727451\n",
      "Q Loss:  0.0010748372878879309\n",
      "Policy Loss:  -0.004082841333001852\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147832 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.015231775119900703\n",
      "Q Loss:  0.008419446647167206\n",
      "Policy Loss:  0.01363096758723259\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147836 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  0.0073715257458388805\n",
      "Q Loss:  0.011191986501216888\n",
      "Policy Loss:  0.015384059399366379\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147840 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003753662109375\n",
      "Value Loss:  0.02126489207148552\n",
      "Q Loss:  0.004184306599199772\n",
      "Policy Loss:  0.002210378646850586\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147844 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.01332074124366045\n",
      "Q Loss:  0.004300125874578953\n",
      "Policy Loss:  -0.008950889110565186\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147848 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0061705103144049644\n",
      "Q Loss:  0.0033000840339809656\n",
      "Policy Loss:  0.016226623207330704\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147852 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  2.9020178772043437e-05\n",
      "Q Loss:  0.0029831225983798504\n",
      "Policy Loss:  0.05649601295590401\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147856 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  14493.359375\n",
      "Q Loss:  14388.34765625\n",
      "Policy Loss:  -40.20364761352539\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147911 length: 55 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015002965927124023\n",
      "Value Loss:  0.0004705778555944562\n",
      "Q Loss:  0.000223242022912018\n",
      "Policy Loss:  0.00798956211656332\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147915 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800251007080078\n",
      "Value Loss:  0.00017912012117449194\n",
      "Q Loss:  0.0002420194068690762\n",
      "Policy Loss:  0.005774362478405237\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147919 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  0.007769051939249039\n",
      "Q Loss:  0.006697189994156361\n",
      "Policy Loss:  -0.028659310191869736\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 147923 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  820.4708251953125\n",
      "Q Loss:  1359.7401123046875\n",
      "Policy Loss:  -67.87506103515625\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148068 length: 145 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.8751818060991354e-05\n",
      "Q Loss:  0.0002906042500399053\n",
      "Policy Loss:  0.004171906039118767\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148072 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.00017233834660146385\n",
      "Q Loss:  0.0004085878608748317\n",
      "Policy Loss:  0.009517548605799675\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003660202026367\n",
      "Value Loss:  6.378636317094788e-05\n",
      "Q Loss:  1.8615917724673636e-05\n",
      "Policy Loss:  -0.004498850554227829\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148080 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  3304.11962890625\n",
      "Q Loss:  5655.33447265625\n",
      "Policy Loss:  -187.25607299804688\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148084 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  1.1144841664645355e-05\n",
      "Q Loss:  0.0006182939978316426\n",
      "Policy Loss:  -0.00959826074540615\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148088 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.3242482964415103e-05\n",
      "Q Loss:  243.23068237304688\n",
      "Policy Loss:  7.637265205383301\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148092 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  8.978565165307373e-05\n",
      "Q Loss:  0.001208258792757988\n",
      "Policy Loss:  0.020162874832749367\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148096 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  0.00012890971265733242\n",
      "Q Loss:  0.0006664539105258882\n",
      "Policy Loss:  -0.001547238789498806\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148100 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003297805786133\n",
      "Value Loss:  0.00028490819386206567\n",
      "Q Loss:  0.00016431670519523323\n",
      "Policy Loss:  0.003730443771928549\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148104 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  8.579531277064234e-05\n",
      "Q Loss:  0.0002885709691327065\n",
      "Policy Loss:  0.00684310169890523\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148108 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800394058227539\n",
      "Value Loss:  3.947129880543798e-05\n",
      "Q Loss:  0.00025048438692465425\n",
      "Policy Loss:  0.007119724061340094\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148112 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  0.018764328211545944\n",
      "Q Loss:  0.007336019538342953\n",
      "Policy Loss:  -0.04283959046006203\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148116 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  4.699689668541396e-07\n",
      "Q Loss:  6.934416887816042e-05\n",
      "Policy Loss:  0.028110913932323456\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148120 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.018052028492093086\n",
      "Q Loss:  0.005813125520944595\n",
      "Policy Loss:  -0.055909376591444016\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148124 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0490107536315918\n",
      "Value Loss:  136.86038208007812\n",
      "Q Loss:  242.53878784179688\n",
      "Policy Loss:  -11.793180465698242\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148219 length: 95 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014002561569213867\n",
      "Value Loss:  0.011524871923029423\n",
      "Q Loss:  0.002458322560414672\n",
      "Policy Loss:  -0.00555012933909893\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148223 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  16375.00390625\n",
      "Q Loss:  16188.955078125\n",
      "Policy Loss:  -22.893783569335938\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148271 length: 48 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01600170135498047\n",
      "Value Loss:  0.0004367775982245803\n",
      "Q Loss:  0.0004525865369942039\n",
      "Policy Loss:  0.006866341456770897\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148275 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04201006889343262\n",
      "Value Loss:  0.006322403438389301\n",
      "Q Loss:  0.006193405482918024\n",
      "Policy Loss:  -0.008685572072863579\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148279 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  0.013105329126119614\n",
      "Q Loss:  0.0027853301726281643\n",
      "Policy Loss:  0.02205650508403778\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148283 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  21821.6953125\n",
      "Q Loss:  21356.22265625\n",
      "Policy Loss:  -32.61646270751953\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148319 length: 36 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.03500843048095703\n",
      "Value Loss:  0.00029986404115334153\n",
      "Q Loss:  0.0007194326026365161\n",
      "Policy Loss:  -0.0023929437156766653\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148323 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  0.00015613021969329566\n",
      "Q Loss:  0.0005425020353868604\n",
      "Policy Loss:  0.010741766542196274\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148327 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004323959350586\n",
      "Value Loss:  0.0002492510247975588\n",
      "Q Loss:  0.003966964315623045\n",
      "Policy Loss:  0.02143339067697525\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148331 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.04500985145568848\n",
      "Value Loss:  0.00020933499035891145\n",
      "Q Loss:  0.0007491015130653977\n",
      "Policy Loss:  0.001026009675115347\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148335 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015004396438598633\n",
      "Value Loss:  0.009499112144112587\n",
      "Q Loss:  0.0030355304479599\n",
      "Policy Loss:  0.0059544844552874565\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148339 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.019162654876708984\n",
      "Value Loss:  0.019302552565932274\n",
      "Q Loss:  0.004255023319274187\n",
      "Policy Loss:  0.00019781291484832764\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148343 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  8.463751873932779e-05\n",
      "Q Loss:  0.0002286694070789963\n",
      "Policy Loss:  0.001667556818574667\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148347 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900339126586914\n",
      "Value Loss:  1.1207221177755855e-05\n",
      "Q Loss:  0.0022139516659080982\n",
      "Policy Loss:  0.01712927222251892\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148351 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  7.246740096888971e-06\n",
      "Q Loss:  0.0021085760090500116\n",
      "Policy Loss:  0.016833320260047913\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148355 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  2.853038313332945e-05\n",
      "Q Loss:  0.00017921836115419865\n",
      "Policy Loss:  0.00581485778093338\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148359 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.010105287656188011\n",
      "Q Loss:  0.009602508507668972\n",
      "Policy Loss:  -0.014100106433033943\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148363 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  0.020158937200903893\n",
      "Q Loss:  0.004080141428858042\n",
      "Policy Loss:  -0.005050353705883026\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148367 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  13492.513671875\n",
      "Q Loss:  13362.69140625\n",
      "Policy Loss:  -39.903316497802734\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148426 length: 59 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.011002063751220703\n",
      "Value Loss:  4.547451226244448e-06\n",
      "Q Loss:  0.00022065996017772704\n",
      "Policy Loss:  0.00802883505821228\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148430 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002157211303711\n",
      "Value Loss:  4.695251845987514e-05\n",
      "Q Loss:  0.00015005862223915756\n",
      "Policy Loss:  -0.008749744854867458\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148434 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.0002820339286699891\n",
      "Q Loss:  0.0006831150385551155\n",
      "Policy Loss:  0.006357329897582531\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148438 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.00034606026019901037\n",
      "Q Loss:  0.0002455396461300552\n",
      "Policy Loss:  0.010317444801330566\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148442 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.00026310322573408484\n",
      "Q Loss:  0.00034510187106207013\n",
      "Policy Loss:  -0.008012549951672554\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148446 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  5.693312414223328e-05\n",
      "Q Loss:  7.411240949295461e-05\n",
      "Policy Loss:  0.0022546774707734585\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148450 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  1.3964075151307043e-05\n",
      "Q Loss:  0.0002737086615525186\n",
      "Policy Loss:  0.009684602729976177\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148454 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003349304199219\n",
      "Value Loss:  1.1451214049884584e-05\n",
      "Q Loss:  0.00016583055548835546\n",
      "Policy Loss:  0.005496790632605553\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148458 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  1.3828179362462834e-05\n",
      "Q Loss:  4.184120916761458e-05\n",
      "Policy Loss:  0.0002069125766865909\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148462 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017004013061523438\n",
      "Value Loss:  6.643398955930024e-05\n",
      "Q Loss:  0.000549815536942333\n",
      "Policy Loss:  -0.010498447343707085\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148466 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  1.8831748962402344\n",
      "Q Loss:  0.004254498053342104\n",
      "Policy Loss:  0.26127710938453674\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148515 length: 49 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.02100396156311035\n",
      "Value Loss:  0.024355238303542137\n",
      "Q Loss:  0.005769885610789061\n",
      "Policy Loss:  -0.06043850630521774\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148519 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015002727508544922\n",
      "Value Loss:  8.691175025887787e-05\n",
      "Q Loss:  0.00014452970935963094\n",
      "Policy Loss:  -0.005558742210268974\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148523 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003681182861328\n",
      "Value Loss:  9.369663894176483e-05\n",
      "Q Loss:  9.843346197158098e-05\n",
      "Policy Loss:  -0.0037951869890093803\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148527 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.02672720141708851\n",
      "Q Loss:  0.013590764254331589\n",
      "Policy Loss:  -0.017890814691781998\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148531 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  7.236025703605264e-05\n",
      "Q Loss:  6.077386933611706e-05\n",
      "Policy Loss:  0.039313383400440216\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148535 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.05410567298531532\n",
      "Q Loss:  0.016268065199255943\n",
      "Policy Loss:  -0.09186238795518875\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148539 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900482177734375\n",
      "Value Loss:  0.03933015465736389\n",
      "Q Loss:  0.008005507290363312\n",
      "Policy Loss:  -0.046364396810531616\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148543 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  1.3022334314882755e-05\n",
      "Q Loss:  0.001500156824477017\n",
      "Policy Loss:  0.018805213272571564\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148547 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  184.78387451171875\n",
      "Q Loss:  313.28277587890625\n",
      "Policy Loss:  -15.959047317504883\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148621 length: 74 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  4.3517366066225804e-06\n",
      "Q Loss:  0.0023051202297210693\n",
      "Policy Loss:  0.02211669646203518\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148625 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  1.6661908375681378e-05\n",
      "Q Loss:  0.001151442527770996\n",
      "Policy Loss:  0.010010439902544022\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148629 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.802522638172377e-05\n",
      "Q Loss:  0.0018300018273293972\n",
      "Policy Loss:  0.018525300547480583\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148633 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.023005008697509766\n",
      "Value Loss:  1.8780488971970044e-05\n",
      "Q Loss:  0.00127057742793113\n",
      "Policy Loss:  0.011912595480680466\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148637 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  9.92359946394572e-06\n",
      "Q Loss:  0.00697046983987093\n",
      "Policy Loss:  0.01293887384235859\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148641 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01500248908996582\n",
      "Value Loss:  13932.12109375\n",
      "Q Loss:  13811.875\n",
      "Policy Loss:  -41.2273063659668\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148698 length: 57 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014002799987792969\n",
      "Value Loss:  3.5526303690858185e-05\n",
      "Q Loss:  0.00027749568107537925\n",
      "Policy Loss:  -0.0014822171069681644\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148702 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.03584710508584976\n",
      "Q Loss:  8.354286546818912e-05\n",
      "Policy Loss:  0.02333161048591137\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148706 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.047586940228939056\n",
      "Q Loss:  4.974295393367356e-07\n",
      "Policy Loss:  -0.012655030004680157\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148710 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.034259214997291565\n",
      "Q Loss:  0.009628950618207455\n",
      "Policy Loss:  -0.0117808748036623\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148714 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.05301237106323242\n",
      "Value Loss:  12997.3798828125\n",
      "Q Loss:  12847.2294921875\n",
      "Policy Loss:  -19.77071189880371\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148774 length: 60 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  1.7746227979660034\n",
      "Q Loss:  0.004670828115195036\n",
      "Policy Loss:  0.2613932490348816\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148826 length: 52 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  1.7596331645108876e-06\n",
      "Q Loss:  0.0005476928781718016\n",
      "Policy Loss:  -0.01243053562939167\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148830 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016002178192138672\n",
      "Value Loss:  9.8625432656263e-06\n",
      "Q Loss:  4.3389918573666364e-05\n",
      "Policy Loss:  0.033545710146427155\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148834 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01900458335876465\n",
      "Value Loss:  1.1107683181762695\n",
      "Q Loss:  11.91087532043457\n",
      "Policy Loss:  0.5261573195457458\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148917 length: 83 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.012477480806410313\n",
      "Q Loss:  0.0070586539804935455\n",
      "Policy Loss:  0.01924992725253105\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148921 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.533688737254124e-05\n",
      "Q Loss:  0.0012399633415043354\n",
      "Policy Loss:  -0.019730864092707634\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148925 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.024005413055419922\n",
      "Value Loss:  4.002921559731476e-05\n",
      "Q Loss:  0.00027917654369957745\n",
      "Policy Loss:  0.02860526368021965\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148929 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018002986907958984\n",
      "Value Loss:  1.716599941253662\n",
      "Q Loss:  0.001930886646732688\n",
      "Policy Loss:  0.24710603058338165\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148982 length: 53 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.015232068486511707\n",
      "Q Loss:  0.005241714883595705\n",
      "Policy Loss:  -0.02108936756849289\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148986 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  6.335718353511766e-05\n",
      "Q Loss:  3.3635092222539242e-06\n",
      "Policy Loss:  0.0009061747114174068\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148990 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  3.97073345084209e-05\n",
      "Q Loss:  1.8189017282566056e-05\n",
      "Policy Loss:  0.0028648581355810165\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148994 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.020004749298095703\n",
      "Value Loss:  1.6822606994537637e-05\n",
      "Q Loss:  4.9638154450803995e-05\n",
      "Policy Loss:  0.005043439567089081\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 148998 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003515243530273\n",
      "Value Loss:  1.0385176210547797e-05\n",
      "Q Loss:  0.0004640550760086626\n",
      "Policy Loss:  0.04233861714601517\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149002 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01812434196472168\n",
      "Value Loss:  1.9511386156082153\n",
      "Q Loss:  0.004183524288237095\n",
      "Policy Loss:  0.28112077713012695\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149048 length: 46 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0001564363483339548\n",
      "Q Loss:  0.00014300961629487574\n",
      "Policy Loss:  -0.005403515882790089\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149052 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.050011634826660156\n",
      "Value Loss:  0.0001113778052967973\n",
      "Q Loss:  6.290277815423906e-05\n",
      "Policy Loss:  0.0009846154134720564\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149056 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600337028503418\n",
      "Value Loss:  2.2410740712075494e-05\n",
      "Q Loss:  0.0002484472352080047\n",
      "Policy Loss:  0.011545035988092422\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149060 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002395629882812\n",
      "Value Loss:  0.024763500317931175\n",
      "Q Loss:  0.0034883650951087475\n",
      "Policy Loss:  0.005266167223453522\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149064 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.02566816657781601\n",
      "Q Loss:  0.019624903798103333\n",
      "Policy Loss:  -0.02633567340672016\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149068 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  4.957846613251604e-06\n",
      "Q Loss:  0.001101410249248147\n",
      "Policy Loss:  0.023122325539588928\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149072 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  2.551860234234482e-06\n",
      "Q Loss:  0.001557880430482328\n",
      "Policy Loss:  0.06056774780154228\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149076 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  1.099859595298767\n",
      "Q Loss:  0.006094483193010092\n",
      "Policy Loss:  0.1607697606086731\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149156 length: 80 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003421783447266\n",
      "Value Loss:  2.3302404770220164e-06\n",
      "Q Loss:  0.0004443292273208499\n",
      "Policy Loss:  0.008454004302620888\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149160 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  4.86275666844449e-07\n",
      "Q Loss:  0.00032983761047944427\n",
      "Policy Loss:  0.004792609717696905\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149164 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.030183538794517517\n",
      "Q Loss:  0.016527894884347916\n",
      "Policy Loss:  -0.0004502739757299423\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149168 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  13400.37890625\n",
      "Q Loss:  13242.427734375\n",
      "Policy Loss:  -21.04899787902832\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149226 length: 58 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.014003276824951172\n",
      "Value Loss:  0.0001280373689951375\n",
      "Q Loss:  0.0021596942096948624\n",
      "Policy Loss:  0.02187993749976158\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149230 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012001752853393555\n",
      "Value Loss:  0.00011256298603257164\n",
      "Q Loss:  0.0029797563329339027\n",
      "Policy Loss:  0.022531362250447273\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149234 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.00015674426686018705\n",
      "Q Loss:  0.00037911662366241217\n",
      "Policy Loss:  0.0053011951968073845\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149238 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01800370216369629\n",
      "Value Loss:  0.00022465262736659497\n",
      "Q Loss:  0.00010620304237818345\n",
      "Policy Loss:  0.004244920797646046\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149242 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.03200697898864746\n",
      "Value Loss:  0.5432339906692505\n",
      "Q Loss:  12.222343444824219\n",
      "Policy Loss:  0.4574025571346283\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149404 length: 162 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.014001607894897461\n",
      "Value Loss:  5428.16455078125\n",
      "Q Loss:  5382.234375\n",
      "Policy Loss:  -8.112696647644043\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149547 length: 143 #teleports:0\n",
      "Got not null reward 1015.0!\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  0.146650031208992\n",
      "Q Loss:  0.0507032684981823\n",
      "Policy Loss:  -0.15700191259384155\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149551 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01400303840637207\n",
      "Value Loss:  0.07260820269584656\n",
      "Q Loss:  0.012991044670343399\n",
      "Policy Loss:  -0.007805127650499344\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149555 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01600360870361328\n",
      "Value Loss:  0.07076172530651093\n",
      "Q Loss:  0.014280203729867935\n",
      "Policy Loss:  -0.004998371005058289\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149559 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  2.693988800048828\n",
      "Q Loss:  0.007818126119673252\n",
      "Policy Loss:  0.4208958148956299\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149591 length: 32 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  0.00028469841345213354\n",
      "Q Loss:  0.0011991942301392555\n",
      "Policy Loss:  -0.017278756946325302\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149595 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.011002779006958008\n",
      "Value Loss:  2.4380300601478666e-05\n",
      "Q Loss:  9.570439578965306e-05\n",
      "Policy Loss:  0.0040387967601418495\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149599 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.0005968532641418278\n",
      "Q Loss:  0.0009616343304514885\n",
      "Policy Loss:  -0.013621171936392784\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149603 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  0.0002847639552783221\n",
      "Q Loss:  371.22259521484375\n",
      "Policy Loss:  11.528165817260742\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149607 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.017003774642944336\n",
      "Value Loss:  0.00028479742468334734\n",
      "Q Loss:  0.0005900509422644973\n",
      "Policy Loss:  0.0015630137640982866\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149611 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01700305938720703\n",
      "Value Loss:  5.5998709285631776e-05\n",
      "Q Loss:  122.52733612060547\n",
      "Policy Loss:  3.830162763595581\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149615 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.06101346015930176\n",
      "Value Loss:  1.919513124448713e-06\n",
      "Q Loss:  0.00029184456798247993\n",
      "Policy Loss:  0.011079862713813782\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149619 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002872467041016\n",
      "Value Loss:  1.079195862985216e-05\n",
      "Q Loss:  0.0001177345693577081\n",
      "Policy Loss:  -0.0013821662869304419\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149623 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.018003463745117188\n",
      "Value Loss:  3.910412488039583e-06\n",
      "Q Loss:  0.00042965757893398404\n",
      "Policy Loss:  0.006409721449017525\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149627 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013002634048461914\n",
      "Value Loss:  0.5430814623832703\n",
      "Q Loss:  0.0072870715521276\n",
      "Policy Loss:  0.08138462156057358\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149794 length: 167 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.022005081176757812\n",
      "Value Loss:  4.7501922040282807e-07\n",
      "Q Loss:  8.069940668065101e-05\n",
      "Policy Loss:  -0.004839310422539711\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149798 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  0.03718794137239456\n",
      "Q Loss:  0.01835535652935505\n",
      "Policy Loss:  0.04107629135251045\n",
      "[(1e-05, 0), (1e-05, 0.0)]\n",
      "Alpha*: 1e-05 tau*: 0 Episode: 149802 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002706527709961\n",
      "Value Loss:  0.037065308541059494\n",
      "Q Loss:  0.01677233912050724\n",
      "Policy Loss:  0.03567446023225784\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149806 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013003110885620117\n",
      "Value Loss:  8.864906703820452e-06\n",
      "Q Loss:  7.505781104555354e-05\n",
      "Policy Loss:  -0.010546615347266197\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149810 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.013268232345581055\n",
      "Value Loss:  7.296143394341925e-06\n",
      "Q Loss:  0.032374847680330276\n",
      "Policy Loss:  -0.0028478563763201237\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149814 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.016004085540771484\n",
      "Value Loss:  0.07186788320541382\n",
      "Q Loss:  0.015145388431847095\n",
      "Policy Loss:  -0.060813821852207184\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149818 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.0780184268951416\n",
      "Value Loss:  0.03503493219614029\n",
      "Q Loss:  0.009848807007074356\n",
      "Policy Loss:  0.03000679239630699\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149822 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.047009944915771484\n",
      "Value Loss:  4.4537391659105197e-05\n",
      "Q Loss:  0.0001251048524864018\n",
      "Policy Loss:  -0.004102063365280628\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149826 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003204345703125\n",
      "Value Loss:  1.0029258728027344\n",
      "Q Loss:  5.318538188934326\n",
      "Policy Loss:  0.3129761815071106\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149914 length: 88 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.012003183364868164\n",
      "Value Loss:  0.0011895409552380443\n",
      "Q Loss:  233.10360717773438\n",
      "Policy Loss:  7.471399307250977\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149918 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01301431655883789\n",
      "Value Loss:  0.0022921673953533173\n",
      "Q Loss:  0.00200844113714993\n",
      "Policy Loss:  0.02423372119665146\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149922 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002229690551758\n",
      "Value Loss:  6.894091347930953e-05\n",
      "Q Loss:  0.000849141099024564\n",
      "Policy Loss:  -0.013959300704300404\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149926 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.012002944946289062\n",
      "Value Loss:  3.195273893652484e-05\n",
      "Q Loss:  0.00013525059330277145\n",
      "Policy Loss:  -0.0009670463623479009\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149930 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.015003442764282227\n",
      "Value Loss:  2.1601503249257803e-05\n",
      "Q Loss:  0.00019277140381745994\n",
      "Policy Loss:  0.05170159786939621\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149934 length: 4 #teleports:0\n",
      "Time for bound evaluation:  0.01200246810913086\n",
      "Value Loss:  1.4853569269180298\n",
      "Q Loss:  0.022585829719901085\n",
      "Policy Loss:  0.14965058863162994\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149994 length: 60 #teleports:0\n",
      "Got not null reward 20.0!\n",
      "Time for bound evaluation:  0.01300358772277832\n",
      "Value Loss:  157765.03125\n",
      "Q Loss:  156625.625\n",
      "Policy Loss:  -252.7532958984375\n",
      "[(2e-05, 0), (2e-05, 0.0)]\n",
      "Alpha*: 2e-05 tau*: 0 Episode: 149999 length: 5 #teleports:0\n",
      "Got not null reward 1000.0!\n",
      "Time for bound evaluation:  0.01256871223449707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmdp.update_tau(0.6)\n",
    "tmdp.reset()\n",
    "cur_res = curriculum_AC_NN(tmdp, policy_pi, ref_policy, v_net, q_net,\n",
    "                           pol_opt, v_opt, q_opt, rep_buffer, \n",
    "                           alpha=.02, alpha_u=.02, episodes=150000, \n",
    "                           batch_size=4, biased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.00530779e-01 4.99469221e-01]\n",
      " [4.99736011e-01 5.00263929e-01]\n",
      " [4.99917656e-01 5.00082374e-01]\n",
      " [5.00327826e-01 4.99672204e-01]\n",
      " [4.99965161e-01 5.00034869e-01]\n",
      " [5.00054777e-01 4.99945253e-01]\n",
      " [5.00023901e-01 4.99976128e-01]\n",
      " [5.00380933e-01 4.99619097e-01]\n",
      " [5.00301659e-01 4.99698311e-01]\n",
      " [2.94292195e-15 1.00000000e+00]]\n",
      "[[ 5.00407457e+00  9.32249129e-02]\n",
      " [ 3.23551804e-01  2.65449584e-02]\n",
      " [-1.31921172e-02 -5.46637177e-03]\n",
      " [-1.24096014e-02  1.68832242e-02]\n",
      " [-1.60815902e-02 -3.29277813e-02]\n",
      " [-8.41375068e-03 -1.54505968e-02]\n",
      " [-8.62501934e-03 -6.49638474e-02]\n",
      " [-2.97140665e-02  4.21619713e-02]\n",
      " [-1.96727104e-02  2.13088970e+01]\n",
      " [ 1.76629469e-01  1.30128952e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(ref_policy.get_probabilities())\n",
    "print(q_net.get_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "optimal performance:  301.78608999693387 curriculum performance:  49.340959379487096\n"
     ]
    }
   ],
   "source": [
    "res = bellman_optimal_q(tmdp.env.P_mat, tmdp.env.reward, tmdp.gamma)\n",
    "Q = res[\"Q\"]\n",
    "\n",
    "d = compute_d_from_tau(tmdp.env.mu, tmdp.env.P_mat, tmdp.xi, get_policy(Q), tmdp.gamma, 0.)\n",
    "d_curr = compute_d_from_tau(tmdp.env.mu, tmdp.P_mat_tau, tmdp.xi, get_policy(ref_policy.get_probabilities()), tmdp.gamma, 0.)\n",
    "\n",
    "print(get_policy(Q))\n",
    "print(get_policy(ref_policy.get_probabilities()))\n",
    "\n",
    "r_s_a = compute_r_s_a(tmdp.env.P_mat, tmdp.env.reward)\n",
    "\n",
    "j_opt = compute_j(r_s_a, get_policy(Q), d, tmdp.gamma)\n",
    "j_curr = compute_j(r_s_a, get_policy(ref_policy.get_probabilities()), d_curr, tmdp.gamma)\n",
    "print(\"optimal performance: \",j_opt, \"curriculum performance: \",j_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x222f74e2fd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reward_records = cur_res[\"reward_records\"]\n",
    "# Generate recent 50 interval average\n",
    "average_reward = []\n",
    "for idx in range(len(reward_records)):\n",
    "    avg_list = np.empty(shape=(1,), dtype=int)\n",
    "    if idx < 50:\n",
    "        avg_list = reward_records[:idx+1]\n",
    "    else:\n",
    "        avg_list = reward_records[idx-49:idx+1]\n",
    "    average_reward.append(np.average(avg_list))\n",
    "# Plot\n",
    "#plt.plot(reward_records)\n",
    "plt.plot(average_reward)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
